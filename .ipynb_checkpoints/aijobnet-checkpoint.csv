,titles,companies,locations,requirements,descriptions,salaries
0,Senior Group Data Engineering Manager,SNC-Lavalin,SNC-Lavalin Atkins Bengaluru Office,Senior-level / Expert,"Job Description
We’re AtkinsRéalis, a world-leading Design, Engineering and Project Management organization. Created by the integration of long-standing organizations dating back to 1911, we are a world-leading professional services and project management company dedicated to engineering a better future for our planet and its people. We create sustainable solutions that connect people, data and technology to transform the world's infrastructure and energy systems. We deploy global capabilities locally to our clients and deliver unique end-to-end services across the whole life cycle of an asset including consulting, advisory & environmental services, intelligent networks & cybersecurity, design & engineering, procurement, project & construction management, operations & maintenance, decommissioning and capital. The breadth and depth of our capabilities are delivered to clients in key strategic sectors such as Engineering Services, Nuclear, Operations & Maintenance and Capital.
News and information are available at www.atkinsrealis.com or follow us on LinkedIn.  
Our teams are proud to deliver on some of the most prestigious projects across the world. It's thanks to our talented people and their diverse thinking, expertise, and knowledge. Join us and you'll be part of our genuinely collaborative environment, where everyone is supported to make the most of their talents and expertise.
When it comes to work-life balance, AtkinsRéalis is a great place to be. So, let's discuss how our flexible and remote working policies can support your priorities. We're passionate about are work while valuing each other equally. So, ask us about some of our recent pledges for Women's Equality and being a 'Disability Confidence' and 'Inclusive Employer’.
Job Description
Role: Group Data Engineering Manager
EAI-AtkinsRéalis is a vibrant and continuously growing team. It is an important part of GTC-AtkinsRéalis and widely recognized for its high and quality project deliveries. This would be a vital role to take EAI one step forward in providing data solutions to our business and client. This role would simultaneously work on multiple projects and would provide planning, designing and delivery of data driven projects. Effective communication and a team player are important characteristics of this role.
Key Activities for This Role
Technical guide for a team of Lead Data Engineers.
Develop, configure, deploy, and optimize Microsoft Azure based Data solutions.
Collaborate with other team members to develop and enhance deliverables.
Continuously improve team processes to ensure information is of the highest quality, contributing to the overall effectiveness of the team.
Stay abreast of industry changes, especially in the areas of cloud data and analytics technologies.
Ability to simultaneously work and deliver on more than one project on Individual contributor role.
Ability to work on multiple areas like Data pipeline ETL, Data modelling & design, writing complex SQL queries etc.
Capable of planning and executing on both short-term and long-term goals on your own and with the team.
Partner with other Data Engineers, Data architects, domain experts, data analysts and other teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service.
Guide, mentor guide Data Engineers, Sr Data Engineers on Data Architecture, data models, implementation techniques and technologies.
Experience & Skills Required:
12+ years of experience designing, developing, Architecture and deploying data solutions using Power BI, Azure platform.
Experience on designing Data pipelines (ETL/ELT), Datawarehouse and Data marts.
Hands-on expert with real-time data processing and analytics, data ingestion (batched and streamed), and data storage solutions.
Hands on Azure Analysis Services & Power BI and good to have experience on other tools.
Hands on experience with Data Factory, Data Lake Storage, Databricks, Data Explorer, Machine Learning, and Azure Synapse Analytics is good to have.
Expert at creating data dissemination diagrams, data flow diagrams, data lifecycle diagrams, data migration diagrams, and data security diagrams etc.
Hands on experience with one of the data presentations tools like PowerBI, Tableau etc.
A proven expert in writing optimized SQL to deal with large data volumes.
Hands on coding in Python along its main data libraries like Pandas, NumPy, Beautiful soup etc.
Good to have ML exposer.
Good to have AWS experience.
Good to have GCP experience.
What We Can Offer You
Varied, interesting and meaningful work.
A hybrid working environment with flexibility and great opportunities.
Opportunities for training and, as the team grows, career progression or sideways moves.
An opportunity to work within a large global multi-disciplinary consultancy on a mission to change the ways we approach business as usual.
Why work for AtkinsRéalis?
We at AtkinsRéalis are committed to developing its people both personally and professionally. Our colleagues have the advantage of access to a high ranging training portfolio and development activities designed to help make the best of individual’s abilities and talents. We also actively support staff in achieving corporate membership of relevant institutions.
Meeting Your Needs
To help you get the most out of life in and outside of work, we offer employees ‘Total Reward’.
Making sure you're supported is important to us. So, if you identify as having a disability, tell us ahead of your interview, and we’ll discuss any adjustments you might need.
Additional Information
We are an equal opportunity, drug-free employer committed to promoting a diverse and inclusive community - a place where we can all be ourselves, thrive and develop. To help embed inclusion for all, from day one, we offer a range of family friendly, inclusive employment policies, flexible working arrangements and employee networks to support staff from different backgrounds. As an Equal Opportunities Employer, we value applications from all backgrounds, cultures and ability.
We care about your privacy and are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data.
Link: Equality, diversity & inclusion | Atkins India (atkinsrealis.com)
Worker Type
Employee
Job Type
Regular
At AtkinsRéalis, we seek to hire individuals with diverse characteristics, backgrounds and perspectives. We strongly believe that world-class talent makes no distinctions based on gender, ethnic or national origin, sexual identity and orientation, age, religion or disability, but enriches itself through these differences.  ",USD 121K - 186K *
1,IND (New) Lead Data Scientist - DM,Quantium,"Hyderabad, Telangana, India",Senior-level / Expert,"Location: Hyderabad,Telangana,India
Quantium
In everyday life, data forms the backbone of every decision we make, every lesson we learn and every direction we choose. Better data, better decisions, better outcomes. But it is so much more than just numbers and technology. It’s what we know, unearthing ideas to solve problems and grasping opportunities that could change the world. Quantium are a global leader in the application of big data analytics to help our clients solve their most important problems.
We started out as a data analytics firm, helping businesses make better decisions. Since then we have grown into a partner to businesses that have the ambition to lead their industries. We help our clients navigate the complex world of data, analytics and technology to deliver powerful insights with clear business applications. We solve commercial problems to improve client efficiency, customer experience and profit. Our most advanced analytics solutions deliver insights that underpin significant investment and strategic decision making for our clients.
We are experts in using the latest technology pioneered in Silicon Valley, pushing the products to the limit and developing new extensions to solve problems that nobody else has thought of.  We are using new data sources and solving client opportunities worth tens if not hundreds of millions of dollars. Our people are passionate about data. They are smart, innovative and motivated to identify and solve new and interesting client problems.  
Joining Quantium enables learning from the best people in Australia in big data analytics and machine learning, having access to the best data sources and the opportunity to solve the most interesting client problems.
 Role summary
The Analytics Lead, Foundational Analytics is pivotal in ensuring that core data assets support the growth of our business. The appointed Lead will be required to apply their experience in managing a range of analytical resources and functions to develop a centre of excellence for analytic capabilities, fostering a culture of innovation, collaboration and expertise. They will work collaboratively with key stakeholders across the business to understand and set appropriate analytical strategies that support business growth, and apply these strategies to their business planning, and in particular support business growth initiatives through allocation of appropriate resources, subject matter expertise and long range planning. They will act as experts in developing the way we manage our foundational data assets and drive innovative analytical solutions that create value. They will also work with Data Engineers and implementation teams on solution design and with business stakeholders on change management.
  Key responsibilities
 ·         Develop relationships with key internal and external stakeholders across Quantium to understand and support the strategic goals and key initiatives of the company
·         Develop and execute strategy and business plans for the ongoing development of our foundational data assets
·         Manage Lead and Senior Analysts in other verticals to achieve business plan goals on an ongoing basis across a variety of teams
·         Set and manage aligned KPIs across one analytics team focussed on a single data partner
·         Develop a culture of innovation and analytic excellence by focussing on development of existing team members and hiring the best talent available
·         Drive accountability within the teams to achieve deadlines and the best possible analytic outcomes
·         Support growth of the business through implementation of capabilities that streamline the ingestion and preparation of new data assets
·         Support development of technology solutions that focus on automation of solutions, operational excellence and innovation by working with implementation and technology teams on solution design
 Key activities
·         Set and manage business plans for three or more foundational data assets including data curation, customer segmentation and other foundational analytics
·         Engage with business and external stakeholders to gather feedback and requirements to drive the foundational analytics roadmap for key business initiatives
·         Set up regular forums to engage stakeholders across the business that use these foundational data assets to receive and give feedback on current and future initiatives and ensure they are supported appropriately
·         Manage the high-level prioritisation process across teams including the use of WIPs, charter cards and business plans which are reviewed by the team on a regular basis, and manage stakeholders’ expectations regarding timeframes
·         Develop and implement resource plans to support business plans and roadmaps
·         Responsible for team recruitment, for both external and internal candidates
·         Ensure tailored performance plans and KPIs are set, monitored and managed on a regular basis for all team members
·         Provide coaching and support to direct reports to develop their management and analytical capabilities
·         Monitor and approve technical designs that implement analytical outcomes and models
·         Drive a culture of innovation by engaging with analysts across the team through a variety of forums including one to ones, skip level meetings, lunch time sessions and analytical showcases
·         Foster a cohesive team spirit through team meetings, awards and strong communication
·         Taking a structured and analytical approach in troubleshooting data issues and problems
·         Performance manager for junior team members and enabling the team to succeed by resolving issues and building on strengths
 Experience and education required
 ·         Strong background and understanding of data structures, data manipulation and transformation
·         Previous experience in the fields of data science or high-level data analysis; data modelling experience highly regarded
·         Previous experience working directly with Big Data Engineers highly regarded
·         Previous experience with project management and people management
·         Proven ability and experience in optimising performance of an existing process with a can-do attitude
·         Desire to work with a team of feedback-driven analysts and developers in a cross-functional and agile environment
·         Lead level data science/data analytics and management of one or more team of analysts
·         Variety of analytical roles preferred, including consulting
 Skills Required
·         Sound knowledge of technical analytics discipline, including data preparation, feature engineering and foundational analytics concepts, preferably including model development and model training
·         Sufficient skills in several disciplines or techniques to autonomously apply without the need for material guidance or revision by others; and
·         Sufficient skills in at least one discipline or technique to be an authoritative source of guidance and support for the team, and to be able to solve problems of a high technical complexity in this domain
·         Strong problem-solving skills, including ability to apply a systematic problem-solving approach
·         Solid interpersonal skills, as the role will need to work in a cross-functional team with both other analysts and specialists from non-analytics disciplines
·         Very strong client and stakeholder management skills
·         Ability to autonomously carry out work following analytics best practice as defined at Quantium for the relevant types of tools or techniques, suggesting improvements where appropriate
·         Ability to motivate peers to follow analytics best practice as defined at Quantium, by positively presenting the benefits and importance of these ways of working
·         Commercial acumen to understand business needs and the commercial impacts of different analytics solutions or approaches
·         Attention to detail
·         Drive for continuous improvement
 What does success look like?
 After three months, the successful candidate will be expected to:
·         Have built strong foundational relationships with team members, peers and stakeholders
·         Have reviewed existing business plans with stakeholders across the business to ensure alignment
·         Have reviewed existing resource plans to ensure an appropriate plan is in place to support execution
·         Have spent one on one time with each team member across the wider team to ensure an understanding of their capabilities and intentions within Quantium
·         Set an operating rhythm with direct reports that allows for an ongoing monitoring and management of tasks within the business plan
·         Have reviewed KPIs across the wider team to ensure alignment
·         Have set in place any additional recruitment required to support the business plan
 After twelve months, the successful candidate will be expected to:
·         Have executed successfully on their business plans across teams
·         Have set the next year’s business plan including resourcing strategy
·         Have demonstrated ongoing stakeholder management through a range of appropriate forums
·         Demonstrably increased the analytic capabilities and experience of the teams
·         Have introduced automation to reduce manual workloads where appropriate
·         Have streamlined and automated the process to bring on board additional data assets as required and apply ongoing management techniques with minimal time and effort
  Apply to this job",USD 136K - 205K *
2,Cloud Data Engineer,Verisk,"Gurugram, India",Mid-level / Intermediate,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
Key Responsibilities
Responsible for working with our Enterprise customers and migrate data into Cloud.
Set up ETL process to move data into Cloud and refresh daily.
Help the team in optimizing queries and evaluating different architectures.
Working with internal teams and helping them make the most of our data lake.
Assists in the analysis, design and development of a roadmap, design pattern, and implementation based upon a current vs. future state in a cohesive architecture viewpoint.
Gathers and analyzes data and develops architectural requirements at project level.
Participates in the Data Governance Council.
Researches and evaluates emerging data technology, industry, and market trends to assist in project development and/or operational support activities.
Contribute to the distributed database schema design geared for scalability and performance using MPP database engines (Redshift).
Support, development, and data operation workloads.
Strong understanding in Data Warehousing, Enterprise Architectures, Dimensional Modelling, ETL Architect, ETL (Extract/Transform/Load), Data Analysis, Data Conversion/Transformation, Database Design, Data Warehouse Optimization, Data Mart Development, and Enterprise Data Warehouse Maintenance and Support etc.
Should have independently worked on proposing architecture, design, and data ingestion concepts.
Qualifications
A minimum of 2-3 years of experience in Data Integration, Data Modeling and ETL/ELT.
2+ years of proven experience in Python in developing and supporting Python-based applications.
2+ years of experience in Big Data Technologies (Spark is a must).
Proficiency in AWS with a focus on services like EC2, S3, SQS, SNS, Lambda, Glue, Redshift and IAM.
Experience in deploying and managing applications on AWS.
Experience in writing API functions for Amazon Lambda to manage some of the AWS services.
Experience in writing advanced SQL scripts involving self joins, windows function, correlated subqueries, CTE’s etc.
Strong understanding of core AWS services, uses, and AWS architecture best practices.
Proficiency in developing, deploying, and debugging cloud-based applications using AWS.
Solid Understanding of Data structures, Algorithm and Analytical problems.
Demonstrated ability to work independently with minimal supervision.
Good communication skill in verbal and written.
Education-
UG:B.Tech/B.E. - Any Specialization, Computers
PG:MS/M.Sc(Science) - Any Specialization, M.Tech - Any Specialization, Computers, Other Engineering, MCA - Computers
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 30K - 56K *
3,Analytics Engineer - Data Engineer,Deliveroo,"Hyderabad, India (Main Office)",Mid-level / Intermediate,"Why Deliveroo?
We're building the definitive online food company, transforming the way the world eats by making hyper-local food more convenient and accessible. We obsess about building the future of food, whilst using our network as a force for good. We're at the forefront of a industry, powered by our market-leading technology and unrivalled network to bring incredible convenience and selection to our customers.
Working at Deliveroo is the perfect environment to build a definitive career, motivated by impact. Firstly, the impact that working here will have on your development, allowing you to grow faster than you might elsewhere; secondly, the impact that you can have on Deliveroo, leaving your mark as we scale; and finally, being part of something bigger, through the impact that we make together in our marketplace and communities.
The Role
Working as part of our analytics engineering team and reporting to one of our Analytics Engineering Managers, your role will be to provide clean, tested, well-documented and well-modelled data sets, that will enable and empower data scientists and business users alike, via tools like Snowflake and/or Looker.
You'll work with product engineering teams to ensure modelling of source data meets downstream requirements.
You will maintain and develop SQL data transformation scripts, and advise and review data scientists on data modelling to achieve denormalised and aggregated output datasets.
You'll work with data scientists and other analytics engineers to surface clean, intuitive datasets in our BI tool, Looker.
You will be responsible for optimisation and further adoption of Looker as a data product in the business, catering to ~1500 current active users who need to discover and interact with data.
Skillset
Required
5+ years experience within the field of Analytics Engineering, Data Engineering, or BI Engineering
Excellent SQL skills
Understanding of data warehousing, data modelling concepts and structuring new data tables
Knowledge of cloud-based MPP data warehousing (e.g. Snowflake, BigQuery, Redshift)
Nice to have
3+ years experience developing in a BI tool (Looker or similar)
Good practical understanding of version control
SQL ETL/ELT knowledge, experience with DAGs to manage script dependencies
Python coding skills, particularly in automation & integrations
Knowledge of the Looker API
Workplace & Diversity
At Deliveroo we know that people are the heart of the business and we prioritise their welfare. We offer multiple great benefits in areas including health, family, finance, community, convenience, growth and relocation.
We believe a great workplace is one that represents the world we live in and how beautifully diverse it can be. That means we have no judgement when it comes to any one of the things that make you who you are - your gender, race, sexuality, religion or a secret aversion to coriander. All you need is a passion for (most) food and a desire to be part of one of the fastest growing start-ups around.
#LI-Hybrid",USD 91K - 172K *
4,Data Architect,Quantiphi,IN KA Bengaluru,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Role & Responsibilities:
Work in tandem with the sales team to engage potential clients, comprehensively understanding their database infrastructure, challenges, and migration requirements.
Provide in-depth technical expertise and guidance throughout the pre-sales process, including solution presentations, proof-of-concepts, and proposal development, training sessions.
Deliver compelling presentations and workshops to showcase proposed database migration solutions, addressing technical queries and concerns effectively to the customer.
Develop robust and tailored database migration strategies, considering factors such as database types, volumes, structures, and client-specific needs.
Analyze client database landscapes to identify migration challenges, risks, and opportunities, translating these into technical specifications and migration plans.
Collaborate closely with internal teams including sales, product development, engineering, and data management to ensure alignment of proposed migration solutions with technical capabilities and product roadmaps.
Prepare comprehensive technical documentation, migration plans, and proposals, articulating migration strategies, methodologies, and expected outcomes clearly.
Stay abreast of the latest trends, tools, and best practices in database migration, ensuring the proposed solutions incorporate cutting-edge methodologies and technologies.
Gather feedback from sales teams and clients to refine migration solution offerings, contributing to the enhancement of best practices and service quality.
Qualification & Skills Required:
Bachelor’s or Master’s degree in Computer Science, Information Technology, or related field.
Extensive experience in a role involving database migrations, solution architecture, or consulting within the data management domain.
Profound knowledge of various database systems, migration tools, methodologies, and best practices in migrating data across different platforms (e.g., SQL Server, Oracle, MySQL, PostgreSQL, etc.).
Strong communication, presentation, and interpersonal skills to effectively convey technical concepts and migration strategies to diverse audiences.
Experience in leading and delivering cloud migration projects, creating project plans, guiding engineers and developing onboarding plans
 Cloud Data Services Proficiency:
Cloud Platforms: Expertise in cloud platforms such as AWS, Azure, Google Cloud, or others, with a deep understanding of their respective data services (AWS RDS, Azure SQL Database, Google Cloud SQL, etc.).
Data Storage: Comprehensive knowledge of various cloud-based storage options (object storage, block storage) and their optimal usage for different types of data.
Big Data Services: Familiarity with cloud-based big data services like AWS EMR, Azure HDInsight, Google Cloud Dataproc, etc., and their integration into migration strategies.
Data Warehousing: Proficiency in cloud-based data warehousing solutions (AWS Redshift, Azure Synapse Analytics, Google BigQuery) and their capabilities for handling large-scale data.
Performance Optimization: Proficiency in optimizing data migration performance on cloud platforms by leveraging features like parallel processing, data compression, and tuning.
Security and Compliance: Knowledge of security best practices and compliance standards related to data migration, ensuring data integrity and confidentiality during migration.
Monitoring and Troubleshooting: Capability to implement monitoring mechanisms and troubleshoot issues during migration, minimizing risks and ensuring a smooth transition.
Cost Optimization: Familiarity with cost-effective strategies for data migration on cloud platforms, optimizing resource utilization and minimizing expenses.
Post-Migration Validation: Ability to conduct thorough validation and testing post-migration to ensure data accuracy, integrity, and compatibility with target systems.
Cross-Platform Migration Experience:
Proven experience in migrating data between different database management systems (SQL Server, Oracle, MySQL, PostgreSQL, etc.) on different platforms [Cloud/ On Premise]

Continual Learning and Adaptability:
A strong inclination toward continual learning and adaptation to evolving cloud technologies, tools, and migration methodologies.

Certifications:
Certifications in cloud platforms (e.g., AWS Certified Database - Specialty, Azure Database Administrator Associate, Google Cloud Professional Data Engineer) that demonstrate proficiency in cloud data services and migration techniques.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 115K - 193K *
5,Data Engineer Level II,MRI Software,"Bengaluru, India Office",Senior-level / Expert,"We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you will create algorithms and conduct statistical analysis. Overall, you’ll strive for efficiency by aligning data systems with business goals. 
To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods.
If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Working as part of the London based Professional Services team to provide integration, application development, report writing and data analysis with a particular focus on MRI’s Enterprise solution. The role is also responsible for providing analytical consulting services for existing and new clients throughout EMEA.
This is an exciting position; the successful candidate must be capable of interpreting client requests to facilitate technology-based solutions to business problems. Key areas of responsibility are;
Responsibilities
Analyze and organize raw data 
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results 
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects
Requirements and skills
Previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages  (e.g. Java and Python)
Azure Synapse Analytics
Azure Data Factory
Data lake
SQL Expertise
If we need one of them to work on reporting, then Power BI 
Hands-on experience with SQL database design
Great numerical and analytical skills
Degree in Computer Science, IT, or similar field; a Master’s is a plus
Data engineering certification (e.g IBM Certified Data Engineer) is a plus",USD 110K - 180K *
6,Senior Software Engineer (Data Engineering),"Demandbase, Inc.",India - Remote,Senior-level / Expert,"Introduction to Demandbase: 
Demandbase is the Smarter GTM™ company for B2B brands. We help B2B companies hit their revenue goals using fewer resources. How? By aligning their sales and marketing teams around a combination of their data, our data, and artificial intelligence — what we call Account Intelligence — so they can identify, engage, and focus their time and money on the accounts most likely to buy. 
As a company, we’re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the San Francisco Bay Area, Seattle, and India, as well as a team in the UK, and allow employees to work remotely. We have also been continuously recognized as one of the best places to work in the San Francisco Bay Area including, “Best Workplaces for Millennials” and “Best Workplaces for Parents”!
We're committed to attracting, developing, retaining, and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, we're increasingly capable of living out our mission to transform how B2B goes to market. We encourage people from historically underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!
About the Role:
Demandbase is seeking creative, highly motivated, enthusiastic engineer individuals to be part of our product development team. You will work in a fast paced agile environment to build and deliver key features of the application. This is a great opportunity to work with a talented, high energy and creative team focused on building a world-class product. Our technology stack is primarily in Java/Javascript and while experience with these languages is great, it's not a necessity. Demandbase engineering focuses on fundamentals, not the tools/languages that you already know.
We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let’s move the world forward, together. We're looking for people who are excellent at fundamentals, have willingness to learn, and have an unstoppable desire to follow through with the job. 
What you'll be doing:
Design, Model and Implement data analysis and analytics solutions.
Be a hands on individual contributor for data projects in high-level design, analysis, experiments, data architecture and data modeling.
Support ETL pipeline modules – by designing state of art transformations, data cleaning, matching , reports/dashboards  and statistical analysis
Hands on with analysis techniques – segmentation, regressions, clustering, data profiling to analyze trends and report key performance indicators.
Team player to build large scale, high availability, fault tolerant data analytics platform - Apache Spark ecosystem, Data Visualization and Advanced Analytics.
Work closely with cross functional teams in an Agile environment
What we're looking for:
You are a strong analytical and problem solving skills
You are self-motivated learner
You are eager to learn new technologies
You are receptive to constructive feedback
You are Confident and articulate with excellent written and verbal communication skills
You are open to work in small development environment
Skills & Education:
Bachelor’s or master’s degree in computer science, Mathematics, Statistics from a top engineering institution.
Practical experience in handling complex analytics projects and experience in advanced SQL for data analysis.
4+ years of Data Engineering experience in building enterprise data/analytics solutions.
Data stewardship to continually improve the quality of data and information including accuracy, integrity , relevance to the business.
Strong practical experience in Databases, Advanced SQL & Python/R.
Very good understanding of Data strategies, articulate data analysis & data model design and evolve data products according to business requirements.
Benchmark data systems, Analyze workflow bottlenecks and propose robust data solutions to eliminate them.
Good to have experience in designing/implementing  ETL data pipelines using open source platforms.
Good to have exposure to big data emerging technologies like Hive, Red Shift (DWH), Hbase, Apache Spark and integration with enterprise visualization framework.
Our Commitment to Diversity, Equity, and Inclusion at Demandbase
At Demandbase, we believe in creating a workplace culture that values and celebrates diversity in all its forms. We recognize that everyone brings unique experiences, perspectives, and identities to the table, and we are committed to building a community where everyone feels valued, respected, and supported. Discrimination of any kind is not tolerated, and we strive to ensure that every individual has an equal opportunity to succeed and grow, regardless of their gender identity, sexual orientation, disability, race, ethnicity, background, marital status, genetic information, education level, veteran status, national origin, or any other protected status. We do not automatically disqualify applicants with criminal records and will consider each applicant on a case-by-case basis.
We recognize that not all candidates will have every skill or qualification listed in this job description. If you feel you have the level of experience to be successful in the role, we encourage you to apply!
We acknowledge that true diversity and inclusion require ongoing effort, and we are committed to doing the work required to make our workplace a safe and equitable space for all. Join us in building a community where we can learn from each other, celebrate our differences, and work together.
Personal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.",USD 121K - 186K *
7,IND (New) Data Scientist - DM,Quantium,"Hyderabad, Telangana, India",Mid-level / Intermediate,"Location: Hyderabad,Telangana,India
Role summary
The Analyst, Foundation Analytics role is a technical individual contributor role within a cross-functional team accountable for the delivery of a data asset roadmap. Working together with the Analytics Lead, Delivery Managers and other technical specialists from analytics and software engineering disciplines, the Analyst will support Analysts and Senior Analysts in the design and specification of analytics that forms part of the core solution offered by Quantium foundation data assets products.
 Key responsibilities
·         In collaboration with a wider team of analysts, deliver advanced analytics solutions for one of Quantium’s data assets
·         Aptitude for learning and acquisition of key analytical, technical and commercial skills and Quantium business knowledge
·         Display interest in your career progression and acquisition of industry knowledge
 Key activities
·         Data extraction and manipulation
·         Delivery of tasks to support a data asset roadmap and BAU data operation tasks, working in a cross-functional team managed by an Analytics Lead or Delivery Manager
·         Writing the first draft of specifications for an analytics algorithm to be implemented by software engineers
·         Carrying out a process required for BAU delivery of any aspect of the data asset that needs regular production operations
·         Investigating objections or issues raised by users
·         Following best practice guidelines, tools and formal processes for analytics practised at Quantium
·         Acting on advice and guidance around how to continuously improve own performance and drive own career development
·         Participation in Analytics Community initiatives, such as participation in events
Experience and education required
To be successful in this role the key competencies required include:
 ·         2-3 years’ experience in a highly technical analytics environment, carrying out data analytics or data science work
·         Tertiary qualifications in engineering, mathematics, actuarial studies, statistics, physics, or a related discipline
·         Developing knowledge of technical analytics discipline, including data preparation, experiment design, feature engineering and foundational analytics concepts
·         Sound knowledge of one or more technical tools and coding languages that are used for analytics
o    A broad range is used at Quantium and the concepts are transferable, so we do not require a specific set of tools
o    However, some tools and programming languages that might qualify include (in no particular order): Scala, R, Python, SQL, Haskell, SAS, MATLAB, S-Plus, C/C++, Perl
·         Strong problem-solving skills, including ability to apply a systematic problem-solving approach
·         Solid interpersonal skills, as the role will need to work in a cross-functional team with both other analysts and specialists from non-analytics disciplines
·         Ability to carry out work following analytics best practice as defined at Quantium for the relevant types of tools or techniques
·         Attention to detail
·         Drive for continuous improvement
What does success look like?
After 3 months in the role the incumbent will be:
 ·         able to apply professional knowledge and understanding to technical problem solving
·         knowledgeable about Quantium’s data, products and solutions
·         across all the processes required to deliver against the role
·         able to work effectively in a team
After 12 months in the role the incumbent will:
 ·         demonstrate proactivity in owning tasks and seeking development opportunities with support from more senior team members (e.g. attending knowledge sharing sessions, determining development areas, seeking relevant work experience)
·         proactive communication on work progress and escalating complexities with relevant stakeholders
·         proactively engage with wider team to identify and implement any improvement initiatives
   Apply to this job",USD 86K - 160K *
8,Data Engineer III - MPAT1133,Walmart,IN TN CHENNAI Home Office RMZ Millenia Biz Park,Senior-level / Expert,"Position Summary...
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales. Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities. Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.
What you'll do...
About Team:
Our organization focuses on managing and delivering world-class data assets, including creating and maintaining data standards, driving policy compliance, creating partnerships, and developing pipelines and self-service tools. We empower our business to leverage data to fuel growth, driving revenue in our core and building new business model opportunities. 
At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our customers.  
Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on.  You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives. 
What you'll do:
Data Strategy: Understands, articulates and applies principles of the defined strategy to routine business problems that involve a single function.
Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends.
Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.
Data Modelling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions.
Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.
Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.
Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working.
Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines.
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales.
What you'll bring: 
3+ years of experience in Data Engineering.
·      You have consistently high standards, your passion for quality is inherent in everything 
Well versed with Hadoop, Hive, Spark using Scala, Kubernetes, Cloud, API and Data Lake concepts .
·      You evangelize an extremely high standard of code quality, system reliability, and performance 
·      You have a proven track record coding with at least one programming language (e.g., Java, Python) 
You’re experienced in computing platforms (e.g., GCP, Azure) 
You’re skilled in data modelling & data migration protocols 
Experience with Kafka connect, Druid, Big Query and Looker is added advantage.
Experience with the integration tools like Automic, Airflow
About Walmart Global Tech:
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people.  That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. 
We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
Flexible, hybrid work:
We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives.
Benefits:
Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more.
Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.
Minimum Qualifications...
Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.
Minimum Qualifications:Option 1: Bachelor's degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science.
Preferred Qualifications...
Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.
Primary Location...
RMZ Millenia Business Park, No 143, Campus 1B (1st -6th floor), Dr. MGR Road, (North Veeranam Salai) Perungudi , India",USD 121K - 186K *
9,ETL & DB Engineer,Zeta Global,Hyderabad,Mid-level / Intermediate," ETL & Database Engineer
The CDP ETL & Database Engineer will specialize in architecting, designing, and implementing solutions that are 
sustainable and scalable. The ideal candidate will understand CRM methodologies, with an analytical mindset, and 
a background in relational modeling in a Hybrid architecture. 
The candidate will help drive the business towards specific technical initiatives and will work closely with the 
Solutions Management, Delivery, and Product Engineering teams. The candidate will join a team of developers across 
the US and India. 
Responsibilities:
• ETL Development – The CDP ETL & Database Engineer will be responsible for building pipelines to feed 
downstream data processes. They will have the ability to analyze data, interpret business requirements, and 
establish relationships between data sets. The ideal candidate will be familiar with different encoding formats 
and file layouts such as JSON and XML.
• Implementations & Onboarding – Will work with the team to onboard new clients onto the ZMP/CDP+ 
platform. The candidate will solidify business requirements, perform ETL file validation, establish users, perform 
complex aggregations, and syndicate data across platforms. The hands-on engineer will take a test-driven 
approach towards development and will be able to document processes and workflows.
• Incremental Change Requests– The CDP ETL & Database Engineer will be responsible for analyzing change 
requests and determining the best approach towards implementation and execution of the request. This 
requires the engineer to have a deep understanding of the overall architecture of the platform. Change requests
will be implemented and tested in a development environment to ensure the introduction of change will not 
have a negative impact on downstream processes.
• Change Data Management – The candidate will adhere to change data management procedures and actively 
participate in CAB meetings where change requests will be presented and approved. Prior to introducing 
change, the engineer will ensure that processes are running in a development environment. The engineer will 
be asked to do peer to peer code reviews as well as solution reviews prior to production code deployment.
• Collaboration & Process Improvement – The engineer will be asked to participate in knowledge share 
sessions where they will engage with peers, discuss solutions, best practices, overall approach, and process. The 
candidate will be able to look for opportunities to streamline processes with an eye towards building a
repeatable model to reduce implementation duration.
Job Requirements:
• The CDP ETL & Database Engineer will be well versed in the following areas:
o Relational data modeling
o ETL and FTP concepts 
o Advanced Analytics using SQL Functions 
o Cloud technologies - AWS, Snowflake 
• Able to decipher requirements, provide recommendations, and implement solutions within predefined 
timeframes. 
• The ability to work independently, but at the same time, the individual will be called upon to contribute in a 
team setting. 
• The engineer will be able to confidently communicate status, raise exceptions, and voice concerns to their direct 
manager.
• Participate in internal client project status meetings with the Solution/Delivery management teams.
• When required, collaborate with the Business Solutions Analyst (BSA) to solidify requirements. 
• Ability to work in a fast paced, agile environment; individual will be able to work with a sense of urgency 
when escalated issues arise. 
• Strong communication and interpersonal skills, ability to multitask and prioritize workload based on client 
demand. 
• Familiarity with Jira for workflow mgmt., and time allocation.
• Familiarity with Scrum framework, backlog, planning, sprints, story points, retrospectives etc. 
Required Skills:
• ETL – ETL tools such as 
o Talend (Preferred, not required) 
o DMExpress – Nice to have
o Informatica – Nice to have
• Database - Hands on experience with the following database Technologies
o Snowflake (Required) 
o Oracle 11 or Higher – Nice to have
o SQL Server SSIS – Nice to have
o MYSQL/PostgreSQL – Nice to have 
o Familiar with NOSQL DB methodologies (Nice to have) 
• Programming Languages – Can demonstrate knowledge of any of the following.
o PLSQL 
o JavaScript Strong Plus 
o Python - Nice to have
o Scala - Nice to have
• AWS – Knowledge of the following AWS services:
o S3 
o EMR (Concepts) 
o EC2 (Concepts) 
o Systems Manager / Parameter Store 
• Understands JSON Data structures, key value pair.
• Working knowledge of Code Repositories such as GIT, Win CVS, SVN. 
• Workflow management tools such as Apache Airflow, Automic/Appworx 
• Jira
Minimum Qualifications 
• Bachelor's degree or equivalent
• 2-4 Years' experience 
• Excellent verbal & written communications skills
• Self-Starter, highly motivated 
• Analytical mindset ",USD 30K - 56K *
10,Associate Manager - Data Products,Novo Nordisk,"Bengaluru, Karnataka, IN",Mid-level / Intermediate,"      Department Name – IO Regional Data Products
  At Novo Nordisk, we strive to be at the forefront of digital healthcare and to succeed with this, we need many bright minds. Working directly or indirectly with all parts of Novo Nordisk Globally, you will play a significant part in leading Novo Nordisk towards the future of digital healthcare securely. We are looking for a people manager for our IO DD&IT Solutions, Commercial IT GBS team. Join a growing team, working in an international environment. Apply now!
  About the department
Digital, Data & IT India is a team of 900+ highly skilled IT professionals located in Global Business Services (GBS) Bangalore. The main role of DD&IT India is to 'manage' IT, which includes System Management, Project Management, Infrastructure Management, Compliance Management, Security Management, Process Management and Vendor Management. Commercial IT department is an integral part of DD&IT India and is responsible for delivering projects and managing systems for Sales, Marketing, Medical & Market Access teams. In DD&IT, we drive projects, manage critical IT systems, services and infrastructure used along the entire value chain of Novo Nordisk. 

The Position
As an Associate Manager - Data Products, you shall be part of Data Products and work closely with the Senior Manager for IO Global Data Products for the Strategic direction for the area. You will be responsible for Service Delivery Excellence and CDP implementation for International Operation (IO) regions.  You will be taking acre of people and budget management for approximately 15-20 people (Data Engineers, Data Architects, ML Engineers, Scrum Masters, Product Owners). The budget responsibility includes Application Licensing, Infrastructure and Vendor Fees. Your primarily responsibility shall be:
Attraction, onboarding and hiring, help build Agile, personal, and professional competencies, taking care of people/career development via coaching and mentoring, reward and performance management and facilitating cross-organisational knowledge sharing.
Maintain governance that allows projects and stakeholders to manage overall project performance and manage program risks within the global nature of some of the programs.
Stakeholder management with frequent engagement with IT directors within SEEMEA, APAC, LATAM, N.W.E, SEEMEA, Germany and Japan, senior project managers for the IO regional projects and up-stream and down-stream Commercial IT colleagues.
Vendor management for Operations and Delivery and collaboration with external vendor through stakeholders for solution building.
Implement and operate within the SAFE Agile Framework and methodology and ensure all the projects and services delivered are within budget, time and quality.
  Qualifications
Master’s degree or bachelor’s degree with 10+ years of experience in working/managing/leading a Data Organization.
Certified SAFe Agilist. Advanced knowledge on SAFe/Agile principles and mindset is preferred.
Certification in change management and coaching.
3+ years leadership experience from similar job.
Seek to understand the thoughts and feelings of self and others, manage self and stay calm even under pressure. Display an inclusive mindset and respect the diversity in others
Build teams and ensure a healthy, engaging and inclusive work environment. Recognise and motivate teams for high performance.
Accelerate development by actively coaching and providing feedback, ensure ongoing dialogue about opportunities to foster growth, provide challenging opportunities to foster growth, identify and develop diverse talents and successors.

Working at Novo Nordisk
Novo Nordisk is its people. We know that life is anything but linear and balancing what is important at different stages of our career is never easy. That’s why we make room for diverse life situations, always putting people first. We value our employees for the unique skills they bring to the table, and we work continuously to bring out the best in them. Working at Novo Nordisk is working towards something bigger than ourselves, and it’s a collective effort. Novo Nordisk relies on the joint potential and collaboration of its more than 40,000 employees. Together, we go further. Together, we’re life changing.
  Contact
To submit your application, please upload your CV online (click on Apply and follow the instructions).
  Deadline
24th January 2024 
    We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 30K - 56K *
11,Senior Manager - Data Science,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Position Summary
We are seeking an innovative and analytical thinker to support our Data Science team in the Middle East and North Africa (MENA) region based in Bangalore, India. As Senior Data Scientist, you are expected to participate in business development, develop predictive and prescriptive models, context-based prototypes, and high impact storyboards to promote a data-driven strategy and solutions approach for the company.

Principal Responsibilities
Serve as an analytics expert in designing, developing and implementing best in analytic solutions.
Experience and expertise in advance analytics in credit and fraud risk areas preferred
Create and deliver powerful insights from data through better visualization and storyboarding
Collaborate with internal and external partners to fully understand business requirements and desired business outcomes
Demonstrate execution proficiency in handing multiple medium-to-large analytics projects in a teaming environment that includes the rest of the Data Science team
Draft detailed scope for assigned projects, addressing suggested methodology and analytics plan
Execute on the analytics plan with appropriate data mining and analytical techniques
Perform quality assurance of data and deliverables for work performed by other Data Scientists and self
Ensure all project documentation is up to date and all projects are reviewed per analytics plan
Ensure project delivery within timelines and budget requirements
Build on team’s analytical skills and business knowledge
Enhance existing analytics techniques by promoting new methodologies and best practices in the Data Science field
Provide subject matter expertise and quality assurance of complex data-driven analytic projects
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Professional Experience
• Minimum of 8 plus years of analytics expertise in applying statistical solutions to business problems
• Well rounded experience across risk and portfolio analytics
• Experience working with Card Payments industry and credit bureau
• Post-graduate degree (Masters or PhD) in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Good knowledge of data, market intelligence, business intelligence, and AI-driven tools and technologies
• Experience planning, organizing, and managing multiple large projects with diverse cross-functional teams
• Demonstrated ability to incorporate new techniques to solve business problems
• Demonstrated resource planning and delivery skills

Technical Expertise
• Experience in distributed computing environments and big data platforms (Hadoop, Elasticsearch, etc.) as well as common database systems and value stores (SQL, Hive, HBase, etc.)
• Ability to write scratch MapReduce jobs and fluency with Spark frameworks
• Familiarity with both common computing environments (e.g. Linux, Shell Scripting) and commonly-used IDE’s (Jupyter Notebooks) proficiency in SAS technologies and techniques
• Strong programming ability in different programming languages such as Python, R, Scala, Java, Matand SQL
• Proficient in some or all of the following techniques Linear and Logistic Regression, Decision Trees, Random Forests, K-Nearest Neighbors, Markov Chain, Monte Carlo, Gibbs Sampling, Evolutionary Algorithms (e.g. Genetic Algorithms, Genetic Programming), Support Vector Machines, Neural Networks, etc.
• Expert knowledge of advanced data mining and statistical modeling techniques, including Predictive modeling (e.g., binomial and multinomial regression, ANOVA) Classification techniques (e.g., Clustering, Principal Component Analysis, factor analysis) Decision Tree techniques (e.g., CART, CHAID)
• Deliver results within committed scope, timeline and budget
• Very strong people and project management skills and experience
• Ability to travel within MENA on short notice
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 95K - 160K *
12,Lead Software Engineer - Machine Learning,Freshworks,"Chennai, India",Senior-level / Expert,"Company Description
About Freshworks
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end user. More than 50,000 companies -- from startups to public companies -- around the world use Freshworks software-as-a-service to enable a better customer experience ]CRM) and employee experience (ITSM, HRSM). Headquartered in San Mateo, California, Freshworks has a dedicated team operating from 13 global locations to serve 50,000+ customers including Bridgestone, Chargebee, DeliveryHero, ITV, Klarna, Multichoice, OfficeMax, TaylorMade and Vice Media.
Freshworks transforms the way world-class organizations collaborate with customers and co-workers. The suite includes Freshdesk (omni-channel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshteam (HR management system). Freshworks has received numerous accolades including 2019 Startup of the Year form Economic Times, #16 ranking on the Forbes’ Cloud 100 list and #22 on the Battery Ventures/Glassdoor Best Places to Work in 2020. Our suite of products has also been recognized by analysts including the Gartner Magic Quadrants for CRM Customer Engagement, IT Service Management and Sales Force Automation.
While Freshworks has had incredible organic growth over the last few years, the company also has made targeted acquisitions that add critical capabilities to the portfolio including Natural Language Processing, Chatbots, Machine Learning, Social and Messaging Transformation. Freshworks has raised over $400 million in capital and is funded by Accel, CapitalG, Sequoia Capital and Tiger Global Management. More information is available at www.Freshworks.com.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose and passion, irrespective of their background, gender, race, sexual orientation, religion or ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, our communities and our business.
Job Description
 Overview of the Role :
As a Machine Learning Engineer, you will focus on building next-generation platform services to enable Machine learning capabilities across the Freshworks suite of products.
As part of your job, you will extensively use your analytical skills, knowledge of distributed systems and scalable, high-performance systems to build ML pipelines and API services.
Responsibilities
Deliver scalable, low latency, and high-performance ML solutions for different Freshworks products Build ML pipelines end-to-end, including stages such as data pre-processing, model generation, cross-validation, and active feedback
Build efficient systems for processing large amounts of data; be proficient with distributed programming frameworks such as Hadoop/Spark Drive solutions and implementation leveraging different open source libraries and distributed systems
Work closely with Data Scientists and come up with scalable system and model architectures for enabling real-time ML/AI services Liaise with architects and engineers from other product teams to build solutions and drive adoption
Elicit quality attributes of the system and define metrics to establish its success.
An ideal candidate profile would include Bachelors or Master’s degree in Computer science or related field A strong grounding in Data structures and algorithms, Database concepts
Good oral and written communication skills, analytical and problem-solving skills
Hands-on programming experience in JVM languages and Python Experience in building scalable, high-performance, low latency systems Foundation in basic math concepts
Background in big data tech, streaming applications Prior experience in building and deploying ML systems Familiarity with Machine learning algorithms
Ability to design ML systems end-to-end; this includes big-data handling, pre-processing, model generation logic, model persistence including choice of online data stores, etc., systems for consuming active feedback (online learning), web services to publish model predictions to consumers.
Qualifications
all technical skills plus mentoring L1 and L2
Additional Information
All your information will be kept confidential according to EEO guidelines.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 45K - 84K *
13,Analytics Engineer,Deliveroo,"Hyderabad, India (Main Office)",Mid-level / Intermediate,"Why Deliveroo?
We're building the definitive online food company, transforming the way the world eats by making hyper-local food more convenient and accessible. We obsess about building the future of food, whilst using our network as a force for good. We're at the forefront of a industry, powered by our market-leading technology and unrivalled network to bring incredible convenience and selection to our customers.
Working at Deliveroo is the perfect environment to build a definitive career, motivated by impact. Firstly, the impact that working here will have on your development, allowing you to grow faster than you might elsewhere; secondly, the impact that you can have on Deliveroo, leaving your mark as we scale; and finally, being part of something bigger, through the impact that we make together in our marketplace and communities.
The Role
Working as part of our analytics engineering team and reporting to one of our Analytics Engineering Managers, your role will be to provide clean, tested, well-documented and well-modelled data sets, that will enable and empower data scientists and business users alike, via tools like Snowflake and/or Looker.
You'll work with product engineering teams to ensure modelling of source data meets downstream requirements.
You will maintain and develop SQL data transformation scripts, and advise and review data scientists on data modelling to achieve denormalised and aggregated output datasets.
You'll work with data scientists and other analytics engineers to surface clean, intuitive datasets in our BI tool, Looker.
You will be responsible for optimisation and further adoption of Looker as a data product in the business, catering to ~1500 current active users who need to discover and interact with data.
Skillset
Required
5+ years experience within the field of Analytics Engineering, Data Engineering, or BI Engineering
Excellent SQL skills
Understanding of data warehousing, data modelling concepts and structuring new data tables
Knowledge of cloud-based MPP data warehousing (e.g. Snowflake, BigQuery, Redshift)
Nice to have
4+ years experience developing in a BI tool (Looker or similar)
Good practical understanding of version control
SQL ETL/ELT knowledge, experience with DAGs to manage script dependencies
Python coding skills, particularly in automation & integrations
Knowledge of the Looker API
Workplace & Diversity
At Deliveroo we know that people are the heart of the business and we prioritise their welfare. We offer multiple great benefits in areas including health, family, finance, community, convenience, growth and relocation.
We believe a great workplace is one that represents the world we live in and how beautifully diverse it can be. That means we have no judgement when it comes to any one of the things that make you who you are - your gender, race, sexuality, religion or a secret aversion to coriander. All you need is a passion for (most) food and a desire to be part of one of the fastest growing start-ups around.
#LI-Hybrid",USD 91K - 172K *
14,Sr. Data Engineer,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Visa Inc. is at the forefront of the Gen AI revolution, developing and executing a shared strategic vision for our Loyalty and Marketing platforms. Our goal is to establish Visa as the world-leading data-driven payments company.
The successful candidate will be a full stack developer for a self-motivated individual with excellent software and data engineering skills and expertise in Java/J2EE, Big Data, Hadoop technologies. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing.  The candidate should be a motivated self-starter and quick learner.
This role is based in Bangalore and will be part of Digital Marketing Experience, Benefits & Loyalty team in Value Added Services group at Visa.
Responsibilities
Lead the design, development, and implementation of various initiatives to deliver the business functionalities.
Design, develop and maintain mission-critical systems, delivering high-availability and performance.
Develop high quality code, participate in code reviews, and mentor junior developers to ensure the deliveries on time.
Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA.
Coordinate and participate in Continuous Integration activities, automation frameworks for testing and deployments etc. in addition to contributing to core product code.
Present technical solutions, capabilities, and features in business terms.
Adhere to Secured coding standards and develop code for high system performance.
Effectively communicate status, issues, and risks in a precise and timely manner.
Work on development of new products iteratively by building quick POCs and converting ideas into real products.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
• 2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experience

Preferred Qualifications
• 3 or more years of work experience with a Bachelor’s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) in computer science, computer engineering or relevant field.
• 1-3 years of software design, architecture, and development experience.
• Strong foundation in computer science, with excellent competencies in data structures, algorithms, and software design, optimized for building highly distributed and parallelized systems.
• Strong experience in building large scale applications using open source and J2EE/Big Data technologies.
• Strong experience with Big Data ecosystem like Hadoop, Spark, Map Reduce, Kafka, Airflow or equivalent.
• Strong in Core Java development concepts and design patterns.
• Good design and coding skills in Java/J2ee, Web Services, Spring, Hibernate, Soap/Rest APIs.
• Capability to work in UI stack using advance Java Script frameworks like AngularJS, Backbone etc. is preferable.
• Capable to leverage DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test-Driven Development to enable the rapid delivery of working code utilizing tools like Jenkins, Maven, Chef, Git and Docker.
• Experience in Agile development using any of the methodologies like SCRUM is a big plus.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 186K *
15,"Data Engineer, Digital IT",Egon Zehnder,"Gurugram, Haryana, India",Mid-level / Intermediate,"The Company
Egon Zehnder (www.egonzehnder.com) is trusted advisor to many of the world’s most respected organizations and a leading Executive Search firm, with more than 550 consultants and 63 offices in 36 countries spanning Europe, the Americas, Asia Pacific, the Middle East and Africa. Our clients range from the largest corporations to emerging growth companies, government and regulatory bodies, and major educational and cultural institutions. The firm is a private partnership which allows us to operate independent of any outside interests. As a result of this unique culture, Egon Zehnder has the highest professional staff retention rate for a global firm in our profession. We have a blue chip client base across all industries and operate at the Board and senior management level.
Knowledge Centre India (KCI)
Established in January 2005, KCI in Gurgaon, works in close collaboration with the Global offices of Egon Zehnder. There are 5 teams that make up KCI: Research, Research Operations, Visual Solutions, Projects/CV Capture and Digital IT.
Your Journey at Egon Zehnder Starts Here
At EZ, you have the opportunity to deliver digital transformation initiatives across the globe for the organization. Our focus on emerging technology solutions along with our commitment to internal career growth and exceptional client value has resulted in a firm that is routinely recognized as a “Best Place to Work.”
 Who we are!
We are part of Digital-IT team established 14 years ago in Gurgaon, India to provide technology support and rollout digital initiatives to 60 plus global offices. Digital IT has six key pillars – Collaboration Technology; Functional Technology; Digital Technology; Security & Architecture; Infrastructure & Services, Digital Success to support business and to take lead on digital transformation initiatives with the total strength of 150+ team members across the globe.
Requirements
Roles and Responsibilities. 
The Data Engineer is expected to build the flow of data within the organization, and security of data.
Executing end-to-end data pipeline, from designing the technical architecture, and developing the application to finally testing and implementing the proposed solution in an agile environment.
The Data Engineer is expected to help in driving the database architecture and design for Egon Zehnder large-scale, Intranet and Internet-based applications.
The Data Engineer should research new tools and technologies and come up with recommendations on how they can be used in Egon Zehnder applications.
The Data Engineer will also be expected to actively participate in design and implementation of projects bearing a high degree of technical complexity and/or scalability and performance significance
Identifying data sources, both internal and external, and working out a plan for data management that is aligned with organizational data strategy.
Collaborate cross-functionally with roles such as IT infrastructure, Digital/application development, and Legal to identify and highlight gaps and risks around Cybersecurity and Data Protection such as GDPR
Ensure code can be deployed using Azure DevOps.
Experience & Key Competencies
  Experience with private and public cloud architectures, pros/cons, and migration considerations.
 Minimum of 3 years of RDBMS experience. 
Experience with JSON, JSON-LD, XML data structures. 
Experience implementing data pipelines using latest technologies and techniques. 
Experience with SDLC products (JIRA, Confluence, Github, etc) or similar agile project management tools.
 3+ years of hands-on experience in programming languages such as python, SQL, Powershell/Perl scripting etc. 
At least 3 years of consulting or client service delivery experience on Azure. 
Bachelor’s or higher degree in Computer Science or related discipline. 
Experience handling Structured and unstructured datasets. 
Expert in USQL, Python, Spark SQL, Data Bricks. 
Strong t-SQL skills with experience in Azure SQL Data Warehouse. 
Experience in Data Modelling and Advanced SQL techniques. 
Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.
 Microsoft Azure certifications are a plus.
Excellent problem solving, analytical, and critical thinking skills.
Skill Set
Experience with JSON, JSON-LD, XML data structures. 
Experience implementing data pipelines using latest technologies and techniques.
Experience with SDLC products (JIRA, Confluence, Github, etc) or similar agile project management tools. 
Experience handling Structured and unstructured datasets.
Expert in USQL, Python, Hive SQL, Spark SQL, Data Bricks.
Strong t-SQL skills with experience in Azure SQL Data Warehouse.
Experience in Data Modelling and Advanced SQL techniques. 
Azure Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc. 
Experience on Azure Purview is a plus, Any RDBMS
Benefits
Benefits which make us unique
At EZ, we know that great people are what makes a great firm. We value our people and offer employees a comprehensive benefits package.
 Benefits Highlights: 5 Days working, Work from Home, Reward and Recognition, Employee friendly policies, Personnel development and training, Health Benefits, Accident Insurance, Gender Diversity
 Potential Growth for you!
We will nurture your talent in an inclusive culture that values diversity. You will have the chance to meet on a consistent basis with the Career Coach that will guide you in your career goals and aspirations. Learn more about where talent can prosper!
Egon Zehnder is an Equal Opportunity Employer",USD 90K - 151K *
16,Data Engineer,Accellor,"Hyderabad, Telangana, India",Mid-level / Intermediate,"Headquartered in the Silicon Valley with offices in London, Hyderabad and Singapore, Accellor is a Microsoft Gold Partner and a premier Salesforce Partner that uses best-of-breed Cloud technology to deliver superior customer engagement and business effectiveness for clients. We bring a deep understanding of Financial, Retail, High Tech, Healthcare, and Retail industries, rolling out end-to-end implementation of salesforce.com and powerful third-party apps. We also build products that are sold on the AppExchange and used by both boutique businesses and Fortune 500 companies.

Majority of our team members based at Hyderabad, delivering best of breed cloud solutions to customers in the US, UK and APAC region. We’ve created an atmosphere that encourages curiosity, constant learning, and persistence. We encourage our employees to grow and explore their interests. We cultivate an environment of collaboration, autonomy and delegation – we know our people have a strong work ethic and a sense of pride and ownership over their work. They are passionate, eager, and motivated – focused on building the perfect solution but never losing sight of the bigger picture.
Responsibilities:
Assist in building a high performing data platform which will power various reporting tools, analytics.
Create data tools for analytics and optimizing data models, articulate pros and cons of different modelling approaches.
Design and build production data pipelines from ingestion to consumption within a big data architecture. Leverage various continuous delivery practices to deploy, support and operate data pipelines.
Though understanding of data enterprise applications such as unified ID, De-duplication, classification, identifying the source of truth, different aggregation models.
Seamlessly include data quality into your day-to-day work as well as into the delivery process.
Working on relational SQL and NoSQL databases such as Redshift or comparable cloud based OLAP databases such as Snowflake.
Writing and processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, Logs, SQL, No SQL databases.
Requirements
Min 3-5 yrs experience as Data Engineer
Experience with Big data, DataLake, Databricks, Synapse, Spark, Azure data factory (ADF), Analytics tools like Power BI, Tableau and SQL server.
Excellent communication and interpersonal skills.
Direct Interactions with clients
Exposure to ETL tools and Data warehouse (would be a plus)
Design relational, multidimensional, and Master data management systems
Goot to have experience in designing and implementing end to end cloud data engineering Solutions preferably Azure or any other cloud platform.
Benefits
Exciting Projects: We focus on industries like High-Tech, communication, media, healthcare, retail and telecom. Our customer list is full of fantastic global brands and leaders who love what we build for them.
Collaborative Environment: You Can expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment — or even abroad in one of our global canters.
Work-Life Balance: Accellor prioritizes work-life balance, which is why we offer flexible work schedules, opportunities to work from home, and paid time off and holidays.
Professional Development: Our dedicated Learning & Development team regularly organizes Communication skills training, Stress Management program, professional certifications, and technical and soft skill trainings.
Excellent Benefits: We provide our employees with competitive salaries, family medical insurance, Personal Accident Insurance, Periodic health awareness program, extended maternity leave, annual performance bonuses, and referral bonuses.
Disclaimer: -
Accellor is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic.",USD 90K - 151K *
17,ETL Developer,Zeta Global,"Hyderabad, IN",Mid-level / Intermediate,"The candidates’ primary responsibilities will be to support our clients CRM needs from a database perspective. As we 
look to migrate our clients to one central platform, we will look for an individual that has experience in both a hosted 
environment and having knowledge in cloud-based technologies is added advantage. The ideal candidate will have 
the ability to grow with the company to support the needs of the business as it stands today as well as future state. 

The candidate will have good Communication Skills and high potential in learning & implementing the new 
technologies quickly.
• Hands-on individual contributor role is responsible for producing excellent quality of code, adhering to 
expected coding standards and industry best practices.
• High levels of ownership and commitment to deliverables
• Effective communication with SM team / Account team and stakeholders to probe a technical problem or 
clarify requirement specifications
• Participate in various projects and new initiatives; develop/ deploy and make suggestions as a technical 
resource involving ETL Tools such as Talend, Spark. as well as performing duties such as documenting 
implemented solutions, deciphering program logic, and adhering to stringent change control processes. 
• The selected individual will be able to work independently or in a team setting, has an analytical mindset 
that will collaborate and share knowledge across teams. 

Required Skill Set: 
• 2 years or more experience in database with the ability to transform and manipulate data.
• Very good knowledge on MySQL database [or any other relational database]
• Solid understanding of data modeling, entity relationships, and ETL methodologies.
• Experience on any of the ETL tools such as Talend, Informatica, DMExpress etc. 
• Hands on experience of loading/unloading of JSONL, XML as well as standard delimited file definitions. 
• Knowledge on Data Warehouse would be an added advantage.
• Strong Performance Tuning skills, ability to understand SQL execution plans
• Should be proficient in any of these programing languages like Java, Python, Scala.
Good to have and/or added advantage:
• Exposure to other database technologies such as SQL Server, Snowflake, Vertica
• Exposure to AWS technologies, specifically S3, Athena, EMR as well as overall architecture of a hybrid 
environment. 
• General understanding of CRM methodologies and customer engagement modeling. 
• Understanding of map reduce, Hadoop, Hive, and Spark.
 
Company Summary
Zeta Global is a data-powered marketing technology company with a heritage of innovation and industry leadership. 
Founded in 2007 by entrepreneur David A. Steinberg and John Sculley, former CEO of Apple Inc and Pepsi-Cola, the 
Company combines the industry’s 3rd largest proprietary data set (2.4B+ identities) with Artificial Intelligence to 
unlock consumer intent, personalize experiences and help our clients drive business growth.
 
Our technology runs on the Zeta Marketing Platform, which powers ‘end to end’ marketing programs for some of the 
world’s leading brands. With expertise encompassing all digital marketing channels – Email, Display, Social, Search 
and Mobile – Zeta orchestrates acquisition and engagement programs that deliver results that are scalable, 
repeatable and sustainable.
Zeta Global is an Equal Opportunity/Affirmative Action employer and does not discriminate on the basis of race, 
gender, ancestry, color, religion, sex, age, marital status, sexual orientation, gender identity, national origin, medical 
condition, disability, veterans status, or any other basis protected by law.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with 
arrest and conviction records.
Zeta Global Recognized in Enterprise Marketing Software and Cross-Channel Campaign Management Reports by 
Independent Research Firm
https://www.prnewswire.com/news-releases/zeta-global-opens-ai--data-labs-in-san-francisco-and-nyc300945353.html
https://www.prnewswire.com/news-releases/zeta-global-recognized-in-enterprise-marketing-software-and-crosschannel-campaign-management-reports-by-independent-research-firm-300938241.html",USD 99K - 143K *
18,Customer Analytics / Data Science - Lead Analyst - Analytics,dentsu international,"Bengaluru, India",Senior-level / Expert,"Company Description
About Merkle
Merkle, a dentsu company, is a leading data-driven customer experience management (CXM) company that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The company’s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive hyper-personalized marketing strategies. Its combined strengths in consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions drive improved marketing results and competitive advantage. With more than 14,000 employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the Americas, EMEA, and APAC. For more information, contact Merkle at
1-877-9-Merkle or visit www.merkle.com.
Job Description
Job Description
Roles & Responsibilities
Convert business problem into an analytical problem by assessing available data sources and data sets
Solve the business problem - identify factors, test hypotheses, conduct EDA, design solution and outputs
Lead the team in evaluating relevant analytical techniques and choose/propose a champion model/methodology
Analyze, assess findings, generate insights and present recommendations through reports/dashboards/excel/presentations
Independently plan and execute key projects including last mile to delivery
Research & develop point of views on emerging problems, new ways of solving existing problems
Mentor and up-skill team on the analytics consulting career roadmap
Spot opportunities that could potentially generate new business for Merkle within existing and new client accounts
Support campaign strategy and planning with audience insights analysis, sizing and research using tools
Document best practices and seek out opportunities to improve existing processes
Manage campaign timelines and deliverables across internal and external teams
Leverage solutions and tools to provide recommendations on driving client’s campaigns and objectives
 Qualifications
Qualifications/Certifications:
- BE/ B.Tech, ME/MTech (Computer Science)
- Advanced degree in a quantitative discipline, preferably Mathematics/Statistics or similar will be an added advantage
Additional Information
Mandatory (top 5)                                                     
SQL (Expert), Python (Intermediate)                                                  
Visualization/BI Tools – (At least one out of Tableau, LookerStudio, PowerBI, Dataroma)                                                    
Statistical Modelling knowledge - Regression, Time-Series, Clustering      
Advanced Excel & Powerpoint                                              
EDA Analysis / business insights recommendations",USD 95K - 160K *
19,Analytics Engineering Manager,Deliveroo,"Hyderabad, India (Main Office)",Mid-level / Intermediate,"Who We Are
Our ambition is to be the definitive food company, feeding people three times a day with great food from the World's best-loved restaurants, all with an unparalleled level of convenience.
From distributed computing to large-scale system design, complex algorithms to beautiful user interfaces, we have teams working on every step of the journey, in real-time, to ensure we continue to offer our customers a growing selection of choice at the best price with a fantastic level of service.
We work with thousands of restaurants worldwide, from renowned local gems to your favourite chains, allowing them to open up a new revenue stream and reach new customers. Our restaurant partners, riders and customers are as passionate about food as we are, and if you want to improve millions of users by solving some of the biggest technical challenges at great scale, come on board and join the ride.
The Team
Analytics Engineering is a growing area at Deliveroo. The team is a major enabler for Data science, Product Development and Business insight. Our analytics engineers are building our ETL, ingesting more and more data every day, building data models and data visualisations, all on our leading Cloud native data platform. Having demonstrated great impact, we need even more Analytics Engineers and more Analytics Engineering managers to support them!
You will spend time:
Hire and grow a diverse, accomplished group of analytics engineers, gaining fantastic exposure to scaling a tech team at a unique pace
Create a learning environment for your team while being a mentor for analytics engineers and up and coming leaders
Line managing one or more teams of analytics engineers
Work with other Analytics Engineering Managers to share understanding of multiple teams
Contribute to product delivery, by ensuring analytics engineers are in the right place at the right time
Become instrumental in improving and implementing processes and values that scale.
Provide technical mentorship to engineers building and deploying large-scale projects internationally
Collaborate with teams including product, design, operations
You will work with the Director of Engineering and Senior Managers in Data Analytics team.
Requirements:
3 years of experience as a Engineering Manager, managing individual contributors (Analytics Engineers/BI developers/Data Platform engineers)
Experience being an analytics/BI engineer at a mid/senior level, but is now not looking to do individual contributor work
Have worked with SQL in the last 2 years
Familiarity with modern cloud data stack (Snowflake, Prefect, Looker, or AWS)
Have experience working with senior partners in projects, and other team members business wide.
Experience working in a matrix organisation
Can bring together a group of individuals from many different backgrounds and skills to form a cohesive team.
Is comfortable managing ICs across multiple teams in different industries, and ruthlessly prioritising.
Workplace & Diversity
At Deliveroo we know that people are the heart of the business and we prioritise their welfare. We offer multiple benefits in areas including health, family, finance, community, convenience, growth and relocation.
We believe a great workplace is one that represents the world we live in and how beautifully diverse it can be. That means we have no judgement when it comes to any one of the things that make you who you are - your gender, race, sexuality, religion or a secret aversion to coriander. All you need is experience with (most) food and a desire to be part of one of the fastest growing startups in an exciting space.
Location:
Hyderabad, Telangana, India",USD 30K - 56K *
20,Data Analyst,Quantiphi,IN MH Mumbai Eureka,Entry-level / Junior,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Role: Analyst - Sales Operations
Experience Level: 2 to 4 Years
Work location: Mumbai or Bangalore
Role & Responsibilities:
 Analyzing and developing sales operations policies and procedures.
 Working with sales representatives from different regions/practices to confirm process, collect timely
inputs towards projections and identify opportunities for improvement.
 Assisting in managing compliance program and sales operations help desk.
 Maintaining existing sales reports and designs new reports as needed.
 Participates in the evaluation, selection, and implementation of a decision-support tool.
 Acting as primary liaison on sales force automation projects/trends.
 Coordinating with cross functional teams to timely report revenue forecasts, establishing high levels of
quality, accuracy, and consistency.
 Assist with maintaining the functional areas of data management, forecasting, contacts, leads,
opportunities, dashboards and reports, and ensuring data integrity throughout our CRM system.
 Establishing effective analysis of sales force trends and performance in an effort to identify greater
efficiencies and better manage and understand process bottlenecks and inconsistencies throughout the
entire sales lifecycle.
 Performing ad hoc analysis for senior management to provide data support for business decisions.
 Evaluating new tools and platforms to improve reporting and sales operations.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 53K - 94K *
21,Data Architect,Gainwell Technologies,"Chennai, TN, IN, 600032",Senior-level / Expert,"Summary
  We’re looking for a high-performing and self-motivated Data architect with strong Healthcare software solution expertize to join our product development team and drive critical initiatives at Gainwell technologies. This role requires close collaboration with engineering, infrastructure and product teams, and involves ongoing interaction with a variety of end-users and internal stakeholders. 
Your role in our mission
Essential Job Functions
Reviews and oversees database environment activity and volume. Highlights issues for concern such as, lack of appropriate resources and ensures that appropriate corrections are implemented.
Provides thought leadership for database management systems (DBMS) teams in responding to database outages and recoveries in critical client-impacting situations. Maintains call-out lists and schedules.
Provides technical expertise and coordinates activities of multiple database management systems (DBMS) resources on a large account or multiple smaller accounts.
Provides technical database consultation on application development, global infrastructure, and other database administration efforts related to specific DBMS. Functions as a decision-making authority on database design decisions to ensure that application solutions exhibit appropriate levels of performance, security, scalability, maintainability, and reliability upon deployment.
Provides work guidance and mentoring to less experienced personnel. Provides database related technical expertise to application development and global infrastructure efforts. Organizes and motivates teams. Ensures communication and understanding of deadlines, assignments, and objectives. Prepares periodic reports regarding unit activities and goal attainment progress.
Provides input to development of vision, specifies key performance requirements and defines technical critical success factors. Provides estimates for required database activities to project and account teams.
Assumes a lead role in influencing client expectations and ensuring client satisfaction in area of responsibility and related issues.
Reviews and performs complex analyses of DBMS products and features regarding their impact on database performance. Researches hardware and software products, recommends solutions and implements approved products.
May participate in proposal efforts and create strategies to win business in new markets or current accounts.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in computer sciences or related field preferred
Nine or more years of experience in data/database architecture
Experience working with Catalyst and/or equivalent client or vendor-mandated methodology
Experience working with differences between database structures (e.g., transaction based vs. data warehouse)
Experience working with software packages or classes of packages within technical expertise
Other Qualifications
Strong project planning and estimating skills related to area of expertise
Strong communication skills
Good leadership skills to guide and mentor the work of less experienced personnel
Ability to be a high-impact player on multiple simultaneous engagements
Ability to think strategically, balancing long and short-term priorities
Willingness to travel
Work Environment
Client or office environment / may work remotely
Frequent evening and weekend work
#LI-DNP
 ",USD 115K - 193K *
22,Modelling / Data Science - Sr Analyst - Analytics,dentsu international,"Bengaluru, India",Senior-level / Expert,"Company Description
About Merkle
Merkle, a dentsu company, is a leading data-driven customer experience management (CXM) company that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The company’s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive hyper-personalized marketing strategies. Its combined strengths in consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions drive improved marketing results and competitive advantage. With more than 14,000 employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the Americas, EMEA, and APAC. For more information, contact Merkle at
1-877-9-Merkle or visit www.merkle.com.
Job Description
Job Description
Roles & Responsibilities
3 + years in Analytics
Strong SQL background ( Must Have, To be evaluated using a written SQL Test)
Strong communication ( Must have)
Analytics Problem solving skills
People with Marketing Analytics/CRM Analytics background ( Nice to Have)
BFSI Background ( Nice to have)
Ideally we are looking for folks who can translate business problems to analytics problem, extract the required data from various databases, do the analysis and be able to present it to the client
We don’t necessarily need folks with Advanced Modeling experience
Qualifications
Qualifications/Certifications:
- BE/ B.Tech, ME/MTech (Computer Science)
- Advanced degree in a quantitative discipline, preferably Mathematics/Statistics or similar will be an added advantage",USD 95K - 160K *
23,Technology Specialist (Solution / Data Architect),Deutsche Bank,Pune - Business Bay,Senior-level / Expert,"Job Description:
Job Title- Technology Specialist (Solution / Data Architect)
Location- Pune
Role Description
About DWS:
Today, markets face a whole new set of pressures – but also a whole lot of opportunity too. Opportunity to innovate differently. Opportunity to invest responsibly. And opportunity to make change.
Join us at DWS, and you can be part of an industry-leading firm with a global presence. You can lead ambitious opportunities and shape the future of investing. You can support our clients, local communities, and the environment.
We’re looking for creative thinkers and innovators to join us as the world continues to transform. As whole markets change, one thing remains clear; our people always work together to capture the opportunities of tomorrow. That’s why we are ‘Investors for a new now’.
As investors on behalf of our clients, it is our role to find investment solutions. Ensuring the best possible foundation for our clients’ financial future. And in return, we’ll give you the support and platform to develop new skills, make an impact and work alongside some of the industry’s greatest thought leaders. This is your chance to achieve your goals and lead an extraordinary career.
Team / division overview
 The COO Division is a key enabler for DWS and is integral to the future success of the company by delivering world-class services across a set of key functions. It covers essential Technology and Operations capabilities, including our data programs and digital transformation. The COO aims to deliver a platform which is efficient, scalable, resilient and agile.
Within the COO Division Data Management is responsible for designing and driving the execution of the data strategy at Group and Divisional/functional level as well as coordinating adherence to Data related processes and policies and any applicable local regulations.
What we’ll offer you
As part of our flexible scheme, here are just some of the benefits that you’ll enjoy
Best in class leave policy
Gender neutral parental leaves
100% reimbursement under childcare assistance benefit (gender neutral)
Sponsorship for Industry relevant certifications and education
Employee Assistance Program for you and your family members
Comprehensive Hospitalization Insurance for you and your dependents
Accident and Term life Insurance
Complementary Health screening for 35 yrs. and above
Your key responsibilities
As a Data Architect you will:
Own a selection of domains within the (logical) Enterprise Data Model (EDM) including all relations
Partnering with the Head of EDM & Information Domain to model DWS' core EDM and derive logical EDM as well as assure general schemas derived will also adhere to and meet overall EDM requirements (e.g. deriving context specific schemas in JSON, AVRO, RDBM), protocols for exchange of data between systems (e.g. in context critical points of data exchange)
Review, improve and implement an updated version of DWS' EDM and support the architecture, data governance and data quality teams to implement new Data Governance and Data Quality management platforms that the (new) EDM needs to be integrated with
Ensure that the EDM is properly integrated within the information domain.
Partner with key stakeholders to model data at source systems that aligns with the EDM
Create and maintain conceptual, logical, and physical data models using best practices to ensure high data quality and reduced redundancy, along with corresponding metadata
Improve and deliver architecture that considers data acquisition, data flow in an event driven architecture / environment, data integrity by design, data archival and discovery, data flow monitoring and alerting, data transformation, data ingestion and consumption as well as defining common patterns for any of these to guide engineering teams to deliver against this architecture
Working across multiple business lines to influence, identify, evaluate and recommend potential objectives to support the delivery of data architecture solutions
Ensure that solutions around metadata captured around the EDM will drive operational excellence in managing, governing and quality assuring data within DWS
Your skills and experience
Strong experience in Enterprise Data Modelling and Architecture especially in an event driven, micro-services based environment
Strong experience in data modelling (0NF, 3NF, Data Vault 2.0, Snowflake / Star, Multi-Dimensional) and able to explain Pros/Cons of each based on requirements
Experience in conceptional, logical and physical modelling using platforms such as PowerDesigner
Very good understanding of RDBMS, i.e. SQL Server, PostgreSQL and Oracle
Experience working with NoSQL/Document Store systems
Good technical understanding of messaging technologies such as Kafka, Google Pub/Sub
Good technical understanding of transport formats such as JSON, AVRO
Extensive experience in architecture standards and methodologies such as TOGAF, SAFe
An understanding of applicable technology/digital regulations such as KAIT, BAIT, DORA would be beneficial
Flexible team player with experience in working in distributed, global environments and teams
Strong conceptual and problem-solving skills, with an ability to develop creative and structured solutions
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 115K - 193K *
24,"Software Engineering Intern, Data Engineer",Poshmark,"Chennai, India",Entry-level / Junior,"Confidence can sometimes hold us back from applying for a job. Here’s a secret: there's no such thing as a ""perfect"" candidate. Poshmark is looking for exceptional people who want to make a positive impact through their work and help create an organization where everyone can thrive. So whatever background you bring with you, please apply if this role would make you excited to come to work every day.
Poshmark is seeking a Software Development Engineer Intern. We are a rapidly growing multiplatform social fashion marketplace and working on developing new user experiences, solving difficult problems and creating delightful solutions to improve user experiences. The role will be dynamic and varied, requiring a versatile self-starter willing to dive into multiple initiatives. Over the duration the intern can expect to become deeply involved in learning the tech stack, implementing new technologies, standards and best practices for software development that may run in production.
Our goal is to give you exposure to a range of development techniques and current technologies, through the experience of applying them to the multi-platform social marketplace dynamics.
This role will provide an excellent opportunity to implement code that may run in production, at scale.  While having the opportunity to work with a talented team to rapidly roll out changes and measure their impact, while being mentored and guided.
This is your chance to solve real world problems while working on cutting-edge technology.
What You’ll Be Potentially Doing:
Develop product features that delight the Poshmark community.
Work with the product and design team to understand and iterate on feature requirements.
Build development stack, programming and software design skills.
Write high quality and maintainable code and test cases.
Learn best practices and design patterns for software development.
What to expect  and to learn:
Exposure: Being a rapidly growing social fashion marketplace gives employees the opportunity to work in a startup environment and focus on deeply interesting work that you wouldn’t get to do anywhere else. Prepare to make a large scale impact in a short amount of time.
Professional Development: Participate in weekly team meetings,  opportunity to find a good balance of working independently and in team formed across multiple business units, develop knowledge of multiple areas of social marketplace, interact with leadership team;
Mentorship: Look forward to one-on-one time with dedicated managers and mentors to facilitate your growth throughout the summer internship experience.
Have fun: Team events, catered lunches(in office)
Ideal Candidate
Solid foundation in computer science with strong competencies in data structures, algorithms and software design
Knowledge in creating web-based APIs and REST APIs
Excited to work with NoSQL data solutions
Experience with any or all of: Ruby, JRuby, Java, HTML5, JavaScript, CSS, Swift, Kotlin, MongoDB, ElasticSearch, RabbitMQ, Linux
Dedication around clean & high-performance code
User-oriented focus and obsession with quality
Good to have exposure on client platforms such as iOS and Android
Good to have exposure on AWS or other Cloud Computing platforms
About Us
Poshmark is a leading social marketplace for new and secondhand style for women, men, kids, pets, home, and more. By combining the human connection of physical shopping with the scale, ease, and selection benefits of e-commerce, Poshmark makes buying and selling simple, social, and sustainable. Its community of more than 80 million registered users across the U.S. and Canada, is driving the future of commerce while promoting more sustainable consumption. For more information, please visit www.poshmark.com, and for company news and announcements, please visit investors.poshmark.com. You can also find Poshmark on Instagram, Facebook, Twitter, Pinterest, and YouTube.
Why Poshmark?
At Poshmark, we’re constantly challenging the status quo and are looking for innovative and passionate people to help shape the future of Poshmark. We’re disrupting the industry by combining social connections with e-commerce through data-driven solutions and the latest technology to optimize our platform. We’re nothing without our amazing team who deliver an unparalleled social shopping experience to the millions of people we connect each day.
We built Poshmark around four core values: 1) focus on people to create empowered communities that drive success; 2) together we grow to support each other to strive for our dreams; 3) lead with love to foster genuine connections built upon a foundation of respect; and 4) embrace your weirdness to accept and empower one another on their own unique journey. We’re invested in our team and community, working together to build an entirely new way to shop. That way, when we win, we all win together. Come help us build the most connected shopping experience ever.  We will set you up with comprehensive global and in-country benefits to support you and your family needs.
Poshmark is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
View Poshmark's Job Applicant Privacy Policy here.",None
25,IND (New) Senior Data Scientist - DM,Quantium,"Hyderabad, Telangana, India",Senior-level / Expert,"Location: Hyderabad,Telangana,India
Quantium
In everyday life, data forms the backbone of every decision we make, every lesson we learn and every direction we choose. Better data, better decisions, better outcomes. But it is so much more than just numbers and technology. It’s what we know, unearthing ideas to solve problems and grasping opportunities that could change the world. Quantium is a global leader in the application of big data analytics to help our clients solve their most important problems.
We started out as a data analytics firm, helping businesses make better decisions. Since then we have grown into a partner to businesses that have the ambition to lead their industries. We help our clients navigate the complex world of data, analytics and technology to deliver powerful insights with clear business applications. We solve commercial problems to improve client efficiency, customer experience and profit. Our most advanced analytics solutions deliver insights that underpin significant investment and strategic decision making for our clients.
We are using technology that pushes our products to the limit and developing tools and applications to solve problems in ways that nobody else has. We are working with pioneering open source technology and solving client opportunities worth tens if not hundreds of millions of dollars. Our people are passionate about data. They are smart, innovative and motivated to identify and solve new and interesting client problems.  
Joining Quantium enables learning from the best people in Australia in big data analytics and machine learning, having access to the best data sources and the opportunity to solve the most interesting client problems.
 Role summary
The Senior Analyst, Foundational Analytics role is a technical contributor and task management role within a cross-functional team accountable for the delivery of a data products roadmap. Working together with the Analytics Lead, analysts and other technical specialists from analytics and software engineering disciplines, the Senior Analyst will be responsible for the design and specification of analytics that forms part of the core solution offered by Quantium foundational analytics.
 Key responsibilities
·         Accountable for the delivery of advanced analytics solutions into Quantium’s core data assets
·         Develop and execute roadmap for the ongoing development of our foundational data assets
·         Project management including overseeing and delegating technical tasks amongst analysts
·         Code review and quality assurance of output produced by analysts
·         Support the Analytics Lead with analytics architecture and solution design
Responsibility
Expected proportion of time
Project management and stakeholder management
30%
Code review and quality assurance
40%
Data, coding, analytics
30%
  Key activities
·         Set and manage roadmap for one foundational data asset including weighting, data curation, customer segmentation and other foundational analytics with the support of Analytics Lead
·         Acting as business liaison to relate consulting requirements into data product specification for assigned sections analytics efforts
·         Delivery of tasks to support a data products roadmap and BAU tasks, working in a cross-functional team managed by Analytics Lead
·         Leading assigned sections of analytics solution design with minimal guidance (e.g. foundational analytics, descriptive analytics, product analytics etc)
·         Creation of analytics approaches to solve business problems in a scalable and repeatable way
·         Design, development or testing of an analytics algorithm, including prototyping
·         Writing the specifications for an analytics algorithm to be implemented by software engineers
·         Peer reviewing the work of other analysts (both conceptual and documentation)
·         Carrying out a process required for BAU delivery of any aspect of the data product that needs regular production
·         Investigating objections or issues raised by users.
·         Following and instilling in junior team members the best practice guidelines, tools and formal processes for analytics practised at Quantium
·         Liaising with users of the data products, predominantly internal, to respond to queries and objections, and communicate updates relating to delivery of new features and BAU
·         Providing estimates of work effort, timeframes and costings for analytics tasks. Peer reviewing estimates developed by team members
·         Taking active steps to continuously improve own performance and drive own career development, requesting assistance as required
·         Taking active steps to drive improvement in the knowledge, capability level and quality of work of Associate Analysts and Analysts in own team
Experience and education required
To be successful in this role the key competencies required include:
 ·         Sound knowledge of technical analytics discipline, including data preparation, experiment design, feature engineering and foundational analytics concepts, descriptive analytics
·         Some specialisation is assumed – not every Senior Analyst will be conversant in every discipline, but should aim to have:
o    sufficient skills in several disciplines or techniques to autonomously apply without the need for material guidance or revision by others; and
o    sufficient skills in at least one discipline or technique to be an authoritative source of guidance and support for the team, and to be able to solve problems of a high technical complexity in this domain
·         Sound knowledge of one or more technical tools and coding languages that are used for analytics
o    A broad range is used at Quantium and the concepts are transferable, so we do not require a specific set of tools
o    However, some tools and programming languages that might qualify include (in no particular order): R, Python, SQL, Scala, Haskell, SAS, MATLAB, S-Plus, C/C++, Perl
·         Strong problem-solving skills, including ability to apply a systematic problem-solving approach
·         Solid interpersonal skills, as the role will need to work in a cross-functional team with both other analysts and specialists from non-analytics disciplines
·         Solid client and stakeholder management skills
·         Ability to autonomously carry out work following analytics best practice as defined at Quantium for the relevant types of tools or techniques, suggesting improvements where appropriate
·         Ability to motivate peers to follow analytics best practice as defined at Quantium, by positively presenting the benefits and importance of these ways of working
·         Commercial acumen to understand business needs and the commercial impacts of different analytics solutions or approaches
·         Attention to detail
·         Drive for continuous improvement
·         5-7 years’ experience in a highly technical analytics environment, carrying out data analytics or data science work
·         Tertiary qualifications in engineering, mathematics, actuarial studies, statistics, physics, or a related discipline
What does success look like?
After 3 months in the role the incumbent will:
·         be knowledgeable and able to speak confidently about Quantium’s data assets and methodologies
·         be across all the processes required to deliver against the role
·         be able to task manage the team autonomously
After 12 months in the role the incumbent will:
·         be building advanced analytical solutions into scalable data products for multiple purposes, for both product and consulting stakeholders
·         define and review methodologies, code and deliverables in line with the data product roadmap and analytical frameworks
·         Significantly contributing to Quantium’s data product development
 Key business capabilities required
1.     Data Discovery: Ability to explore the availability, suitability and compatibility of available data and assess the viability of the project/product
2.     Data Quality Assessment: Assess the fitness/ quality of the data to serve its business or operational purpose for Quantium or its clients
3.     Data Manipulation: Manipulate data effectively to improve its functional application, useability, interconnectivity, or quality
4.     Method Selection: Choose the appropriate type of analytics or modelling to best solve the problem, given all inputs and prescribed outputs
5.     Insight Generation: Convert information into meaningful, actionable recommendations for Quantium's clients and partners
 Key People and leadership capabilities required
1.     Self-aware: You have a clear perception of yourself, you take responsibility for your actions and you accept others without biases
2.     Agile & innovative: You act decisively, think nimbly, and you look for creative ways to deliver better results
3.     Achieve & perform: You have high standards of excellence and consistently deliver great results for our clients
4.     Brand advocate: You believe in what we do and speak positively about Quantium
5.     Alignment: You mobilise yourself and others towards our future direction and strategy
6.     Achievement oriented: You contribute to a culture of high performance and seek opportunities to make a difference
7.     Grow others: You naturally look to unlock the potential of yourself and others
  Apply to this job",USD 136K - 205K *
26,Senior Data Analyst,Circana,"Pune, Maharashtra, India",Senior-level / Expert,"Sr Data Analyst
Let’s be unstoppable together!
Circana (formerly IRI and NPD) is the leading advisor on the complexity of consumer behavior. Through unparalleled technology, advanced analytics, cross-industry data, and deep expertise, we provide clarity that helps almost 7,000 of the world’s leading brands and retailers take action and unlock business growth. We understand more about the complete consumer, the complete store, and the complete wallet so our clients can go beyond the data to apply insights, ignite innovation, meet consumer demand, and outpace the competition.
At Circana, we are fueled by our passion for continuous learning and growth, we seek and share feedback freely, and we celebrate victories both big and small in an environment that is flexible and accommodating to our work and personal lives. We have a global commitment to diversity, equity, and inclusion as we believe in the undeniable strength that diversity brings to our business, employees, clients, and communities (with us you can always bring your full self to work). Join our inclusive, committed team to be a challenger, own outcomes, and stay curious together. Learn more at www.circana.com
Job description
Experience:  5 years
Technical Skills
Hands on with SQL coding and scripting. This is a must have skill (primary skills)
Hands on experience in writing and optimizing SQL queries in SSMS.
Skilled in writing SQL stored procedure coding and custom functions for either derived tables or reports.
Proficient in using Tableau/ Power BI to create tabular report and visualizations. (Secondary skills)
Experience in Data analysis (familiar with Imputation, outlier detection, etc.)
Experience in working with large volumes of data
Good quantitative skills
Experience in SSRS  to create tabular/drill down reports is not mandatory but good to have.
Experience in Python , R would be good to have.
  Non-Technical Skills
Analytical ability - Must have a clear understanding and experience in extracting Insights from data
Should be familiar with CPG/Retail Domain. Familiarity with IRI/Nielsen data would be a big plus
Communication - Strong communication skills with the ability to put across discussion points/viewpoints for both technical and non-technical audiences.
Team working - Ability to work with and in cross-functional and virtual teams across locations.
Organizational awareness – Ability to see the ‘whole picture’ and recognize the impact and opportunities of activities across the organization.  
Innovation – Ability to develop innovative ways to solve complex problems, within constraints.
  Circana Behaviors
As well as the technical skills, experience and attributes that are required for the role, our shared behaviors sit at the core of our organization. Therefore, we always look for people who can continuously champion these behaviors throughout the business within their day-to-day role:
Stay Curious: Being hungry to learn and grow, always asking the big questions
Seek Clarity: Embracing complexity to create clarity and inspire action
Own the Outcome: Being accountable for decisions and taking ownership of our choices
Center on the Client: Relentlessly adding value for our customers
Be a Challenger: Never complacent, always striving for continuous improvement
Champion Inclusivity: Fostering trust in relationships engaging with empathy, respect and integrity
Commit to each other: Contributing to making Circana a great place to work for everyone
  Location
This position can be located in the following area(s): Pune/Bangalore
 ",USD 93K - 144K *
27,Deputy Manager - Pricing Analytics (Power BI),ZF Friedrichshafen AG,"Chennai, TN, IN, 600116",Senior-level / Expert," Req ID 63864 GBS Chennai, India
      Your Tasks:
•    Analyse & draw insights from large volumes of data using a deep understanding of data modelling 
•    Test & Investigate deviations to defined data manipulation methodology and propose actions to close the gap 
•    Define & manage the open actions items with the different stakeholders in the organisation
•    Consolidate data from different ERP systems & local data sources into a single usable format for pricing analytics
•    Ensure the data integrity from different systems & sourcesRespond to queries on data and liaise with pricing team to ensure data delivery in the right format
  Your Profile:
•    Successfully completed Bachelor/Master degree with Min. 8-12 years of professional experience in the area of responsibility - data analytics , Pricing and Supply chain management .
•    Strong experience in advaned Excel is a must & experience with analytics platforms like PowerBI is Mandatory ( able to write DAX queries)
•    Excellent communication & project management skills with the ability to manage cross functionally
•    Very good data manipulation & consolidation skills. Rigorous & detail-oriented when handling data
•    Knowledge of statistical modelling &/or Python programming would be a plus
    Be part of our ZF team as Deputy Manager - Pricing Analytics (Power BI) and apply now!
Contact
Priyanka Simhala",USD 45K - 84K *
28,ML Engineer,Deutsche Bank,INBLR02 - Bengaluru - Milesstone Buildcon,Mid-level / Intermediate,"Position: ML Engineer
Location: Bangalore, India
Job Summary:
As a Data Scientist at Maersk Technology Centre, you will be part of a dynamic team working on cutting-edge data-driven solutions for the global logistics and shipping industry. Leveraging your expertise in data science and machine learning, you will play a crucial role in analyzing complex data sets, deriving valuable insights, and developing predictive models to drive business decision-making.
Responsibilities:
Utilize advanced data analytics techniques to extract, process, and analyze large and diverse datasets to identify trends, patterns, and insights.
Develop and implement machine learning models and algorithms to solve business problems, optimize processes, and enhance operational efficiency.
Collaborate with cross-functional teams, including business stakeholders, data engineers, and software developers, to understand requirements and deliver scalable, data-driven solutions.
Design and conduct experiments, A/B testing, and hypothesis testing to validate model performance and improve model accuracy. Explore and adopt new data science technologies, tools, and methodologies to continuously enhance the team's capabilities.
Communicate complex technical concepts and findings to non-technical stakeholders effectively, ensuring that data-driven insights are understood and actionable.
Participate in data governance and ensure data quality, integrity, and security throughout the data science lifecycle.
Stay up-to-date with the latest developments in data science, machine learning, and artificial intelligence, and apply relevant research findings to real-world projects.
Requirements:
Bachelor's or Master's degree in Computer Science, Statistics, Applied Mathematics, or related fields. A PhD is a plus.
Proven experience (5 to 8 years) in data science, machine learning, and statistical modelling, preferably in the domain of logistics, shipping, or supply chain.
Proficiency in programming languages such as Python, R, or Scala for data manipulation, analysis, and building machine learning models.
Strong knowledge and experience with machine learning libraries and frameworks, such as sci-kit-learn, TensorFlow, or PyTorch.
Experience with big data technologies and tools like Hadoop, Spark, or Hive for processing and analyzing large datasets is desirable.
Demonstrated expertise in data visualization and data storytelling to effectively convey insights to stakeholders.
Solid understanding of data structures, database systems, and data integration techniques.
Excellent problem-solving skills, analytical mindset, and ability to work in a fast-paced and collaborative environment.
Strong communication skills, both written and verbal, to present findings and ideas clearly and persuasively.
Join our team at Maersk Technology Centre and significantly impact the future of global logistics through data-driven innovation. We offer a competitive salary, comprehensive benefits, and a stimulating work environment that fosters personal and professional growth.",USD 125K - 160K *
29,"Data Analytics - TrackWise, Veeva, Palantir Foundry",Merck Group,"Bengaluru, Karnataka, IN, 560100",Mid-level / Intermediate,"  Work Your Magic with us!  
  Ready to explore, break barriers, and discover more? We know you’ve got big plans – so do we! Our colleagues across the globe love innovating with science and technology to enrich people’s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.  
  You will support the Digital and Data Management team within Organization by using a collaborative, hands on,
analytical problem-solving based approach to facilitate data extraction and cleansing activities in various eQMS systems and monitor progress.
You will participate in projects to roll out eQA Systems (e,g, TrackWise, Veeva, Palantir Foundry…) and in regular global eQA GLU Meeting as LS representative.
  Support data extraction and analysis for business cleansing activities from various ERPs.
Support data cleansing by creating rule-based data verification programs. 
Create data sets, mappings and expressions for KPI development and extension.
Propose new KPI ideas based on available data and business requirements.
Support data enhancement and cleansing initiatives to fine tune reporting.
Support End User by sharing knowledge about data quality, scope and completeness
Perform functions on data governance - data quality, compliance, security and privacy.
Support eQA Management System development, validation and roll outs including trainings
  Who you are
  Bachelor’s degree in business (Quality/Operations/Product Management), IS, Data Analytics or related field
4 years’ experience in data analysis and quality process improvement projects
Experience in various data preparation, migration, load and maintenance processes/methods
Profound Project management skills
Demonstrated good communication, organizational, presentation skills and problem-solving capacities.
Fluency in written and spoken English
Experience in working in international teams
  Department LS-QD-D Digital Systems
   
What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
 
Apply now and become a part of our diverse team!
 ",USD 37K - 70K *
30,Data Engineer - Bigdata + Java/Scala,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
As part of Global Initiative team, We are looking for a Data Engineer to build next generation analytics and reporting platform. The successful candidate will be a well-rounded data engineer with a strong expertise and experience in building large scale applications with Big Data technologies like Hadoop, Spark, Hive, Map Reduce etc.
 Job Responsibilities:
 · Work with business partners and team members to fully understand business requirements and desired business outcomes.
· Assist in scoping and designing analytic data assets, implementing modelled attributes, and contributing to brainstorming sessions.
· Build and maintain a robust data engineering process to develop and implement self-serve data and tools for Visa’s data scientists.
· Find opportunities to create, automate and scale repeatable analyses or build self-service tools for business users.
· Implement data engineering projects ranging from small to large either individually or as part of a project team.
· Ensure project delivery within timelines and budget requirements
 Qualifications
Basic Qualifications:
· 3-4 years of relevant work experience with a bachelor’s degree or 2 years of relevant work experience with an advanced degree (e.g. Masters).
 Preferred Qualifications:
 · Relevant working experience in big data technologies: Hive, Spark, Hadoop etc.
· Knowledge of successful design, and development of data driven real time and batch systems.
· 3-4 years of development experience in one or more the following: Java, Scala.
· 2 years of relevant experience with any of the cloud technologies AWS, GCP, or Azure, preferably in an AI/ML production environment.
· Hands-on with Kubernetes/EKS is considered a significant advantage.
· Good to have working experience with messaging queue like Kafka.
· Familiarity in building large scale distributed, high performance systems in payments or other domains.
· Well versed with common software development tools, CICD, Agile methodologies and scrum practices.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 90K - 151K *
31,Senior Data Engineer,Crunchyroll Inc.,"Hyderabad, Telangana, India",Senior-level / Expert,"About Crunchyroll
WE HELP EVERYONE BELONG. IT’S OUR PURPOSE.
Founded by fans, Crunchyroll delivers the art and culture of anime to a passionate community. We super-serve over 100 million anime and manga fans across 200+ countries and territories, and help them connect with the stories and characters they crave. Whether that experience is online or in-person, streaming video, theatrical, games, merchandise, events and more, it’s powered by the anime content we all love.
Join our team, and help us shape the future of anime!
About the role
We are hiring a Senior Data Engineer to join our India Operations and play a crucial role in our mission to establish a world-class data engineering team within the Center for Data and Insights (CDI). Reporting directly to the Director of Data Engineering, you will be a key contributor, advancing our data engineering capabilities in the AWS and GCP ecosystems. Your responsibilities include collaborating with the data team and implementing various projects across data architecture, data lake infrastructure, data and ML job orchestration. Your contributions will ensure the consistency and reliability of data and insights, aligning with our objective of enabling well-informed decision-making.
The ideal candidate will demonstrate an empathetic and service-oriented approach, fostering a thriving data and insights culture while enhancing and safeguarding our data infrastructure. This role presents a unique opportunity to build and strengthen our data engineering platforms at a global level. If you are an experienced professional with a passion for impactful data engineering initiatives and a commitment to driving transformative changes, we encourage you to explore this role. Joining us as a Senior Data Engineer allows you to significantly contribute to the trajectory of our CDI, making a lasting impact on our data-centric aspirations as we aim for new heights.
Core Areas of Responsibility
Implement robust data infrastructure, platforms, and solutions by ensuring the delivery of timely data load and jobs tailored to their unique needs.
Collaborate effectively with the data team by prioritizing a service-oriented approach and quick response times.
Strong adherence to high data quality standards, KPI certification methods, and engineering best practices.
Approach reporting platforms and analytical processes with innovative thinking, considering the evolving demands of the business.
Master the different data tools, clouds (AWS, GCP) and data engineering practices in the CDI ecosystem.
Continuously improve reporting workflows and efficiency, harnessing the power of automation whenever feasible.
Enhance the performance, reliability, and scalability of storage and compute layers of the data lake.
In the role of Senior Data Engineer, you will report to the Director, Data Engineering.
We are considering applicants for the location(s) of Hyderabad.
About You
We get excited about candidates, like you, because...
5+ years of hands-on experience in data engineering and/or software development.
Skilled in programming languages like Python, Spark & SQL
Comfortable using BI tools like Tableau, Preset, and so on
Experience in managing large-scale data sets, handling Terabytes of data and billions of records effectively (across structured and unstructured datasets)
Good understanding of implementing compute and orchestration tools like Databricks, Airflow, Talend, and others.
Good experience leveraging AWS services including EMR Spark, Redshift, and S3 among others. Nice to have exposure to GCP services like BigQuery, Google Storage, Looker, Google Analytics, and so on
Nice to have experience in event data collection tools such as Snowplow, Segment, Google Tag Manager, Tealium, or mParticle, 
You holds a Bachelor's degree in Computer Science, Information Systems, or a related field, providing a strong foundational knowledge
About the Team
Center for Data and Insights (CDI) is a service oriented horizontal organization that is uniquely positioned within the company to be the trusted and unbiased source of timely data-based insights for Crunchyroll. Our vision is to inspire, support and guide our stakeholders to be data-aware and build the systems of intelligence to discover insights and act on them. We have built a highly functional organization that truly believes in being a responsive partner, with the utmost curiosity, unwavering accountability and the courage to lead with actions.
Why you will love working at Crunchyroll
In addition to getting to work with fun, passionate and inspired colleagues, you will also enjoy the following benefits and perks:
Receive a great compensation package including salary plus performance bonus earning potential, paid annually.
Flexible time off policies allowing you to take the time you need to be your whole self.
Generous medical, dental, vision, STD, LTD, and life insurance
Health Saving Account HSA program
Health care and dependent care FSA
401(k) plan, with employer match
Employer paid commuter benefit
Support program for new parents
Pet insurance and some of our offices are pet friendly!
#LifeAtCrunchyroll #LI-onsite
About our Values
We want to be everything for someone rather than something for everyone and we do this by living and modeling our values in all that we do. We value
Courage. We believe that when we overcome fear, we enable our best selves.
Curiosity. We are curious, which is the gateway to empathy, inclusion, and understanding.
Service. We serve our community with humility, enabling joy and belonging for others.
Kaizen. We have a growth mindset committed to constant forward progress.
Our commitment to diversity and inclusion
Our mission of helping people belong reflects our commitment to diversity & inclusion. It's just the way we do business.
We are an equal opportunity employer and value diversity at Crunchyroll. Pursuant to applicable law, we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Crunchyroll, LLC is an independently operated joint venture between US-based Sony Pictures Entertainment, and Japan's Aniplex, a subsidiary of Sony Music Entertainment (Japan) Inc., both subsidiaries of Tokyo-based Sony Group Corporation.
Questions about Crunchyroll's hiring process? Please check out our Hiring FAQs: https://help.crunchyroll.com/hc/en-us/articles/360040471712-Crunchyroll-Hiring-FAQs
Please beware of recent scams to online job seekers. Those applying to our job openings will only be contacted directly from @crunchyroll.com email account.",USD 121K - 186K *
32,Lead Software Engineer - Data Engineering,Freshworks,"Bengaluru, India",Senior-level / Expert,"Company Description
About Freshworks
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end user. Headquartered in San Mateo, California, Freshworks has a global team operating from 13 global locations to serve more than 65,000 companies -- from startups to public companies – that rely on Freshworks software-as-a-service to enable a better customer experience (CRM, CX) and employee experience (ITSM). 
Freshworks’ cloud-based software suite includes Freshdesk (omni-channel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshchat (AI-powered bots), supported by Neo, our underlying platform of shared services.
Freshworks is featured in global national press including CNBC, Forbes, Fortune, Bloomberg and has been a BuiltIn Best Place to work in San Francisco and Denver for the last 3 years. Our customer ratings have earned Freshworks products TrustRadius Top Rated Software ratings and G2 Best of Awards for Best Feature Set, Best Value for the Price and Best Relationship. 
Job Description
The Analytics Platform Team is looking for a Lead System/Data Engineer  who can implement the  technology roadmap in coherence with the asks from business and evolve our Platforms into cutting edge technology offerings in the industry. You will work with an energetic and talented team of engineers to own and iteratively build one or more of our platform services, while partnering with architects and Product Managers from our many Products who will directly consume your work. You will be building scalable and reliable distributed systems that are milli-second efficient, always available and working at internet scale. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. All our Data Engineers wield end-to-end ownership of their platform services - from design, to development and testing, to deployment, and all the way to nurturing the systems in production. The future includes not only new business problems to add into the mix and new levels of scale to achieve, but also the overall technology vision of the Freshworks Platform as a whole related to not just how we build but also who we build for.
Qualifications
Responsibilities
Independently able to Design, Develop, and Maintain data intensive applications
Implementing ETL pipelines to bring data from distributed data sources 
Responsible for availability, scalability, reliability, and performance of the big data system
Ensure 99.99% availability and 99.999% uptime of your production systems
Plan and execute goals, proven track record
Strong opinions on engineering best practices
Assist Product Owners with planning and roadmaps
Leads will communicate and coordinate with other teams across Freshworks
Mentoring other engineers in the team
Platform teams tend to be small but self-sufficient.  You will have a large scope of responsibilities.  They also tend not to have any QA or Ops personnel
Skills and Qualifications
Experience in building big data ETL data pipelines and Streaming applications using Spark (PySpark), Kafka and other big data frameworks.
Experience in Data Warehousing, and OLAP databases like Snowflake, Redshift, and Lakehouse architectures
Strong SQL expertise, data modeling, optimizing complex joins and database concepts
Strong programming development experience in languages like Python and Java.
Extensive experience building and operating scalable, fault-tolerant, distributed systems in the area of large scale data intensive applications.
Experience with Infra Scaling and Cost Optimizations
Strong documentation skills — translate product requirements into feasible high-level design documents with technical implementation descriptions
Strong track record with handling Production workloads and troubleshooting challenging issues
Cloud/SaaS experience
Strong analytical and problem solving skills
Minimum of 8 years relevant experience
Additional Information
Experience in Analytics and  Business Intelligence domain is a plus
Knowledge of Snowflake, Databricks, Apache Kafka, Apache Flink, Query Engines (Trino, Presto), Apache Airflow  etc. is a plus
Experience influencing product roadmaps by demonstrating the art of the possible through exploration and POCs
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 121K - 186K *
33,Data Engineer,Appen,Hyderabad,Mid-level / Intermediate,"About Appen

Appen is a leader in AI enablement for critical tasks such as model improvement, supervision, and evaluation. To do this we leverage our global crowd of over one million skilled contractors, speaking over 180 languages and dialects, representing 130 countries. In addition, we utilize the industry's most advanced AI-assisted data annotation platform to collect and label various types of data like images, text, speech, audio, and video.

Our data is crucial for building and continuously improving the world's most innovative artificial intelligence systems and Appen is already trusted by the world's largest technology companies. Now with the explosion of interest in generative AI, Appen is helping leaders in automotive, financial services, retail, healthcare, and governments the confidence to deploy world-class AI products.

At Appen, we are purpose driven. Our fundamental role in AI is to ensure all models are helpful, honest, and harmless, so we firmly believe in unlocking the power of AI to build a better world. We have a learn-it-all culture that values perspective, growth, and innovation. We are customer-obsessed, action-oriented, and celebrate winning together.

At Appen, we are committed to creating an inclusive and diverse workplace. We are an equal opportunity employer that does not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Appen is seeking a highly skilled and motivated Data Engineer to join our dynamic team. In this role, you will use your extensive knowledge of software development to build and enhance complex systems and applications, contributing to the evolution of AI and machine learning.
Key Responsibilities:
Create and maintain optimal data pipeline architecture.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Build analytics tools that utilizes the data pipeline to provide actionable insights into customer delivered data, operational efficiency and other key business performance metrics.
Optimize and improve our existing data products.
Qualifications :
Bachelor's degree in computer science, Software Engineering, or a related field. A master's degree is a plus. 
2-5 years of experience in data engineering background.
Strong programming skills in Python/Java, excellent SQL skills.
Experience with relational SQL and NoSQL databases.
Expertise in AWS services EMR, RDS, Glue, Athena, S3, Data Pipeline, Redshift, Lambda, API Gateway.
Experience with big data tools: Spark, Kafka.
Experience with data streaming systems like spark-streaming, storm.
Experience with data pipeline and workflow management tools: Airflow
Experience with shell scripting.
Ability to quickly understand and appreciate underlying business context, problems and objectives of analytical projects.
Clear communication skills to run well defined analysis and produce reports.
Excellent time management skills
Appen is the global leader in data for the AI Lifecycle with more than 25 years’ experience in data sourcing, annotation, and model evaluation. Through our expertise, platform, and global crowd, we enable organizations to launch the world’s most innovative artificial intelligence products with speed and at scale. Appen maintains the industry’s most advanced AI-assisted data annotation platform and boasts a global crowd of more than 1 million contributors worldwide, speaking more than 235 languages. Our products and services make Appen a trusted partner to leaders in technology, automotive, finance, retail, healthcare, and government. Appen has customers and offices globally. ",USD 90K - 151K *
34,Data Operation Analyst Job,Yash Technologies,"Pune, IN",Entry-level / Junior,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Apache Nifi Professionals in the following areas :
  Job Description:
  Experience required: 3-5 years
  About role
We have an opening for Data Operations Analysts, who will be responsible for working in Data Technology Team performing L1 and L2 activities and handling communication with business segments. He / She will monitor activities related to Data Flow sustenance using technologies like Informatica IICS, Apache Minifi Big Data, SQL, Unix etc. The role demands to lead by example by demonstrating a positive attitude and team focus and by sharing knowledge and expertise with team.
  The Data Operations Analysts has operational oversight for the Quality Acceptance & Production environment and the daily execution of workflows, sessions, tasks, and other data integration processes. Responsibilities includes, but are not limited to - training and supervision of system operators, review of execution statistics, managing the scheduling for upgrades to the system and application software as well as the release of data integration processes. In the event of an execution failure, the Data Operations Analyst must be able to read application logs and/or any other associated log files and should also follow pre-defined procedures(SOPs) for addressing the problem, including reinitiating the failed job(s) and/or notifying the appropriate application/solution team.
  Qualifications and Requirements
Essential qualifications
▪ Bachelor’s or master’s degree in computer science or related field.
▪ 3 to 6 Yrs. Experience in supporting operations support using Unix, Informatica IICS, BDM, Apache Nifi , Rundeck scheduler , Oracle Database.
▪ Strong Oracle SQL and Unix skills.
▪ Experience working with incident management tool – Remedy, ESM-ServiceNow.
▪ Experience working on Google Cloud / Azure Cloud is a plus.
▪ Excellent communication, verbal and written skills.
  Key competencies
▪ Has experience in the ETL operations environment.
▪ Possesses general knowledge in client/server computing environment technologies.
▪ Understands server operating systems.
▪ Strong problem-solving skills.
▪ Administrator experience in relevant operating systems is desirable.
▪ Production supervisory experience.
▪ Excellent organizational and follow-up skills.
  Good to have - skills and abilities
▪ ITIL Certification (specially for Incident Management and Problem Management).
▪ Good to have experience of supporting Informatica, Cloud eco systems.
▪ Knowledge in Power BI / Power platforms.
▪ Understanding & capabilities on Automation.
      At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 22K - 42K *
35,EY - GDS Consulting - D&A - Data Scientist - Senior,EY,"Kolkata, WB, IN, 700091",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        Job Description: Senior Data Scientist
Role Overview: We are seeking a highly skilled and experienced Senior Data Scientist with a minimum of 4 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role.
  Responsibilities:
Your technical responsibilities: 
Contribute to the design and implementation of state-of-the-art AI solutions.
Assist in the development and implementation of AI models and systems, leveraging techniques such as Language Models (LLMs) and generative AI.
Collaborate with stakeholders to identify business opportunities and define AI project goals.
Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges.
Utilize generative AI techniques, such as LLMs, to develop innovative solutions for enterprise industry use cases.
Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities.
Implement and optimize end-to-end pipelines for generative AI projects, ensuring seamless data processing and model deployment.
Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs.
Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs.
Collaborate with domain experts, stakeholders, and clients to understand specific business requirements and tailor generative AI solutions accordingly.
Conduct research and evaluation of advanced AI techniques, including transfer learning, domain adaptation, and model compression, to enhance performance and efficiency.
Establish evaluation metrics and methodologies to assess the quality, coherence, and relevance of generative AI outputs for enterprise industry use cases.
Ensure compliance with data privacy, security, and ethical considerations in AI applications.
Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications.
  Requirements:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field. A Ph.D. is a plus.
Minimum 4 years of experience in Data Science and Machine Learning.
In-depth knowledge of machine learning, deep learning, and generative AI techniques.
Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch.
Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models.
Familiarity with computer vision techniques for image recognition, object detection, or image generation.
Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment.
Expertise in data engineering, including data curation, cleaning, and preprocessing.
Knowledge of trusted AI practices, ensuring fairness, transparency, and accountability in AI models and systems.
Strong collaboration with software engineering and operations teams to ensure seamless integration and deployment of AI models.
Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions.
Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels.
Understanding of data privacy, security, and ethical considerations in AI applications.
Track record of driving innovation and staying updated with the latest AI research and advancements.
  Good to Have Skills:
Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems.
Utilize optimization tools and techniques, including MIP (Mixed Integer Programming).
Drive DevOps and MLOps practices, covering continuous integration, deployment, and monitoring of AI models.
Implement CI/CD pipelines for streamlined model deployment and scaling processes.
Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines.
Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation.
Implement monitoring and logging tools to ensure AI model performance and reliability.
Collaborate seamlessly with software engineering and operations teams for efficient AI model integration and deployment.
Familiarity with DevOps and MLOps practices, including continuous integration, deployment, and monitoring of AI models.
  EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 136K - 205K *
36,Business Intelligence Specialist IV,Rackspace,India - Remote,Mid-level / Intermediate,"JOB TITLE: Business Intelligence Specialist III/IV

 PRIMARY RESPONSIBILITY:  Works to transform large stores of data into business value by discovering, interpreting, and communicating data trends. Collects and pre-processes data for analysis. Applies data mining, statistical analysis, and modeling techniques to isolate and visualize patterns. Presents results in a readily consumable manner for non-technical personnel. Resolves technical issues and creates documentation as needed.
  KNOWLEDGE/SKILLS/ABILITY:  Strong proficiency in statistical analysis, quantitative analytics, and optimization algorithms. Advanced fluency with relational databases, SQL, Excel and business intelligence tools such as Qliksense, Power BI and Tableau. Working technical knowledge as well as demonstrated problem-solving, analytical, and troubleshooting abilities. General knowledge in several of the following: data visualization, statistics, data mining, modeling, programming, big data. Ability to learn Rackspace internal operations, structure, and systems. Working knowledge of product development life cycle and the ability to contribute testing recommendations. Ideally have comprehension of business as it relates to the hosting industry and an understanding of how related technologies are used in hosting and cloud. Intermediate presentation skills. 
  JOB COMPLEXITY: 
-      Responsible for data collection, statistical analysis, visualization, and modeling
-      Works closely with other business leaders to ensure requirements are met for building their reporting needs
-      Authoring advanced SQL to effectively query and navigate across multiple data domains to produce data analysis findings
-      Able to use complex joins, subqueries, analytical functions to return clean, comprehensive, and relevant datasets.
-      Understanding the existing database design (logical/physical) that support complex business processes/applications
-      Understand data repositories and their ETL and data management processes to include source to target mappings, business and transformation rules and data consuming systems.
-      Self-learner and eager to understand data, business processes, concepts, and technologies.
-      Strong quantitative skills, including use and analysis of large data sets, and facility with sophisticated mathematical and statistical concepts and models.
-      Highly analytic and critical mindset demonstrated by asking second and third order questions developed through exploratory data analysis
-      Fosters positive working relationships with internal stakeholder and partner groups.
  SUPERVISION: Operates under low supervision with latitude for independent judgment.


EXPERIENCE/EDUCATION:  High School diploma or equivalent required. Bachelor’s degree in statistics, mathematics, or a technology-related field plus 5 years of work experience in hands-on statistical and data analysis and programming.  Graduate degree in Statistics or a related field preferred.  At the manager’s discretion, additional relevant experience may be substituted for the degree requirement. Experienced in independently analyzing, troubleshooting and problem solving issues. Experienced in handling multiple tasks.
 PHYSICAL DEMANDS:  General office environment. Low levels of stress may occur when solving internal customer issues. May require long periods sitting and viewing a computer monitor. No special physical demands required.
   The above information has been designed to indicate the general nature and level of work performed by employees in this classification.  It is not designed to contain or to be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of the employee assigned to this job.

About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
  More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",USD 21K - 39K *
37,Senior Data Engineer,Equifax,IND-Bengaluru-Equifax Credit Information Services,Senior-level / Expert,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds,  and make a meaningful impact, we want to hear from you.
Synopsis of the role:
The Data Engineer – Data Engineering position is responsible for managing the BAU for DFKL and DF data for Consumer and commercial bureau. Also, the development and maintenance of ongoing programs/project metrics, presentations, analysis, dashboards, etc. to inform a wide variety of stakeholders.
 What you’ll do:
Designing and Building Data Infrastructure.
Data Ingestion and Integration.
Data Modeling and Database Management.
Data Transformation and Processing.
Data Security and Governance.
What experience you need:
Work location of this role (You should be willing to work from our “Mumbai / Bangalore / Pune” Office.
Bachelor Degree in Computer Science/Engineering or other related discipline.
Minimum of 4 years of data management, engineering, and/or, data analysis experience in the credit risk, financial services domain.
Proficiency in SQL and understanding of relational databases - Experience in writing Advanced SQL queries, stored.
Procedures, views, triggers and performance tuning, query and cost optimization.
Good understanding of ETL and Data Tools - Using Python/Pyspark, SQL, Apache Spark, Apache beam, Airflow and RDBMS. (SQL Server, Oracle, MySQL etc).
Understanding of data modeling and integration concepts, with the ability to design and implement data architectures.
Strong programming skills in languages such as Python, PySpark, Scala, C# or Java, with experience in data manipulation, transformation, and analysis.
Experience with big data technologies and frameworks, such as Hadoop, Spark, or Hive.
Design and build scalable and efficient data infrastructure on GCP platform.
Understanding of SDLC, data warehousing, data modeling and ETL concepts.
Familiarity with data quality and governance principles.
Excellent problem-solving and analytical skills, with the ability to identify and resolve complex data engineering challenges.
Strong collaboration and communication skills, with the ability to work effectively within a team and interact with stakeholders.
Knowledge of Agile methodology and working within an agile team.
Mandatory keywords - (SQL and Python) or (SQL and PySpark) or (SQL and Spark) or (BigQuery, Spark, PySpark, Dataflow).
Additional Keywords - ETL, Scala, Bigdata, Dataflow, Airflow, BigQuery, Apache Beam,PubSub, Dataproc, Hive, Data Warehousing , Redshift, Azure Data Factory (ADF), Data Lake, data bricks, Snowflake.
What could set you apart:
Knowledge of credit bureau data
Certification on Data Engineering, Data Science is added advantage
Knowledge on Cloud Platforms - preferably on GCP is added advantage
rtunity Employer. All qualified applicants will receive consideration for employment without
 We offer a hybrid work setting, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Primary Location:
IND-Bangalore-Equifax Credit Information Services
Function:
Function - Data and Analytics
Schedule:
Full time",USD 121K - 186K *
38,"Incentive Compensation Data Analyst I On-site, Bangalore",Optiv,"Bengaluru, Karnataka",Entry-level / Junior,"The Incentive Compensation Analyst will provide administration and on-going process improvement efforts associated with incentive compensation. This individual will be responsible for validating and reconciling all commission and bonus calculations and will work closely with various cross-functional teams to ensure the accuracy and timeliness of all incentive compensation payment and associated reporting.

How you’ll make an impact

Data Management
Analyzes incentive compensation reporting from various sources, validates data and researches all exceptions.
Utilize all reporting systems to compile data for payment calculation or analysis.
Perform audits of all data sources to confirm accuracy and functionality of system/process and manage issue resolution with appropriate teams as necessary and ensure all internal audit controls are effective.
Collaborate and assist with system integration and improvement projects.
Trouble Shooting
Provide timely responses and issue resolution, escalating as appropriate, to all inquiries from all levels of the organization.
Resolves reconciliation issues related to commission data and/or incentive payments.
Serve as Subject Matter Expert (SME) in troubleshooting and problem solving with internal departments on data and process issues.
Execute and create incentive compensation training curriculum, content, and materials.
Pay Plan Administration/Execution
Ownership of the day-to-day administration and issue resolution for incentive compensation processes.
Calculates incentive award payments to incentivized personnel based on pay plan provisions.
Performs activities needed for the design, development, implementation, communication and administration of incentive programs, plans, policies, and quotas.
Ensure accuracy and timeliness of incentive payments as outlined in the plan.
Review incentive payment reports for accuracy and completeness.
The calculation, reconciliation, and payment of bonuses on a quarterly, semi-annual, and annual basis which includes soliciting achievement against targets from business leaders and collecting appropriate approvals, as well as the reporting of bonus amounts for payroll processing and the calculating and posting of bonus accruals.
Maintenance, review, and distribution of incentive compensation plan documents on an ongoing basis, as well as communication and launch of plan components and documents for annual compensation plan updates.
Documentation of all processes and policies.
Track approvals for all non-standard adjustment requests, as required.
Administration of Anaplan or other data-collecting, calculation, and reporting tools.
Reporting
Design and implementation of reporting packages for various groups in the organization depending on business need.
Analyze sales performance results, prepare standardized calculation statements, presentations and recommendations for business leaders, Finance and/or HR.
Perform cost and/or trend analysis or modeling of alternative commission/incentive plan design or quota levels.
Continuous Process Improvement
Development or improvement of systems to effectively track or capture data.
Reduce redundant and/or manual processes wherever possible by enhancing/expanding the current system usage.
Proactively solicit and consolidate feedback from the organization.
Develop and execute incentive-compensation-related training and communication for the organization.
What we’re looking for
Bachelor’s Degree in Finance, Accounting, or Business Administration preferred
Two to three years of work experience in incentive compensation or related field preferred
Understanding of accounting principles
Preferred experience with Anaplan or other enterprise incentive compensation tool
Financial planning and analysis experience a plus
Budgeting and forecasting experience a plus
Experience working with large amounts of data
Strong communication skills, experience working in a cross-functional environment is required
Strong technical skills including, advanced Excel, with knowledge of pivot tables and complex formulas, proficiency with VBA (preferred), Word, Outlook, Anaplan, Salesforce.com and NetSuite is strongly preferred
Strong project management and problem-solving skills
Ability to be flexible, adapt and succeed in a fast-paced, dynamic environment
Strong organization skills and ability to manage daily responsibilities and prioritize duties efficiently and accurately
Must be detail-oriented
Ability to interact and build relationships with different departments to complete core responsibilities
Must be a self-motivated individual who is willing and able to take on additional responsibility and work independently with minimal supervision.
Must be an innovative thinker with a focus on long-term sustainable results for a fast-paced, growing, and dynamic organization.

If you are seeking a culture that supports growth, fosters success, and moves the industry forward, find your place at Optiv! As a market-leading provider of cyber security solutions, Optiv has the most comprehensive ecosystem of security products and partners to deliver unparalleled services. Our rich and successful history with our clients is based on trust, serving more than 12,000 clients of varying sizes and industries, including commercial, government, and education. We have the proven expertise to plan, build, and run successful security programs across Risk Management, Cyber Digital Transformation, Threat Management, Security Operations - Managed Services, and Identity and Data Management.

With Optiv you can expect
• A company committed to championing Diversity, Equality, and Inclusion through our Affinity groups including, Black Employee Network, Disabled Employee Network, Latino Employee Network, Optiv Pride (LGBTQIA+), Veterans Support Network, and Women's Network.
• Work/life balance.
• Professional training resources
• Creative problem-solving and the ability to tackle unique, complex projects
• Volunteer Opportunities. “Optiv Chips In” encourages employees to volunteer and engage with their teams and communities.
• The ability and technology necessary to productively work remote/from home (where applicable)


Optiv is an equal opportunity employer. All qualified applicants for employment will be considered without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, status as an individual with a disability, veteran status, or any other basis protected by federal, state, or local law. Optiv respects your privacy.  By providing your information through this page or applying for a job at Optiv, you acknowledge that Optiv will collect, use, and process your information, which may include personal information and sensitive personal information, in connection with Optiv’s selection and recruitment activities.  For additional details on how Optiv uses and protects your personal information in the application process, click here to view our Applicant Privacy Notice. If you sign up to receive notifications of job postings, you may unsubscribe at any time.",USD 53K - 94K *
39,Staff Data Engineer - Product Manager,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Perform market research to find global or individual market opportunities for implementing new solutions or add features to existing solutions.
Be able to compare multiple solutions and create a detailed solution analysis report from a functionality perspective.
Create an end to end business case with required validations performed, create prioritization framework for the list of business cases and checklists for business case submission (market revenue, new user growth, compliance, competency etc.)
Come up with a solution design including design mockups, RACI matric based on the product requirements, initial sizing, dependencies and feasibility assessment.
Collaborate with the engineering team to come up with effort estimates, detailed implementation plans with regular milestones releases
Be able to perform data quality checks on the solution being built
Take lead in setting up discussion with clients/regional leads for feedback, legal review and socialize with regions.
Work in collaboration with the Engineering leads to define a MVP version, Risk assessment, Initial GTM plan, UAT with end users, Internal demos and commercialization strategies.
Define performance measuring metrics, FAQ’s, user guide, define end user personas and key use cases.
Lead the Go-To-Market activities to make the solution ready for market, create sales pitch/market campaign activities, user support/training, artefacts for sales enablement and create pricing updates or new price sheets.
Own the solution enhancement process by collating the end user feedback, enhancement requests, prioritization exercises with internal and external stakeholders and plan ongoing maintenance from a business perspective
Define and own the product roadmap by creating a long term roadmap with quarterly planned short term goals with monthly review of roadmap for updates, product release calendar, etc.
Lead a 2-3 member team of Data, scientists and visualization engineers to implement the solution following the agile methodology.
Regularly monitor the solution usage, create usage reports and collect necessary information to retire the solution or identify enhancements to the solution to increase the usage
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
• 8+ years successful post college product or business experience. Masters/MBA degree is a plus.
• 3-5 years combined experience in product and building data solutions, with preferably 2-3 years in payment systems and/or financial services.
• Good business acumen to orient data analysis to business needs of clients and key stakeholders.
• Ability to translate data and technical concepts into requirements documents, business cases and user stories.
• Ability to write SQL or PySpark codes to perform both frontend and backend data validations.
• Experience working with technology teams using Agile methodologies to drive product development and delivery
• Ability to work some flexible hours due to varying time zones across Visa’s regions. We are a global product.
• Ability to work cross-functionally and influence decisions and actions without complete authority over the teams.
• Good communication and presentation skills with ability to interact with different cross-functional team members at varying levels
• Ability to prioritize, manage and deliver on multiple projects simultaneously - highly motived and able to work against aggressive schedules
• Experience gathering the ‘voice of customer’ and translating it into product feature requirements
• Superior analytical and problem-solving skills to synthesize and communicate complex information effectively
• Ability to set the vision, strategy, define success metrics and make decisions around product growth
• Skill to dissect a data file, read file specs and author both technical documentation and marketing collateral
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 186K *
40,Senior Data Scientist Engineer,Deutsche Bank,INBLR02 - Bengaluru - Milesstone Buildcon,Senior-level / Expert,"Senior Data Scientist for ISCE
Senior Data Scientist/ML Engineer with recommendation experience for visibility
Maersk, the world’s largest shipping company responsible for moving 20 % of global trade, is on a mission to become the Global Integrator of Container Logistics. To achieve this, we are transforming into an industrial digital giant by combining our assets across air, land, ocean, and ports with our growing portfolio of digital assets to connect and simplify our customer’s supply chain through global end-to-end solutions, all the while rethinking the way we engage with customers and partners.
In this role as senior data scientist/ML engineer on the Global Data and Analytics (GDA) team, you will be working on our new strategic visibility initiative to develop recommendation solutions facing internal and external users. The overall objective is to develop actionable recommendations which enable unprecedented flexibility during supply chain execution and strategic planning and unlock new types of services for our internal users and our customers. Building on top of a best-in-class visibility data foundation, you will be partnering with product managers and engineering counterparts to develop scalable solutions following industry best-practices. You will be empowered to take ownership of your domain and we expect you to proactively contribute to identifying opportunities and solutions. There is a lot of exciting challenges ahead of us, and the ideal candidate will have a passion for working on industry-transforming products and creating impact from the ground up in a fast-paced environment.
You should have demonstrated ability to make sense out of large, integrated datasets, and build statistical and machine learning (ML) models on top of these data sets. Hands-on experience developing recommendation systems and putting solutions to production in collaboration with data engineering and software engineering is crucial for this role. Furthermore, you must have demonstrated experience in initiating and leading ML projects in a dynamic, international environment. Over time, and when you are ready, we will be looking to you to take on more leadership responsibility.
No prior knowledge of logistics needed; we will help you learn what you’ll need to succeed.
Key responsibilities
Develop, test, and deploy recommendation system solutions and other analytical tools together with the team. In addition to the topics mentioned above, this can range from building integrated data sets over analyses to dashboards and machine learning models
Lead model development, implementation and deployment end-to-end incl. MLOps (mindset and technical implementation). Specifically, you will drive problem formulation, modeling approach, implementation, testing, deployment and monitoring.
Collaborate with software engineers and data engineers to deploy recommendation solutions to production
Partner with product managers to drive maturation of ideas into production solutions, including challenging problem formulation
Communicate effectively with technical and non-technical audiences
Basic qualifications
BSc/MSc/PhD in computer science, data science or related discipline with 10+ years of industry experience building cloud-based ML solutions for production at scale, including solution architecture and design experience
3+ years of hands-on experience building ML solutions in Python, incl knowledge of common python data science libraries (e.g. scikit-learn, PyTorch, etc)
Hands-on experience building end-to-end data products based on recommendation technologies
Experience with collaborative development workflow: version control (we use github), code reviews, DevOps (incl automated testing), CI/CD
Communication and leadership experience, with experience initiating, driving and delivering projects
Team player, eager to collaborate
Preferred qualifications
Experience as tech lead or engineering manager (still hands-on)
Experience with a common dashboarding technology (we use PowerBI)
Experience working in cross-functional product engineering teams following agile development methodologies (scrum/Kanban/…)
Experience with Spark and distributed computing
Strong hands-on experience with MLOps solutions, including open source solutions.
Experience with cloud-based orchestration technologies, e.g. Airflow, KubeFlow, etc
Experience with containerization: Kubernetes & Docker",USD 136K - 205K *
41,"Manager, Forward Deployed Data Strategy",Arcesium,"Hyderabad, TG, IN",Senior-level / Expert,".Arcesium seeks a highly motivated Forward Deployed Data Strategist (FDDS) to join our Client and Partner Development team in Hyderabad / Bangalore and work on client implementations for Private Markets. The candidate will be responsible for understanding the client requirements and onboard the Private Market clients’ in Arcesium platform. The candidate will also work for deep dive presentations, and proof of concept projects to help Arcesium win new business with private markets fund managers (private equity, private credit, real estate, infrastructure). The candidate should be willing to work in a dynamic and challenging environment of new client implementations into Arcesium platform and other special projects.
What You’ll do:
Develop a deep understanding and working knowledge of Arcesium’s business and functional domain, products, solutions, and the underlying technology,
Work with pre-onboarding teams like project management and other Forward Deployed teams to understand and gather the scope and client requirements.
Review and understand key fund organizational documents and operational workflows. This will be required for onboarding Implementing Private Fund’s data in to Arcesium platform.
Perform various activities like Data Mapping, data transformation, loading and reconciliation in Arcesium platform as a part of client implementations,
Liaise with various stakeholders within projects during the phases of implementation project.
Support building/enhancing the implementation tools for seamless & faster onboarding.
Work with technology teams as needed for assisting/testing in developing bespoke reports and any special requirement identified during requirement gathering phase.
Manage a team for independent execution of the implementation project.
What You’ll need:
8 to 10 years of financial industry experience along with professional certification like CA, MBA or CFA
A background in private capital markets with strong Fund Accounting / Middle Office and operations domain expertise is required.
Prior experience of client implementations/onboarding is an added advantage.
Working knowledge of various Private Fund structures, fee calculations, carried interest etc.
Well versed with GAV/NAV calculations and overall investor allocations process
Expert knowledge of Microsoft Office, including Word, PowerPoint, Visio, and Excel.  Knowledge of private equity accounting systems like Investran and is a significant plus.
A good understanding of financial products
Strong analytical & problem-solving skills.
Willingness to work in a very dynamic environment and meet tight timelines.
Arcesium and its affiliates do not discriminate in employment matters on the basis of race, color, religion, gender, gender identity, pregnancy, national origin, age, military service eligibility, veteran status, sexual orientation, marital status, disability, or any other category protected by law. Note that for us, this is more than just a legal boilerplate. We are genuinely committed to these principles, which form an important part of our corporate culture, and are eager to hear from extraordinarily well qualified individuals having a wide range of backgrounds and personal characteristics.
Arcesium's Personal Data Privacy Notice for Candidates is linked at the bottom of this page.
 ",USD 45K - 84K *
42,Senior Machine Learning Engineer,Deliveroo,"Hyderabad, India (Main Office)",Senior-level / Expert,"The Data & Science Org
At Deliveroo, we have a world-class data science organisation with a mission to enable the highest quality human and machine decision-making. We work throughout the company - in product, business and platform teams to answer some of the most interesting questions out there. For example, how do data and technology help restaurants to grow as consumer habits change? How can we predict what someone wants to order for dinner long before the idea has even crossed their mind? At Deliveroo, these are just some of the tough problems we are solving - and there is no challenge that cannot be yours. No solution is owned by a particular team, which means the scope for growth and personal impact is enormous.
Data Scientists and ML Engineers at Deliveroo report to our data science management team, and we have a strong, active data science community with guest lecturers, a robust technical review process, a career progression framework, and plenty of opportunities to learn new things.
As a Senior Machine Learning Engineer, you will play a crucial role in the development and implementation of cutting-edge artificial intelligence products. Your responsibilities will involve designing and constructing sophisticated machine learning models, as well as refining and updating existing systems. In order to thrive in this position, you must possess exceptional skills in statistics and programming, as well as a deep understanding of data science and software engineering principles.
  The Ads ML Team
We are part of the cross-functional Ads Tech at Deliveroo, a group of 20+ passionate engineers, scientists, and machine learning engineers who focus on building our internal Ad Platform, where our Partners can advertise their restaurants.
The Ads ML Team is responsible for recommending sponsored content on Deliveroo. The team strives to push the boundary of what's possible in this space, working on Click-Through-Rate estimation, Automated Bidding, Budget Recommendation and Dynamic Ads Load. Apart from excelling in complex prompt engineering, there will be a focus on developing in-house models and auction simulators, deploying models in production, and improving ML model monitoring and alerting.
We evaluate the performance of all our decision-making machines via robust experimentation powered by our world-class experimentation platform.
You will report into a Machine Learning Engineer. This is a hybrid role that can be based in either Hyderabad or Bengaluru, with some expectations to come into the office.
  What You'll Do
Work in a cross-functional team alongside engineers, data scientists specialised in analytics and inference, and product managers to develop systems that make automated decisions at a massive scale
Use frameworks such as Tensorflow to build new and improve existing machine learning models for sponsored content recommendation, automated bidding, budget recommendation, and dynamic ad load
Automate training and inference pipeline using job orchestrating frameworks such as Argo Workflow.
Mentor and coach team members on ML engineering best practices
Requirements
A master's degree in Computer Science, Mathematics, or a related quantitative discipline
5+ years' experience deploying machine learning models at scale in production environments
Proficiency in writing production-quality Python code
Familiarity with Python data science and machine learning libraries, including scikit-learn, TensorFlow, Keras, pandas, numpy, and XGBoost
Thorough understanding of best practices in MLOps
Sound knowledge of the machine learning application development life cycle, encompassing CI/CD, version control (git), testing frameworks, MLOps, agile methodologies, monitoring, and alerting
Hands-on experience in operationalising ML models and constructing ML pipelines
Proficient in exploratory data analysis, model/algorithm prototyping and selection, and model pipeline design and development
Practical experience with AWS or a comparable cloud service provider
Comfortable working with Docker and containerised applications
Familiarity with Git, GitOps practices, Argo Workflow, etc.
Familiarity with CI/CD tools such as Jenkins, CircleCI, GitHub Actions, etc.
Strong collaborative skills, able to work alongside scientists, engineers, and non-technical stakeholders
Ability to combine business acumen with the application of advanced solutions
A deep interest in staying up-to-date with the latest developments in Data Science and Machine Learning communities
A bias for simplicity and impact
Experience developing Click-Through-Rate estimation and automated bidding models
Why Deliveroo
Our mission is to transform the way you shop and eat, bringing the neighbourhood to your door by connecting consumers, restaurants, shops and riders. . We are transforming the way the world eats and shops by making access to food and products more convenient and enjoyable. We give people the opportunity to buy what they want, as they want it, when and where they want it.
We are a technology-driven company at the forefront of the most rapidly expanding industry in the world. We are still a small team, making a very large impact, looking to answer some of the most interesting questions out there. We move fast, value autonomy and ownership, and we are always looking for new ideas.
Workplace & Benefits
At Deliveroo we know that people are the heart of the business and we prioritise their welfare. Benefits differ by country, but we offer many benefits in areas including healthcare, well-being, parental leave, pensions, and generous annual leave allowances, including time off to support a charitable cause of your choice. Benefits are country-specific, please ask your recruiter for more information.
Diversity
At Deliveroo, we believe a great workplace is one that represents the world we live in and how beautifully diverse it can be. That means we have no judgement when it comes to any one of the things that make you who you are - your gender, race, sexuality, religion or a secret aversion to coriander. All you need is a passion for (most) food and a desire to be part of one of the fastest-growing businesses in a rapidly growing industry.
We are committed to diversity, equity and inclusion in all aspects of our hiring process. We recognise that some candidates may require adjustments to apply for a position or fairly participate in the interview process. If you require any adjustments, please don't hesitate to let us know. We will make every effort to provide the necessary adjustments to ensure you have an equitable opportunity to succeed.",USD 150K - 232K *
43,"Principal Machine Learning Engineer - Spark, ETL, Pre-Processing, Pipeline, Machine Learning - REF7856R",Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
  Responsibilities:
At the Premier Cloud Security Provider, we are working with the massive scale of network data, security data, and enterprise data every day. We are seeking out engineers with a passion to build out tools and platforms, process and analyze data at scale, and solve real-world business problems.
As a software engineer for our Machine Learning platform, you have three main responsibilities:
You will architect, build and maintain large-scale distributed systems to support the whole pipeline including data collection, feature engineering, model training, model evaluation, model deployment, and real-time serving.
You will apply analytical and math/statistics skills to stay on top of data and to ensure results are coherent and reliable.
You will solve complex real-world business problems (e.g., threat detection, automation, and business intelligence) by working closely with various stakeholders including data scientists, product management, and product engineering teams.
You may not have any prior data science and ML background but you need to have a desire in building up knowledge in this area. For example, we expect you to have tremendous curiosity in how the data can and will be utilized by the data scientist in order to have a very effective collaboration with data scientists.
Required Skills:
- 15+ years of prior work experience as a Software Engineer or ML platform engineer
- Very strong algorithm and programming skills in building out data collection/processing infrastructure, Machine Learning model training, and serving platforms
- Very strong Python and SQL scripting skills
- 10+ year of experience using distributed data processing such as Spark, BigQuery or Apache Beam
- 10+ year of experience with event messaging such as Kafka, RabbitMQ, etc
- 10+ years of experience working with Docker, Kubernetes
- Ability to learn, evaluate and adopt new technologies
- BS Degree in Computer Science or related field
  Desirable Skills:
- Experience with Go, C++, or Javascript
- Experience with setting up SQL/NoSql database such as Postgres, MongoDB, Redis, and table schema
- 5+ year of experience with ML automation platforms such as Kubeflow, Airflow or MLFlow
- Experience with data serialization techniques and data stores for persisting events
- Experience with Google cloud (or other public cloud)
- Experience with building quality software by writing robust interfaces, considering design principles, and applying sound testing practices
- Ability to lead and execute projects from start to finish
- Knowledge of NLP/Text mining techniques and related open-source tools
- Familiarity with networking and networking security
- Excellent interpersonal, technical, and communication skills
- Advanced degree in Machine Learning, Computer Science, Electrical Engineering, Physics, Statistics, Applied Math or other quantitative fields from a reputed university (Ph.D. a plus)
    #LI - AN4
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 150K - 232K *
44,AWS Data Engineer,NTT DATA,"Bengaluru, Whitefield, KA, IN",Mid-level / Intermediate,"  Req ID: 265853 
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a AWS Data Engineer to join our team in Bangalore, Whitefield, Karnātaka (IN-KA), India (IN).
As an AWS Data Engineer, you will contribute to our client and will have the below responsibilities:
Work with technical development team and team lead to understand desired application capabilities.
Candidate would need to do development using application development by lifecycles, & continuous integration/deployment practices.
Working to integrate open-source components into data-analytic solutions
Willingness to continuously learn & share learnings with others
Required:
5+ years of direct applicable experience with key focus:
Glue and Python; AWS; Data Pipeline creation
Develop code using Python, such as o Developing data pipelines from various external data sources to internal data.
Use of Glue for extracting data from the design data base. Developing Python APIs as needed
Minimum 3 years of hands-on experience in Amazon Web Services including EC2, VPC, S3, EBS, ELB, Cloud-Front, IAM, RDS, Cloud Watch.
Able to interpret business requirements, analyzing, designing and developing application on AWS Cloud and ETL technologies
Able to design and architect server less application using AWS Lambda, EMR, and DynamoDB
Ability to leverage AWS data migration tools and technologies including Storage Gateway, Database Migration and Import Export services.
Understands relational database design, stored procedures, triggers, user-defined functions, SQL jobs.
Familiar with CI/CD tools e.g., Jenkins, UCD for Automated application deployments
Understanding of OLAP, OLTP, Star Schema, Snow Flake Schema, Logical/Physical/Dimensional Data Modeling.
Ability to extract data from multiple operational sources and load into staging, Data warehouse, Data Marts etc. using SCDs (Type 1/Type 2/ Type 3/Hybrid) loads.
Familiar with Software Development Life Cycle (SDLC) stages in a Waterfall and Agile environment.
Nice to have:
Familiar with the use of source control management tools for Branching, Merging, Labeling/Tagging and Integration, such as GIT and SVN.
Experience working with UNIX/LINUX environments
Hand-on experience with IDEs such as Jupiter Notebook
Education & Certification University degree or diploma and applicable years of experience
  About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",USD 24K - 44K *
45,"Big Data Engineers (Airflow, Python, Spark)",Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the Role

- You’ll be working within an international group of teams which span from the US till India. This group is responsible for building our Audience Builder application and components which is part of Nielsen’s Advanced Audiences in the Nielsen ONE product suite. Your specific team will be responsible to build data pipelines, services and UIs to support our complex entitlement needs for our current and future web applications.

- As a Software Data Engineer you will be responsible for data pipelines to work on both scheduled and real time use cases.  Schedule pipelines run typically in Airflow and real time processing could be airflow or integrated querying in backend services. 
Responsibilities
Work closely with team leads and backend developers to design and develop functional, robust pipelines to support internal and customer needs.
Write both unit and integration tests, and develop automation tools for daily tasks.
Develop high quality, well documented, and efficient code.
Manage and optimize scalable pipelines in the cloud.
Optimize internal and external applications for performance and scalability.
Develop automated tests to ensure business needs are met, and write unit, integration, or data quality tests.
Communicate regularly with stakeholders, project managers, quality assurance teams, and other developers regarding progress on long-term technology roadmap.
Recommend systems solutions by comparing advantages and disadvantages of custom development and purchased alternatives.
Key Skills (Domain Expertise)
2+ years of experience as a software/data engineer.
Bachelor’s degree in Computer Science, MIS, or Engineering.
Technical SKills
Experience with database systems, with knowledge of SQL and NoSQL stores (e.g. MySQL, Oracle, MongoDB, Couchbase, etc.)
Experience developing sophisticated data driven software platforms.
Experience with relational databases and/or analytical data stores (e.g., Spark, Presto, Pandas).
Experience delivering, supporting enterprise software.
Experience with cloud service technologies, ex: AWS.
Experience with container technologies, ex: Docker.
Experience with source control systems, ex: GIT.
Information visualization.
""Big data"" systems and analysis.
Experience with data warehouses or data lakes.
Mindset and Attributes
Strong communication skills with ability to communicate complex technical concepts and align organization on decisions.
Sound problem-solving skills with the ability to quickly process complex information and present it clearly and simply.
Utilizes team collaboration to create innovative solutions efficiently.",USD 30K - 56K *
46,Power BI Data Analyst,Bosch Group,"Bengaluru:, India",Entry-level / Junior,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Proficient towards creating and maintaining internal dashboards.Understanding and resolving internal customer issues with regards to reporting tasks.Perform internal checks for data quality.Responsible for building data models, analyzing/optimizing datasets and building reports.Managing supplier surveys for sustainability topics.Driving operational and functional improvements in the reporting area. Excellent analytical, interpersonal and problem solving skills.Handling of multiple stakeholders globally across the organization and divisions.
Qualifications
B.E graduate or other degree in IT background
Additional Information
3-5 years of relevant experience, Microsoft Power BI Data Analyst certification is an advantage (PL-300), Good knowledge of power-bi (other reporting tools), Microsoft office, SAP and IT tools (RB-SRM, etc), Experience in reporting tasks.",USD 50K - 72K *
47,"Data Engineer, Analyst",BlackRock,HA3-Gurgaon - DLF Cyber City,Mid-level / Intermediate,"About this role
The DataOps Engineering team builds and maintains a cutting-edge data platform that provides quality data to all users such as investors, operations staff, data scientists, Aladdin applications and engineers. Our goal is to provide highly available, consistent data of the highest quality to our clients, while evolving our platform to deliver exponential scale to the firm and powering the future growth of Aladdin. We engineer high performance data pipelines, provide a fabric to discover and consume data and continually evolve our data storage capabilities.
Front-end Engineering
Our Front-end team within DataOps Engineering builds web and Java applications across our market data and portfolio analytics pipelines and workflows. We enable over a thousand internal users supporting data operations as well as users at hundreds of clients. The team is responsible for the data management toolkit including ETL pipeline configuration tools, CRUD applications for core data maintenance, data quality inspection tools, customized client request workflows, and back-end APIs to support Aladdin. The key mission for the team is to enable operations teams to deliver high quality data at scale with intuitive tools and a great UX.
Job Description and Responsibilities:
Design, build, and maintain various front-end and corresponding back-end platform components, working with Product and Program Managers.
Implement new user interfaces and business functionalities to meet evolving business and customer requirements, working with end users, with corresponding clear and concise documentation.
Analyze and improve performance of applications and related operational workflows to improve efficiency and throughput.
Diagnose, research, and resolve software defects. • Ensure software stability via documentation, code reviews, regression, unit and user acceptance testing for smooth production operations.
Oversee level 2&3 application support ensuring smooth operation of existing processes, and new business opportunities are being met.
Be a self-starter and work with minimal direction in a globally distributed team
Role Essentials:
A passion for engineering highly available, performant full stack applications with a “Student of Markets and Technology” attitude
2+ years of professional experience working in teams or a fresher with extraordinary skillset.
Bachelor’s / master’s degree in computer science or engineering or a related field.
Experience in full-stack user-facing application development using web technologies (Angular 10+ ecosystem), Java Swing, and Java based REST API (Spring framework),
Experience in testing frameworks such as Protractor, TestCafe, Jest.
Experience crafting wireframes for prototyping UX.
Knowledge of relational database development or NoSQL Database.
Knowledge of Object Oriented Analysis and Design with Design Patterns.
Knowledge of software development methodologies (analysis, design, development, testing) and basic understanding of Agile / Scrum methodology and practices.
Passion to work in a team-environment, multi-tasking and effective communication skills are a must.
Excellent analytical, problem-solving, and debugging skills.
#EarlyCareers
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 90K - 151K *
48,Technology Specialist- Solution / Data Architect,Deutsche Bank,Pune - Business Bay,Senior-level / Expert,"Job Description:
Job Title- Technology Specialist (Solution / Data Architect)
Location- Pune
Role Description
About DWS:
Today, markets face a whole new set of pressures – but also a whole lot of opportunity too. Opportunity to innovate differently. Opportunity to invest responsibly. And opportunity to make change.
Join us at DWS, and you can be part of an industry-leading firm with a global presence. You can lead ambitious opportunities and shape the future of investing. You can support our clients, local communities, and the environment.
We’re looking for creative thinkers and innovators to join us as the world continues to transform. As whole markets change, one thing remains clear; our people always work together to capture the opportunities of tomorrow. That’s why we are ‘Investors for a new now’.
As investors on behalf of our clients, it is our role to find investment solutions. Ensuring the best possible foundation for our clients’ financial future. And in return, we’ll give you the support and platform to develop new skills, make an impact and work alongside some of the industry’s greatest thought leaders. This is your chance to achieve your goals and lead an extraordinary career.
Team / division overview
 The COO Division is a key enabler for DWS and is integral to the future success of the company by delivering world-class services across a set of key functions. It covers essential Technology and Operations capabilities, including our data programs and digital transformation. The COO aims to deliver a platform which is efficient, scalable, resilient and agile.
Within the COO Division Data Management is responsible for designing and driving the execution of the data strategy at Group and Divisional/functional level as well as coordinating adherence to Data related processes and policies and any applicable local regulations.
What we’ll offer you
As part of our flexible scheme, here are just some of the benefits that you’ll enjoy
Best in class leave policy
Gender neutral parental leaves
100% reimbursement under childcare assistance benefit (gender neutral)
Sponsorship for Industry relevant certifications and education
Employee Assistance Program for you and your family members
Comprehensive Hospitalization Insurance for you and your dependents
Accident and Term life Insurance
Complementary Health screening for 35 yrs. and above
Your key responsibilities
As a Data Architect you will:
Own a selection of domains within the (logical) Enterprise Data Model (EDM) including all relations
Partnering with the Head of EDM & Information Domain to model DWS' core EDM and derive logical EDM as well as assure general schemas derived will also adhere to and meet overall EDM requirements (e.g. deriving context specific schemas in JSON, AVRO, RDBM), protocols for exchange of data between systems (e.g. in context critical points of data exchange)
Review, improve and implement an updated version of DWS' EDM and support the architecture, data governance and data quality teams to implement new Data Governance and Data Quality management platforms that the (new) EDM needs to be integrated with
Ensure that the EDM is properly integrated within the information domain.
Partner with key stakeholders to model data at source systems that aligns with the EDM
Create and maintain conceptual, logical, and physical data models using best practices to ensure high data quality and reduced redundancy, along with corresponding metadata
Improve and deliver architecture that considers data acquisition, data flow in an event driven architecture / environment, data integrity by design, data archival and discovery, data flow monitoring and alerting, data transformation, data ingestion and consumption as well as defining common patterns for any of these to guide engineering teams to deliver against this architecture
Working across multiple business lines to influence, identify, evaluate and recommend potential objectives to support the delivery of data architecture solutions
Ensure that solutions around metadata captured around the EDM will drive operational excellence in managing, governing and quality assuring data within DWS
Your skills and experience
Strong experience in Enterprise Data Modelling and Architecture especially in an event driven, micro-services based environment
Strong experience in data modelling (0NF, 3NF, Data Vault 2.0, Snowflake / Star, Multi-Dimensional) and able to explain Pros/Cons of each based on requirements
Experience in conceptional, logical and physical modelling using platforms such as PowerDesigner
Very good understanding of RDBMS, i.e. SQL Server, PostgreSQL and Oracle
Experience working with NoSQL/Document Store systems
Good technical understanding of messaging technologies such as Kafka, Google Pub/Sub
Good technical understanding of transport formats such as JSON, AVRO
Extensive experience in architecture standards and methodologies such as TOGAF, SAFe
An understanding of applicable technology/digital regulations such as KAIT, BAIT, DORA would be beneficial
Flexible team player with experience in working in distributed, global environments and teams
Strong conceptual and problem-solving skills, with an ability to develop creative and structured solutions
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 115K - 193K *
49,"Principal Data Engineer (Python, AWS)",Verisk,"Hyderabad, India",Senior-level / Expert,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
Accountable for leading application development supporting business objectives while demonstrating independence in software development lifecycle phases from concept and design to testing.
Lead new and existing applications along with enhancements to applications and infrastructure.
Perform hands-on coding while designing and architecting data processing and analytics solutions.
Serve as a liaison to internal customers, research groups and various business support areas.
Provides technical guidance to junior programmers and other software engineers.
Ability to troubleshoot and maintain mid-level to complex applications.
Completes all responsibilities as outlined on annual Performance Plan.
Completes all special projects and other duties as assigned.
Must be able to perform duties with or without reasonable accommodation.
 Requirements:
8+ years of proven experience in software development and system maintenance.
Highly proficient experience and understanding in the following technologies: Python 2/3, Linux, AWS, OLTP and OLAP databases, any Data Warehouse
Ability to learn and adapt to continuously changing technology.
Demonstrated experience with N-tiered applications and multi-tier architecture.
Highly experienced at developing elegant-yet-simple systems using best practices and design patterns.
Highly experienced with multi-threading, memory management, networking, I/O concepts, and performance aspects of common classes and algorithms.
RDBMS based on MPP/Cluster, Jupyter, Docker, Kubernetes, Spark, Git, CI/CD.
Experience with any of the following technologies a plus: Snowflake (DBaaS), Greenplum.
Highly experienced at leading teams, interacting with business partners or customers, and guiding project direction.
Excellent understanding of object-oriented design concepts and software development processes and methods.
Superior organization skills, skilled at recognizing priorities and keeping a team focused most important features.
Must have passion for development and latest technologies
Leadership and ability to guide design and technical meetings
Demonstrated ability to work independently with minimal supervision.
.NET and Angular experience desirable
Tableau/Tableau server experience desirable
Qualifications
Requirements:
8+ years of proven experience in software development and system maintenance.
Highly proficient experience and understanding in the following technologies: Python 2/3, Linux, AWS, OLTP and OLAP databases, any Data Warehouse
Ability to learn and adapt to continuously changing technology.
Demonstrated experience with N-tiered applications and multi-tier architecture.
Highly experienced at developing elegant-yet-simple systems using best practices and design patterns.
Highly experienced with multi-threading, memory management, networking, I/O concepts, and performance aspects of common classes and algorithms.
RDBMS based on MPP/Cluster, Jupyter, Docker, Kubernetes, Spark, Git, CI/CD.
Experience with any of the following technologies a plus: Snowflake (DBaaS), Greenplum.
Highly experienced at leading teams, interacting with business partners or customers, and guiding project direction.
Excellent understanding of object-oriented design concepts and software development processes and methods.
Superior organization skills, skilled at recognizing priorities and keeping a team focused most important features.
Must have passion for development and latest technologies
Leadership and ability to guide design and technical meetings
Demonstrated ability to work independently with minimal supervision.
.NET and Angular experience desirable
Tableau/Tableau server experience desirable
#LI-NK1
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 121K - 186K *
50,Customer Analytics / Data Science - Manager - Analytics,dentsu international,"Bengaluru, India",Mid-level / Intermediate,"Company Description
About Merkle
Merkle, a dentsu company, is a leading data-driven customer experience management (CXM) company that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The company’s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive hyper-personalized marketing strategies. Its combined strengths in consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions drive improved marketing results and competitive advantage. With more than 14,000 employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the Americas, EMEA, and APAC. For more information, contact Merkle at
1-877-9-Merkle or visit www.merkle.com.
Job Description
Job Description
Roles & Responsibilities
Manage multiple clients and teams
Build advanced machine learning models for Media Mix and Multi-Touch Attribution
Turn complex data and models into practical and actionable marketing insights
Support development of efficient and accurate project management plans for project delivery
Need to have strong understanding of analytical solutions
Analytics work, starting from data gathering, cleaning,transforming, building machine learning models & model validation
Strong work ethic and drive to learn as much as possible within the digital marketing space
Mentor and up-skill team on the analytics consulting career roadmap
Spot opportunities that could potentially generate new business for Merkle within existing and new client accounts
Support campaign strategy and planning with audience insights analysis, sizing and research using tools
Document best practices and seek out opportunities to improve existing processes
Manage campaign timelines and deliverables across internal and external teams
 Qualifications
Qualifications/Certifications:
- BE/ B.Tech, ME/MTech (Computer Science)
- Advanced degree in a quantitative discipline, preferably Mathematics/Statistics or similar will be an added advantage
Additional Information
Mandatory (top 5)                                                     
SQL (Expert), Python (Intermediate)                                                  
Visualization/BI Tools – (At least one out of Tableau, LookerStudio, PowerBI, Dataroma)                                                    
Statistical Modelling knowledge - Regression, Time-Series, Clustering      
Advanced Excel & Powerpoint                                              
EDA Analysis / business insights recommendations                                                    ",USD 110K - 223K *
51,Economic Data Lead,Swiss Re,"Bengaluru, KA, IN",Senior-level / Expert,"About the role
  The role of Economic Data Lead (based in Bangalore), in Group Economic & Sigma Research is an excellent opportunity for you to work on data-related projects with a tangible business impact. This role sits within a high-calibre and motivated international team that focuses on economic and insurance research and forecasts for Swiss Re. The role is a unique, broad and exciting professional growth opportunity and an excellent steppingstone within the company with frequent exposure to senior management and other teams across the Group.
  In this role, you will be the business owner and manage the GESR data infrastructure. This includes leading the project to upgrade the in-house database for storing economic and insurance market forecasts, as well as overseeing data collection, storing and distribution either directly or through connected data assets of other teams within GESR. As such, team work and project management skills will be important in order to closely liaise with stakeholders for smooth functioning of all data assets. You should expect a dynamic working environment and should be able to demonstrate flexibility, adaptability and autonomy in your daily work.
  Key tasks and responsibilities include:
You will be one of the key points of contact for all data related queries in GESR.
You are expected to quickly understand the GESR data infrastructure landscape, including the in-house database. You should also pro-actively look for opportunities to improve the data infrastructure including better ways of collecting, storing and distributing data.
For the in-house database, you'll be required to do the day-to-day management of it, as well as lead the project to upgrade it from the current Fame-based database to a new, better, lean, efficient and user-friendly database option.
As part of the above point, you will need to communicate business needs to IT, provide inputs and guidance to IT where required and supervise and monitor the implementation of solutions by IT. You will also need to closely liaise and collaborate with other stakeholders (e.g. data providers, users in other teams) for smooth functioning of all data assets.
Continuously monitor the broader data infrastructure and fix any possible issues in advance, to ensure that users are not impacted.
Oversee data collection, storing and distribution either directly or through connected data assets of other teams.
Assist economic and insurance research colleagues in their data projects - these projects may be related to quantifying and modelling the impact of economic risks, climate change, energy prices, health care reform, mortality, etc. on economy, insurance and reinsurance industry.
Manage and deliver all data projects and other tasks to completion with minimal supervision/guidance and have good interpersonal and communication skills.
You will work in a cross functional team in Bangalore reporting to GE&SR Bangalore Hub with a functional reporting to GESR Economist Data Lead
  About the Team:
    Group Economic & Sigma Research (GESR) is part of the Risk Management and is responsible for analysing and forecasting the global macroeconomic and insurance market environment. GESR holds a crucial role in steering Swiss Re's capital allocation for both sides of the balance sheet. The team also drives thought leadership on topics of strategic importance for the Group and helps shaping the policy dialogue and outcome. GESR is responsible for Swiss Re's flagship sigma publication series.
  GESR is highly visible and interacts with a wide variety of key partners and decision makers across the organization and externally. We are a truly global team located in Zurich, New York, Hong Kong and Beijing and collaborate closely with all of Swiss Re's re/insurance business units and Group functions.
Swiss Re embraces diversity and equal opportunity. We are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. We further collaborate in a flexible working environment, providing all of our employees with a compelling degree of autonomy to decide how, when and where we work most effectively.
  Key tasks and responsibilities include:
    An advanced (minimum masters) degree in economics, insurance, statistics or other finance disciplines with at least 3 years of applicable work experience.
Hands on experience of econometric analysis, financial analysis, quantitative modelling, economic research and/or business consulting. Insurance experience and industry certifications would be an added advantage.
Intermediate to advanced econometric and programming skills such as R/Python/Stata/Matlab/EViews/VBA, is a must. R is preferred over the others
IT skills will be an added advantage and intermediate knowledge of one or more of the major operating systems such as Unix/Linux OS, would be preferred.
Proficiency in MS Office applications (Excel, PowerPoint, Word). Knowledge of advanced excel (VBA, excel macros) and databases (MS Access, SQL and 4GLs) preferred.
Hands on experience on tools/databases like Bloomberg, AM Best, Datastream, CEIC, Factiva, Capital IQ, Power BI, Tableau, etc.
Independent and able to operate with minimal level of guidance, while collaborating with stakeholders across the organization, especially from different global locations.
Team player, comfortable working with colleagues across all different levels, experience in training and mentoring new team members is also preferred
Strong analytical skills and ability to think strategically and steer & deliver high quality deliverables.
Excellent written and verbal communication skills in English.
Internationally focused and highly motivated with a can-do attitude; dedication to continuous learning and willingness to challenge and improve the status quo
Very agile, open-minded and curious personality with ability to work under tight timelines
Mature and proactive; showing a high degree of own initiative
Ability and enthusiasm to work in a global and multicultural environment
          About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 128009 
   ",USD 80K - 200K *
52,Data Analyst,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About the role:
The Global Product Management (GPM) organization is responsible for business performance of all research products. The Research Business Analytics (RBA) team is part of GPM and performs analysis related to all aspects of Gartner’s Research. This includes client value drivers: Research content, research interaction, and the research role in conferences and events. RBA also supports the Research & Advisory (R&A) organization by enabling and performing analysis running from client retention analytics, associate performance analytics, budget and financial analysis (in partnership with the finance organization), and client demand sensing.  We power fact-based decision making by providing data, insights, and analytic tools to continuously improve our business – operationally and strategically.
We are looking for a Data analyst who has a passion for analytical problem solving to be part of our growing team. This individual will solve a wide range of problems related to content analytics, and interaction analytics, demand sensing, staffing models, cost reporting, automation, standard reporting, and ad-hoc analytics.  Initial projects are likely to focus on Client Demand Sensing and aligning Research & Advisory expert staffing to areas with the largest economic opportunity.  Individuals in this role will work closely with Research Business Analytics leadership to structure problems, identify data sources, perform analysis, and communicate findings.  Strong performers will build skills to independently own project workstreams and interact with stakeholders. Projects will include a mix of team problem solving and independent problem solving. Some projects will also involve automation and collaboration with the Information Technology team.
What you will do: 
Partner with GPM and RBA colleagues to do analysis that surfaces actionable insight for the Research & Advisory organization. Effectively communicate findings to drive adoption and implementation. Build dashboards and reporting
Project ownership: Contribute to key projects following rollout plan, success criteria and metrics
Domain expertise: Become a deep subject-matter expert on Gartner’s data, analytic tools, reports & data infrastructure.  Take responsibility for problem solving, root cause analysis, and devising testing methodologies for validation and articulately explaining data sources to senior audiences
Continuous improvement: Support and enable  improvement initiatives related both to RBA deliverables (e.g. new, innovative data sources, analytic insights, tools) as well as operational process improvement (e.g. improving RBA processes and communications)
Collaborate with the Information Technology team and data scientists to ensure data quality, integrity, and consistency
What you will need:
Experience: 2+ years of experience involving analysis of large volumes of data with strong hands-on experience with analytical tools.  Ability to gather, analyze, restructure, identify and articulate insights from qualitative and quantitative data
Education: Bachelor’s Degree, preferably with a quantitative concentration (e.g., statistics, data science, mathematics, engineering, operational research, computer science, or economics)
Exceptional problem solving: Proven track record of solving complex problems, thinking creatively, and using data to tell a story
Leadership: Shown ability to engage teams and key stakeholders
Technical competency: Advanced Excel. Intermediate SQL, Python/R
Collaboration: Strong collaboration and influencing
Communication: Strong verbal and written communication as well as the ability to work independently
What you will get:  
Competitive salary, generous paid time off policy, charity match program, Medical, Dental & Vision Plans, Parental Leave, Employee Assistance Program (EAP), 401K matching and more!
Collaborative, team-oriented culture that embraces diversity 
Professional development and unlimited growth opportunities
#LI-PM3
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:83906
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 67K - 110K *
53,IND (New) Lead Data Engineer,Quantium,"Hyderabad, Telangana, India",Senior-level / Expert,"Location: Hyderabad,Telangana,India
Since 2002, Quantium have combined the best of human and artificial intelligence to power possibilities for individuals, organisations and society.
Our solutions make sense of what has happened and what will, could or should be done to re-shape industries and societies around the needs of the people they serve. 
As one of the world’s fully diversified data science and AI leaders we operate across every sector of the economy and we’re growing fast - with growth comes opportunity!
We’re passionate about building out our team of smart, fun, diverse and motivated people.
We combine a team of experts that spans data scientists, actuaries, statisticians, business analysts, strategy consultants, engineers, technologists, programmers, product developers, and futurists – all dedicated to harnessing the power of data to drive transformational outcomes for our clients.
We actively foster a culture where our people can stretch themselves to reach their full potential.
We also know that work has to work for you, and modern life is fast-paced and balance can be tricky. You want to work where you are respected and valued as an individual, not a number.
Quantium embraces a flexible and supportive environment dedicated to powering possibilities for our team members, clients and partners.
Role summary
As a Lead Data Engineer you will be accountable for the enhancement, maintenance and support of the product on which your team is working, within your technology area.
You will be responsible for your own hands-on coding, ensuring the quality of your team’s output, representing your team in product-level forums and ensuring your team provides input to and aligns with the overall product road-map.
You will work with Engineers in other technology areas to define the overall technical direction for the product, with product owners and business stakeholders to shape the product's delivery road-map and with support teams to ensure its smooth operation.
You will also be responsible for line management of your team of Engineers, potentially across multiple locations, ensuring that they perform to the expected levels and that their career development is fully supported.
As a Lead Data Engineer you will be responsible for developing readable, maintainable and efficient code to realise user stories that deliver the product road-map. You will be accountable for coordinating Engineers and other stakeholders in breaking down large epics into collections of smaller stories / tasks and in implementing the overall functionality.
Key responsibilities
Produce Quality Code
Code follows team standards, is structured to ensure readability and maintainability and goes through review smoothly, even for complex changes
Designs respect best practices and are favourably reviewed by peers
Critical paths through code are covered by appropriate tests
High-level designs / architectures align to wider technical strategy, presenting reusable APIs where possible and minimizing system dependencies
Data updates are monitored and complete within SLA
Operate at a High Level of Productivity
Estimates are consistently ‘challenging, but realistic’
Most tasks are delivered within estimate
Complex or larger tasks are delivered autonomously
Squad Collaboration
Sprint goals are consistently achieved
Demonstrate commitment to continuous improvement of squad activities
The product backlog is consistently well-groomed, with a responsible balance of new features and technical debt mitigation
Other Engineers in the Squad feel supported in their development
Key activities
Write polished code, aligned to team standards, including appropriate unit / integration tests
Review code and test cases produced by others, to ensure changes satisfy the associated business requirement, follow best practices, and integrate with the existing code-base
Provide constructive feedback to other team members on quality of code and test cases
Collaborate with other Lead / Senior Engineers to produce high-level designs for larger pieces of work
Validate technical designs and estimates produced by other team members
Merge reviewed code into release branches, resolving any conflicts that arise, and periodically deploy updates to production and non-production environments
Troubleshoot production problems and raise / prioritize bug tickets to resolve any issues
Proactively monitor system health and act to report / resolve any issues
Provide out of hours support for periodic ETL processes, ensuring SLAs are met
Work with business stakeholders and other leads to define and estimate new epics
Contribute to backlog refinement sessions, helping to break down each epic into a collection of smaller user stories that will deliver the overall feature
Work closely with Product Owners to ensure the product backlog is prioritized to maximize business value and manage technical debt
Contribute to work breakdown sessions to define the technical tasks required to implement each user story
Contribute to sprint planning sessions, ensuring the team takes a 'realistic but challenging' amount of work into each sprint and each person is productively occupied
Contribute to the team’s daily stand-up, highlighting any delays or impediments to progress and proposing mitigation for those issues
Contribute to sprint review and sprint retro sessions, to maintain a culture of continuous improvement within the
Coach / mentor more junior Engineers to support their continuing development
Identify each direct reports' longer-term career objectives and, as far as possible, factor this into work assignments
Conduct technical interviews as necessary to recruit new Engineers
Experience and education required
8+ years’ experience designing and implementing data warehousing solutions in a large commercial environment using Microsoft SQL Server (T-SQL, SSIS)
Expertise in performance analysis, query and workload tuning, index optimization, etc.
Confident working with very large, complex data-sets
Solid understanding of database design and dimensional modelling principles (Kimball)
Experience using Visual Studio 2013+ with SSDT
1+ years' experience developing at scale applications using Scala
Proven experience manipulating large data-sets using Spark
Good foundation in functional programming and data structures
Values delivering high-quality, peer-reviewed, well-tested code
Awareness of DevOps functions and appetite to contribute to CI / CD pipelines
Knowledge of SSAS/MDX and cloud based data warehousing solutions is a plus
Experience working with source control tools (GIT preferred) with good understanding of branching / merging strategies
Bachelor’s degree in Computer Science, Information Technology or a related discipline
Comfortable working in a fast moving, agile development environment
Excellent problem solving / analytical skills
Good written / verbal communication skills
Commercially aware, with the ability to work with a diverse range of stakeholders
Apply to this job",USD 121K - 186K *
54,AI Solutions Engineer,Intel,IND - Bengaluru,Mid-level / Intermediate,"Job Details:
Job Description: 
Influences and advocates technical abilities of Intel based products and solutions for Intel's BUs through a vertically oriented, solutions led approach to business and information technology (IT). Manages endcustomer technical relationships, provides technical expertise, and works with Intel business/account development and/or sales teams to drive Intelbased product purchases. Develops technically advanced solutions that help solve customer business challenges, while creating significant pull for Intel's products and solutions. Collaborates with global cloud service providers (CSPs), digital services/SaaS providers, enterprise, cloud and public sector customers, independent software vendors (ISVs) and solutions integrator/managed service provider (SI/MSP) partners to maximize utilization of Intel products' capabilities. Develops the industry offerings to drive endcustomer deal wins and/or open new market segments for cloudbased services in the industry. Exhibits solid understanding of key technology trends, industry segments and Intel's product lines to develop technically advanced solutions that help solve customer business problems, while creating significant pull for Intel's products and solutions. Works with the customers, partners/ISVs/SIs and BU development teams to create new solutions, software and services optimization through technical engagement and utilization of Intel product capabilities across the solution stack. Gathers customer feedback of assigned accounts to understand the drivers of satisfaction and/or dissatisfaction. Conveys deep technical requirements from partners and customers as a strategic input to product development roadmap. Delivers keynotes and presentations at Intel, industry and customers technical forums to position Intel as thought and product leader. Note: This is a commissioned sales position.
Qualifications:
Data Engineer, Data Science, Machine Learning Deep Learning - Models Consulting, Performance Tuning, Pipelines, Metrics, Frameworks Ability to build custom models, experience with fine-tuning, pre-training models will help. Showcase of end to end deployed AI solutions. Deployment considerations for On-Prem and Cloud
          Job Type:
Experienced Hire
Shift:
Shift 1 (India)
Primary Location: 
India, Bangalore
Additional Locations:
Business group:
Intel's Sales and Marketing (SMG) organization works with global customers and partners to solve critical business problems with Intel based technology solutions. SMG works across business units to amplify the customer voice and deliver solutions that accelerate their business. We work across numerous industries, including retail, enterprise and government, cloud services and healthcare as examples. The operations team focuses on forecasting, driving alignment with factory production and delivering efficiency tools and our marketing capability drives demand and localized marketing in locations around the globe. Our sales force navigates a complex partner and customer ecosystem while shaping product roadmaps, driving value for our customers, and collaborating to harness emerging technology trends to deliver comprehensive solutions.
Posting Statement:
All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
Position of Trust
N/A
Work Model for this Role
This role will require an on-site presence.",USD 30K - 56K *
55,Senior Member Technical ETL Processing,Broadridge,Bengaluru-EPIP Industrial Area,Senior-level / Expert,"At Broadridge, we've built a culture where the highest goal is to empower others to accomplish more. If you’re passionate about developing your career, while helping others along the way, come join the Broadridge team.
Roles and Responsibilities
Data Collection & Cleaning – Weekly and Monthly Processing of engineering data
Automation of our ETL processes by setting up and maintaining API calls
Maintaining the governance process by working with Finance and Engineering to validate the data
Front-End PBI development including automating / refreshing data flows, build new Power BI dashboards
Load and combine new data
Monitoring and maintenance of model performance and tracking data quality

Broadridge associates helped us envision our Connected Workplace - a work model that allows associates around the globe, dependent upon their role responsibilities, take advantage of the benefits of both on-site and off-site work to support our clients, one another, and the communities where we live and work. Our Connected Workplace is grounded in the concept of FACS: Flexible, Accountable, Connected, and Supported, which is our commitment to our associates. FACS supports our strong culture and allows us to achieve business goals while supporting meaningful work-life integration for our associates.

We are dedicated to fostering a diverse, equitable, and inclusive environment and committed to providing a workplace that empowers associates to be authentic and bring their best to work. We believe that associates can only do their best when they feel safe, understood, and valued, and we work diligently and collaboratively to ensure Broadridge is a company—and ultimately a community—that recognizes and celebrates diversity in all its dimensions.",USD 45K - 84K *
56,"Associate, Internal Audit Data Analytics",BlackRock,"MU8-South (A) Wing, 7-10 Floor, Nesco IT Park Tower 4, Western Express Highway, Mumbai",Entry-level / Junior,"About this role
Internal Audit’s primary mission is to provide independent assurance to the Board of Directors and Executive Management regarding the management of BlackRock’s businesses. The team engages with senior leaders and all of BlackRock’s individual business units globally to understand and advise on the risks in their business, evaluate the effectiveness of key processes and assist in the design of best practices that can improve their results. Internal Audit reports directly to the Audit Committee of the Board of Directors, and our work builds confidence that BlackRock will meet its obligations to clients, shareholders, employees and other stakeholders.
As part of the third line of defense, you will have the opportunity to be part of a team that provides independent opinion on the firm’s control environment as it relates to the ever evolving technology landscape that is relied upon to deliver its objectives. We are looking for individuals that want to be part of a global team that embraces analytics, audit, technology and learning and able to bring their creative mindsets to enhance audit techniques.
Data Analytics
 Internal Audit’s Data Analytics (DA) team leverages various data science, business intelligence, and analytical methods to assess BlackRock’s control environment. DA team members may design and perform certain testing as part of audits of BlackRock business units (including investment and asset management, risk management, operations, finance, and legal and compliance) and technology controls across application systems and infrastructure components (such as databases, operating systems, data centers and messaging platforms).  The DA team is also responsible for building and maintaining an inventory of self-service tools for the auditors, supporting the risk assessment of auditable units for the annual planning process, and assisting the development of timely and accurate Internal Audit management information.
Role Description:
 The DA Associate will engage collaboratively with business & technology teams, internal risk partners and with IT teams to support the goals of Internal Audit.  Our DA team is looking for an analytical self-starter, eager to learn new technologies and work with others to deploy and explain them. We value creativity and encourage our team members to challenge the status quo of how audits and audit testing used to be performed.  Successful DA team members embrace a fast-paced environment and add value to the performance of audits by working alongside audit teams and by helping to evolve our audit processes, tools and methodologies.
Specific responsibilities will include:
Develop code to execute audit tests, build tools, and/or execute data centric activities supporting the department and ensure that all code is properly documented and maintained.
Contribute to the strategic development of the DA program including the design and implementation of tools and technologies, development, delivery, and distribution of data analytics presentations, training, and methodology.
Propose alternative and creative approaches to audit testing, leveraging technology to either gain efficiencies or provide additional coverage.
Participate in short term data analysis activities aimed at supporting audit delivery and/or other ad-hoc requests including closure verification of issues, regulatory inquiries, strategic initiatives.
Networking to cultivate strong relationships with firm-wide partners to ensure successful analytic activities such as retrieval of new data sets, learning technology architecture, troubleshooting, etc.
Skills and Experience:
Bachelor’s or Master’s degree in information systems, data analytics, data science, computer science, economics, risk management or another quantitative related field
At least 5-7 years in data analytics and/or audit, risk management function, preferably within the wealth management/asset management/banking industry.
Strong SQL skills required, along with programming experience in Python or R , experience of any other scripting languages (VBA, PowerShell, etc.).
Working experience of any Business Intelligence tool (PowerBI, Tableau) is preferred.
Experience with both structured and unstructured data as well as experience with Data Warehousing, Extract Transform and Load (ETL). Hands on experience on techniques like text analytics, web scraping, Selenium, N-Gram analysis, Sentiment Analysis, etc. is preferred.
Awareness of development life cycle and tools like Azure Dev Ops, JIRA.
Team player with attention to detail with demonstrated analytical and problem-solving skills.
Strong interpersonal and communication skills (verbal, written, and listening).
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 22K - 42K *
57,Data Scientist II,"6sense Insights, Inc.","India, Remote",Mid-level / Intermediate,"Our Mission: 
6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue. 
Our People: 
People are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in deﬁning the future of our industry-leading technology.  6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers. 
We want 6sense to be the best chapter of your career. 
Data Scientist II
About Us:
6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It uses big data at scale, advanced machine learning and predictive modelling to find buyers and predict what they will purchase, when and how much.
6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry’s most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand PlatformTM, marketing and sales professionals can uncover, prioritize, and engage buyers to drive more revenue.
We’ve more than doubled our revenue in the past five years and completed our Series E funding of $200M last year, giving us a stable foundation for growth.
Recent articles:
https://www.businesswire.com/news/home/20230815281505/en/6sense-Ranks-Number-763-on-The-Inc.-5000-the-Annual-Ranking-of-the-Fastest-Growing-Companies-in-America
https://martechseries.com/predictive-ai/ai-platforms-machine-learning/6sense-continues-to-lead-the-way-in-b2b-marketing-and-sales-with-seventh-consecutive-g2-leader-recognition/
https://www.businesswire.com/news/home/20230809060528/en/6sense-Named-to-the-2023-Forbes-Cloud-100
Purpose of the Job:
Data Scientist II leverages analytical and modelling skills to derive actionable insights from data, develop and evaluate models, and deploy AI solutions. The role focuses on fostering innovation, ensuring ethical data handling, and aligning with the product vision, ultimately contributing to data-driven decision-making, and enhancing stakeholder engagement. Effective collaboration within the team is vital for achieving these objectives.
Responsibilities & Accountabilities:
Understand AI concepts and apply them to solve business problems, identifying key stakeholders and relevant data sources. Evaluate and select basic algorithms and data sets for AI solutions, following established development practices and procedures.
Demonstrate strong proficiency in SQL and data manipulation tools, effectively working with larger and complex data sets.Apply statistical methods, machine learning algorithms, and data visualization techniques to
perform exploratory data analysis and derive key insights.
Build models using statistical software like R or Python and interpret existing models by experienced data scientists.
Apply data pre-processing techniques and utilize data visualization to interpret and communicate model outputs effectively.
Write well-documented, clean code with appropriate comments, adhering to best practices, and execute and document comprehensive test cases for AI modules and pipelines.
Apply data science concepts to align with product development, considering user needs and effectively communicating insights to stakeholders.
Recognize areas of improvement in existing data solutions, seek guidance, and contribute to new ideas through active participation in discussions.
Adhere to ethical guidelines and comply with industry standards in data handling and privacy.
Collaborate effectively within a team, understand stakeholder goals, and engage in productive communication, aligning with project and product objectives.
Evaluate existing models and suggest enhancements for better performance.
Integrate AI models into applications and workflows, ensuring effective deployment.
Educational and Experience Requirements:
Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, or a related field.
Minimum of 2 years of hands-on experience in data analysis, modeling, and AI solutions development.
Proficiency in handling and analyzing large, complex datasets using SQL and data manipulation tools.
Demonstrated expertise in implementing machine learning models and algorithms,
including regression, classification, and other advanced techniques.Strong programming skills in Python or R, showcasing the ability to write efficient, well- documented code.
Experience in utilizing data visualization techniques to interpret model outputs and communicate insights effectively.
Deploy AI solutions, integrate models into applications, and understand cloud platforms for deployment.
Proven ability to collaborate within a team, effectively communicate insights to stakeholders and work cohesively in a professional setting.
Demonstrated willingness to learn, adapt to new technologies and methodologies, and contribute to innovative ideas and approaches.
Adherence to ethical guidelines and best practices in data handling and privacy compliance.
Understanding of integrating data science concepts into product development and considering user needs for product enhancement.
Ability to analyze problems, make data-driven decisions, and optimize solutions to address business challenges.
Our Benefits: 
Full-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We’ll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our oﬃces. 
We have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions, and everyone has access to meQuilibrium – a platform to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds. 
Equal Opportunity Employer: 
6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to jobs@6sense.com. ",USD 86K - 160K *
58,Junior Data Engineer (Delhi- NCR),Wizikey,"Gurugram, India",Entry-level / Junior,"Company Description
Wizikey is a cloud-based marketing and Communications software that uses AI technology to monitor news, provide media insights, and automate reporting. It helps companies track their news presence, gather competitive intelligence, and connect with relevant reporters. With Wizikey, businesses can measure their PR efforts, optimize strategies, and drive better outcomes. Trusted by over 100+ businesses, including Reliance, Infosys, MapmyIndia, Blusmart, Physics Wallah and WebEngage, Wizikey enhances brand visibility globally.
Job Description
Role Overview:
We are seeking a passionate and talented Junior Data Engineer to join our team. As a key member of our data team, you will play a crucial role in managing our data systems and pipelines. This position is ideal for individuals who are eager to develop their skills in a fast-paced, innovative environment.
Key Responsibilities:
(ETL/ELT) Data Pipeline Development: Design, build, and maintain efficient ETL/ELT data pipelines to support data collection, integration, and extraction processes.
Database Management: Work with various database technologies, both SQL and NoSQL, to store and manage data effectively.
Data Analysis and Reporting: Assist in analyzing data to provide actionable insights. Develop and maintain dashboards and reports for internal teams.
Collaboration: Work closely with other teams, including engineering, product, and analytics, to understand data needs and implement solutions.
Quality Assurance: Ensure the accuracy and integrity of data through quality checks and validation processes.
Learning and Growth: Continuously learn and stay updated with the latest technologies and practices in data engineering.
Qualifications
0-3 years of experience in a data engineering role (including internships or academic projects).
Proficiency in Python.
Familiarity with data pipeline and workflow management tools (preferably Apache Airflow).
Basic understanding of SQL and experience with relational databases.
Knowledge of big data technologies (e.g., Hadoop, Spark) is a plus.
Knowledge of cloud platforms (preferably AWS) is a plus.
Strong problem-solving skills and attention to detail.
Candidates from Delhi NCR will be preferred.
Excellent communication and teamwork abilities.
Additional Information
""Wizikey encourages and celebrates entrepreneurial culture. When you set out to create a new industry, you need to build a team of immensely talented folks from Technology and Communications and give them the freedom to experiment, learn and keep building. And with every addition of talent, this gets new fuel and the magic happens. And that is why we call ourselves Wizards"" ",USD 60K - 125K *
59,Lead Data Visualization and Reporting,Fidelity International,Gurgaon Office,Senior-level / Expert,"About the Opportunity
Job Type: Permanent
Application Deadline: 31 January 2024
Job Description
                      Title: LEAD DATA VISUALISATION AND REPORTING
Department: Global Risk                                                        
Reports To: Head of Investment Risk Oversight
Level :  4                     
We’re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our team and feel like you’re part of something bigger.
Department Description
General Counsel:
General Counsel (GC) is a trusted advisor to all parts of FIL, providing high-value independent advisory and assurance expertise through our specialist teams. GC comprises of Legal, Risk, Compliance, Tax, Public Policy & Strategic Relationship Management.
Global Risk:
The risk team in Fidelity covers the management oversight of Fidelity’s risk profile including key risk frameworks, policies and procedures and oversight and challenge processes. The team partner with the businesses to ensure Fidelity manages its risk profile within defined risk appetite.
The team is circa 50-strong, and growing, covering all facets of risk management including investment, operational, enterprise, and technology risk. The function is currently being strengthened to enhance global risk type coverage across FILs (Fidelity International) regions.
Investment Risk:
The Investment Risk team is part of Global Risk and is responsible for the framework and governance of all aspects of Investment Risk including market risk, derivatives risk, sub-advised risk, fund liquidity risk and fund counterparty risk. The team also provides oversight of the Operational Risk within the Investment Team and EUC (End-User Computing) Risk across the organisation.
The India business and operations team works upon providing data analytics solutions to enable data driven Risk oversight & controls on Investment data sourced from multiple sources.
Purpose of your role
The primary function of the role is to develop enterprise grade visualization tools, data pipelines and data analytics using Datawarehouse(SQL), Python & Power BI connecting to complex and high-volume data sources. The role will be working as part of an expanding data analytics team for Investment Risk Oversight within Global Risk Function, partnering with businesses and key stakeholders across FIL (Fidelity International) locations to deliver the desired business outcomes.
Key Responsibilities
As a Data Visualization and Reporting Lead you will be responsible for managing end-to-end data and visualization solutions for our various subject areas in Investment Risk. This role will entail:
Analysing complex data using expert SQL Queries and Excel Modeling techniques
Exploratory data analysis using Python (Pandas and Numpy) for data quality issue and analysis
Prototype desired data model using Excel and SQL Server database design documents
Creating scalable data models using Power BI ETL Engine (Power Query) and SQL Server
Converting raw data into meaningful insights through interactive and easy-to-understand dashboards and reports.
Extracting and integrating data from various data sources including a central data warehouse, directly from source systems or other unstructured forms of data (such as flat files, email, etc.)
Create semantic data layers (dimension modelling) to map data to specific business / operational processes and develop flexible, reliable easy to understand dimensional data models
Develop project execution methodology and documentation and implement development best practices, version control and deployment pipeline management.
Work on multiple project streams running in different stages varying from analysis, data modelling, development and production support
Well versed with AGILE methodologies and release management principles
Experience and Qualifications Required
Excellent skills in writing complex SQL (Structured Query Language) statements with multiple joins and optimising skills
Intermediate level database knowledge (DDL and DML) on SQL Server 17 or Oracle 12+
Well versed with database designing concepts and maintenance
Create scalable data models using SQL Server, Python and Power BI (Power Query)
Know-how of Publish and refresh strategies on Power BI Workspace
Admin activities for gateway and access management on Power Bi Workspace
Experience in creating professional data visualization tools using Power BI
Knowledge of Investment Management domain, Financial Capital markets, Types of Assets, Trading life cycle, Funds management etc.
Data Science and Data Analytics knowledge - Ability to understand, analyse complex data sets
Good problem solver and ability to adapt to changing requirements or deliverables
Strong verbal and written communication skills, strong stakeholder management
Essential Skills
The role will require a minimum of 7+ years of experience in developing and implementing Reporting and Analytics solutions.
High degree of proficiency in SQL Queries, Power Query, advance DAX calculations & modelling techniques and developing intuitive visualizations solutions.
Hands-On experience in Python based data analysis and troubleshooting
Exposure to data analytivs using Pandas and Numpy
Hands-on experience in managing production dashboards and configuring refreshes on Power BI Workspace
Strong experience in developing and managing dimensional data models in Power BI or in data warehouse environment
High degree of proficiency in MS Excel (strong knowledge of power pivot, data sorting, filters, etc). Ability to develop complex models and data structures, including macros, will be of advantage
Managing data from multiple sources in excel, CSV or MS Access like tactical data management solutions
Demonstrates proficiency in data integration and architecture including dimensional data modelling, database design, data warehousing, ETL (Extract, transform and load) development, and query performance tuning
Good understanding of Data Quality and Data management frameworks
Ability to work with stakeholders at multiple levels and high degree of comfort in working with ambiguity and under pressure, with the ability to prioritise and manage multiple tasks
Self-motivated with an eagerness to learn Investment Risk Domain and a positive work ethic
Desirable Skills
Experience with developing Power Automate (Flow) and Power Apps based solutions will be an advantage
Experience of the asset management industry would be an advantage
Experience based domain knowledge of Risk management, regulatory compliance or operational compliance functions would be an advantage
Focussed on providing high level customer service across various geographical areas
Flexible and adaptable, responds rapidly to changing agendas
Ability to use good judgement in the use of confidential information
Clear open communication with a willingness to learn & listen
Feel rewarded
For starters, we’ll offer you a comprehensive benefits package. We’ll value your wellbeing and support your development. And we’ll be as flexible as we can about where and when you work – finding a balance that works for all of us. It’s all part of our commitment to making you feel motivated by the work you do and happy to be part of our team. For more about our work, our approach to dynamic working and how you could build your future here, visit careers.fidelityinternational.com.
For more about our work, our approach to dynamic working and how you could build your future here, visit careers.fidelityinternational.com.",USD 45K - 84K *
60,"Sr. Manager, Data Science- Credit card",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
What a Sr. Manager, Data Science Managed Services does at Visa:
The candidate will be part of the Visa Consulting and Analytics (VCA) team.
Specific responsibilities will include:
Building & helping our partners to build data science capabilities & analytical solutions to solve their business problems.
Working knowledge in retail banking & credit card domain to guide the teams on the solution architecture.
Drive innovation through using data science techniques.
Act as data science advocate within our partners, advising and coaching analytical teams and sharing best practices and case studies.
Continually look at the environment to challenge our assumptions around new sources of data, potential analytics partners, tools, talent and infrastructure.
Explore leading methodologies and best practices to other teams and importing successful methodologies from other international markets.
Qualifications
What you will need:
• 10+ years' experience building end-to-end analytical systems as a Consultant, Data Scientist, or ML Engineer (or equivalent)
• Master’s degree in an analytical field such as computer science, data engineering, data science, econometrics, or similar
• Experience in Card or Retail banking analytical domain is necessary.
• Experience in managing multiple stakeholders at client site.
• 7+ years of experience in data science, analytics, and statistical modeling or relevant area
• Experience in SQL and statistical programming languages

What will also help:
• Knowledge of payment industry
• Experience in working closely with data science community.
• Outstanding problem-solving skills, with demonstrated ability to think creatively and strategically.
• Self-motivated, results oriented individual with the ability to handle numerous projects.
• Technology-driven mindset, digitally curious
• Up-to-date with digital and technology literature, trends.
• Able to challenge the status quo diplomatically and bring teams along with strategy.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 95K - 160K *
61,"Data Engineer (Python, SQL, Query Optimization, DBMS)",Blue Yonder,Bengaluru,Mid-level / Intermediate,"Scope:
The Execution Machine Learning team works closely with sales, product, and engineering teams to design and implement the next generation of retail solutions. Data Science team members are tasked with turning both small, sparse, and massive data into actionable insights with measurable improvements to the customer bottom line. They use rigorous analysis and repeatable processes to implement both black box and interpretable models.
Our machine learning platform ingests data in real time, processes information from millions of retail items to serve deep learning models, and produces billions of predictions on a daily basis
What you’ll do:
Design, architect, implement and help operate the Execution Machine Learning platform by
Observing inefficiencies, both in cost and reliability, of existing processes
Researching alternative solutions using custom or existing open-source technologies
Designing replacement processes and components
Implementing processes, extending, and configuring open-source components
Work with the DevOps and Support teams to operate platform by
Helping implement DevOps best practices of in-house and open-source components.
Ensuring smooth operation via monitoring and alerting facilities
Work with the data scientists to
Design scalable solutions for both model building and serving.
What we are looking for:
Bachelor’s degree in computer science is required, Masters is preferred
2+ years of Python programming experience with understanding of Object-Oriented Design.
1+ years working with SQL DBMS and Query Optimization; Big Query preferred.
1+ years of experience working on at least one cloud environment, GCP/Azure/Snowflake.
Should have experience in Data Warehousing and ETL Tools.
1+ Working Experience on Kafka and its integration with Cloud Services.
Some experience with streaming frameworks, preferably Beam on Samza/Flink/DataFlow
Familiarity with modern Big Data computing platforms such as Hadoop and Spark
Experience working with CI/CD and modern software engineering practices.
Some experience with Data Analysis and Visualization tools (Power BI/Tableau/Superset)
Good to have Supply Chain domain knowledge.
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Diversity, Inclusion, Value & Equality (DIVE) is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural Diversity Report which outlines our commitment to change, and our video celebrating the differences in all of us in the words of some of our associates from around the world.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",USD 90K - 151K *
62,"Senior Data Scientist, Analytics",Expedia Group,India - Gurgaon,Senior-level / Expert,"If you need assistance during the recruiting process due to a disability, please reach out to our Recruiting Accommodations Team through the Accommodation Request form. This form is used only by individuals with disabilities who require assistance or adjustments in applying and interviewing for a job. This form is not for inquiring about a position or the status of an application.
Are you excited by the opportunity to pioneer the future of travel? Do you want to redefine the way people plan, search for, and book their travel? At Expedia Group, we believe that travel brings the world together, and we are passionate about endless possibilities. The InsurTech group at Expedia team is responsible for managing the InsurTech P&L and driving its strategy, product, technology, and business development efforts across the Expedia Group globally. We deliver millions of dollars of incremental revenue, making a direct and meaningful impact on the company's bottom line. At the same time, we increase customers’ confidence to book travel, peace of mind, and make a difference in their lives. 
As part of the InsurTech Data Science Team, we are passionate about enhancing the end-to-end traveler experience! We leverage the power of data to drive end to end data driven insights and recommendations for Data Foundation, product analytics, Experimentation, traveler behavior, and provide insightful recommendations.
We're seeking an enthusiastic and self-driven individual to join our inclusive, diverse, and dynamic team, someone who thrives on using data to shape compelling business strategies, solve intricate challenges, enhance ongoing operations, and contribute to a team that plays a pivotal role in decision-making. In this role, your analytical prowess and business acumen will serve as catalysts, inspiring collaboration across product, engineering, finance, business strategy, and our valued strategic partners to prioritize, implement, and scale innovative product solutions that redefine the traveler experience.
We’re looking for a highly motivated individual to join our team to help drive data driven solutions and to deliver impactful analytics insights. If you enjoy using data to build business cases, solve business problems, improve ongoing business activities, and to work on a team that functions as the “business owner” you will fit right in. In this role, you will use your analytical and business skills to inspire product, engineering, finance, business and strategy, and our strategic partners to prioritize, implement and scale our product ideas. 
 What You’ll Do: 
Provide analysis and insights for the InsurTech business, while actively looking for opportunities to grow the business 
Apply your expertise in data modeling, quantitative analysis, data mining, data visualization with a goal of improving traveler experience and business outcomes with a strong focus on impactful analytics, steward product team to drive insights 
Own end to end process in evaluating A/B or multivariate tests to improve learning; proactively uncover opportunities and recommend new features for test and learn; evaluate and apply alternative methods to supplement randomized testing 
Deep dive into product tests for InsurTech team to identify additional insights and recommendations 
Analyze business opportunities across different products in our portfolio 
Function independently, assessing existing and upcoming business needs 
Help lead and mentor a team and colleagues  
 Requirements: 
Bachelor's, Masters or PhD degree in Mathematics, Science, Statistics, Engineering and 7+ years of data science experience 
Demonstrated ability to work through complex business problems and partner with internal and external partners using consultative data driven approaches 
Prior experience in managing and mentoring a team and colleagues  
Strong analytical/modeling skills with ability to convert raw data into insights, actionable outcomes, and recommendations 
Able to structure / work on data exploration problems, with innovative ways and solutions, bringing to bear strong reporting and data visualization skills 
Strong hands-on experience in SQL 
Proficient in building data visualizations (Tableau, Looker, etc.) 
Intermediate (or better) knowledge of Statistics and Data Science  
Experience with R, python, or other coding language  
Experience with web analytics tools such as Adobe Analytics or Google Analytics 
 About Expedia Group 
Expedia Group (NASDAQ: EXPE) powers travel for everyone, everywhere through our global platform. Driven by the core belief that travel is a force for good, we help people experience the world in new ways and build lasting connections. We provide industry-leading technology solutions to fuel partner growth and success, while facilitating memorable experiences for travelers. Expedia Group's family of brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Vrbo®, trivago®, Orbitz®, Travelocity®, Hotwire®, Wotif®, ebookers®, CheapTickets®, Expedia Group™ Media Solutions, Expedia Local Expert®, CarRentals.com™, and Expedia Cruises™.  
© 2021 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. CST: 2029030-50
Employment opportunities and job offers at Expedia Group will always come from Expedia Group’s Talent Acquisition and hiring teams. Never provide sensitive, personal information to someone unless you’re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals to whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com/jobs.
Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",USD 136K - 205K *
63,Module Lead - Data Modelling Job,Yash Technologies,"Hyderabad, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Data Modelling Professionals in the following areas :
  Experience
5-8 Years
Job Description
Should have strong experience in Data warehousing and database designing concepts
Should have strong experience in SQL/PL SQL
Experience with data modeling concepts (entity-relationship, star schema, dimensional)
Strong experience with database design and modeling tools (e.g., Erwin, TOAD, or equivalent)
Analyzing and translating business needs into long-term solution data models.
Ability to work productively with stakeholders, including project managers, business analysts, and developers
Good to have experience with any ETL tools and building data pipelines.
Good to have work experience on Azure Data Platform
Work with business and application/solution teams to implement data strategies, build data flows, and develop conceptual/logical/physical data models and implementation of RDBMS, operational data store (ODS), data marts, and data lakes on target platforms (SQL/NoSQL)
Work proactively and independently to address project requirements and articulate issues/challenges to reduce project delivery risks.
Excellent documentation, communication and collaboration skills
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
64,Artificial Intelligence Lead - Airbus India Innovation Centre,Airbus,Bengaluru (Airbus),Senior-level / Expert,"Job Description:
Job Title : A.I. Lead - Airbus Innovation Centre
Job Summary:
Airbus Innovation Centre India & South Asia (AIC) is one of the only three innovation centres for Airbus outside the European Union. AIC collaborates with a number of stakeholders both internal and external to develop innovative and bleeding edge products with a particular focus on digital and AI topics. We are seeking an experienced and highly skilled AI Lead to lead our team of data scientists and data analysts in the development of cutting-edge AI products within the aviation field. The ideal candidate should possess a minimum of 10 years of hands-on experience working with Large Language Models (LLM), Computer Vision, and various open-source machine learning models. A strong foundation in system engineering is essential, and familiarity with Model-Based Systems Engineering (MBSE) would be a significant advantage. The AI Lead will be responsible for guiding the team's technical direction, ensuring successful project outcomes, and driving innovation in the application of AI technologies.
Responsibilities
Lead and manage a team of data scientists and data analysts to design, develop, and deploy AI-driven solutions for the aviation industry.
Collaborate closely with cross-functional teams including engineers, domain experts, and product managers to define project goals, scope, and technical requirements.
Provide technical expertise and leadership in the selection, implementation, and optimization of machine learning models and techniques, with a strong focus on LLM, Computer Vision, and open-source frameworks.
Drive the development of AI models and algorithms to solve complex aviation challenges, such as predictive maintenance, anomaly detection, and optimization of operational processes.
Apply a deep understanding of system engineering principles to ensure AI solutions integrate seamlessly within aviation systems and adhere to safety and regulatory standards.
Mentor and guide team members, fostering a culture of continuous learning and technical excellence.
Stay up-to-date with the latest advancements in AI and machine learning, and identify opportunities to apply emerging technologies to enhance our products and services.
Collaborate with stakeholders to communicate project progress, technical insights, and potential risks in a clear and concise manner.
Requirements:
Minimum of 7+ years of hands-on experience in the field of AI, with a strong focus on LLM, Computer Vision, and open-source machine learning models.
Proven track record of leading and managing teams in the successful development and deployment of AI products.
In-depth knowledge of system engineering principles, with the ability to apply them to complex projects within the aviation domain.
Familiarity with Model-Based Systems Engineering (MBSE) concepts is a significant advantage.
Extensive experience in designing, training, and optimizing AI models using a variety of machine learning techniques and frameworks.
Strong programming skills in languages such as Python, and proficiency in relevant libraries and tools (e.g., SageMaker, TensorFlow, PyTorch, scikit-learn).
Excellent problem-solving abilities, critical thinking, and a data-driven approach to decision-making.
Effective communication skills to collaborate with cross-functional teams and convey technical concepts to non-technical stakeholders.
Proven ability to stay updated with the latest advancements in AI and machine learning research.
A master's or doctoral degree in a relevant field (e.g., Computer Science, Electrical Engineering, Aerospace Engineering) is preferred.
This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company’s success, reputation and sustainable growth.
Company:
Airbus Group India Private Limited
Employment Type:
Permanent
-------
Experience Level:
Professional
Job Family:
By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus.
Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.
Airbus is, and always has been, committed to equal opportunities for all. As such, we will never ask for any type of monetary exchange in the frame of a recruitment process. Any impersonation of Airbus to do so should be reported to emsom@airbus.com.
At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.",USD 45K - 84K *
65,Data operations - Assistant Vice President,State Street,"Hyderabad, India",Executive-level / Director,"Functional Job Title             : Billing Transformation Program – AVP 
Reports to                                : VP 
Department/ Division        : Controllership, Bangalore/Hyderabad 
 Background: 
State Street has established a Global Billing Function under Controllership, which is responsible for client billing set up and invoicing across all business lines and geographies globally at State Street. Organizationally, it combines all groups performing these activities globally, and also includes centers residing in State Street Shared Service locations in Poland, India and China. Billing Organization owns aspects of business-as-usual activities within billing areas and also drives process improvements and automation. Global Billing Function is in the process of migrating to a new technology platform which will be used for all business units and regions. 
 Basic Purpose of Job:  
 The Conversion AVP will be responsible for migrating clients from the legacy system to the new platform. They will perform the following responsibilities: 
Timely review of fee schedule for any additions or deletions of billable item or language changes, accordingly, update GBIC. 
Liaison as part of Fee schedule governance team for any new billable item to be added and correspondingly work with Rules & data sourcing teams for sourcing Data source and Rules. 
Serve as SPOC for any internal and externa audit. 
Oversee the progress and automation of the product order and eliminate the lengthy process which is currently followed. 
Flexible to work on any projects like the CLM, Non-STD clean up and further STD billable items clean up. 
Take key decisions relating to Non-STD Billable items /STD billable items based on calculation methodology. 
Conversion exception analysis - Review the data conversion exceptions, research exceptions, update conversion rules, correct data exceptions. 
Reconcile, analyze and document root cause of invoice related data and calculation differences between the legacy and new platform. 
Quality control Invoice Documents for accuracy and consistency  
Work across the project team with business and technology to analyze and explain any issues. 
Develop procedures and checklists to control activities and report status.  
The Conversion lead will work in a fast-paced complex engagement model on a day-to-day basis.  
The individual will be directly responsible for the resolution of exceptions and conversion of customers to the new billing platform. 
Collaborate closely with the onshore team to understand expectations and deliverable timelines and ensure that deliverables of the team are load balanced as compared to team staffing.  
Develop the team to adopt ""owner's mind set"", work independently, and effectively manage timelines.  
Manage/collaborate with resources to assist with ad-hoc projects and new activities to support the GBO controller group and program. 
Evolve process for Billing Transformation, performing managerial reasonableness reviews and discussing reporting & analytics deliverables prepared by the team.  
Provide support to key stakeholders of the team to present analytical results, triage findings and identify solutions.  
First point of escalation within the local reporting line for dealing with issues (people/process/technology) and ensuring that compliance requirements are adhered to (e.g. company policies surrounding standard of conduct, information security, employment regulations) 
Coaches' Strong collaboration with the team and works with onshore leadership to establish the team member goals and gather feedback for performance appraisals.  
Ensure completion of deliverables within the committed timeframe including assistance with development of deliverable plans.  
Design the training Material, train and groom junior and new joiners. 
 Work Experiences: 
 Bachelor’s/master’s degree in finance, 10-16 years of progressive experience in Accounts receivable, banking areas with major financial institutions Financial Planning & Analysis in a global setting 
MBA Finance) will be an added advantage. 
Well versed with billing processes in corporate environment  
Exposure to Financial services industry  
Experience within global projects and global organizations 
Complex operational setting involving analysis of financial data. 
Engaged in business or technical migration/conversion processes. 
Good knowledge of Order to Cash process an advantage. 
Experience of Oracle Revenue Management and Billing (ORMB) application an advantage 
Direct support to business or product line management / executives 
Variance analysis of reference and financial data.  and reporting of insights 
Should have knowledge on setting up clients in banking sector. 
Demonstrated knowledge in improving the billing function for multiple geographies and business areas. 
 Skills: 
 Excellent interpersonal, written, and verbal communication skills, with the ability to interface effectively with individuals at various levels, both internal and external 
Analytical, with strong problem-solving abilities and creative resolution skills 
Ability to work on multiple topics in a fast-paced, high-volume environment. 
Strong Analytical skill set used for financial data comparisons, reconciliations and investigations. 
Ability to remain organized, pay strict attention to detail, and meet critical deadlines within program schedule. 
Detailed orientated with ability to consistently and accurately execute against operational processes and controls. 
Comfortable presenting and pitching new ideas to senior management teams in large settings. 
Ability to adapt to a changing environment and demands of transition of new clients.  
Strong communication skills with ability to participate in or lead conference calls and present financial results to financial and non-financial audiences at various levels of seniority. 
Pride of ownership with the ability to drive results within the Business. 
Solid business knowledge as it relates to the financial services industry including financial product and institution knowledge. 
Self-motivated, self-assured, and self-managed 
Results oriented ownership mindset. 
Other Skills required: 
Proficiency in Microsoft Office suite (Excel, Access, PowerPoint, Word, Visio), advance levels of Excel (pivot tables, formulas, excel workbook maintenance best practices) 
Conceptual understanding of company-wide financial architecture (GL, sub-GL technology, specialized tools) applicable to the above process groups of processes would be an added advantage. 
Independent decision-making capabilities, demonstrated thought leadership.  
Pride of ownership with the ability to deliver high quality results timely.  
Strong analytical and ability to analyze and summarize complex financial transactions.  
Highly organized with ability to multi-task and work under high pressure deadlines  ",USD 49K - 91K *
66,Senior Data Scientist,Innovaccer,"Noida, Uttar Pradesh, India",Senior-level / Expert,"Your Role
The technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.
Data is our bread and butter for innovation. We are looking for a Senior Data Scientist who understands healthcare data and can leverage the data to build algorithms to personalize treatments based on the clinical and behavioral history of patients. We are looking for a superstar who will define and build the next generation of predictive analytics tools in healthcare.. 
A Day in the Life
Design and lead the development of various artificial intelligence initiatives to help improve health and wellness of patients
Work with the business leaders and customers  to understand their pain-points and build large-scale solutions for them. 
Define technical architecture to productize Innovaccer’s machine-learning algorithms and take them to market with partnerships with different organizations
Proven ability to break down complex business problems into machine learning problems and design solution workflows.
Work with our data platform and applications team to help them successfully integrate the data science capability or algorithms in their product/workflows. 
Work with development teams to build tools for repeatable data tasks that will accelerate and automate development cycle.
Define and execute on the quarterly roadmap
What You Need
Masters in Computer Science, Computer Engineering or other relevant fields (PhD Preferred)
4+ years of experience in Data Science (healthcare experience will be a plus)
Strong written and spoken communication skills
Strong hands-on experience in Python - building enterprise applications alongwith optimization techniques.  
Deep understanding of classical ML techniques - Random Forests, SVM, Boosting, Bagging -  and building training and evaluation pipelines. 
Experience in ML Frameworks like XgBoost, Scikit-Learn, Pycaret
Demonstrate experience with global and local model explainability using LIME, SHAP and associated techniques.
Hands on experience with at least one ML platform among Databricks, Azure ML, Sagemaker s
Experience in developing and deploying production ready models
Knowledge of implementing an MLOps framework.
Experience with deep learning frameworks like Pytorch, Tensorflow will be a big plus.
Possess a customer-focused attitude through conversations and documentation
What We Offer:
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications.
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic.
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists.
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered.  
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative.
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them. 
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments.
Disclaimer: Innovaccer does not charge any fees or require any payment from individuals or agencies for securing employment with us. We do not guarantee job spots or engage in any financial transactions related to employment. If you encounter any posts or requests asking for payment or personal information, we strongly advise you to report them immediately to our HR department at px@innovaccer.com. Additionally, please exercise caution and verify the authenticity of any requests before disclosing personal and confidential information, including bank account details.
 ",USD 136K - 205K *
67,Data Scientist,Dolby Laboratories,"Bengaluru, IN",Senior-level / Expert,"Join the leader in entertainment innovation and help us design the future. At Dolby, science meets art, and high tech means more than computer code. As a member of the Dolby team, you’ll see and hear the results of your work everywhere, from movie theaters to smartphones. We continue to revolutionize how people create, deliver, and enjoy entertainment worldwide. To do that, we need the absolute best talent. We’re big enough to give you all the resources you need, and small enough so you can make a real difference and earn recognition for your work. We offer a collegial culture, challenging projects, and excellent compensation and benefits, not to mention a Flex Work approach that is truly flexible to support where, when, and how you do your best work.
Scope and responsibilities
  The audio and video technologies developed by Dolby are implemented in billions of device and service offerings worldwide. Billions of people around the world use Dolby technologies to create, edit, and enjoy multimedia content. For us, it is crucial to understand how the technologies we built are being used and experienced on a daily base. To do so, we are investing in a comprehensive, large-scale data platform and data science effort.
Therefore, Dolby is looking for an AI researcher/mathematician to analyze large amounts of raw data generated continuously from various systems. This role is responsible for helping build advanced data analysis tools and automated analytics using machine learning and artificial intelligence. You will develop statistical modelling and prediction algorithms based on a variety of data types including audio, speech, image, and text data coming from a variety of sources. These algorithms will help us understand how users engage with our technologies. We will gain a deeper understanding how users worldwide feel and think about the experiences we enable as a company. These insights will be crucial to define our technology and investment directions.
  Research, develop and apply data science, machine learning, and statistical methods to large sets of multimedia, contextual, and metadata data. Mine data using modern tools and programming languages.
Design state-of-the-art data analysis techniques to understand how Dolby technologies are being deployed and used.
Design state-of-the-art data analysis techniques to understand how users engage in interactive multimedia experiences delivered by Dolby.
End-to-end planning and execution of data science initiatives scoping, building, testing, implementation, maintenance, tracking and optimisation of predictive models.
Influence technology strategy with data, be focused on impact, and collaborate with other teams.
Maintain proficiency within the data science domain by keeping up with technology and trend shifts.
Foster data driven innovation, provide domain-specific expertise in cross-organization projects/initiatives.
Build automation needed for effective labelling of data, perform data preparation, and data augmentation required for the training and deployment of the artificial intelligence algorithms and frameworks.
Create tools for data processing, labelling, analysis and generating synthetic data.
Help with and support the development of scalable data pipelines to support increasing data volume and complexity. Support enhancing data sets, provide labelling methodologies and perform data preparation required ML algorithm research.
Present information to different stakeholders using data visualization techniques.
    Education & Experience
  PhD degree in Mathematics, Artificial Intelligence, Computer Science, or equivalent.
Strong background in mathematical modelling, stochastics research, artificial intelligence.
Background in statistical signal processing, decision theory, greedy algorithms, dynamic programming, Bayesian modelling, random algorithms, time series analysis, hypothesis testing, classification, clustering, hypothesis testing and multivariate regression analysis.
Experienced in designing experiments, defining hypotheses, and developing statistical model to reach a scientifically sound conclusion.
Extensive experience using statistics, mathematics, algorithms and programming languages to solve big data challenges.
Fluent in structured and unstructured data, its management, and modern data transformation methodologies.
Ability to define and create complex models to pull valuable insights, predictions and innovation from data.
Experience working with large, sparse, and noisy datasets.
Proficiency in Python required. Proficiency in C/C++, Matlab desired
Desired:  
Experience with SQL/MySQL, Databricks, Spark/PySpark and AWS.
A-grade extract, transform, and load (ETL) skills for data wrangling heavily around the unstructured data using big-data technologies such as Hadoop/Spark.
Experienced in preprocessing of structured and unstructured data and prepare them for ML/AI learning systems.
Strong communication skills and data reporting/visualization capabilities
Strong interpersonal skills, ability to work as part of a global R&D team.
    Build your career profile, also within the Careers tab in Employee Central to open the possibility of new opportunities finding you. Express your interest. If you want to express your interest in a specific opportunity and be contacted by a recruiter, click the apply button associated with the relevant job description. The Recruiter is the only one who will see your application.
Please refer to the recruiting website for more information:  https://jobs.dolby.com/careers
  #LI-MX1
 ",USD 136K - 205K *
68,Senior Data Analyst,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
The Auto practice within Epsilon accelerates and drives growth for major players of the automotive industry, from Original Equipment Manufacturers (OEM) to Dealers big and small in the US and Canada. Part of a 1,600-member global team, the practice offers the automotive world’s largest service reminder platform along with agency services and digital media solutions. A leader in the automotive space, the team supports over 50% dealers in the US and manages 280M+ customer vehicle relations. Our Auto team is home to innovative thoughts, latest in technology and is always at the front of learning new. The Automotive Analytics team within Epsilon partners with internal and external clients and data providers, leveraging advanced statistical and data management techniques to drive strategic thought and effective decision making. The Senior Data Analyst manages analytic initiatives from conception to completion, providing clients and key stakeholders actionable results and insights that help them achieve their business objectives. This role requires a strong analytical mindset, being able to take large datasets and use statistical methodologies to solve business problems. 
Role Responsibilities:
Serve as the day-to-day contact for project phases from kick-off to presentation of results.
Explore data requirements, integrates data from multiple sources using programming scripts to produce required data elements.
Prepare reports, uncovering insights and developing business recommendations based on data findings and effectively present that to key internal and external stakeholders.
Bring in value addition and innovation to the existing or new process/projects by researching new ways of doing things.
Follows the best practices of programming, reporting, dashboarding, project documentation, and system management.
Ensures data integrity and accuracy through rigorous testing and quality control processes, inspiring confidence in the analysis results.
Collaborates within and cross teams to gather details and deliver results to stakeholders.
 Qualifications
Master’s or Bachelor’s degree in engineering or quantitative discipline (Statistics, Economics, Mathematics, Analytics).
5-7 years of hands-on coding skills in Advanced SAS, SQL, Tableau.
4+ years of experience in Reporting, Dashboarding and Presenting Insights.
Good knowledge of Digital Marketing knowledge is a plus.
Good experience in visual representation of data, presentation, and storytelling skills.
Excellent communication skills and able to build good working relationship with clients.
Flexibility to work in a virtual environment with stakeholders in US time zones.
Exhibit technical acumen and possess good learning mindset.
Highly motivated and collaborative team player with good interpersonal skills.",USD 93K - 144K *
69,"Senior Technologist, Data Analytics Engineering",Western Digital,"Bengaluru, India",Senior-level / Expert,"Company Description
At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.
At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that. Our technology helped people put a man on the moon.
We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world’s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.
Binge-watch any shows, use social media or shop online lately? You’ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That’s us, too.
We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital®, G-Technology™, SanDisk® and WD® brands.
Today’s exceptional challenges require your unique skills. It’s You & Western Digital. Together, we’re the next BIG thing in data.
 ABOUT ADVANCED ANALYTICS OFFICE (AAO) and BIG DATA PLATFORM (BDP)
AAO is missioned with accelerating Analytics solutions at scale across the Enterprise to rapidly capture business value. These solutions target key business metrics, such as, reducing manufacturing cost, improve capital efficiency, reduce time-to market to develop new products, improve operational efficiency, and improve customer experience. These solutions are built using cutting edge Industrial 4.0 technologies and are delivered through a platform approach to enable rapid scaling. The solutions span AI/ML for improving manufacturing yield, quality, equipment uptime, and adaptive testing, Operations Research for capacity and scheduling optimization, Digital Twin for inventory and logistics optimization, and Product Telematics for managing customer fleet management solutions.
Big data platform, BDP team provides self-service data and application platforms enabling rapid scaling of services to make ever increasing business impact. You will have the opportunity to partner in making remarkable things happen across WDT’s more than dozen factories across the globe, global product development teams, customer solutions, and supporting operations like Finance, supply chain, Procurement, Sales etc
Job Description
We are looking for a dynamic Senior Analytics Partner (Director role equivalent) who will play a pivotal role in bridging language barriers across Enterprise Functional domain problems and AI/ML application solution approaches. In other words, the candidate will be playing an AI translator role while working across Enterprise domain functions. Though a Senior Technologist role, the primary responsibility will be to engage with the internal stakeholders in discovery work to build and qualify the pipeline of analytics projects. This will often involve understanding ambiguously defined problem from stakeholders,  and then recasting the problem statement for clarity and getting buy-in from stakeholders. The position definitely will require establishing credibility with the stakeholders and will exercise both your technical and influence skills.  
 Serve as an internal business consultant, to identify, evaluate, develop, and manage complex projects that involve advanced analytics.
Role requires a focus on both business understanding and Analytics technologies; need ability to see business opportunities and how to unleash them through new solutions.
Role requires ability to effectively communicate complex technical concepts to non-technical stakeholders, including the ability to break down technical jargon into plain language and to communicate the benefits and risks of AI in a clear and concise manner.
Engage in discovery work with stakeholders to identify, refine and qualify analytics project and influence the project direction and scope for best stakeholder outcome.
Must be comfortable with ambiguity, exploring requirements that are not yet clearly defined, and bringing clarity to business for prioritizing projects and resources.
Should be open to learning new material, staying up to date with fast evolving technologies, and expanding beyond current areas of expertise.
As an Analytics Business Partner (AI translator), you need to have solid understanding of Machine Learning techniques on Inferential techniques, Image Analytics, NLP, Gen AI (LLM), Reinforcement learning etc., to conceptualize high-level business solution.
Architect and design end-to-end analytics solutions on cloud/Hybrid-cloud platforms. Collaborate with infrastructure teams on compute, storage, and network requirements.
Role requires a good business domain experience in engineering, procurement, supply chain, manufacturing, order management. Preference will be given to knowledge in High-Tech industry, and specifically semiconductors.
Preference will be given to candidates who have experience in assessing and capturing business value of AI projects, and have done consulting engagements.
Stay up-to-date on cloud, edge computing and advancements related to analytics and AI. Identify how new capabilities can be applied to business problems.
Qualifications
Master's or Ph.D. in a relevant field (e.g., Data Science, Computer Science, Statistics, Engineering, Applied Sciences).
15+ years of proven experience with at least 10+ years of data science or advanced analytics, with a track record of successful project execution.
Very comfortable leading or participating in cross-functional teams.
Experience in drafting AI project proposals/executing plan.
Strong ability to translate business/function problems into analytics problem for practical solutioning.
Solid exposure ton data visualization tools and programming languages (e.g., Python, R).
Excellent communication and stakeholder management skills to influence stakeholders to act based on insights from analytics.
Additional Information
All your information will be kept confidential according to EEO guidelines.",USD 128K - 190K *
70,Lead/Senior Data Scientist,3Pillar Global,Noida,Senior-level / Expert,"We are 3PILLAR GLOBAL
We build breakthrough software products that power digital businesses. We are an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders in Software and SaaS, Media and Publishing, Information Services, and Retail. Our key differentiator is our Product Mindset. Our development teams focus on building for outcomes and all of our team members around the globe are trained on the Product Mindset’s core values – Minimize Time to Value, Solve For Need, and Excel at Change. Our teams apply this mindset to build digital products that are customer-facing and revenue-generating. Our business-minded approach to agile development ensures that we align to client goals from the earliest conceptual stages through market launch and beyond.

In 2023, 3Pillar Global India was named as a “Great Place to Work” for the sixth year in a row based on how our employees feel about our company, collaborative culture, and work/life balance - come join our growing team

Job Description:
 We are looking for a Lead/Senior Data Scientist with 7 to 15 years of experience to be part of the product engineering team.



Responsibilities
Data Science: Lead the development and design efforts of model architecture, ensuring high-quality results
Mentorship and Code Review: Mentor junior developers, conduct code reviews, and enforce coding standards to maintain code quality and facilitate skill development within the team.
Performance Optimization: Identify and resolve performance, optimizing model and backend integration for efficiency and more accurate results
Documentation and Collaboration: Create and maintain technical documentation, collaborate with cross-functional teams, and contribute to project planning and estimation, ensuring effective communication and project success.Help the Data Science & Analytics Practice grow by mentoring, coaching junior Practice members, leading initiatives
Provide thought leadership to the Practice and the Organization, believes in leading by influance through Community of Practice
Technical Competencies
Must have
Masters or PhD on NLP + 3-5 years of experience OR 8+ years of experience in ML focused on NLP
Python, R, or Julia
Extensive knowledge of NLP libraries such as NLTK, spaCy, Gensim, Transformers (Hugging Face), LangChain, AllenNLP, etc.
Hands-on experience with machine learning frameworks (TensorFlow, PyTorch, Scikit-learn) for NLP applications.
Experience in topics like Semantic Search, Topic Modelling, Summarization, Q&A, RAG, Ontologies
Experience in Gen AI using GPT, Llama or others
Solid understanding of statistical analysis, probability theory, and data manipulation techniques for text data.
Nice to have:
Computer Vision experience, CNNs, object detection, face recognition
Benefits
A competitive annual salary based on experience and market demands 
Flexi-timings 
Work From Anywhere
Medical insurance with the option to purchase a premium plan or HSA option for your entire family 
Regular Health check-up camps arranged by the company 
Recreational activities (Pool, TT, Wii, PS2) 
Business casual atmosphere
#LI-Remote",USD 136K - 205K *
71,Data Engineer,Commonwealth Bank,Bengaluru - Manyata Tech Park Road,Senior-level / Expert,"Your Team -
Enterprise Services (ES) is responsible for the world leading application of technology and operations across every aspect of CommBank, from innovative product platforms for our customers to essential tools within our business. We also use technology to drive efficient and timely processing, an essential component of great customer service.
The Chief Data Office (CDO) provides specialised data services and platforms for the CommBank group & is accountable for developing Group’s data strategy, data policy & standards, governance and set requirements for data enablers/tools. The team is also accountable to facilitate a community of practitioners to share best practice and build data talent and capabilities.
Core Responsibilities -
Design and develop highly reliable and scalable data pipelines and data platforms with comprehensive test coverage.
Collaborate with stakeholders to analyse and translate requirements to technical implementation.
Identify and drive opportunities for continuous improvement within the team and in delivery of products.
Provide mentoring and technical assistance to other members of the team, including more junior Data Engineers.
Produce high quality, sustainable solutions to meet business requirements, leveraging approved delivery frameworks and by applying industry best practice.
Provide technical governance of product delivery to ensure successful delivery and adoption.
Deliver data engineering solutions aligned to core concepts of data design, preparation, transformation, and load.
Build and implement data pipelines in distributed data platforms including warehouses, databases, data lakes and cloud lakehouses to enable data predictions and models, and reporting and visualisation analysis via data integration tools and frameworks.
Contribute to domain planning, providing guidance to ensure that technical deliveries are aligned to engineering direction and strategy.
Skills -
Abinitio, hadoop, DW, Snowflake, AWS
If you're already part of the Commonwealth Bank Group (including Bankwest, x15ventures), you'll need to apply through Sidekick to submit a valid application. We’re keen to support you with the next step in your career.
We're aware of some accessibility issues on this site, particularly for screen reader users. We want to make finding your dream job as easy as possible, so if you require additional support please contact HR Direct on 1800 989 696.
Advertising End Date: 16/01/2024",USD 110K - 180K *
72,Track - Data Operations Associate,G2,Bengaluru,Mid-level / Intermediate,"About G2 - The Company
G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.
G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here!
About G2 - Our People 
G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.  
As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community  strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs). 
We support our employees by offering generous benefits, such as flexible work, ample parental leave, and unlimited PTO. Click here to learn more about our benefits. 
G2 is excited to offer a remote work environment for our employees, unless otherwise stated in the job description. If you are interested and eligible to partake in a hybrid office plan, please ask your recruiter for more information. 
About The Role
G2 is looking for a Data Operations Associate to join our data operations functions on the Track Product Line within Product R&D. This role will be responsible for examining data from various transaction sources, break down high-level information into detailed insights, and parse data into meaningful sets using established rules. Possess analytical skills to ensure data integrity and contribute to workflow solutions in support of data operations adhering to the team guidelines and policies shared during training.
In this role you will:- 
Critically evaluate data gathered from multiple transaction sources, disintegrate and analyze high-level information into finer details
Parsing data blocks into smaller chunks by following a set of rules and generating a meaningful set
Analytical mindset and ability to participate in processes focusing on data integrity and workflow solutions to support data operations
Make recommendations to processes to improve customer experience and team efficiency
Responsible for reviewing legal documents like SaaS Purchase Agreements, Service Agreements, Master Service Agreements for SaaS Contracts
Attention to detail and the ability to successfully manage multiple competing priorities simultaneously
Minimum Qualifications:
We realize applying for jobs can feel daunting at times. Even if you don’t check all the boxes in the job description, we encourage you to apply anyway. 
1- 2  years of working experience in the Data Operations Assistant/Operations. Coordinator role, Analyst role preferred
Good analytical bent of mind, detail-oriented
Experience in the Microsoft Office suite, particularly Excel and SQL
Proficiency in carrying out secondary research and contributing actionable recommendations based on the findings
Excellent written and verbal communication skills and the ability to express thoughts logically and succinctly
Our Commitment to Inclusivity and Diversity
At G2, we are committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, or marital, veteran, or physical or mental disability status. Learn more about our commitments here. ",USD 30K - 56K *
73,Data Analytics & Management Chapter Lead - Data Engineering Director Role,Telstra,Telstra ICC Bengaluru,Senior-level / Expert,"Employment Type
Permanent
Closing Date
29 June 2024 11:59pm
Job Title
Data Analytics & Management Chapter Lead - Data Engineering Director Role
Job Summary
As a Data Analytics & Management Chapter Lead, your role is two-fold where you will combine your deep expertise in Data Analytics & Management with people leadership. Through your passion for leadership you connect, engage and develop your chapter members so they deliver value aligned to Telstra’s strategic roadmap.

Through your mission work, you directly shape the design, implementation and delivery of strategic data programs that leverage insights and advanced analytics to drive improved service performance, business insights and customer experiences.
Job Description
At Telstra, we have a clear purpose: to build a connected future so everyone can thrive. We believe it’s people who give purpose to our technology. So we are committed to staying close to our customers and providing them the best experience. And delivering the best technology.
This is where YOU come in, by playing your part in helping our customers connect: faster, better and smarter.
Who we are:
Telstra is Australia's leading telecommunications and technology company with a rich heritage that’s been built over 100 years. From our humble beginnings in the Postmaster General’s Office to the global business we are today our people have been at the forefront of technology innovation. More recently, we have the largest Internet of Things network in Australia and are leading the way in 5G. And this is just the beginning of what we’re hoping to achieve together.
What is the focus of the role?
As a Data Engineering Chapter Lead, your will combine your deep expertise in Data Engineering Technology and Strong People leadership & Management capabilities to deliver the Data & AI aspirations & objectives of the company.
Through your passion for leadership you will connect, mentor, engage, and develop your chapter (Team) members so they deliver value aligned to Telstra’s strategic roadmap.
Through your Technical mission work, you will directly design, implement, and deliver to strategic Data & AI programs that leverage your Technology & Big Data Engineering skills to build a Data & AI fuelled Organisation.
Location - Bangalore
Organizational Leadership:
Strong Leadership experience, with a track record of successfully leading and mentoring team members in Data Engineering value chain.
Coaching and developing members within Data Engineering Team to enable them to deliver high quality capabilities in Data Acquisition, Data Ingestion, Data Processing, Data analytics & Data Value chain, support, Develop and provide feedback along the way.
Build strong, trusting relationships within the team that enable a culture of high performance and living Telstra values.
Providing clarity on performance, behavioural goals, and expectations to the chapter team members and ensure that they can contribute to both mission and chapter goals effectively.
Actively maintaining a talent pipeline for the chapter to ensure that workforce strategy objectives are achieved.
Modelling a culture of collaboration and continuous learning to support development of domain and interpersonal capability within the Chapter.
Managing resource allocation to ensure capability required is available and resourcing issues are mitigated, in collaboration with Group Owners.
Ability to manage team finances and applying commercial acumen to ensure chapter and resourcing priorities are achieved within allocated budget targets.
Collaborating with Organisation leadership and Peer Leaders to determine and implement tools/common practices to be used by chapter team members.
Providing clarity to chapter team members on current and future capability requirements to enable them to own and drive their development so they can continually grow and add value in different ways.
Drive thought leadership & Engineering excellence to innovate and shape technological strategies, fostering an innovative thinking culture.
Using timely feedback conversations to inspire chapter member performance and achievement of challenging goals.
Manage end-to-end vendor relationships, including assessment, onboarding, and ongoing resourcing, to ensure seamless collaboration and alignment with chapter and mission objectives.
Acting as a champion and exemplifying the ways of working mindsets and practices for all teams in which you participate. Fostering the culture of growth mindset in the team.
Identifying opportunities to innovate and create new Data Engineering & Management practices/approaches to improve efficiency and effectiveness.
Data Engineering Leadership
12+ Years of industry experience, majorly in data engineering.
Deliver end-to-end data engineering solutions to improve operational efficiency and outcomes.
Translate the business needs into actionable solutions, applying commercial and business lens to enable decision-making and resolve problems.
Transform data into actionable insights by interlinking high-value datasets, advanced analytics, and architecture, catering to the needs of both internal and external customers.
Proven experience in data engineering, with a focus on designing and implementing scalable data infrastructure.
Strong proficiency in relevant programming languages (e.g., Python, Java, Scala) and experience with ETL tools.
Expertise in managing and optimizing relational and non-relational databases, including hands on experience in SQL-PL/SQL and database administration.
In-depth knowledge of database management, data modelling, and data warehousing.
To be successful in the role, you will have working experience in big data technologies and cloud platforms (Azure/AWS).
Big Data: Apache Spark, Flink, Hadoop, AWS Kinesis/Azure Synapse etc.
Data processing: Azure Data Bricks, Azure Data Factory.
Data Warehousing: RedShift, Snowflake etc.
Excellent problem-solving, communication, and collaboration skills.
Visualise data to create a story for the business which identifies opportunities, risks, and maximises performance for business areas.
Strong understanding of Agile methodologies and the ability to adapt to changing requirements Articulate to the business the value of data analytics and encourage the business to use predictive analytics and data solutions to obtain a commercial advantage. Well versed experience in Confluence, Jira etc.
Anticipate potential issues before they arise and develop mitigating actions to address and communicate to the team and relevant stakeholders.
Build, automate and maintain complex analytics and data queries which compile relevant data on performance and cost strategy analysis.
Develop data management capabilities and appropriate solutions to ensure data quality, alignment and risk management strategies are in place to support ongoing management of data.
Determine and articulate the business and customer impacts resulting from changes or improvements in data management approaches to facilitate support from key stakeholders and justify investments.
Support data governance through the implementation of business processes and management guidelines which can include strategies for effective storage, sharing and utilisation across the enterprise.
Stay up to date on innovative and emerging data engineering and management practices and consider how it can be implemented in Telstra to enhance current processes and systems.
An individual with a strategic growth mindset, technical expertise, and a strong enthusiasm for advancing data excellence within an organization.
Soft Skills
Data engineering tools and techniques, Data Analytics & Insights knowledge, Understanding of Data Science AI & ML, Analysing data, Data Solutioning design and architecture knowledge, Data Automation, Data Governance, Data Insights, Programming & coding skills related to data engineering,
Active Listening, Agile Methodology, People Leadership & management, Budget Management, Vendor management, Demand & Resource Management Career Development Coaching, Communicating with Influence, Strong Stakeholder management, Influencing Change, Motivating Teams, Feedback management, Strategy Development, Team Building, Team Coaching, Team Performance Management.
What we offer
Dynamic, innovative and knowledgeable, our people are the brains behind amazing achievements such as keeping on top of the latest technology or masterminding the store of the future. And because they share the same vision, they take the time to pass on their knowledge, mentor you, and guide you in your career path.
Here you’ll have the opportunity to work with some of the best minds in the industry, people who are passionate about Telstra and technology, and who work together to achieve great things.
Not only will you be rewarded with a competitive salary package, but there are a range of lifestyle products and services that you can access, including options to purchase additional leave, volunteer leave and the list goes on.
Sound like you?
A career with us will give you a platform to shape tomorrow through technology. For you, that means helping us to push the boundaries of what’s possible today, and in the future. It also gives you the opportunity to empower millions helping businesses grow, evolve and reach their potential.
 At Telstra, you can thrive, your way. We foster new ideas, we embrace different ways of working and thinking, and we believe an inclusive and diverse team will lead us to innovate for the future.
We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit our Telstra Careers Website: http://tel.st/allrolesfle",USD 121K - 186K *
74,Senior Data Scientist,Equifax,IND-Bengaluru-Equifax Credit Information Services,Senior-level / Expert,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds,  and make a meaningful impact, we want to hear from you.
Synopsis of the role:
This role will provide vital input into the design, project management, delivery of analytical research and insight solutions across a range of external and internal clients and industries for Equifax. Work directly with Insight Analytics manager, marketing, product and other areas to formulate insights for PR, to drive brand presence and other internal insights. Produce new and innovative insight for Equifax based on research and untapped data sources within the business.
What you’ll do
Work with the Equifax bureau in India to build bureau based Analytics capabilities and use the new age technology to implement those solutions
Contribute to Building the BFSI Analytics practice through on- going identification of new opportunities
Understanding of key business and risk KPI’s for retail banking products, drawing insights from bureau datasets
Self-motivation, discipline, task focus, the ability to structure and present work and a proven record of delivering high quality results to strict deadlines
Analysts use their advanced data manipulation and analytic visualization skills to produce valuable insights for Equifax.
Own and deliver reporting capabilities for customers and internal insights through the development of a centralized insights repository.
What experience you need
5-6 years’ experience in handling BFSI analytics/implementing models/Big data/Cloud solution architect
Good knowledge of SAS, SQL, Big data , HDFS,ML model, Spark ,Python,R
Good understanding of banking products
Strong analytical skill, logical thinking and problem solving capabilities
What could set you apart
Adaptability to work in project based engagements across different kinds of banking clients
Knowledge on statistical and probability concepts
Self-starter with high energy levels and ability to work in a fast paced environment
We offer a hybrid work setting, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Primary Location:
IND-Bangalore-Equifax Credit Information Services
Function:
Function - Data and Analytics
Schedule:
Full time",USD 136K - 205K *
75,Systems Administrator - Archive Data Management,Kyndryl,INMANBP Bengaluru (INMANBP) Manyatha,Senior-level / Expert,"Who We Are
At Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.

The Role
 HPSA , HP CSA, HP DMA, HP OO,
Work with business analysts and application developers to understand infrastructure, automation and operational requirements and build a backlog
Educate, mentor and coach engineers and architects on frameworks and approaches
Prepare and lead technical presentations or demonstrations to gain client commitment
Contribute to architecture knowledge base and methods with technique papers, work product descriptions, architectural decisions, guiding principles, documents, and code assets

Who You Are
Expertise with HPSA,HPOO
Deep expertise in cloud-based infrastructures, SDLC pipelines, Agile, and deployments/configurations and definition/evangelism of best practices/standards 
Deep expertise in Data platforms – RDBMS, MS SQL, Oracle, l,
Deep expertise in implementing Automation workflows using MF OO, MF SA, MF CSA, MF DMA  
 
Being You
Diversity is a whole lot more than what we look like or where we come from, it’s how we think and who we are. We welcome people of all cultures, backgrounds, and experiences. But we’re not doing it single-handily: Our Kyndryl Inclusion Networks are only one of many ways we create a workplace where all Kyndryls can find and provide support and advice. This dedication to welcoming everyone into our company means that Kyndryl gives you – and everyone next to you – the ability to bring your whole self to work, individually and collectively, and support the activation of our equitable culture. That’s the Kyndryl Way.

What You Can Expect
With state-of-the-art resources and Fortune 100 clients, every day is an opportunity to innovate, build new capabilities, new relationships, new processes, and new value. Kyndryl cares about your well-being and prides itself on offering benefits that give you choice, reflect the diversity of our employees and support you and your family through the moments that matter – wherever you are in your life journey. Our employee learning programs give you access to the best learning in the industry to receive certifications, including Microsoft, Google, Amazon, Skillsoft, and many more. Through our company-wide volunteering and giving platform, you can donate, start fundraisers, volunteer, and search over 2 million non-profit organizations.  At Kyndryl, we invest heavily in you, we want you to succeed so that together, we will all succeed.
Get Referred!
If you know someone that works at Kyndryl, when asked ‘How Did You Hear About Us’ during the application process, select ‘Employee Referral’ and enter your contact's Kyndryl email address.",USD 45K - 84K *
76,Big data Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
 Interact with stakeholders in departments across the company, identify opportunities for Data Engineering to enhance our business, match the optimal techniques to the specific business need, and then build the models that get the job done.  This is an opportunity for the right candidate to go from end-to-end in the process, from recognizing a problem to implementing the solution, and integrating it with the business teams. You will:
•               Solicit requirements for Data Engineering models, including what data they will use and how the company will use them after they are built
•               Build Big Data Analytics and Visualization platform for handling high-volume batch-oriented and real-time data streams.
•               Help with building big data deployment infrastructure 
•               Work on ETL and high-volume real-time data pipeline
•               Work on Rest API Layer to support analytical/ui requirements
•               Analytics built on top of Python
Qualifications
Qualifications
In order to be successful in this role, we need someone who has:
•               Successful project experience in Data Engineering in an Enterprise setting.
•               Hands-on Expertise with Java 8, Spring Boot Programming
•                Good understanding of Object-Oriented methodologies, design patterns and data structures
•               Excellent working knowledge of Cloudera CDH Tech stack : Apache Spark, Hdfs, Hbase, Hive, impala, kudu and Parquet along with Kafka
•               Excellent hands-on experience with shell scripts and SQL including performance tuning utilizing indexes/partitions
•               Should have hands-on experience and knowledge of spark programming both batch and streaming and should have working knowledge of ETL programming.
•               Experience working on Hadoop Cloudera distribution and has conceptual understanding of Cloudera Administration and Management.
•               Good understanding of streaming technologies and real time analytics
•               Exceptional debugging, testing and problem solving skills
•               Ability to learn quickly in a fast-paced, dynamic team environment
•               Highly effective communication and collaboration skill
•               BS or MS Degree in Computer Science or equivalent experience.
•               5+ years of overall experience with at least 1 in big data end-to-end implementation.
•                
Desired Skills:
 •               Experience on Cloudera CDP environment
•               Good to have working and conceptual knowledge of data cleaning and preparation methods prior to building ML models. Fundamental knowledge of Python Programming and usage of packages like Pandas/Numpy should help here.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
77,Data Science NLP developer,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
2-8 years of experience in commercial software development & data science for medium to large scale deployments. Must have worked on multi domain and wide range of technologies and hands-on on leading technologies. Quick learner and passionate to drive the programs through technical strengths.Tasks
Research & Development of Algorithms in the area of ML, NLP, NLU and Text Analytics
Work closely with the research & product teams to investigate the approach & develop professional grade software for Business Units
Study & extend the Open-Source frameworks in ML & NLP, Analytics for suitable requirements.
Grasp and learn from the on-job assignments in the area of research, suggest innovative approaches & work independently.
Own the complete pipeline with Data Engineering activities.
Benchmarking with SOTA models and extend/improve the results by closely working with domain experts and senior researchers.
Requirements
In Depth knowledge of Machine Learning Algorithms and that are used in NLP and NLU
Conceptual and hands on experience in using and implementing Deep Learning architectures like CNN, RNN and its various flavors.
Strong knowledge in Data Structures
Expert in Production Deployment and Development using python
In depth knowledge of python libraries like NumPy, SciKit, Pandas etc.
Production experience on know-how of SDLC/Agile development
Strong Mathematics w.r.t Machine Learning and Deep Learning
Experience in extending functionalities from Open-Source projects.
Experience in working as or along with Research Team shall be an added advantage.
Technical Skills and Competency:
Excellent in Python programming skill is a MUST.
Hands on experience in Python in Production is mandatory.
R knowledge would be an added advantage.
Experience in NLTK, Spacy, Spark ML shall be an added advantage.
Knowledge of Web-Services/SoA/RESTful Services and Semantics shall be an added advantage.
Excellent Communication and Interpersonal skills
Fundamentals of Generative AI and Experience with LLMs & RAG would be a big plus.
 Qualifications
BE/MS/M. Tech (Electronics, Computer Science or related)
Additional Information
2-8 Years of experience",USD 95K - 160K *
78,Engineering Manager - Data Pipes,Ollion,"Pune, India",Mid-level / Intermediate,"Company Description
WORKING AT OLLION
Innovation is risky. It demands bold steps and big questions, but that’s the price of making change. We’ve got our head in the cloud and two feet on the ground, channeling tech’s endless potential towards a single goal: making a world of difference. And we’re building a global team to do just that— a team capable of making game-changing breakthroughs without ever losing sight of the people it will impact. This is more than consulting. This is the change you can be.
 THE OLLION DIFFERENCE
At Ollion, we’re all in on your independence. Our teams are seasoned. Our solutions are straightforward—sometimes even groundbreaking. And our engagements? Exactly as long as you want them to be. We deliver fresh thinking and hard-earned insight in a way that works for you and your customers, arming your organization with everything you need to make your transformation truly mean something.
Job Description
Job brief
We are seeking a highly skilled and experienced Engineering Manager to join our team. In this role, you will be responsible for leading and coordinating development for a SaaS data product. Your primary focus will be on developing efficient processes, executing effective strategies, and ensuring the timely completion of features and projects.
As an Engineering Manager, you will play a key role in researching and developing innovative products. Collaborating closely with various teams, you will ensure that projects are delivered on schedule and within budget, maintaining a high level of quality and adherence to organizational objectives.
Responsibilities
Team Management: Lead, mentor, and manage a team of engineers responsible for product development. Foster collaboration and high-performance culture within the team.
Product Delivery: Ensure the timely and high-quality delivery of products, aligning with project objectives, scope, and timelines.
Technical Expertise: Leverage deep technical knowledge in front-end, back-end, cloud, and CI/CD to guide the technical aspects of product development. Ensure alignment with industry best practices and standards.
Product and Technology Leadership: Provide input on system and application design, ensuring the technical architecture supports the product's goals and objectives.
Impediment Removal: Identify and remove impediments that may hinder the team's progress and product delivery.
Quality Assurance: Implement quality assurance processes to guarantee the delivery of high-quality products. Oversee testing methodologies and quality control procedures.
Code Delivery Updates: Provide regular updates on code delivery progress, including scope and timeline information to stakeholders.
Qualifications
Requirements and skills
Proven work experience as an Engineering Manager or similar role
Analytical skills for evaluating information carefully and solving complex problems
Communication skills for overseeing staff and working with other management personnel
Detail-oriented with the ability to catch minor errors which can result in major problems
Deep knowledge in Relational Database Management System (RDBMS) such as Oracle and SQL.
Strong technical expertise in front-end (FE), back-end (BE), cloud technologies, and CI/CD best practices, along with the ability to guide the team effectively.
Ability to build products that scale well and deal with a large volume of data/users
Strong technical expertise- Angular or React, jQuery, Typescript Java/Python APIs
Strong expertise in Data Engineering and Data Science
Relevant training and/or certifications as an Engineering Manager
Additional Information
All your information will be kept confidential according to EEO guidelines.
Ollion is an equal opportunity employer. We celebrate diversity and we are committed to creating an inclusive environment for all employees. Ollion does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, military service, or other non-merit factor.",USD 30K - 56K *
79,Data Analyst,Rotork,"Chennai, India",Entry-level / Junior,"Company Description
Rotork is the market-leading global flow control and instrumentation company, helping our customers manage the flow or liquids, gases and powders across many industries worldwide.
Our purpose is Keeping the World Flowing for Future Generations.
 For over sixty years, the world has relied on us to create the things that keep everything moving. From oil and gas to water and shipping, pharmaceuticals and food- these are the flows on which our modern world depends.
 Today we're respected and admired for our people, performance and products. Our success flows from our commitment to engineering excellence, and that's what we will always pursue, safely and sustainably.
 Rotork is going through an exciting period of change and growth, building on our existing market success. It's a great time to join us and make an impact in shaping the future of our business.
http://www.rotork.com 
Job Description
Working as part of the Data team and support team on all aspects of Data management.
Your responsibilities will include,
Data profiling, Schema mapping, Master Data Management, Data analysis, Data cleansing, Data migration
Data quality checks and advising project teams on potential data issues and actions.
Deliver data service requests in line with BAU demand.
Technical Skills
Essential:
Relational Databases – SQL Server, 2016 is a minimum, Oracle nice to have.
SQL – T-SQL, Stored Procedures, Views, DML, DDL
ETL/ELT – SSIS and Azure Data Factory
Exposure to Azure SQL Database
Office – Advanced Excel skills, Word, Visio, PowerPoint
Desirable:
Data Migration Tools
Microsoft 365 Applications - Power BI, PowerApps, SharePoint
Exposure to Microsoft Dynamics or any ERP
  Qualifications
Soft Skills
Essential:
Excellent written and verbal communication skills
Great attention to detail
Commitment to personal excellence
Desire to expand technical expertise.
Congenial attitude - team player
Disciplined work ethic
Desirable:
Out-of-the-box thinker with creative problem-solving ability.
Ability/Experience to establish priorities, work independently, and proceed with objectives without supervision
Personal Specification:
Essential
Demonstrate integrity and honesty.
Capable of communicating at all levels
Ethical and transparent leadership, setting an example to others.
Demonstrate an appetite and ability to work collaboratively in a complex and matrixed business.
Able to deal with people with different cultures throughout the region.
Able to thrive in a changing business, embracing ambiguity and solving complex problems.
Additional Information
  ",USD 53K - 94K *
80,Big Data Engineer (Java/Python/Scala/SQL),Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the role

- As an Associate Software Developer, you will be a contributor of a Scrum/DevOps team focusing on analyzing, developing, testing, and supporting highly complex application software build on Big Data.

- Your primary objective is to ensure project goals are achieved and are aligned with business objectives.  You will also work closely with your Scrum team and program team to test, develop, refine and implement quality software in production via standard Agile methodologies.

Responsibilities
Assist in building and testing Cloud-based applications for new and existing backend systems to help facilitate development teams to migrate to the cloud with an emphasis on quality, best-practice coding standards, and cost-effectiveness 
Build platform reusable code and components that could be used by multiple project teams. 
Provide cloud integration development support to various project teams. 
Leverage modern design patterns and architectural principles to build platform reusable code and components that can be used across projects and teams
Write both unit and integration tests, and develop automation tools for daily tasks
Support product owner in defining future stories and tech lead in defining technical requirements for new initiatives
Build rapid technical prototypes for early customer validation of new technologies
Collaborate effectively with Data Science to understand, translate, and integrate methodologies into engineering build pipelines 
Collaborate with cross-functional teams and stakeholders to align development objectives with broader business goals

Key Skills (Domain Expertise)
Up to 3 years of hands-on software development with a bachelor’s degree in computer science, engineering or similar field
Understanding of cloud architecture / cloud implementation principles
Familiarity with storage, network, computer services, multi-zone, region-based design

Technical Skills
Mid level Experience in software development using programming languages & tools/services: Java or Python or Scala and SQL.
Experience in big data processing tools/languages using Spark Scala is a plus
Knowledge on Unix/Linux OS, commands, shell scripting, python, JSON, YAML.
Knowledge of AWS S3, PostgreSQL or MySQL 
Agile scrum experience in application development 
Understanding of Gitlab /Bitbucket.
Knowledge in Compute: EC2, EMR, AWS Lambda is a plus
Exposure to orchestration tools such as Apache Airflow or similar is a plus
Deployment and automation: Terraform, Cloud Formation is a plus.
AWS Certification is a plus.

Mindset and attributes
Strong verbal/written communication and interpersonal skills.
Must have strong analytical and technical skills in troubleshooting and problem resolution.
Proactive learning and collaborative attitude. 


#LI-DD1",USD 30K - 56K *
81,Data Scientist,Deutsche Bank,Pune - Business Bay,Mid-level / Intermediate,"Job Description:
Data Scientist– Role Description
Data Scientists build and maintain data systems. They construct datasets that are easy to analyze and support company requirements.
Data Scientists are tasked with managing and organizing data, while also keeping an eye out for trends or inconsistencies that will impact business goals. It’s a highly technical position, requiring experience and skills in areas like programming, mathematics and computer science. But Data Scientists also need soft skills to communicate data trends to others in the organization and to help the business make use of the data it collects.
Role Overview
The Experience Reporting & Analytics Team (ERA) will deliver a step change in proactive data management and analytics across End User Computing. Supporting the definition and control of End User Data Architecture together with automated reporting, self-service data provisioning and predictive analysis will establish ERA as the consulting partner of choice across EUC.
ERA’s tools and reports will be integrated into the daily work of our partners, delivered through the following workstream pillars:
BAU Operations  -  standard reporting, new requests, user admin and  support, data analytics and User Experience Dashboard.
Service Transformation – bespoke analytical projects (e.g. Systrack, Service Desk Contact Reductions).
Self-Service Automation – dashboard development and maintenance, user training and support, report automation.
Internal Op  Model – agile new demand and WIP processes (Kanban), benefits realization and team capabilities
Innovation – tooling, capabilities and scope.
Primary Skills:
Experienced in Business Intelligence Tools (e.g SAP BO, Tableau)
Strong problem solving skills with an emphasis with attention to details
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Secondary Skills
Build data systems and pipelines
Analyze and organize raw data
Interpret trends and patterns
Conduct complex data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects
Technical Knowledge
Technical expertise with data models, text/data mining, and segmentation & classification techniques
Hands-on experience with SQL database design
Great numerical and analytical skills
Degree in Computer Science, IT, or similar field; is a plus
Data Scientist certification
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Filter and “clean” unstructured data & seek pattern to improve user experience Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 126K - 198K *
82,Associate Technical Architect - Data Engineering,dentsu international,"Pune, India",Mid-level / Intermediate,"Company Description
DENTSU CREATIVE is dentsu's global creative network that transforms brands and businesses through the power of Modern Creativity. Widely reputed for its innovative and creative approach to marketing and advertising. Dentsu Creative has won numerous awards for its work, including Cannes Lions agency of the year 2022, D&AD Awards, and Effie Awards, among others. The company's global network of offices allows it to serve clients across industries and geographies, and it has worked with many of the world's leading brands. With its focus on creativity, innovation, and results, Dentsu Creative is a leading player in the advertising and marketing industry.
Job Description
Design, build, test, and maintain highly scalable data platforms, ensuring that these systems meet business requirements and industry best practices.
Incorporate new data engineering technologies into existing systems, to help move data across systems.
Create custom data pipelines and solution components that extract, cleanse, transform, move, and aggregate data across various enterprise systems
Identify potential opportunities for data acquisition and explore new uses for existing data.
Develop processes and standards for common data models, and data mapping across systems.
Use a range of ETL tools, Data integration platforms, and underlying languages and tools to integrate disparate data systems effectively.
Leverage data virtualization technologies for data aggregation and unification from multiple, disparate data sources, without the use of any ETL.
Recommend ways to improve data reliability, efficiency, and quality.
Foster collaboration with data architects, modelers, and IT team members on project goals.
Provide technical leadership and consultation on complex projects involving data management, data virtualization, and unification.
Qualifications
Bachelor’s/Master’s degree in Computer Science, Data Science, Information Systems, or a related field.
Minimum of 5 years of experience in a data engineering role, with a focus on data management and data pipeline construction.
Demonstrable experience with data engineering solutions, including data aggregation, data transformation, data movement, and data unification strategies.
Proficiency with Data Lakes built on Cloud Services such as Azure and AWS – e.g., ADLS (Azure Data Lake Storage Gen2),
Proficiency with cloud platforms, and cloud services, on at least 1 major enterprise cloud (Azure or AWS Cloud)
Solid exposure to and experience with data virtualization technologies and platforms, particularly the Denodo platform, is highly preferred.
Proficiency with data orchestration services and data workflow platforms – e.g., Apache Airflow, highly preferred.
Proficiency in scripting and data intensive languages like SQL, Python, etc.
Experience with big data frameworks and associated languages / toolsets is nice-to-have",USD 90K - 151K *
83,Junior ETL Developer,BETSOL,"Bengaluru, India",Entry-level / Junior,"Company Description
BETSOL is a cloud-first digital transformation and data management company offering products and IT services to enterprises in over 40 countries. BETSOL team holds several engineering patents, is recognized with industry awards, and BETSOL maintains a net promoter score that is 2x the industry average. BETSOL’s open source backup and recovery product line, Zmanda (Zmanda.com), delivers up to 50% savings in total cost of ownership (TCO) and best-in-class performance. BETSOL Global IT Services (BETSOL.com) builds and supports end-to-end enterprise solutions, reducing time-to-market for its customers. BETSOL offices are set against the vibrant backdrops of Broomfield, Colorado and Bangalore, India. We take pride in being an employee-centric organization, offering comprehensive health insurance, competitive salaries, 401K, volunteer programs, and scholarship opportunities. Office amenities include a fitness center, cafe, and recreational facilities. Learn more at betsol.com
Job Description
Candidate Must Have:
- 2-4 yrs Experience in Business Intelligence along with database design and integration experience with SQL Server databases
- Strong experience of SQL Server 2016/Azure databases
- Data Marts / Data Warehouse Solution Design, Dimensional Modeling (Kimball Methodology)
- ETL (Extraction, Transformation and Loading) Design & Development (Microsoft SSIS & T-SQL)
Preferred Skills:
- Azure Data Factory & Data Lake
- Analytics/ OLAP Cube Development (Microsoft SSAS/AAS, MDX - Multidimensional Model, DAX - Tabular Model)
- Report and Dashboard Development (Microsoft SSRS and Microsoft Power BI)
Primary responsibilities:
- Demonstrate advanced knowledge and skills in designing and implementing Data Marts, Data Warehouse, ETL and BI solutions 
- Expertise / Handson skills in data modelling, ETL and data components development using: SQL Server T-SQL, SQL stored procedures, triggers and views, SSIS, and SQL agent jobs
- Designing, developing and testing data transformations for reporting and interfaces between systems
- Understanding of database architecture, security and deployment strategies

Secondary Responsibilities:
- Developing Cubes using SSAS Models and querying data using Excel and Powerview
- Developing Reports using SSRS / PowerBI
- Helping business with Self-service BI and Analytics
- Hands on administrative experience with SQL Server 2016
Soft Skills:
- Ability to read, analyze, and interpret general business documentation, technical specifications and project management documentation
- Data gathering, research and analytical abilities so as to develop insightful conclusions and generate solutions to address user needs
- Good analytical, logical reasoning and problem-solving skills
- Good interpersonal, written, and oral communication skills
- Self-motivated and directed, with keen attention to detail
- Able to prioritize and execute tasks in a high-pressure environment
- Experience working in a team-oriented, collaborative environment 
Qualifications
BE/BTECH in Information Technology, Computer Science, or related field
Additional Information
All your information will be kept confidential according to EEO guidelines.",USD 99K - 143K *
84,"Engineer - Mechanical, Highrise, REC (Noida/Mumbai/Chennai)",Ramboll,"Noida, India",Senior-level / Expert,"Company Description
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Job Description
Responsibilities
 Prepare feasibility study reports to meet brief requirements in the agreed format and review with the leads
Work with India & Middle East Team to assemble a design specification compliant with the employers’ requirements, agree its format and content, and monitor and review its preparation ensuring delivery by the due date
Agree and monitor scope of works with the Head of MEP
Clearly define building requirements and purpose of use with the MEP Lead and ME Team to allow detailed design
Carry out detailed design to Middle East Building Regulations and relevant Code of Practice and standards ensuring Construction Design and Management (CDM), QA and technical review and sign off by the Local CRC Head of MEP Leads, including complex calculations and co-ordination issues
Review and monitor the production of calculations including QA, technical reviews and sign off
Ensure that information for project costing preparation is completed in requisite detail and to deadlines, and keep the senior Team informed regarding design progress through explanation of design decisions
Provide documentary information via the senior Team to assist in the preparation of tender documents, ensuring that information for tender preparation is completed in requisite detail and to deadlines, and keep the senior Team informed regarding design progress through explanation of design decisions
Co-ordinate project contracts documents (drawings and specifications) and reviews input from team members
Deal with the day to day queries from the ME Team, ensuring that relevant information is available on time for construction activity
Project manage commissions from the ME Team, using applicable project management tools
Lead the design process and encourage the rest of the team to deliver appropriate and cost effective solutions to the agreed programme
Follow in full the document control, archiving CDM and QA processes relevant to project work, ensuring drawings, specifications, reports and correspondence are issued, and filed in an appropriate manner, coach junior staff in their usage
Technical and Project Management
Raise the level of technical competence within the teams
Implement delivery and quality measurement processes
Promote technical excellence in all our projects
Undertake technical reviews, checks and contribute to the concept design
Provide continuous feedback to the Head of teams on the effectiveness of the protocols and processes in place with a view to continuous improvement
Develop positive professional relationship with the ME & Client Team, communicating openly about project progress
Participate in team meetings, disseminate information within the team, and communicate with other teams in REC
Identify and act on, or refer, potential risk issues and follow in full the company commercial and contracting processes
Manage delegated tasks to ensure that deadlines are met and flag resourcing concerns to team leader
Complete timesheet accurately ahead of weekly deadlines
Assist in elements of financial management
Deputize for team leader
 Qualifications
B.Tech/M. Tech (Mechanical)
Minimum of 5-12 years of relevant experience
 Additional Information
Key Competencies / Skills
 A sound understanding of Microsoft Outlook, Word, Excel, Project is essential
Must be fluent in English with an excellent understanding of technical terminology.
Applicants need to be able to demonstrate good management and technical skills and be capable of working both within the team and independently, as dictated by work load
Cultural awareness, conscientious and an open mind and excellent communication skills are essential requirements for the role.
High degree of self-motivation and ability to motivate others.
Ability to work under pressure and with minimum of supervision
Mandatory Skills
 Progress in HVAC Concept design Improves Area, Pressure and Classification zoning. Confirms the design and Concept with QA for regulatory requirements, Preparation of IFC Drawings, Schedules, Datasheet schematics and P&ID
Should possess membership to an accredited engineering body i.e. MIET, CIBSE, INSRAE, ASHRAE, IMechE
Excellent working knowledge of ASHRAE and good working knowledge of ME codes would be advantageous.
Prepare heat load calculations – IES, HAP, TRACE
Carryout preparation of Technical submittals of various materials, equipment’s etc.,
Knowledge of software like Revit, BIM 360, AutoCAD, MEP & other drafting software’s.
Magic Cad will be an added highlight.
Carry out detailed design, calculations & drawings.
Carry out regular design reviews
Understand the specifications and tender conditions accordingly design.
Receive, analyse and evaluate quotations suiting our requirements.
Implement cost effective measures for reducing project cost.
Preparation & Maintenance of design files and documents.
capable of discussing with the clients/ consultants/ other agencies to carry out the design activities
knowledge about other services like electrical, PHE etc. to carryout design co-ordination
Good presentation skills are also required
Must be fully conversant with technical software, such as Hevacomp,
Valid passport",USD 45K - 84K *
85,Data Engineer,HARMAN International,IN Bengaluru Manyata Embassy BSNS Park HCS,Senior-level / Expert,"HARMAN’s engineers and designers are creative, purposeful and agile. As part of this team, you’ll combine your technical expertise with innovative ideas to help drive cutting-edge solutions in the car, enterprise and connected ecosystem. Every day, you will push the boundaries of creative design, and HARMAN is committed to providing you with the opportunities, innovative technologies and resources to build a successful career.
A Career at HARMAN
As a technology leader that is rapidly on the move, HARMAN is filled with people who are focused on making life better. Innovation, inclusivity and teamwork are a part of our DNA. When you add that to the challenges we take on and solve together, you’ll discover that at HARMAN you can grow, make a difference and be proud of the work you do everyday.
Job Description :- (Exp: 2+)
Design and implement effective database solutions and models to store and retrieve data after identifying source data structures.
Discover trends and patterns, combine various algorithms and modules, and bring up the data representation using various data visualization techniques and tools.
Implementing end-to-end data modeling, from the technical architecture, and developing the application to finally testing and implementing the proposed solution.
Development experience on GCP (Big query, Vertex AI, Anomaly detection, AI/ML and Python Programming) and good to have AWS knowledge as well.
Good to have database management and administration knowledge.
Extensive coding experience in programming languages Python
HARMAN is an Equal Opportunity /Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race,color, religion, sex, sexual orientation, gender identity, national origin,disability or Protected Veterans status. HARMAN offers a great work environment, challenging career opportunities, professional training and competitive compensation. (www.harman.com)",USD 121K - 186K *
86,Masterdata Analyst,DSM,India,Entry-level / Junior,"Job title – Masterdata Analyst
Location- Hyderabad
Job model – Hybrid
  As a part of the MDM Operations Team, you will support the Global Group Planning within Group Supply Chain organization. In this role you will be expected to support master data operations within SAP APO system and alignment of master data in SAP ECC. This activity will have a critical impact in the quality of the planning results across the organization and interacts with Global Supply chain, master data governance and group planning community.
  Your key responsibilities
- First line of support, ensuring systems master data, issues and requests are handled correctly within deadlines.
- Check/Monitor the systems looking for inconsistencies, wrong master data settings and contact the users and group planning to clarify/update the data.
- Perform consistency checks on all master data changes requirements, interact with users to validate any inconsistencies according with master data consistency rules.
- Perform master data alignments checks needed, corelate the impact of requested changes to other master data fields between SAP ECC and SAP APO according with master data accuracy rules and execute needed master data alignment.
- Ensure the documentation (process and training material) are kept updated for the demand and supply planning community.
    We bring
The ability to be a part of a highly creative and imaginative team in an incredibly competitive and inspiring industry.
A challenging and rewarding function embedded in a team of passionate professionals.
A rich history and a promising future of bold scientific innovation and passionate creation with our customers.
The opportunity to work for a company where sustainability is much more than a claim and is core to our strategy and purpose.
A flexible work environment that empowers people to take accountability for their work and own the outcome.
A firm belief that working together with our customers is the key to achieving great things.
    You bring 
- Graduate in B.Tech., M.Tech.
- English business proficient
- Excellent communication skills.
- Experience in using SAP systems is a must
- Proficient in Microsoft office - Excel, PowerPoint, powerBI
- Minimum 5+ years of relevant work experience
  The application process
Interested in this position? Please apply on-line by uploading your resume in English via our career portal. For further information, please contact Kubra Ali Khan, Talent Acquisition (kubra.ali-khan@dsm.com)
    Equal Opportunities Commitment
  dsm-firmenich is fully dedicated to inclusion because when people feel engaged and empowered, their creativity and innovation drives unprecedented progress. We aim to build a workplace where opportunity really is equal, so everyone can thrive. We do not discriminate there's a place for everyone at dsm-firmenich.
dsm-firmenich is an Equal Opportunity and Affirmative Action Employer. dsm-firmenich people are as diverse as our customers. For us that includes a commitment to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law.
We are committed to providing reasonable support for disabled applicants in our recruiting process. Should you need assistance, and are comfortable to share this, please let us know.
    About dsm-firmenich
As innovators in nutrition, health, and beauty, dsm-firmenich reinvents, manufactures, and combines vital nutrients, flavors, and fragrances for the world's growing population to thrive. With our comprehensive range of solutions, with natural and renewable ingredients and renowned science and technology capabilities, we work to create what is essential for life, desirable for consumers, and more sustainable for the planet dsm-firmenich is a Swiss-Dutch company, listed on the Euronext Amsterdam, with operations in almost 60 countries and revenues of more than €12 billion. With a diverse, worldwide team of nearly 30,000 employees, we bring progress to life™ every day, everywhere, for billions of people.
  Please note this is a direct search led by dsm-firmenich. We only accept applications from candidates, not from agencies nor subject to agency’s fees, percentages or similar.  
    #ext",USD 53K - 94K *
87,Big Data Engineers (Java/Scala/Hadoop/Spark/AWS),Nielsen,"Bengaluru, India",Senior-level / Expert,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the role

- As a  Senior Software Developer, you will be a contributor of a Scrum/DevOps team focusing on analyzing, developing, testing, and supporting highly complex application software build on Big Data.

- Your primary objective is to ensure project goals are achieved and are aligned with business objectives.  You will also work closely with your Scrum team and program team to test, develop, refine and implement quality software in production via standard Agile methodologies.

Responsibilities
Build scalable, reliable, cost-effective solutions for both the Cloud and on-premises with an emphasis on quality, best-practice coding standards, and cost-effectiveness
Build and test Cloud-based applications for new and existing backend systems to help facilitate development teams to migrate to the cloud. 
Build platform reusable code and components that could be used by multiple project teams.
Understand the enterprise architecture within the context of existing platforms, services and strategic direction.
Implement end-to-end solutions with sound technical architecture, in Big Data analytics framework along with customized solutions that are scalable, with primary focus on performance, quality, maintainability, cost and testability.
Drive innovative solutions within the platform to establish common components, while allowing customization of solutions for different products.
Develop design specifications, continuous build and deployment strategy to drive Agile methodology
Setup and manage expectations with consultants engaged in the projects.
Provide cloud integration development support to various project teams. 
Build rapid technical prototypes for early customer validation of new technologies
Collaborate effectively with Data Science to understand, translate, and integrate methodologies into engineering build pipelines 
Collaborate with product owners to translate complex business requirements into technical solutions, providing leadership in the design and architecture processes.
Provide expert apprenticeship to project teams on technology strategy, cultivating advanced skill sets in application engineering and implementing modern software engineering practices
Mentor junior team members, providing guidance and support in their professional development
Stay informed about the latest technology and methodology by participating in industry forums, having an active peer network, and engaging actively with customers
Cultivate a team environment focused on continuous learning, where innovative technologies are developed and refined through collaborative effort

Key Skills (Domain Expertise)
Bachelor’s degree in computer science, engineering plus 4-8 years of experience in information technology solutions development. 
Must have strong cloud Implementation expertise in cloud architecture. 
Must have strong analytical and technical skills in troubleshooting and problem resolution. 
Must have the ability to provide solutions utilizing best practices for resilience, scalability, cloud optimization and security. 
 3+ years of experience: big data using Apache Spark in developing distributed processing. applications; building applications with immutable infrastructure in the AWS Cloud with automation technologies like Terraform or Ansible or Cloud Formation.

Technical Skills
Experience in Service-oriented architecture, Spark Streaming, and Git.
Experience in software development using programming languages & tools/services: Java or Scala, Big Data, Hadoop, Spark, Spark SQL, Presto \ Hive,Cloud (preferably AWS), Docker, RDBMS (such as Postgres and/or Oracle), Linux, Shell scripting, GitLab, Airflow.
Experience in big data processing tools/languages using Apache Spark Scala.
Experience with orchestration tools: Apache Airflow or similar tools.
Strong knowledge on Unix/Linux OS, commands, shell scripting, python, JSON, YAML.
Agile scrum experience in application development is required. 
Strong knowledge  in AWS S3, PostgreSQL or MySQL.
Strong knowledge  in  AWS Compute: EC2, EMR, AWS Lambda.
Strong knowledge in Gitlab /Bitbucket .
AWS Certification is a plus.

Mindset and attributes
Very strong verbal and written communication skills
Advanced analytical and technical skills in troubleshooting and problem resolution
Ability to coach, mentor and provide guidance to junior colleagues


#LI-DD1",USD 45K - 84K *
88,Senior Electrical Engineer (Chennai/Noida/Mumbai),Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Ramboll was founded in 1945 in Denmark. Today, we employ 16,000 engineering, design and consultancy specialists. We hold a leading position in the Nordic market (Denmark, Sweden, Norway, and Finland) and have more than 300 offices in 35 countries.
Job Description
We invite you to bring your Electrical System experience into play as you will provide electrical engineering services on projects to Ramboll and its Clients, in coordination with Architects and structural consultants, for all stages; i.e concept, schematic, detailed design, tender & construction. This shall include technical and project leadership within the electrical engineering team. To succeed in this role you must have B.Tech/ M.Tech in Electrical Engineering with 8 to 10 years of professional experience in the relevant field. Are you our new Senior Engineer- Electrical, Buildings? Click the apply-button to send your application.
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies and people around the world.
You will join our Buildings Department
As our new Senior Engineer– Electrical, Buildings you will be part of our global High-Rise department, Ramboll’s dedicated team of high-rise experts which have designed over 150 tall building projects globally, including some of the most technically challenging. You would be responsible for coordinating with project managers and/or engineers for design and draughting work in the High-Rise department in India offices and supporting the global department which also has offices in Copenhagen, Dubai and Singapore.
Your key tasks and responsibilities will be:
As a Senior Electrical Engineer, you shall be responsible for the design and delivery of all electrical and associated ELV systems of a wide range of projects in the building services. Key responsibilities and duties are listed, but not limited to, the below:
Technical engineering of all electrical systems and including:
Lead discipline on projects.
Developing and guiding junior engineers.
Applying policies relating to health & safety, quality, and training.
Preparation of load estimation for the project and conducting primary technical calculations, drawings, reports, specifications and reviews on design deliverables related to electrical system design.
Develop a thorough design philosophy, effectively contributing to the inception, development, and detailed delivery of projects across all stages.
Coordinate and liaise with all other design team members, including architects and structural engineers plus client, project managers and QS.
To act as discipline lead on projects to successfully deliver high quality discipline projects in accordance with corporate and client requirements.
Capability of leading MEP for small to medium sized projects.
Attend external meetings and prepare design presentations and design reports.
Where design on middle east projects is being performed remotely with other Ramboll offices or by subconsultant, collaborate closely with those remote design teams and ensure compliance with local requirements and where directed, assist and represent the satisfactory performance of their services to local clients and stakeholders.
Provide electrical engineering technical support and engage personally where required to successfully enable Local Authorities’ approvals on all projects.
Support client and sustainability sub-consultant in studies, calculations and reports for sustainability options within the project.
Mentor and coach junior and graduate engineers.
Check and review electrical design work undertaken by junior and graduate engineers.
Responsible for the correctness, accuracy, and complete multi-disciplinary coordination of the design documentation in accordance with QA/QC review processes.
Have a good knowledge of buildability & construction techniques.
Demonstrated critical thinking skills, ability to work methodically and analytically in a quantitative problem-solving environment.
Forecast, plan and manage own workload and progress against agreed plan and criteria.
Evaluate and advise to project lead engineer on electrical related design changes to ensure change management.
Strong attention to detail, team working, collaboration, organization, and problem-solving skills.
Have a basic understanding of the financial and commercial management of projects.
Provide technical support to respond to prequalification documents, RFPs, and other client inquiries.
Excellent written and verbal communication skills.
Ensure that Health & Safety is embedded into all work practices in line with company policies.
Maintain and participate in Continuing Professional Development (CPD) events to develop own expertise.
Qualifications
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this Senior Electrical Engineer role, we believe your starting point is:
B.E /M.E in Electrical with 8 to 10 years of professional experience, out of which a minimum of 4 years should be in Middle East projects as an added advantage.
Proven track record in building services design with different types of sectors, including high rise, commercial, residential, retail, healthcare, industrial, educational, refurbishment, etc.
Proven record as a Project Engineer on several projects.
Experienced in working within teams on multi-disciplinary projects and interacting with a wide range of architectural, engineering and planning disciplines.
Advanced knowledge of electrical engineering principles for LV, Lighting, ELV and FA/FLS designs.
Good system overview knowledge of buildings mechanical and public health systems.
An ability to adapt to different working styles and the unique business culture of the Middle East.
Excellent knowledge of local and international design standards, including BS-EN, CIBSE, ASHRAE, NFPA etc.
An excellent knowledge and experience of local statutory authorities’ regulations and submission requirements across Middle East, mainly UAE and KSA, such as DEWA, ADDC, SEC, SBC, Etisalat, Du, Civil Defence etc and procedures for Local Authority approvals.
Proven ability to carry out both manual and computer aided calculations, problem solving, technical analyses, etc.
Proficient in LV power system modelling and analysis software such as Amtech (or similar), lighting software (Dialux Evo, Relux, or similar), Lightning Protection (Strike Risk or similar) and generator sizing.
Competent use of relevant software such as MS Office suite.
Knowledge and experience of AutoCAD, Autodesk Revit and Navisworks would be recommended.
Detailed knowledge of BIM automation / digitalisation techniques and standards.
Knowledge of sustainable design practices and technologies, preferably having worked on LEED or Estidama certified projects.
Personal qualities that will help you succeed in this role include: self-motivated, team player and able to work independently with minimum supervision and a flexible attitude in an environment with frequently changing deadlines and can be relied on to meet deadlines.
Additional Information
Welcome to our Buildings division
As one of the top 10 building designers in the world, Ramboll works on more than 10,000 building projects each year. 5,000 experts across the world specialise in creating more innovative, sustainable and liveable buildings. We place particular emphasis on our liveable buildings concept where we balance the cultural, social and physical values of buildings, to improve the quality of life for building users.
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 45K - 84K *
89,Senior Data Analyst (Cloud Finance),Palo Alto Networks,"Bengaluru, India",Senior-level / Expert,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Our Approach to Work
We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!
Job Description
Your Career
Cloud infrastructure is a critical strategic component to our cloud delivered security offerings. The Cloud Finance team manages cloud spend across the whole PANW portfolio and across Cloud Service Providers (CSPs). We directly manage relationships with our CSPs and drive procurement optimizations via rate negotiations and committed/reserved usage discounts.  Working alongside a tight-knit cross-functional group with CloudOps and IT, we build tooling and dashboards to provide teams with visibility into usage optimization opportunities and cloud unit economics, enabling teams to make the best strategic business decisions and providing Executive Staff with insightful, proactive recommendations to drive both topline and bottom-line growth across various portfolios within the Company.  
Your Impact
Support Finance teams on data extraction, clean-up and analysis to enable business decision making and negotiations with cloud service providers (e.g. impact of various CSP pricing changes, cloud service usage patterns etc.)
Work with Central IT on financial data validation and UAT on central dashboards
Partner with cross-functional business partners and CSP vendor to implement best practices, automation, and continuous process improvements
Drive new initiatives and assist with special projects and ad hoc requests as needed
Quantify the cloud hosting costs per product and assess the impact of new product launches
 Qualifications
Your Experience
Engineering or Technical Degrees (BE/B.Tech/ME/M.Tech/M.Sc/MCA) (MBA preferred)
2 to 5 years experience in querying data using SQL and consolidating, transforming and analyzing large data sets in excel
Expertise in BI solutions like Tableau or Looker. Experience building simple dashboards preferred
FinOps experience and certification preferred
Intermediate to advanced Excel skills required
Strong communication skills both written and verbal
Demonstrated ability to work cross-functionally in a matrixed organizational structure
Ability to analyze data and help teams to identify anomalies
Additional Information
The Team
We are the global cybersecurity leader, known for always challenging the security status quo.
Our mission is to protect our way of life in the digital age by preventing successful cyberattacks. This has given us the privilege of safely enabling tens of thousands of organizations and their customers. Our pioneering Security Operating Platform emboldens their digital transformation with continuous innovation that seizes the latest breakthroughs in security, automation, and analytics. By delivering a true platform and empowering a growing ecosystem of change-makers like us, we provide highly effective and innovative cybersecurity across clouds, networks, and mobile devices.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: No. Please note that we will not sponsor applicants for work visas for this position.
Covid-19 Vaccination Information for Palo Alto Networks Jobs
Vaccine requirements and disclosure obligations vary by country.
Unless applicable law requires otherwise, you must be vaccinated for COVID or qualify for a reasonable accommodation if:
The job requires accessing a company worksite
The job requires in-person customer contact and the customer has implemented such requirements
You choose to access a Palo Alto Networks worksite
If you have questions about the vaccine requirements of this particular position based on your location or job requirements, please inquire with the recruiter.",USD 93K - 144K *
90,Supply Chain (Data Analytics),GlobalFoundries,IND - Karnataka - BANGALORE,Senior-level / Expert,"Job Title: Principal Analyst Supply Chain Bus Operations
Principal Analyst Supply Chain (Data Analytics)
About GlobalFoundries:
GlobalFoundries is a leading full-service semiconductor foundry providing a unique combination of design, development, and fabrication services to some of the world’s most inspired technology companies. With a global manufacturing footprint spanning three continents, GlobalFoundries makes possible the technologies and systems that transform industries and give customers the power to shape their markets. For more information, visit www.gf.com.
Summary of Role:
In this role, you will help us to better serve our internal organizations/stakeholders through data analysis activities. The Data Analyst will assist us in analysing the requirements, preparing and execution of Daily / Weekly / Monthly / Quarterly/ Annual master data reports, applying your strong attention to detail and excellent analytical skills to analyze reported information, then working closely with the team/stakeholders to improve the overall efficiency, accuracy and reliability of the master data. Will also be responsible for data validation and making certain reporting aligns with the business requirements for internally developed systems.
Essential Responsibilities include:
Devlier KPIs, Metric and Identify Areas of Risk, Drive Analysis, Patches
Generate data and use reporting tools to provide accurate information from disparate data source systems
Analyze reported data to identify opportunities to drive efficiency, reduce costs, identify problem areas, and recommend improvements
Perform system analyst role in performing data analysis between touch points, root cause analysis on any gaps/issues, design, develop & validate the reports using PowerBI reporting platform.
Work with various stakeholder groups, ensuring that business requirements are captured and met
Designing and maintaining KPIs, dashboards and reports that support decision making within the organization with a high level of quality and accuracy
Maintaining and executing SQL against both structured and unstructured data sets
Track work and provide updates in project management tools
Directly work with the ETL Engineers and Data Engineers to communicate and define reporting requirements
Perform all activities in a safe & responsible manner and support all Environmental, Health, Safety & Security requirements and programs.
Required Qualifications:
Experience – bachelor’s degree with 4-6 years, master's degree with 2-5 years of experience
Bachelor’s degree in data analytics or Computer Science or Information Technology or a related field
Experience in Data Analytics of Supply Chain/Global Operations business domain.
Minimum 3 years of Experience in reporting & visualizing data with Power BI or Tableau
Minimum 3 years of Experience of SQL (or any query language)
Must have experience in Python (Machine learning & Error Detection)
Good communication skills (includes oral & written)
Language Fluency – English
Good analytical skills are a MUST required qualification for this role.
Ability to quickly build relationships with department and other stakeholders
Aptitude for meaningful interpretation and application of data for the purpose of process improvement
Must have a proactive, collaborative approach to problem solving
Ability to work autonomously and apply problem-solving skills
Ability to work with a sense of urgency and prioritize in a deadline driven environment
Act with integrity in all ways and at all times, remaining honest, transparent, and respectful in all relationships
Information about our benefits you can find here: https://gf.com/about-us/careers/opportunities-asia
 ",USD 37K - 70K *
91,Quantitative Analyst / Data Scientist,BestEx Research,"Bengaluru, Karnataka, India",Mid-level / Intermediate,"Quantitative analyst contributes to the design and management of execution algorithms for global equities, futures, and foreign exchange with the aim of continuously minimizing trading costs for our clients. BestEx Research quants will learn about algorithmic trading, data management, performance measurement, and market microstructure, globally. Quants are nested within a talented team of experts and practitioners in the field and may participate in writing research papers and interface closely with client research teams to improve trading costs. Our internal research environment includes tick-by-tick market data, historical backtesting simulators, instrument-level daily analytics and normalized order and execution data to facilitate new research. Our infrastructure allows speedy creation of execution algorithms and contains simulation capability for testing. Day-to-day responsibilities of this role may include but are not limited to:
● Contribute to end-to-end research and implementation of execution algorithms, including idea generation, data collection and cleaning, model development, evaluation, and improvement
● Work with Senior Quants and Product managers to produce custom client analysis and refine existing algorithms
● Maintain, and optimize data pipeline and ETL process for our analytics product
● Review results of production implementation including verification and testing.
● Document theory, models, and results for a variety of audiences
● Analyze and understand the idiosyncratic characteristics of client order flow and optimize execution algorithms
Requirements
● Highly motivated, willing to take ownership of work
● Collaborative mindset with strong independent research abilities
● Bachelors in computer science, data science or Masters in statistics, economics, quantitative finance, MBA (Finance) or other quantitative fields with a strong foundation in statistics and programming. 
● Prior experience (0-3 years) building high frequency trading strategies, algorithmic trading strategies or statistical arbitrage is valued but not required
● Experience using data to answer questions and communicating the results, including model building
● Experience cleaning data, quickly and efficiently scrubbing, formatting, and manipulating large, raw data sources
● Strong command of the foundations of applied statistics and modeling
● Strong preference for demonstrated proficiency in SQL and R or Python, but experience using at least one programming language is required
● Experience with C++ valued but not required
● Excellent communication skills and ability to articulate ideas and work to colleagues and clients",USD 86K - 160K *
92,Assistant Manager - Data Quality,TransUnion,Mumbai - One World Center,Mid-level / Intermediate,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are one of India’s leading credit information company with one of the largest collections of consumer information. We aim to be more than just a credit reporting agency. We are a sophisticated, global risk information provider striving to use information for good.
We take immense pride in playing a pivotal role in catalyzing the BFSI industry in the country. We got here by tapping into our excitement and passion of wanting to make a difference in the lives of our clients and consumers.
We at TransUnion CIBIL are an equal opportunity employer and are committed to a policy of treating all our associates and job applicants equally. Applicants are evaluated on the basis of job qualification - not race, color, sex / gender, religion, caste, national origin, age, disability, marital status, citizenship status, sexual orientation, gender identity or any other status, whether or not protected. We are committed to taking affirmative action to employ and advance minorities, women, and qualified disabled individuals. We ensure a safe, productive, and harassment-free workplace for all.
Culture and Values
Our culture is welcoming, energetic, and innovative. There’s an overall synergy that flows throughout the company, creating a sense of connect, belonging and unity in knowing that we’re all working to achieve the same overall goal. Our core values which we live by every day are integrity, People, Customer, and Innovation.
https://www.transunion.com/privacy/global-job-applicant
What is excitement and passion for us?
We define it as a blend of curiosity, ability to unlearn and yet continuously learn, able to connect with meaning and finally the drive to execute ideas till the last mile is achieved. This passion helps us focus on continuous improvement, creative problem solving and collaboration which ensures delivery excellence.
Dynamics of the Role
This is an exciting time in TransUnion CIBIL. With investments in our people, technology and new business markets, we are redefining the role and purpose of a credit bureau.
The role will be responsible for assisting in formulating and managing the development and implementation of goals, objectives, policies and procedures for data quality and performance. S/he will be responsible for ensuring proper implementation of quality assurance objectives and meeting the set target for Commercial Data in lending Industry.
What You'll Bring:
Roles & Responsibilities
Responsibility 1): Build & Manage Business intelligence process
• Understand the core process of Data reporting by Credit Bureaus by Financial institution
• Develop mechanism to analyze Daily data flow into the repository.
• Share insights , trends and monitor key business metrics around Personal/ consumer and Rural lending
• Create custom dashboards and MIS for top management
• Conduct RCA and review mechanism for critical data fields.
Responsibility 2): Big Data Analysis
• Apply Big data tools Spark/ HiveSQL / Pyspark/ SQL to prepare meaningful stories related to Quality and Risk parameters
• Build automation jobs on Hadoop / Mapr platform for BAU ( day to day ) activities
• Create Analytical dashboard on powerBI / Tableau for sharing insights and decision making
Responsibility 3): Engagement with members/ financial institution
• Conduct detail analysis of new/existing members who are submitting data.
• Develop & monitor variables for deep dive into data as per regulatory /compliance.
• Identify and share analysis with member institution for continuous improvement.
• Lias with cross functional teams to improve the quality of data in Fintech space
• Engage with external financial institutions to drive the improvement in data quality.
Impact You'll Make:
Experience and Skills
3+ year work experience in BFSI Domain Business Intelligence
Atleast 3+ year of strong database experience (RDBMS etc.) using SQL / Spark / HiveSQL
Hands on experience in SQL / Pyspark and ability to write complex queries is mandatory
3+ years’ experience in working with large database and datamarts (in GB’s and TB’s of data) with focus on efficiency of data access to run analytics engagement
3+ years of working exposure to BI and visualization platforms for developing Business dashboard solutions
2+ years of experience in Tableau / PowerBI
Exposure to data warehousing concepts and practices would be preferred
Exposure to BIG data technologies will be a plus
Exposure to digital and advance analytics would be a Plus
Tableau/PowerBI certified or any other technical certification will be plus
Self-starter, ability to work independently, handle ambiguous situations and exercise judgement in variety of situations.
** Strong communication, organizational, verbal & written skills. (Important Skill)
High degree of responsibility and ownership, strong multitasking, coordination and tenaciously looking for ways to get results.
TransUnion Job Title
Specialist I, Data Design and Analysis",USD 30K - 56K *
93,Business Data Analyst,BMT Group,"Alandi, IN",Entry-level / Junior,"Department: Analytics & Data Science
  Designation – Deputy Manager

    
Experience – 10- 12 Years
  Qualification – B.sc /M.sc /BE 
  Job description
•    Uses a range of data tools to provide analysis and reports within a reporting framework.
•    Collaborates with internal and/or external clients to understand business requirements.
•    Prepares and presents interpretation of findings to internal and/or external clients.
•    Compiles, interprets and sorts data with limited variables in preparation of analysis
•    Identifies and resolves any data quality issue by conducting both routine and ad-hoc data cleaning and testing. 
•    Develops routine ad-hoc reports and dashboards. 
•    Sets up and carries out research, studies and benchmarks at request or at own initiative. 
•    Collects, selects, structures, combines and interprets external and internal data, information and developments. 
•    Assures functional specifications are consistent with the technology roadmap. Executes test scenarios and test scripts, makes necessary changes to meet requirements. 
•    Enables data distribution to the right user. Uses recovery techniques and backup data. 
•    Provides data management support, acts as a key user.

Profile Requirement
•    Good communication & presentation skills with a positive mind
•    Good knowledge of English, written as well as spoken
•    First relevant experience with data management and ERP system
•    Knowledge and experience with business intelligence tools and reporting (preferably SAP Analytics Cloud, can also be Power BI or Tableau or Qlik…)
•    Knowledge of visual best practices for reporting
•    Knowledge of data modeling & SQL
•    Knowledge of ETL with SAP Data Services or Microsoft SSIS is a plus
•    Knowledge of SAP HANA Modeling is a plus
•    Self-steering team player
•    Strong analytical thinking and problem solving 
•    Punctual, accurate and focus on quality of data

Skill/Attributes
•    Good communication & presentation skills
•    Relevant experience with data management and ERP system. 
•    Knowledge on SAP, Cloud, SQL, Power BI, Qlik.",USD 35K - 94K *
94,Manager - Risk & Data Science,Meesho,"Bengaluru, Karnataka",Mid-level / Intermediate,"About the Team

Would you like to be part of creating a unicorn within a unicorn? Solve some of the biggest challenges facing financial inclusion of Bharat? Well, then here’s your chance!

Financial Services (FS) is one of the biggest new bets we are taking at Meesho on the next 10x horizon opportunity for us. Just as Ant Financial did for Alibaba, and Mercado Pago did for Mercado Libre, our vision is to build financial services for Meesho, becoming our key growth and revenue driver. 

We are building out our founding team, currently in our 0-to-1 phase where we will find our Product-Market Fit - designing the right products and working with the right partners - and scale 1-to-n soon after - driving traffic and constantly improving our product. It is possibly one of the most exciting and enriching experiences one could consider in their career.

As a Financial Services team, we always look at the bottom line. And the bottom line is - in this team, you should expect to have fun as you learn and grow.

About the Role

Lending is going to be our primary focus in this phase of our FS journey, and risk management is at the core of building any sustainable credit business at scale. Herein also lies potentially our biggest challenge for

Meesho users: How do we assess risk of borrowers without any credit history? How can we leverage alternative information to better profile borrowers? How can we leverage our platform uniquely to create a sustained competitive advantage? 

The Person will be responsible for driving the analytics behind all these questions, from creating analytical frameworks, developing high quality analysis, driving insights and actions, and owning policy decisions.
What you will Do
In the early phases, your role will focus more on developing rudimentary analysis to define day-1 policies:
Analyzing and Designing credit policies using Meesho platform data, bureau data, alternate data.
Creating Scorecards and models for approval.
Designing experiments to test cohort behavior and experimental policies.
Identifying leading indicators / EWS.
Automate reporting and tracking of the portfolio on multiple levels, Ops performance measures, key performance indicators and associated drivers.

Responsibilities Over the longer horizon, as the program scales you are expected to do the following:
Credit Risk Management / Portfolio monitoringRefine the Credit policies and create new policies to lend in unexplored segments.
Own end to end ML model development methodology : feature creation, development, tuning, validating, monitoring, calibrating wherever required and creating strategies on top of it.
Coding up BRE , automating credit policies as well as underwriting decisions if need be.
Initially an IC role but expected to guide and manage a team of analysts.
What you will need
6-9  years of relevant Fin-Tech experience, preferably in Digital Unsecured Lending, with products like business loans ( SME ), BNPL and PL ( Consumer )
Independently drive and conceptualize projects on Risk and Data science. 
Strong RCA skills along with excellent critical thinking skills, combined with the ability to present your beliefs clearly and compellingly, both verbally and in written form.
Working knowledge of SQL, Big Data systems like Hive, metabase or any  other database for data mining in structured as well as unstructured data analytics.
Expert in PD, EAD, LGD modeling in Python environment. Ability to thrive in a fast-paced, collaborative VUCA environment.
Engineering or Masters in Statistics or Data SciencePrior experience in fast paced Credit Risk policy, Risk  Analytics or Decision Science team.
About Meesho

Meet Meesho - India’s only true e-commerce marketplace.
Welcome to Meesho, where every story begins with a spark of inspiration and a dash of entrepreneurial spirit. We're not just a platform; we're your partner in turning dreams into realities.
Meesho (Meri shop) started with a single idea in mind - to be an e-commerce destination for the next billion Indian consumers and enable 100 million small businesses to succeed online. Meesho is democratizing internet commerce in India. The company provides sellers with a range of industry-first benefits such as zero commission and the lowest shipping cost. Over 1.4 million sellers are registered on Meesho, growing their business by tapping the company’s massive customer base, state-of-the-art tech infrastructure, pan-India logistics at the lowest cost through third-party logistics providers in an 'Everyday Lowest Cost' channel for sellers.


Meesho has been a catalyst for over individual entrepreneurs, propelling them into an online business with zero initial investment. What sets us apart is our revolutionary 0% commission model for sellers, a pioneering concept in the Indian e-commerce landscape. Our vision extends beyond being a platform; we aspire to be the e-commerce destination for Bharat—a testament to our dedication to inclusivity and accessibility.

Meesho milestone:

Our journey is marked by significant milestones, including a valuation of $4.9 billion and the unwavering support of renowned investors such as Sequoia Capital, Softbank, Fidelity, Prosus Ventures, Facebook, and Elevation Capital. Meesho proudly found its place in Y Combinator’s 2021 Top Companies List and was the sole Indian startup featured in Fast Company’s The World’s 50 Most Innovative Companies in 2020. In 2021, we claimed the 6th spot in Linkedin’s Top Startups List.
 9 crore orders  every month~13 Lakh seller on the platform 75% of user from Tier 2+ cities of India 3.6 cr monthly  and 14 cr Annual  transiting users12+ Cr product listings on Meesho A new product uploaded every second

But beyond the numbers and accolades, our true strength lies in our people. At Meesho, we champion a people-first culture with gender-neutral and inclusive policies. Discover opportunities to be part of our dynamic team at meesho.careers.
Join us on this exhilarating journey, where innovation meets inclusivity, and every entrepreneur's dream finds a home. Explore more about our story and vision through our insightful blogs!

Our mission:

Democratising e-commerce for Bharat.Meesho is focused on building and making e-commerce accessible for the next billion users. Affordable, relatable merchandise mirroring local markets has helped us make inroads with first-time internet users in the country. With ~80% of Meesho’s 140 million annual transacting customers coming from Tier 2+ cities and towns, the company has been instrumental in bringing new-to-e-commerce users online. Meesho has made e-Commerce more accessible, affordable and engaging for a unique and underserved ‘non-affluent’ user segment. With a strong value proposition of Everyday Lowest Prices, the platform hosts one of the largest selection of quality products at affordable prices

Our purpose:

Har Indian ka APNA MARKET


Our founders:
Vidit Aatrey : Co-Founder and CEO
Sanjeev Barnwal : Co-Founder and CTO
meesho.ioMeesho Blogs | One Of The Best Tech Blogs In India
Learn about Meesho culture, news and what goes on in building the fastest growing e-commerce app in India.",USD 110K - 223K *
95,Lead Bigdata Developer,S&P Global,IN - HYDERABAD ORION,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
10
S&P Global Ratings 
The Role: Lead Big Data developer. 
 The Team:
Content Externalization team at S&P Ratings responsible for data distribution to both external & internal clients through various pipeline.. 
Each of our employees plays a vital role—uncovering the essential intelligence that our clients rely on day in and day out to make the decisions that matter. We pursue excellence in everything we do. We value results, encourage teamwork, and embrace change. Our team is responsible for the design, architecture, develop, and implement various ETL pipelines and distribution channels. 
The team has a broad and expert knowledge domain, technology stacks and architectural patterns. They foster knowledge sharing and collaboration that results in a unified strategy. Team members provide leadership, innovation, timely delivery, and the ability to articulate business value. 
 The Impact:  
As a member of the Content Externalization Team, you will be responsible for analysis, design, architecture, development, and support of ETL pipelines using Spark framework in Databricks platform. The ideal candidate should have expertise with cutting edge technologies and a desire to drive change through all alignment across the enterprise. The role requires the candidate to be a hands-on problem solver and developer helping to extend and manage the ETL pipelines. 
 What’s in it for you:  
Exposure to work on Latest cutting-edge Technologies. 
Opportunity to grow personally and professionally. 
Exposure to cutover legacy ETL pipelines to Spark framework. 
 Responsibilities:  
Demonstrate a strong sense of ownership and responsibility with release goals. This includes understanding requirements, technical specifications, design, architecture, implementation, unit testing, builds/deployments, and code management. 
Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards. 
Build and maintain the environment for speed, accuracy, consistency and ‘up’ time 
Hands-on position requiring strong analytical, architecture, development and debugging skills that includes both development and operations. 
Attaint in-depth Functional knowledge of the domain that we are working on. 
Understand Incident Management, Change Management and Problem Management, root cause analysis. 
Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the Data. 
Be in tune with emerging trends cloud technologies & Big Data. 
Should drive and execute complex technical requirements. 
Demonstrate excellent verbal and written communication skills. 
Collaborate with team members across the globe. 
Interface with cross functional teams and downstream applications as needed. 
Be a self-starter that is also an excellent team player. 
Follow agile best practices. Experienced in working with global teams. 
Regularly evaluate cloud applications, hardware, and software. 
Work closely with cyber security team to monitor the organization’s cloud policy. 
Focus on building a team culture that is based on trust. Inspire your team member so that they focus on continuous growth. 
What We’re Looking For 
Minimum 8+ years of working experience in Technology (application development and production support). 
5+ years of experience in development of pipeline that extract, transform, and load data into an information product that helps the organization reach its strategic goals. 
Minimum 3+ years of experience in developing & supporting ETLs and using Python/Scala in Databricks/Spark platform. 
Experience with Python, Spark, and Hive and Understanding of data-warehousing and data-modeling techniques. 
Knowledge of industry-wide visualization and analytics tools (ex: Tableau, R) 
Strong data engineering skills with AWS cloud platform 
Experience with streaming frameworks such as Kafka 
Knowledge of Core Java, Linux, SQL, and any scripting language  
Experience working with any relational Databases preferably Oracle. 
Experience in continuous delivery through CI/CD pipelines, containers, and orchestration technologies.  
Experience working in an Agile development environment. 
Experience working with cross functional teams, with strong interpersonal and written communication skills. 
Candidate must have the desire and ability to quickly understand and work within new technologies. 
 Flexible Working (optional) 
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.   
 Return to Work 
Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. 
 About S&P Global Ratings
At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.
S&P Global Ratings is a division of S&P Global (NYSE: SPGI).  S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.  
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
IFTECH202.1 - Middle Professional Tier I (EEO Job Group)",USD 85K - 120K *
96,Staff Data Scientist,"6sense Insights, Inc.","Bengaluru, Karnataka, India",Senior-level / Expert,"Our Mission: 
6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue. 
Our People: 
People are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in deﬁning the future of our industry-leading technology.  6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers. 
We want 6sense to be the best chapter of your career. 
About the role :
Staff Data Scientist leads and drives advanced data science initiatives within the organization. By leveraging mastery in advanced statistical methods, machine learning, and programming, the Staff Data Scientist is responsible for designing and implementing complex AI solutions. This role involves innovatively solving business problems, optimizing algorithms, and deploying AI models to provide data-driven insights that align with the organization's strategic goals. Additionally, the Staff Data Scientist ensures efficient workflows, automates processes, and effectively communicates insights to stakeholders, aiming to enhance productivity, strategic decision-making, and overall business success.
Responsibilities & Accountabilities:
Lead the design and development of complex AI solutions, employing advanced techniques to optimize algorithms and data sets for superior performance. 
Design and implement experiments to rigorously evaluate AI solution performance and provide valuable insights for refinement. 
Develop detailed AI solution requirements and effectively manage the development process, adapting to changing circumstances and requirements. 
Collaborate effectively with cross-functional teams and stakeholders, ensuring successful delivery while adapting to evolving needs and circumstances. 
Stay updated with the latest trends and advancements in AI technology, incorporating newfound knowledge into solution design and development. 
Apply mastery of statistical methods, machine learning algorithms, and programming languages to analyze unstructured data and derive actionable insights. 
Develop novel modeling techniques and algorithms, utilizing advanced methodologies like Bayesian inference, reinforcement learning, and causal inference. 
Create scalable models capable of handling large volumes of real-time data, ensuring transparency and explainability in the model's functioning. 
Develop models that inform strategic decision-making at the highest organizational levels, leveraging advanced machine learning techniques. 
Align business objectives with innovative data science solutions, proactively identifying opportunities for data-driven insights and product innovations. 
Develop and implement advanced AI models, utilizing techniques like transfer learning, ensemble methods, and neural networks for complex problem-solving. 
Design and implement efficient workflows, automate data-related tasks, and lead process improvement initiatives to enhance productivity and data accuracy. 
Lead product development efforts, demonstrating an understanding of the business model and leveraging data for product decision-making and roadmap planning.
Ethical Product Development: Understand and consider the ethical and legal implications of data-driven products and solutions, ensuring responsible and compliant development practices. 
Educational and Experience Requirements: 
Ph.D. or Master's in Computer Science, Data Science, or related field. 
10+ years in data science, machine learning, and AI, with progressive tech leadership roles. 
Mastery in Python, R, SQL, and advanced statistical and ML techniques. 
Designing tailored ML models, optimizing algorithms, and AI solution deployment. 
Designing efficient workflows, automation, and process improvements. 
Exceptional communication and leadership skills, managing data science teams. 
Driving innovation, staying updated with emerging tech, and ensuring ethical compliance. 
Effective collaboration, adaptability to changing requirements and circumstances. 
Published research or thought leadership in reputable journals or conferences. #LI-remote
Our Benefits: 
Full-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We’ll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our oﬃces. 
We have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions, and everyone has access to meQuilibrium – a platform to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds. 
Equal Opportunity Employer: 
6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to jobs@6sense.com. ",USD 31K - 58K *
97,Big Data Engineer (Airflow/Python/Spark),Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the role

- You’ll be working within an international group of teams which span from the US till India. This group is responsible for building our Audience Builder application and components which is part of Nielsen’s Advanced Audiences in the Nielsen ONE product suite. Your specific team will be responsible to build data pipelines, services and UIs to support our complex entitlement needs for our current and future web applications.

- As an Associate Data Engineer you will be responsible for data pipelines to work on both scheduled and real time use cases.  Schedule pipelines run typically in Airflow and real time processing could be airflow or integrated querying in backend services.  

Responsibilities
Work closely with team leads and backend developers to design and develop functional, robust pipelines to support internal and customer needs
Write both unit and integration tests, and develop automation tools for daily tasks
Develop high quality, well documented, and efficient code 
Manage and optimize scalable pipelines in the cloud
Optimize internal and external applications for performance and scalability
Develop automated tests to ensure business needs are met, and write unit, integration, or data quality tests
Communicate regularly with stakeholders, project managers, quality assurance teams, and other developers regarding progress on long-term technology roadmap
Recommend systems solutions by comparing advantages and disadvantages of custom development and purchased alternatives

Key Skills (Domain Expertise)
0-2 years of experience as a software/data engineer 
Bachelor’s degree in Computer Science, MIS, or Engineering

Technical Skills Preferred
Experience with database systems, with knowledge of SQL and NoSQL stores (e.g. MySQL, Oracle, MongoDB, Couchbase, etc.)
Experience on a team developing sophisticated data driven software platforms
Experience with relational databases and/or analytical data stores (e.g., Spark, Presto, Pandas)
Contributing to delivery and support of enterprise software
Experience with cloud service technologies, ex: AWS
Experience with container technologies, ex: Docker
Experience with source control systems, ex: GIT
Information visualization
""Big data"" systems and analysis
Experience with data warehouses or data lakes

Mindset and Attributes
Strong communication skills with ability to communicate complex technical concepts and align organization on decisions
Sound problem-solving skills with the ability to quickly process complex information and present it clearly and simply
Utilizes team collaboration to create innovative solutions efficiently


#LI-DD1",USD 30K - 56K *
98,Senior Quality Analyst - ETL,Sapiens,"Bengaluru, IN",Senior-level / Expert,"Location: Bangalore, India
  Sapiens International Corporation (NASDAQ and TASE: SPNS) is a leading global provider of software solutions for the insurance industry, with a growing presence in the financial services sector. We offer integrated core software solutions and business services, and a full digital suite for the property and casualty/general insurance; life, pension, and annuities; and reinsurance markets. Sapiens also services the workers’ compensation and financial and compliance markets.
Our portfolio includes policy administration, billing, and claims; underwriting, illustration and electronic application; reinsurance and decision management software. Sapiens’ digital platform features customer and agent portals, and a business intelligence platform. With a 30-year track record of delivering to more than 500 organizations, Sapiens’ team of over 3,400 operates through our fully-owned subsidiaries in North America, the United Kingdom, EMEA, and Asia Pacific. For more information: www.sapiens.com.
Job Description:
Roles & Responsibilities:
Conduct BI/DWH Testing;
Understanding insurance business process and the Business Requirements
Preparing Functional/Technical Specifications.
Design test cases for all scenarios (i.e. positive, negative testing, boundary) including expected outputs from the Business Requirements and Functional to ensure maximum coverage.
Verify requirement traceability from System Requirements through test cases and defects
Validate Test Preparation and verify all teams are aligned with what needs to occur to build/prepare the test plan
Validate the Data against source and target on various platforms / layers
Update & maintain documentation of the executed test cases
Proficient in converting complex business rules to SQL test scripts.
Proficient in test data creation
Proficient in Test management tools, HP AL, Jira - Zephyr.
  Requirement: -
Overall 5 to 9 years of experience in DWH and Report software testing.
Understanding insurance business process and the Business Requirements and Functional/Technical Specifications.
Strong hands an End to End experience in ETL Testing, Report Testing.
Proficient in converting business scenarios into SQL queries.
Should be involved in designing and preparing Test Scenarios, Test Plans, Test Strategies, Test Cases, Test Data
Should have experience in Test Management tool - HP ALM, Jira
Should have experience in SDLC & STLC
Good Analytical and communication skills.
Automation experience in any open source platform is plus
Experience in Big Data Testing is plus
ISTQB Certified is a plus
Prior Insurance industry experience is a plus
Any Scripting language python /java is a plus",USD 45K - 84K *
99,Data Scientist,Innovaccer,"Noida, Uttar Pradesh, India",Mid-level / Intermediate,"Your Role
As a Data Scientist at Innovaccer, you will be responsible for designing and implementing data-driven solutions that help our customers improve patient outcomes, reduce costs, and improve operational efficiency. You will work closely with our customers, business leaders, and product teams to understand their needs and build solutions that meet their requirements. You will also work with our data platform and applications team to help them integrate data science capabilities into their products and workflows.
A Day in the Life
Design scalable solutions for real-time performance on large data sets using big data technologies to optimize infrastructure and improve performance.
Build intelligent systems to capture and model vast amounts of behavioral data to enrich content understanding with behavioral information.
Work with business leaders and customers to understand their pain-points and build large-scale solutions for them.
Define technical architecture to productize Innovaccer's machine-learning algorithms and take them to market with partnerships with different organizations.
Work with customers and BI experts to build out reports and dashboards that are most useful to customers.
Work with development teams to build tools for repeatable data tasks to accelerate and automate the development cycle.
Define and execute the roadmap.
What You Need
Bachelor's degree in Computer Science, Computer Engineering, or other relevant fields.
2+ years of experience in data science (healthcare experience will be a plus).
Strong written and spoken communication skills.
Strong hands-on experience in SQL, Python, AWS, and PySpark.
Experience working with Docker, Git, APIs, Kafka, etc.
Understanding of deep learning frameworks like Keras, TensorFlow, and PyTorch.
Deep understanding of Machine learning modes and their business application..
Ability to work with and influence multiple stakeholders and deliver solutions within a given timeframe.
What We Offer:
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications.
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic.
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists.
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered.  
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative.
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them. 
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments.
Disclaimer: Innovaccer does not charge any fees or require any payment from individuals or agencies for securing employment with us. We do not guarantee job spots or engage in any financial transactions related to employment. If you encounter any posts or requests asking for payment or personal information, we strongly advise you to report them immediately to our HR department at px@innovaccer.com. Additionally, please exercise caution and verify the authenticity of any requests before disclosing personal and confidential information, including bank account details.
 ",USD 86K - 160K *
100,Big Data Engineer (Airflow/Python/Spark),Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the role

- You’ll be working within an international group of teams which span from the US till India. This group is responsible for building our Audience Builder application and components which is part of Nielsen’s Advanced Audiences in the Nielsen ONE product suite. Your specific team will be responsible to build data pipelines, services and UIs to support our complex entitlement needs for our current and future web applications.

- As an Associate Data Engineer you will be responsible for data pipelines to work on both scheduled and real time use cases.  Schedule pipelines run typically in Airflow and real time processing could be airflow or integrated querying in backend services.  

Responsibilities
Work closely with team leads and backend developers to design and develop functional, robust pipelines to support internal and customer needs
Write both unit and integration tests, and develop automation tools for daily tasks
Develop high quality, well documented, and efficient code 
Manage and optimize scalable pipelines in the cloud
Optimize internal and external applications for performance and scalability
Develop automated tests to ensure business needs are met, and write unit, integration, or data quality tests
Communicate regularly with stakeholders, project managers, quality assurance teams, and other developers regarding progress on long-term technology roadmap
Recommend systems solutions by comparing advantages and disadvantages of custom development and purchased alternatives

Key Skills (Domain Expertise)
0-2 years of experience as a software/data engineer 
Bachelor’s degree in Computer Science, MIS, or Engineering

Technical Skills Preferred
Experience with database systems, with knowledge of SQL and NoSQL stores (e.g. MySQL, Oracle, MongoDB, Couchbase, etc.)
Experience on a team developing sophisticated data driven software platforms
Experience with relational databases and/or analytical data stores (e.g., Spark, Presto, Pandas)
Contributing to delivery and support of enterprise software
Experience with cloud service technologies, ex: AWS
Experience with container technologies, ex: Docker
Experience with source control systems, ex: GIT
Information visualization
""Big data"" systems and analysis
Experience with data warehouses or data lakes

Mindset and Attributes
Strong communication skills with ability to communicate complex technical concepts and align organization on decisions
Sound problem-solving skills with the ability to quickly process complex information and present it clearly and simply
Utilizes team collaboration to create innovative solutions efficiently


#LI-DD1",USD 30K - 56K *
101,Senior Quality Analyst - ETL,Sapiens,"Bengaluru, IN",Senior-level / Expert,"Location: Bangalore, India
  Sapiens International Corporation (NASDAQ and TASE: SPNS) is a leading global provider of software solutions for the insurance industry, with a growing presence in the financial services sector. We offer integrated core software solutions and business services, and a full digital suite for the property and casualty/general insurance; life, pension, and annuities; and reinsurance markets. Sapiens also services the workers’ compensation and financial and compliance markets.
Our portfolio includes policy administration, billing, and claims; underwriting, illustration and electronic application; reinsurance and decision management software. Sapiens’ digital platform features customer and agent portals, and a business intelligence platform. With a 30-year track record of delivering to more than 500 organizations, Sapiens’ team of over 3,400 operates through our fully-owned subsidiaries in North America, the United Kingdom, EMEA, and Asia Pacific. For more information: www.sapiens.com.
Job Description:
Roles & Responsibilities:
Conduct BI/DWH Testing;
Understanding insurance business process and the Business Requirements
Preparing Functional/Technical Specifications.
Design test cases for all scenarios (i.e. positive, negative testing, boundary) including expected outputs from the Business Requirements and Functional to ensure maximum coverage.
Verify requirement traceability from System Requirements through test cases and defects
Validate Test Preparation and verify all teams are aligned with what needs to occur to build/prepare the test plan
Validate the Data against source and target on various platforms / layers
Update & maintain documentation of the executed test cases
Proficient in converting complex business rules to SQL test scripts.
Proficient in test data creation
Proficient in Test management tools, HP AL, Jira - Zephyr.
  Requirement: -
Overall 5 to 9 years of experience in DWH and Report software testing.
Understanding insurance business process and the Business Requirements and Functional/Technical Specifications.
Strong hands an End to End experience in ETL Testing, Report Testing.
Proficient in converting business scenarios into SQL queries.
Should be involved in designing and preparing Test Scenarios, Test Plans, Test Strategies, Test Cases, Test Data
Should have experience in Test Management tool - HP ALM, Jira
Should have experience in SDLC & STLC
Good Analytical and communication skills.
Automation experience in any open source platform is plus
Experience in Big Data Testing is plus
ISTQB Certified is a plus
Prior Insurance industry experience is a plus
Any Scripting language python /java is a plus",USD 45K - 84K *
102,Data Scientist,Innovaccer,"Noida, Uttar Pradesh, India",Mid-level / Intermediate,"Your Role
As a Data Scientist at Innovaccer, you will be responsible for designing and implementing data-driven solutions that help our customers improve patient outcomes, reduce costs, and improve operational efficiency. You will work closely with our customers, business leaders, and product teams to understand their needs and build solutions that meet their requirements. You will also work with our data platform and applications team to help them integrate data science capabilities into their products and workflows.
A Day in the Life
Design scalable solutions for real-time performance on large data sets using big data technologies to optimize infrastructure and improve performance.
Build intelligent systems to capture and model vast amounts of behavioral data to enrich content understanding with behavioral information.
Work with business leaders and customers to understand their pain-points and build large-scale solutions for them.
Define technical architecture to productize Innovaccer's machine-learning algorithms and take them to market with partnerships with different organizations.
Work with customers and BI experts to build out reports and dashboards that are most useful to customers.
Work with development teams to build tools for repeatable data tasks to accelerate and automate the development cycle.
Define and execute the roadmap.
What You Need
Bachelor's degree in Computer Science, Computer Engineering, or other relevant fields.
2+ years of experience in data science (healthcare experience will be a plus).
Strong written and spoken communication skills.
Strong hands-on experience in SQL, Python, AWS, and PySpark.
Experience working with Docker, Git, APIs, Kafka, etc.
Understanding of deep learning frameworks like Keras, TensorFlow, and PyTorch.
Deep understanding of Machine learning modes and their business application..
Ability to work with and influence multiple stakeholders and deliver solutions within a given timeframe.
What We Offer:
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications.
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic.
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists.
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered.  
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative.
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them. 
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments.
Disclaimer: Innovaccer does not charge any fees or require any payment from individuals or agencies for securing employment with us. We do not guarantee job spots or engage in any financial transactions related to employment. If you encounter any posts or requests asking for payment or personal information, we strongly advise you to report them immediately to our HR department at px@innovaccer.com. Additionally, please exercise caution and verify the authenticity of any requests before disclosing personal and confidential information, including bank account details.
 ",USD 86K - 160K *
103,Sr Machine Learning Quality Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
5+ years of related experience with a Bachelor's degree; or 3 years and a Master's degree; or a PhD without experience; or equivalent work experience
Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms
Experience building new products that use challenging algorithms
Expertise in coding efficient, object-oriented, modularized and quality software
Knowledge of core AI/ML techniques and algorithms
Knowledge of unit testing, profiling, and code tuning

FD21
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
104,Head of Data Science & AI,Merck Group,"Bengaluru, Karnataka, IN, 560100",Executive-level / Director,"  Work Your Magic with us!  
  Ready to explore, break barriers, and discover more? We know you’ve got big plans – so do we! Our colleagues across the globe love innovating with science and technology to enrich people’s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.  
  Your role:
  We are seeking a seasoned professional for the role of Head, Data Science & AI  As a leader in our Innovation & Data team, you will be responsible for driving ideation, incubation,  use case enablement and development of AI/ML/NLP/GenAI and Data & Analytics Solutions.
  Job Description/ Key Responsibilities:
  Lead  design and development of MBS wide data science (ML) , NLP,  GenAI, Data & Analytics solutions aligned with business vision and goals
Drive Data and AI related innovation initiatives, right from identifying opportunities to prototyping and MVP solution development. Liaison with stakeholders across MBS to secure buy-ins and approvals for scale-out of such solutions 
Lead the Data Science Team in managing organisational analytics/informatics development and application.
Develop and manage teams specializing in development of such solutions. Provide coaching, guidance, and foster a culture of continuous learning.
Coordinate with stakeholders, including executive leadership, business teams, IT, CDO and external partners to ensure successful rollout of these solutions.
Demonstrate strong expertise in Cloud Engineering, Architecture, and Agile & DevOps practices. Deep understanding of digital solutions development and their industrialization is essential. 
    Who you are:
  Graduate Degree / master’s degree (Computer Science/Engineering) or equivalent, Proficiency in English (Verbal, Written)
  Professional Skills, Qualifications and Experience
  Primary Skills
15+ years in IT and/or Digital organizations
5+ years in AI and data solutions
Proven track record in leading large AI opportunities and driving enterprise-scale solutions
Demonstrate strong expertise in Cloud Engineering, Architecture, and Agile & DevOps practices. Deep understanding of digital solutions development and their industrialization is essential
Hands-on experience in productionising and operationalizing AI/ML/NLP solutions.
Experience in developing ML Models using multiple python/R libraiies.
Experience in managing the complete life cycle of data science projects from model development to production deployment
Implemented MLOps practices and adhering to responsible and ethical AI principles. Good understanding and practical experience in using GenAI and LLMs to solve business problems.
Proficient in data technologies such as PowerBI/Tableau visualizations, ETL, Data lakes/warehouses, Modern Data Stack concepts and Data Mesh/Fabric. Good understanding of data management/governance and it's role in harnessing the power of data in large enterprises.
  Secondary Skills:
Experience in working within large enterprises and matrixed organizations.
Consulting & Customer centric mindset.
Exposure to developing solutions in regulated environments
Experience in developing solutions for GBS domains ( Finance, Procurement, HR)
Highly skilled in statistical and modelling packages such as SAS, Statistica, Matlab, R, visualisation and other advanced analysis tools
Understanding of other emerging technologies like blockchain/web3, IoT, XR and their interplay with AI is a good to have.
  Register now to our new Talent Zone! It is a great way to stay connected, learn more about our company, career opportunities and events!

What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
 
Apply now and become a part of our diverse team!
 ",USD 110K - 185K *
105,Sr. Data Science Consultant,Blue Yonder,Bengaluru,Senior-level / Expert,"Overview:
 Leading AI-driven Global Supply Chain Solutions Software Product Company and one of Glassdoor’s “Best
Places to Work”
 Seeking an astute individual who has a strong statistical/analytical foundation with the additional ability to
be hands-on with the broader team as part of the deploy/operate cycle. Knowledge of industry best practices,
with the ability to implement them would be a bonus.
 Scope:
 Core responsibilities to include participation in onboarding of clients with BY’s Luminate Planning suite of
solutions and their continued support during the BAU phase.
 The team currently comprises of ~30 associates in India, part of a larger global team spread across US,
Germany and is expected to grow rapidly. The incumbent will need to have leadership qualities to also mentor
junior and mid-level associates in our team
What you’ll do:
• Selecting features, building and optimizing classifiers using machine learning techniques
• Data mining using state-of-the-art methods & tools
• Extending company’s data with third party sources of information when needed
• Enhancing data collection procedures to include information that is relevant for building analytic systems
• Processing, cleansing, and verifying the integrity of data used for analysis
• Performing ad-hoc analysis and presenting results in a clear manner
What we are looking for:
• Excellent understanding of machine learning techniques and algorithms, such as K means clustering, Naive Bayes
etc
• Experience with common data science toolkits, such as Python, R, Weka, NumPy, MatLab, etc. Excellence in at
least one of these is required
• Experience in Supply Chain concepts
• Experience in Statistical Analysis, Operations Research concepts – Integer/Linear/Stochastic programming
• Experience with data visualization tools, such as D3.js
• Proficiency in using query languages such as SQL, Hive, Pig
• Experience with NoSQL databases, such as MongoDB, Cassandra
• Good applied statistics skills, such as distributions, statistical testing, regression, etc.
• Good scripting and programming skills
• Data-oriented personality
• Bachelors or Masters in Computer Science w/Data Science specialty
• Experience preferred: 5-10 yrs
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Diversity, Inclusion, Value & Equality (DIVE) is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural Diversity Report which outlines our commitment to change, and our video celebrating the differences in all of us in the words of some of our associates from around the world.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",USD 95K - 160K *
106,Senior Software/ Staff Engineer (Java | Elasticsearch | Cassandra | AWS | Kafka),Zscaler,"Hyderabad, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Location- Hyderabad

7+ years of experience in a highly-distributed and enterprise-scale mission critical environment
Current hands-on experience in building data engineering pipelines with Kafka as a firehouse using primarily Java.
Hands-on experience in scaling distributed data stores like Cassandra, Druid, and Elasticsearch.
Working knowledge of cloud infrastructure services on AWS/Hybrid cloud.
Experience working with RDBMS systems. Experience with postgres is a plus.
Ability to learn, evaluate, document, and adopt new technologies.
Experience working with docker and Kubernetes is a plus
Qualifications
Qualifications/Your Background:
Experience working with streaming data processing infrastructure.
Experience designing and building solutions based on Microservices architecture.
Experience in implementing services following the REST model.
Experience with at least one of the OLAP and OLTP systems.
Bachelor’s degree/or master’s degree in computer science or equivalent experience
Additional information
#LI-MS6
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 45K - 84K *
107,"Sr. Manager - Data Science (ML, Python, Modelling)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Essential Functions
Lead a team of Data Scientists within Global Data Science, including project oversight, coaching and professional development
Work with internal/external clients to understand their strategic business questions and lead project scoping/design to answer those questions by leveraging Visa’s data
Be an out-of-the-box thinker who is passionate about brainstorming innovative ways to use our unique data to answer business problems
Communicate with clients to understand the challenges they face and convince them with data
Extract and understand data to form an opinion on how to best help our clients and derive relevant insights
Develop visualizations to make your complex analyses accessible to a broad audience
Find opportunities to craft products out of analyses that are suitable for multiple clients
Leverage big data and cutting-edge data mining techniques, provide thought leadership in analytic techniques and business applications to unlock the value of Visa’s unique data set
Synthesize ideas/proposals in writing and engage in productive discussions with external or internal stakeholders
Mine and analyze data from company databases to drive optimization and improvement of product, marketing techniques and business strategies for Visa and its clients
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, advertising targeting and other business outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy
Broad knowledge across the entire data science lifecycle, including data engineering, statistics and governance
Provide guidance in modern analytic techniques and business applications to unlock the value of Visa’s unique data set, in keeping with market trends, client needs and emerging techniques
Organize and manage multiple data science projects with diverse cross-functional stakeholders
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
- 11+ years of relevant work experience with a Bachelor’s Degree or 10+ years of relevant work experience with an Advanced Degree (e.g. Master’s, MBA, JD, MD) or 3+ years of experience with a PhD
- Minimum of 6+ years of analytical experience in applying solutions to business problems in relevant fields such as analytics, business consulting, or other data-driven functions
- Post Graduate degree in quantitative/relevant field such as Statistics, Operational Research, Computer Science, Economics, Business Analytics, Data Science, Business Administration, etc.
- Expert knowledge of databases and engineering concepts with hands on experience with one or more data analytics/programming tools such as Hive/R/SQL/Python/SAS
- Experience with extracting and aggregating data from large data sets using SQL or other tools
- Competence in Excel, PowerPoint and Tableau
- Familiarity or experience with data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.) is strongly preferred
- Experience in managing analytics/data science projects from scoping to delivery
- Articulate communicator able to translate data and technical concepts for a business audience
- Experience with managing project teams and providing direction and thought leadership
- Previous experience working in credit cards, financial services, banks, or lending products is strongly preferred
- Previous experience working with machine learning tools & techniques to measure data quality/integrity is strongly preferred
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 95K - 160K *
108,Senior Data Engineer,Quantiphi,IN MH Mumbai Eureka,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Role & Responsibilities: ● Work with support team and ensure that the application is running as per the SLA ● Communicate with the stakeholders in case of any major production failure or other issues. ● Bug management and incident resolution process. ● Resolve Issues within defined SLA. ● Manage and own application Bugs and incident life cycle, and drive those to permanent resolutions, implement preventive measures to avoid repetitive issues ● Troubleshoot, root cause analysis. ● Resolve complex bugs with long term fixes following BI best practices and collaborate with BI team for solution review of complex bugs and incident resolution. ● Perform weekly incident/bug review meetings with the application team. ● Responsible for 24 x 7 production system support, including off hours and weekend 'on call' production support responsibilities. ● Monitor ETL jobs using IICS monitor, AWS Cloud watch. ● Responsible for continued system improvements by introducing automations to help reduce tech debt costs. ● Monitor the usage of database space and performance. ● Optimize the Job monitoring and alerting mechanism.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 121K - 186K *
109,"Sr. Manager, Product Management (Data Management/Data Security)",Capital One,"Bengaluru, In",Senior-level / Expert,"Voyager (94001), India, Bangalore, Karnataka
Sr. Manager, Product Management (Data Management/Data Security)
At Capital One India, we work in a fast paced and intellectually rigorous environment to solve fundamental business problems at scale. Using advanced analytics, data science and machine learning, we derive valuable insights about product and process design, consumer behavior, regulatory and credit risk, and more from large volumes of data, and use it to build cutting edge patentable products that drive the business forward.
Capital One has taken a bold journey to build a technology company, while operating in a complex, highly regulated business. We have built out a large engineering organization, moved to the cloud, re-architected our applications and data platforms, and embraced machine learning at scale. Our AI/ML capabilities are now at the forefront of what’s possible in banking (e.g., Eno).
As we uncovered new challenges along the way, we built and battle tested new capabilities to meet those needs. We’ve open sourced several of the software tools we built (e.g., Cloud Custodian, Hygieia) and forged new partnerships with other digital leaders (e.g., MSFT). 
We've developed a suite of internal solutions uniquely designed to meet the challenges of a digital-first, cloud-first business at scale. Today, the Capital One Software team is exploring how these internal solutions across cloud, data, security, governance, and applications could serve the needs of other companies born or built in the cloud.
Product Management at Capital One is a critical, vibrant craft that requires a blend of entrepreneurial drive, keen business acumen, customer experience obsession, technical depth and strong people leadership.  At Capital One India, we are building a Product Management team for Capital One Software, a new B-to-B software business focused on the booming Enterprise Data Management market.  We’re looking for a Sr. Manager, Product Management to join as a founding member of this growing team to lead critical product development efforts in collaboration with the U.S.-based leadership team. 
The leader in this role will partner with a technology peer to build a key data security product that furthers our mission of making every data security breach immaterial. 
Specific responsibilities include, but are not limited to:
Develop and communicate the product vision and strategy for key components of the product
Partner with technology leadership to align on prioritization of features to maximize business and customer outcomes
Build a team of product managers / owners 
Deeply understand the needs of data security professionals, the users of data security products, and goals of would be customer data thieves
Incorporate design thinking and data analytics to inform product design
Enable collaboration and ensure communication between teams
Maintain a healthy backlog of work and play a critical role in many agile ceremonies.
Support the team with escalation and resolution of impediments
Serve as the connection between customers, Capital One’s mission, and your team
We want you if you are:
Interested in building lasting relationships with peers and having fun while building products that delight customers and drive value to the business
You are a learner who is able to quickly get up to speed in a highly technical environment. Willing and able to get deep into the technical weeds of a product, able to explain its architecture and how it works. Even better if you’re experienced in having substantive debates about the technical direction of products with your tech peers that lead to an optimal outcome.
You are passionate about building a well-rounded product management skill set that is human centered, business focused, and technology driven with an emphasis on integrated problem solving and people leadership. 
You are experienced working in an Agile environment
You are a do-er who can also zoom out and think strategically
You have excellent oral and written communication skills
You are highly collaborative and have the ability to influence and lead
You have experience managing and developing top talent
Basic Qualifications:
Bachelor’s Degree 
At least 10+ years of experience in product management or at least 10+  years of experience in product design, agile delivery, business analysis, data science, or software engineering 
Preferred Qualifications:
Bachelor’s Degree in Computer Science or Engineering
MBA or Master’s degree 
Experience building data security and/or data management products
Experience working at a startup or in a startup environment
3+ years of experience in Agile product management
2 years of people leadership experience leading product manager teams
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",USD 45K - 84K *
110,Manager-Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Follow Tesco's Business Code of Conduct and always act with integrity and due diligence
- Accountable for engaging with markets to understand their key outcomes; identifying and implementing analytics projects that will result in disproportionate returns
- Drive value realization through delivery of high impact projects and efficiency gain by automating repeatable tasks
- Track and measure return on investment for Analytical Investments
- Accountable for achieving teams objectives; partner management and issue management
- Institutionalize robust ways of working through reusable frameworks; code and knowledge management
- Develop analytical assets that are deployed in production and will deliver value on sustained periods of time
- Collaborate with colleagues to craft; implement and measure analytical solution
- Develop and lead an impactful team; crafting an environment for success by setting direction and mentoring them to succeed through inspiring conversations every day
- Hands-on problem solving. You will be required to get hands dirty with data and applied math
- Initiates and crafts continuous improvements initiatives to drive performance within their teams
- Diagnose and recommends solutions to operational challenges; using specialist knowledge and operational expertise.
Qualifications
- Understanding of machine learning techniques - Linear & Logistics regression; Decision Trees; Random Forest; XgBoost and Neural Network
- Knowledge of Python; SQL; Hive and one of the visualization tools (Tableau)
- Stakeholder management; Operations Delivery; Analysis and Judgment; People Policies and Processes; Foundational Statistics & Math
7-10 yrs of experience in Leading analytics engagements in any one of domains like retail; cpg; telecom or hospitality and for one of the following functional areas - marketing; supply chain; customer; merchandising; operations; finance or digital
Additional Information
Last Date of Application-14th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
111,Sr. BI Developer,Teladoc Health,India - Remote,Senior-level / Expert,"Teladoc Health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. As an employee, you’re empowered to show up every day as your most authentic self and be a part of something bigger – thriving both personally and professionally. Together, let’s empower people everywhere to live their healthiest lives.
Summary of Position
Teladoc Health is hiring a Senior BI Developer! You will work closely with our business colleagues to develop analytic solutions, reports and dashboards to provide business and operational insights leading to business growth and operational efficiencies in a dynamic environment. This role provides you an opportunity to translate business requirements into reports and dashboards with facts that tell the story and present the inferences, transforming data to knowledge.
Role and Responsibilities 
Work with both internal users in a consultative mode 
Analyze and validate data requested by the users 
Present information through reports and visualization  
Provide insight into patterns in data that translates into value for business partners 
Monitor data reliability, quality and consistency across available data sources and collaborate to address issues
Evaluate business performance and identify important trends;
Build, develop and maintain data pipelines, prediction models, dashboards and performance metrics that support key business decisions
Lead projects from inception to completion 
Other duties as assigned 
Skill Requirements/Preferences 
Deep understanding of data management best practices, including reporting, analytics, SQL, data modeling, data management, file management, reference data management, etc. 
3 plus years of experience in Tableau or Power BI Development. 
Excellent communication skills, both written and oral - comfortable recommending and presenting solutions to senior managers 
Problem-solving and critical thinking skills 
Proven ability to work directly with business users in a consultative mode to gather requirements and ensure successful timely delivery of solution 
Ability and willingness to work in a team environment and adopt a culture of ownership and initiative, and promote such within the team 
Knowledge of current reporting and analytics technologies. 
Ability to run small projects from inception to completion in multi-functional environment 
Dedicated, innovative, and creative in meeting client/customer needs. Always keeping a “Can do!” attitude 
Qualifications Expected for Position
Bachelor's degree or above in economics, mathematics, statistics, engineering, computer science or other field; work experience may be substituted. 
2+ years of experience as a developer in Analytics and Reporting domain.   
2+ years of experience in Tableau or Power BI
Experience with multi-dimensional data models  
Strong experience with analytics engineering tech stack (ETL/ELT, SQL, Python, R, DBT)
Proficiency in querying complex data structures using SQL 
Skilled in data analysis / data mining 
Knowledge and familiarity with database security concepts and standard methodologies 
Experience with SQL Server databases a plus. 
Experience with Salesforce Sales Cloud and CPQ data a plus. 
Experience with GitHub is a plus.
The base salary range for this position is $80,000K-$95,000K. In addition to a base salary, this position is eligible for performance bonus, RSU’s, and benefits (subject to eligibility requirements) listed here: Teladoc Health Benefits 2023.Total compensation is based on several factors including, but not limited to, type of position, location, education level, work experience, and certifications. This information is applicable for all full-time positions.
#LI-SM2
Why Join Teladoc Health?

A New Category in Healthcare:  Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives. 

Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person’s health journey. 

Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals. 

Focus on PEOPLE:  Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.

Diversity and Inclusion:  At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation:  We’ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.  
 As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.",USD 80K - 95K
112,Assistant Manager Data Quality,TransUnion,Mumbai - One World Center,Mid-level / Intermediate,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are one of India’s leading credit information company with one of the largest collections of consumer information. We aim to be more than just a credit reporting agency. We are a sophisticated, global risk information provider striving to use information for good.
We take immense pride in playing a pivotal role in catalyzing the BFSI industry in the country. We got here by tapping into our excitement and passion of wanting to make a difference in the lives of our clients and consumers.
We at TransUnion CIBIL are an equal opportunity employer and are committed to a policy of treating all our associates and job applicants equally. Applicants are evaluated on the basis of job qualification - not race, color, sex / gender, religion, caste, national origin, age, disability, marital status, citizenship status, sexual orientation, gender identity or any other status, whether or not protected. We are committed to taking affirmative action to employ and advance minorities, women, and qualified disabled individuals. We ensure a safe, productive, and harassment-free workplace for all.
Culture and Values
Our culture is welcoming, energetic, and innovative. There’s an overall synergy that flows throughout the company, creating a sense of connect, belonging and unity in knowing that we’re all working to achieve the same overall goal. Our core values which we live by every day are integrity, People, Customer, and Innovation.
https://www.transunion.com/privacy/global-job-applicant
What is excitement and passion for us?
We define it as a blend of curiosity, ability to unlearn and yet continuously learn, able to connect with meaning and finally the drive to execute ideas till the last mile is achieved. This passion helps us focus on continuous improvement, creative problem solving and collaboration which ensures delivery excellence.
Dynamics of the Role
This is an exciting time in TransUnion CIBIL. With investments in our people, technology and new business markets, we are redefining the role and purpose of a credit bureau.
The role will be responsible for assisting in formulating and managing the development and implementation of goals, objectives, policies and procedures for data quality and performance. S/he will be responsible for ensuring proper implementation of quality assurance objectives and meeting the set target for Commercial Data in lending Industry.
What You'll Bring:
Roles & Responsibilities

Responsibility 1): Build & Manage Business intelligence process
• Understand the core process of Data reporting by Credit Bureaus by Financial institution
• Develop mechanism to analyze Daily data flow into the repository.
• Share insights , trends and monitor key business metrics around Personal/ consumer and Rural lending
• Create custom dashboards and MIS for top management
• Conduct RCA and review mechanism for critical data fields.
Responsibility 2): Big Data Analysis
• Apply Big data tools Spark/ HiveSQL / Pyspark/ SQL to prepare meaningful stories related to Quality and Risk parameters
• Build automation jobs on Hadoop / Mapr platform for BAU ( day to day ) activities
• Create Analytical dashboard on powerBI / Tableau for sharing insights and decision making

Responsibility 3): Engagement with members/ financial institution
• Conduct detail analysis of new/existing members who are submitting data.
• Develop & monitor variables for deep dive into data as per regulatory /compliance.
• Identify and share analysis with member institution for continuous improvement.
• Lias with cross functional teams to improve the quality of data in Fintech space
• Engage with external financial institutions to drive the improvement in data quality.
Impact You'll Make:
TransUnion Job Title
Specialist I, Data Design and Analysis",USD 30K - 56K *
113,Machine Learning Engineer,Uniphore,Bengaluru or Chennai,Senior-level / Expert,"Uniphore is one of the largest B2B AI-native companies—decades-proven, built-for-scale and designed for the enterprise. The company drives business outcomes, across multiple industry verticals, and enables the largest global deployments.  
  Uniphore infuses AI into every part of the enterprise that impacts the customer. We deliver the only multimodal architecture centered on customers that combines Generative AI, Knowledge AI, Emotion AI, workflow automation and a co-pilot to guide you. We understand better than anyone how to capture voice, video and text and how to analyze all types of data.  
  As AI becomes more powerful, every part of the enterprise that impacts the customer will be disrupted. We believe the future will run on the connective tissue between people, machines and data: all in the service of creating the most human processes and experiences for customers and employees. 

Skills & Responsibilities: -
• Hands-on experience in developing production-ready ML services and operationalizing model lifecycle management.
• Design, deploy & monitor end-to-end AI applications
• Learn, develop, and deploy cutting-edge AI/LLM technologies to achieve business objectives
• Own end-to-end pipelines in production and work with cross-functional support towards customer success
• Hands-on development of reliable, efficient code for AI applications
• Perform data ingestion, pre-processing, analysis, and feature engineering with focus on quality and reliability
• Automate software components through stages of AI lifecycle - data management (quality, governance), model Ops (development, testing, serving and monitoring), AI platform adoption (solution & metrics)
• Optimize & scale AI products and services for latency, throughput, concurrency, traceability and maintenance.
• Implement AI solutions for batch and online algorithms with automatic performance testing and A B testing
• Continuous learning and incorporate advancements in machine learning techniques to improve AI solutions and products
• In-depth knowledge of LLM optimization and service techniques
• Expertise in developing and packaging models to services
• Familiar with Transformers and used Hugging face library and LLMs to solve NLP problems.

Relevant Technologies:-
• ML: Hugging Face, PyTorch/TensorFlow
• MLOPs: Hands-on experience with any of the MLOPs frameworks (Sagemaker, DeepSpeed, Seldon, DVC, etc.)
• Deployment: Docker, AWS.
• Datastores: Postgres, S3.
• LLM: Familiarity with multiple LLMs and optimization techniques (PEFT, LoRA, etc.)

Who You Are:-
• You hold a Masters with 3 to 5 years of experience in ML Engineering or MLOps or 7 - 10 years of relevant industry experience with degree in Computer Science, Engineering, Statistics & Applied Mathematics, or related fields.
• You have demonstrated experience in designing and executing AI solutions at scale in real-world applications.
• You have worked with large amounts of data and developed approaches to address quality issues, and the ability to interpret data with a focus on business goals.
• You have solid experience in Python programming
• You have demonstrated collaboration and teamwork to solve hard problems. • You can learn new skills and share know-how with team members to empower and elevate.


Benefits:-
Uniphore offers a competitive offer and premium benefits, including insurance, leave and other perks
Uniphore is an equal opportunity employer committed to diversity in the workplace. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, disability, veteran status, and other protected characteristics.
 For more information on how Uniphore uses AI to unify—and humanize—every enterprise experience, please visit www.uniphore.com.

All applicants - to review our privacy notice, please click here

Information regarding recruiting and phishing scams: 
Employment offers will always be made by a Uniphore hiring manager or Talent Acquisition team member with a @uniphore.com email address only. We will never text you about an employment opportunity, interviews or employment offers, and we do not make job offers after only one interview. Additionally, we will never ask you to provide funds for onboarding, supplies or anything else, nor we will ask you to submit your personal information (date of birth, passport details, banking information, social security number, etc.) as part of the interview process. If you are receiving an employment inquiry or employment offer from a non Uniphore.com email address, please assume it is spam. If you believe you have been a victim of a phishing or false employment scam, you may want to report this incidents to the FBI iC3, or visit the Department of Homeland Security’s Cyber Smart website to learn how to report such scam.",USD 150K - 232K *
114,Lead Engineer - Industrial AI Software Engineering,Thomson Reuters,Bengaluru,Senior-level / Expert,"Job Description Summary
Responsible for designing and programming a small module or a large component and designing a feature, set of features, or whole feature area. She/he will work independently and contribute to the immediate team and to other teams across business. She/he will Lead design discussion in a limited manner.
Job Description
Roles and Responsibilities
In this role, you will:
• Identify the scope of the work, provide initial estimate and justify the estimate with facts
• Demonstrate the understanding of Agile software development lifecycle and able to distinguish the core inputs and outputs in each cycle.
• Engage in technical discussions; participate in technical designs and present technical ideas through white boarding
• Execute in a fast pace delivery mode and focus in delivering tasks to meet the product release goal
• Maintain code quality through best practices, unit testing and code quality automation
• Seek and provide feedback on design and development
• Demonstrate the ability to make informed technology choices after due diligence and impact assessment
• Understand whole product, its modules and the interrelationship between them while being an expert in the assigned component or module
• Help in designing interfaces and information exchange between modules
• Articulate the need for scalability and understand the importance of improving quality through testing.
• Be an expert in writing code that meets standards and delivers the desired functionality using the technology selected for the project
• Drive design reviews, define interfaces between code modules, and applies existing technology to designs
• Be an expert in assessing application performance and optimizing/improving it through design and best coding practices
• Be an expert in core data structures as well as algorithms and has the ability to implement them using language of choice
• Be responsible for providing technical leadership and defining, developing, and evolving software in a fast paced and agile development environment using the latest software development technologies and infrastructure
• Provide guidance to developers with either planning and execution and/or design architecture using agile methodologies such as SCRUM
• Work with Product Line Leaders (PLLs) to understand product requirements & vision
•Write code that meets standards and delivers desired functionality using the technology selected for the project
Required Qualifications
Bachelor's Degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math) with advanced experience.
experience: 6years - 10 years
Desired Characteristics
Technical Expertise:
Strong knowledge of Object-Oriented Analysis and Design, Software Design Patterns and coding principles related to any Object-Oriented programming language.
Hands-on experience in web services (REST, SOAP, WSDL etc.), using Apache Commons Suite & Maven, SQL Database such as Oracle MySQL, PostgreSQL etc.
Hands-on experience in utilizing any Web Development Framework (Spring boot, Django, Flask etc.)
Hands-on experience in version control (Git), Docker and CI/CD.
Hands on experience in distributed system architecture, microservices and event driven development.
Hands on experience in multi-threaded applications, message queue/message queuing service (Kafka, MQTT etc.)
Experience with Big Data / Hadoop and NoSQL Database is a big plus.
Hands-on experience with web development using HTML5, Java Script, jQuery, CSS. Also, experience in implementing Java OSGi modules and using an OSGi container is a big plus.
Experience with Angular/React is a big plus
• Experience with Play framework, Angular is a big plus
• Advanced Degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math)
Additional Information
Relocation Assistance Provided: Yes",USD 45K - 84K *
115,Manager Machine Learning Engrg Mgmt,ServiceNow,"Hyderabad, India",Mid-level / Intermediate,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
8+ years of related experience with a Bachelor's degree; or 6 years and a Master's degree; or a PhD with 3 years' experience; or equivalent work experience
A minimum of 1-2 years of management experience, proficiency in providing feedback to work group strategies, policies and plans
Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms
Experience building new products that use challenging algorithms
Expertise in coding efficient, object-oriented, modularized and quality software
Knowledge of core AI/ML techniques and algorithms
Knowledge of unit testing, profiling, and code tuning
 Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 30K - 56K *
116,Tech Lead - Generative AI,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
DENTSU CREATIVE is dentsu's global creative network that transforms brands and businesses through the power of Modern Creativity. Widely reputed for its innovative and creative approach to marketing and advertising. Dentsu Creative has won numerous awards for its work, including Cannes Lions agency of the year 2022, D&AD Awards, and Effie Awards, among others. The company's global network of offices allows it to serve clients across industries and geographies, and it has worked with many of the world's leading brands. With its focus on creativity, innovation, and results, Dentsu Creative is a leading player in the advertising and marketing industry.
Job Description
Develop and implement advanced Generative AL models, with a specific focus on Text, Image generation and fine tuning AI
Collaborate with cross-functional teams to understand client requirements and translate them into scalable AI solutions.
Research and explore emerging trends and techniques in the field of generative AI to stay at the forefront of innovation.
Evaluate and fine-tune models to ensure high performance and accuracy.
Collaborate with data scientists and engineers to integrate AI solutions into existing systems.
Stay up-to-date with the latest advancements in the field of AI and contribute to the company's technical knowledge base.
Qualifications
3+ years of experience in Generative AI
Degree in Computer Science, Artificial Intelligence, or a related field
Proven track record of successfully implementing Generative AI models and solutions in real-world applications.
Strong problem-solving and analytical skills.
Excellent communication and collaboration abilities.
Must have Skills
Python programming
End to End Understanding of back end work Flows
Good understanding of chatbots /Dialogue Flows
Good Understanding od NO SQL and Unstructured data
Ready to work on POC &Technical Evaluations
Good to have
Good to have frameworks such as TensorFlow, Py-Torch, or Keras.
Strong Good to have Basic knowledge of machine learning algorithms and their practical applications.
Experience in feature engineering, and model evaluation.
Familiarity Hands On Exp with one of the cloud platforms such as AWS and Azure for scalable model deployment.
Additional Information
Secondary Technical Skills:
Basic Understanding with natural language processing (NLP) techniques and frameworks.
Familiarity with computer vision and image processing techniques.
Familiarity of distributed computing and parallel processing.
Innovation and Technical Skills:
Proven track record of developing innovative solutions and pushing the boundaries with flavour of AI technology.
Strong problem-solving skills and ability to think creatively.
Basic understanding of machine learning principles and techniques.
Ability to effectively communicate complex technical concepts to both technical and non-technical stakeholders.
Strong analytical and critical thinking abilities.",USD 45K - 84K *
117,Research Intern NLP,Intel,Bengaluru,Entry-level / Junior,"Job Description Summary
We are looking to grow our Software Controls and Optimization team at GE Aerospace Research & are looking for top notch researchers to be part of this exciting journey. As a group, we innovate and execute on the R&D strategy for GE Aerospace on a range of problems from designing inspections solutions for aircraft engines to building predictive/prescriptive analytics for a variety of applications that improve process efficiencies in the business.
Job Description
Job Description
We are looking for highly motivated people with proven track record to conduct research in natural language processing, artificial intelligence, and machine learning. As a Research Intern, you will be working with scientists in GE Aerospace Research to develop and search and recommendation systems to improve the productivity of our Engineering teams. Your responsibilities will include developing and implementing algorithms to process Aerospace domain data for recommendation systems, design experiments, conduct thorough evaluations, and document your work (e.g., publications, invention disclosures). It will also include effectively communicating your findings with the appropriate stakeholders. You will encounter and have an opportunity to tackle unique challenges posed by the data and problems in the Aerospace domain including data quality, highly domain specific vocabulary, and how to integrate NLP/LLM-based solutions into our safety critical and regulated workflows and processes.
Required Qualifications
Enrolled in full-time Master’s or PhD Degree program in Computer Science, Electronics, Industrial, Electrical, Mechanical or related Engineering field with specialization in Natural Language Processing, Machine Learning, or Statistics.
At least one of year of experience in conducting independent research ideally in the following areas: Large Language Models, Entity and Relation extraction, Zero / Few-shot Learning.
Proficient in implementing algorithms and solutions in Python.
Self-starter, ability to work in ambiguous environments, and excellent communication skills.
Desired Characteristics
Enrolled in a PhD Degree program with at least three years of experience in conducting independent research.
Previous experience in training, fine-tuning (including instruction-tuning), and deploying Large Language Models.
Proven track record of publications at top AI conferences (or co-located workshops).
Experience of working with problems and data from industrial domains (Aviation, Energy, Healthcare, Manufacturing, etc.).
Strong foundations in design, analysis, and implementation of algorithms in different computing architectures is desired.
Background in Knowledge Representation and Knowledge Graph technologies is a plus.
Additional Information
Relocation Assistance Provided: Yes",None
118,Senior Software Engineer - Generative AI,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
DENTSU CREATIVE is dentsu's global creative network that transforms brands and businesses through the power of Modern Creativity. Widely reputed for its innovative and creative approach to marketing and advertising. Dentsu Creative has won numerous awards for its work, including Cannes Lions agency of the year 2022, D&AD Awards, and Effie Awards, among others. The company's global network of offices allows it to serve clients across industries and geographies, and it has worked with many of the world's leading brands. With its focus on creativity, innovation, and results, Dentsu Creative is a leading player in the advertising and marketing industry.
Job Description
Responsibilities:
Develop and implement state-of-the-art generative AI models and algorithms.
Collaborate with cross-functional teams to identify business challenges and define AI solutions.
Design and optimize neural networks for generative tasks, including image synthesis, text generation, and audio generation.
Conduct research and stay up-to-date with the latest advancements in generative AI.
Evaluate and improve the performance of existing generative models.
Collaborate with data scientists and engineers to gather and preprocess data for training generative models.
Implement and maintain scalable and efficient training pipelines.
Collaborate with software engineers to deploy and integrate generative models into production systems.
Ensure the ethical and responsible use of generative AI technologies.
Primary Technical Skills:
Strong programming skills in Python and experience with backend development.
Familiarity with cloud platforms such as AWS or Azure (Preferred).
Proficiency in NoSQL and SQL Databases
Secondary Technical Skills:
Basic knowledge of computer vision, natural language processing, or audio processing is a plus.
Knowledge of distributed computing and parallel processing.
Strong logical skills to work with Generative AI solutions and fast-paced AI Tools
Qualifications
Degree in Computer Science, Engineering, or a related field.
Experience in developing and deploying generative AI models in real-world scenarios.
Strong problem-solving and analytical skills.
Excellent communication and teamwork abilities.
Ability to work in a fast-paced and dynamic environment
Additional Information
  ",USD 45K - 84K *
119,Senior Data Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:   
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.
We’re disruptive. We work hard but try not to take ourselves too seriously. We are highly adaptable and constantly evolving. We are passionate about our product, and we live for our customers. We have high expectations and a career at ServiceNow means challenging yourself to always be better.
What you get to do in this role:
We are building a modern Data Platform for AI at ServiceNow. This platform will evolve to address various data needs from AI practitioners, both from teams inside of ServiceNow and from end customers of ServiceNow. We are in the early phase of defining and developing this platform and the vision is to grow into a comprehensive platform that addresses 
AI development (by the Advanced Technology Group and the various Business Units within ServiceNow)
Production solutions - to build/tune AI solutions based on customer specific data.
End customers - to enable customers to effectively build their own AI solutions.
This is a strategic initiative at ServiceNow and it will have a significant impact in accelerating AI solution development on the ServiceNow platform.
We are in the early stages of this journey and are looking for Technical leadership to drive various aspects of the Data Platform. Significant areas of responsibility are listed below. The expectation is to independently pursue these open-ended areas, investigate, propose, design and implement ideal solutions for ServiceNow. We are looking for strong technical leads who can conceive and develop new systems and lead the evolution of the Solution Architecture with a strong business focus.
Core Data Platform  & Interfaces for data – 
Explore Open Table formats (delta-lake, Apache Iceberg, Apache Hudi) & execution engines (spark SQL / trino),  
Expose suitable Data models and APIs for Data.
Data Pipelines – Data Extraction improvements. Optimized data pipelines. Orchestration of pipelines. 
Governance/Security/Auditing – Establish data governance and security policies as per requirements. End to end security, governance, access control, audit etc.
Drive large features all the way from design to implementation.
Due diligence with respect to functional and test coverage is a given.
Data Catalog/Data Discovery & Lineage
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.
 Qualifications
To be successful in this role you have:
Significant exposure to Data engineering.
Bachelor's degrees in Computer Science or Computer Engineering
4+ Years of experience typically.
Strong experience in Data Engineering & Big Data technologies. Building robust and resilient data pipelines, Data modeling (Dimensional etc.) for Analytic workloads.
Ability to learn and work with multiple technologies in a fast paced environment, to effectively build large scale end-end Analytics solutions.
Expertise in Glide, SQL, PLSQL, Java, Python, Performance tuning to build effective large scale systems is a must. Versatility in using various programming languages, tools and frameworks with effective judgement and focus on the eventual end-end solution is required.
Good understanding of Cloud architecture, security, networking, monitoring and deployments
Hands on experience on any one cloud – AWS, Azure, Google or Oracle is desired. Experience building scalable, highly available and secure distributed multi-tiered systems experience with relational databases
Good knowledge in Rest API development and usage is desirable.
Strong communication and interpersonal skills
Knowledge/experience with data-science techniques is desirable.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
120,Senior Analyst-Data Analysis,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Following Tesco's Business Code of Conduct and always act with integrity and due diligence - Engaging with business & functional partners to understand business priorities; ask relevant questions and scope same into a analytical solution document calling out how application of data science will improve decision making - In depth understanding of techniques to prepare the analytical data set leveraging multiple complex data set sources - Building Statistical models and ML algorithms with practitioner level competency - Writing structured; modularized & codified algorithms using Continuous Improvement principles (development of knowledge assets and reusable modules on GitHub; Wiki; etc) with expert competency - Building easy visualization layer on top of the algorithms in order to empower end-users to take decisions - this could be on a visualization platform (Tableau / Python) or through a recommendation set through PPTs - Working with the line manager to ensure application / consumption and proactively identifying opportunities to help the larger Tesco business with areas of improvement - Keeping up-to-date with the latest in data science and retail analytics and disseminating the knowledge among colleagues
Qualifications
Enable data driven decision making across the Tesco business globally by developing analytics solutions using a combination of math; tech and business knowledge
- Applied Math: Applied Statistics; Design of Experiments; Regression; Decision Trees; Forecasting; Optimization algorithms; Clustering; NLP
- Tech: SQL; Hadoop; Spark; Python; Tableau; MS Excel; MS Powerpoint; GitHub
- Business: Basic understanding of Retail domain
- Soft Skills: Analytical Thinking & Problem solving; Storyboarding; Articulate communication
Additional Information
Last Date of Application-10th Jan 2024
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
121,Lead - Data Engineer,Equifax,IND-Bengaluru-Equifax Credit Information Services,Senior-level / Expert,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds,  and make a meaningful impact, we want to hear from you.
Synopsis of the role
The Data Engineer  – Data Engineering position is responsible for managing the BAU for DFKL and DF data for Consumer and Commercial bureau. Also, the development and maintenance of ongoing programs/project metrics, presentations, analyses, dashboards, etc. to inform a wide variety of stakeholders.
What you’ll do
Designing and Building Data Infrastructure Data Ingestion and Integration Data.
Modeling and Database Management Data Transformation and Processing Data Security and Governance
What experience you need
Work location of this role is Bangalore
Bachelor's Degree in Computer Science/Engineering or other related discipline
Minimum of 4 years of data management, engineering, and/or, data analysis experience in the credit risk, financial services domain Proficiency in SQL and understanding of relational databases
Experience in writing Advanced SQL queries, stored procedures, views, triggers and performance tuning, query and cost optimization.
Good understanding of ETL and Data Tools - Using Python/Pyspark, SQL, Apache Spark, Apache beam, Airflow and RDBMS (SQL Server, Oracle, MySQL etc).
Understanding of data modeling and integration concepts, with the ability to design and implement data architectures.
Strong programming skills in languages such as Python, PySpark, Scala, C# or Java, with experience in data manipulation, transformation, and analysis.
Experience with big data technologies and frameworks, such as Hadoop, Spark, or Hive.
Design and build scalable and efficient data infrastructure on GCP platform
Understanding of SDLC, data warehousing, data modeling and ETL concepts Familiarity with data quality and governance principles..
Excellent problem-solving and analytical skills, with the ability to identify and resolve complex data engineering challenges.
Strong collaboration and communication skills, with the ability to work effectively within a team and interact with stakeholders.
Knowledge of Agile methodology and working within an agile team
What could set you apart
Knowledge of credit bureau data Certification on Data Engineering, Data Science is added advantage.
Knowledge on Cloud Platforms - preferably on GCP is added advantage
We offer a hybrid work setting, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Primary Location:
IND-Bangalore-Equifax Credit Information Services
Function:
Function - Data and Analytics
Schedule:
Full time",USD 121K - 186K *
122,Junior Data Engineer,Wizikey,"Gurugram, India",Entry-level / Junior,"Company Description
Wizikey is a cloud-based marketing and Communications software that uses AI technology to monitor news, provide media insights, and automate reporting. It helps companies track their news presence, gather competitive intelligence, and connect with relevant reporters. With Wizikey, businesses can measure their PR efforts, optimize strategies, and drive better outcomes. Trusted by over 100+ businesses, including Reliance, Infosys, MapmyIndia, Blusmart, Physics Wallah and WebEngage, Wizikey enhances brand visibility globally.
Job Description
Role Overview:
We are seeking a passionate and talented Junior Data Engineer to join our team. As a key member of our data team, you will play a crucial role in managing our data systems and pipelines. This position is ideal for individuals who are eager to develop their skills in a fast-paced, innovative environment.
Key Responsibilities:
(ETL/ELT) Data Pipeline Development: Design, build, and maintain efficient ETL/ELT data pipelines to support data collection, integration, and extraction processes.
Database Management: Work with various database technologies, both SQL and NoSQL, to store and manage data effectively.
Data Analysis and Reporting: Assist in analyzing data to provide actionable insights. Develop and maintain dashboards and reports for internal teams.
Collaboration: Work closely with other teams, including engineering, product, and analytics, to understand data needs and implement solutions.
Quality Assurance: Ensure the accuracy and integrity of data through quality checks and validation processes.
Learning and Growth: Continuously learn and stay updated with the latest technologies and practices in data engineering.
Qualifications
0-3 years of experience in a data engineering role (including internships or academic projects).
Proficiency in Python.
Familiarity with data pipeline and workflow management tools (preferably Apache Airflow).
Basic understanding of SQL and experience with relational databases.
Knowledge of big data technologies (e.g., Hadoop, Spark) is a plus.
Knowledge of cloud platforms (preferably AWS) is a plus.
Strong problem-solving skills and attention to detail.
Excellent communication and teamwork abilities.
Additional Information
""Wizikey encourages and celebrates entrepreneurial culture. When you set out to create a new industry, you need to build a team of immensely talented folks from Technology and Communications and give them the freedom to experiment, learn and keep building. And with every addition of talent, this gets new fuel and the magic happens. And that is why we call ourselves Wizards"" ",USD 60K - 125K *
123,Insurance Enabling Technologies – DATA Developer - Senior Associate 2 - Hyderabad,PwC,Hyderabad - My Home Twitza,Mid-level / Intermediate,"Line of Service
Advisory
Industry/Sector
Not Applicable
Specialism
Functional & Industry Technologies
Management Level
Senior Associate
Job Description & Summary
A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities, coaching them to deliver results.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Use a broad range of tools and techniques to extract insights from current industry or sector trends.
Review your work and that of others for quality, accuracy and relevance.
Know how and when to use tools available for a given situation and can explain the reasons for this choice.
Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Minimum 5+ Years of experience in the IT industry
Must have 4+ years’ experience in ETL skill set, Policy Migration Tool(GW tool to leverage), Java/Spring boot skill set should have strong experience in SQL on creating tables, views, stored proc, functions and in writing complex SQL queries and Datawarehouse concepts.
Preferably Guidewire DataHub & insurance knowledge.
Providing estimation for development activities based on the design and  analyzing data source, data volume & business rules
Should have working experience of agile.
High quality written and verbal communication skills, strong listening skills
Must have skill : ETL skill set, Policy Migration Tool(GW tool to leverage), Java/Spring boot skill set
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
0%
Available for Work Visa Sponsorship?
No
Government Clearance Required?
No
Job Posting End Date",USD 72K - 100K *
124,"Mgr, AI Engineering",IQVIA,"Kochi, India",Senior-level / Expert,"Responsibilities
Lead from the front as a hands-on subject matter expert, architecting and crafting scalable solutions, and driving data excellence across the organization.
Coordinate between the front-end, back-end, and integration teams to ensure seamless delivery of the solution. This includes facilitating communication, resolving conflicts, and ensuring that all teams are aligned with the project goals and timelines
Architect a full ML Platform and build out the infrastructure to support scalability.
Provide collaborative leadership to build out the AI function, MLEs, MLOps and Data Engineering.
Collaborate with stakeholders a to turn business goals into technical solutions.
Define best AI/ML driven practices and AI lifecycle.
Oversee model training and optimization.
Coach and mentor the team.
Skills & Experience
Good understanding of GenAI LLM models (ChatGPT, LLAMA 2, etc.), Vector databases, LangChain, and LlamaIndex.
Good understanding of Prompt Engineering.
Hands-on experience with Deep Learning architecture, NLP, and OCR.
Expertise in building, deploying, and fine-tuning natural language understanding, questioning, and semantic reasoning systems.
Knowledge of writing unit-test code for robustness, including edge cases, usability, and general reliability.
Experience in improving and fine-tuning model performance and implementing new technologies.
Total 8 - 12 years of software development experience, including experience in Python.
Expertise in SQL and API development.
Expertise in Azure cognitive services.
Expertise in the MLOps framework.
Expertise in Docker/Kubernetes
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com",USD 106K - 223K *
125,Data Engineer(ML&LL Mode),Unison Consulting Pte Ltd,"Bengaluru,Chennai, Karnataka, India",Senior-level / Expert,"4 years in data science and Machine learning, Data Engineering Worked on Finance / Banking projects.
Understanding of data structures, data modeling, ML algorithms and software architecture.
Work closely with clients to understand their requirements and deliver custom solutions.
Extend prototypes and improve them to robust and scalable solutions.
Design and fine-tune large language models for specific applications.
Efficiently handle large language models in production environments to enable (almost) real-time solutions.
Build and run ML pipelines, and deploy models that improve accuracy of various process steps within our pipeline.
Write technical papers, reports, and document best practices.
Experience writing code in Python+ ML frameworks (like Keras or PyTorch) and libraries (like scikit-learn).
Practical experience with ML cloud Services on AZure or AWS (I.e. Azure ML,Amazon SageMaker or MLFlow)
Basic understanding of access management, e.g. IAM and RBAC.
Optimization experience in areas such as deep learning computational frameworks is a plus
Learning oriented and keen on stay updated on cutting-edge advancements in large language models and NLP.
Strong analytical and problem-solving skills.
Excellent communication skills.
Python,pyspark Programming, Large Language Models (LLM), ML, Cloud and SQL",USD 121K - 186K *
126,Operations Engineer - Machine Learning,Beam Suntory,"Gurgaon, HR, IN",Senior-level / Expert,"Experience
JOIN OUR BEAM SUNTORY FAMILY!
With two centuries of family heritage, Beam Suntory is a world leader in premium spirits. As a truly global business, we bring together the best of our culturally diverse heritage. We value both agility and long-term thinking, we share a collective commitment to excellence and a dedication to craftsmanship, and across borders and roles, we collaborate to delight our consumers responsibly, and contribute to a more sustainable society for all of our stakeholders. 
Our Vision is Growing for Good and our mission is to be the world’s most admired, fastest-growing premium spirits company. We’re a business that runs on responsibility, integrity, ambition and drive, and we celebrate exceptional performance. We welcome our people to dream big and tenaciously pursue ambitious goals – we call it our Yatte Minahare Spirit.
But perhaps most importantly – we value difference, and we appreciate what each of us can contribute. We inspire each other, and challenge ourselves to innovate, improve, advance new ideas and try new things. We create endless opportunities to Unleash Your Spirit every day in a culture that is charged, creative, challenging and fun. 
What makes this a great opportunity?
Beam Suntory is a leader in the spirits industry with a track record of profitability and growth.
Opportunity to help shape the Digital Technologies & Analytics initiatives.
Growth potential beyond this role
Role Responsibilities
Role Responsibilities
Outcomes/Success Criteria
Drive the implementation of the defined innovation strategy through the design and architecture of analytics platform components/services utilizing Google Cloud Platform infrastructure and provide technical expertise to deliver advanced analytics.
Designs, builds, and runs machine learning systems at scale.
Should be able to work independently and in a team environment and be passionate about creating highly scalable, efficient, and easy-to-maintain solutions.
Responsible for maintaining the infrastructure that supports the models and algorithms that power the analytical products, including:
Monitoring the performance of these systems.
Identifying ways to improve their performance.
Investigating issues when they arise 
Responsibilities
Train models and tune their hyperparameters.
Analyze the errors of the model and designs strategies to overcome them.
Deploy models to production.
Build CI/CD pipelines orchestration by GitHub Actions, Nexus, Airflow, Jenkins or similar tools.
Perform data science model review, run the code refactoring and optimization, containerization, deployment, versioning, and monitors for quality.
Perform data science models testing, validation and test automation.
Communicate with a team of data scientists, data engineers and architect and document the processes.
Drive innovation through developing proofs of concept and prototypes to help illustrate approaches to technology and business problems.
Provide strong technical skills with ability to design, architect, and get into low-level implementation details.
Understand business objectives and develop models that help to achieve them, along with metrics to track their progress.
Explore and visualize data to gain an understanding of it, and identify differences in data distribution that could affect performance when deploying the model in the real world.
Proven experience in working with globally distributed agile teams. 
Qualification
A Bachelor's / Master’s degree in computer science, math, physics, engineering, data science, or a related field.
4+ years of progressive experience in data and advanced analytics.",USD 37K - 70K *
127,Data Engineer,StockX,"Bengaluru, India",Senior-level / Expert,"Help empower our global customers to connect to culture through their passions.
Why you’ll love this role
As a Data Engineer, you will be empowered to leverage data to drive amazing customer experiences and business results. You will own the end to end development of data engineering solutions to support analytical needs of the business. The ideal candidate will be passionate about working with disparate datasets and be someone who loves to bring data together to answer business questions at speed. You should have deep expertise in the creation and management of datasets and the proven ability to translate the data into meaningful insights through collaboration with analysts, data scientists and business stakeholders.
What you'll do 
Design and build mission-critical data pipelines with a highly scalable distributed architecture - including data ingestion (streaming, events and batch), data integration, data curation 
Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business stakeholders 
Build and support reusable framework to ingest, integration and provision data 
Automation of end to end data pipeline with metadata, data quality checks and audit 
Build and support a big data platform on the cloud 
Define and implement automation of jobs and testing 
Optimize the data pipeline to support ML workloads and use cases 
Support mission critical applications and near real time data needs from the data platform 
Capture and publish metadata and new data to subscribed users 
Work collaboratively with business analysts, product managers, data scientists as well as business partners and actively participate in design thinking session 
Participate in design and code reviews 
Motivate, coach, and serve as a role model and mentor for other development team associates/members that leverage the platform 
About you 
Minimum of 2 years’ experience in distributed systems like Data warehouse / Data lake technical architecture
2+ years of experience in using programming languages (Python / Scala / Java / C#) to build data pipelines 
Minimum 2 years of Big Data and Big Data tools in one or more of the following: Batch Processing (e.g. Hadoop distributions, Spark, Databricks), Real time processing (e.g. Kafka, Flink/Spark Streaming) 
Minimum of 2 years' experience with AWS or engineering in other cloud environments 
Advanced proficiency in SQL and familiarity with DBT
Experience with Database Architecture, Schema design 
Strong familiarity with batch processing and workflow tools such as AirFlow, NiFi 
Ability to work independently with business partners and management to understand their needs and exceed expectations in delivering tools/solutions 
Strong interpersonal, verbal and written communication skills and ability to present complex technical/analytical concepts to executive audience 
Strong business mindset with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery 
Experience providing technical leadership and mentoring other engineers for best practices on data engineering 
Bachelor's degree in Computer Science, or a related technical field 
Nice to have: 
Masters in Computer Science or related quantitative field 
 About Us

StockX is proud to be a Detroit-based technology leader focused on the large and growing online market for sneakers, apparel, accessories, electronics, collectibles, trading cards, and more. StockX's powerful platform connects buyers and sellers of high-demand consumer goods from around the world using dynamic pricing mechanics. This approach affords access and market visibility powered by real-time data that empowers buyers and sellers to determine and transact based on market value. The StockX platform features hundreds of brands across verticals including Jordan Brand, adidas, Nike, Supreme, BAPE, Off-White, Louis Vuitton, Gucci; collectibles from artists including KAWS and Takashi Murakami; and electronics from industry-leading manufacturers Sony, Microsoft, Nvidia, and Apple. Launched in 2016, StockX employs more than 1,000 people across offices and verification centers around the world.
    We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. However, this job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. StockX reserves the right to amend this job description at any time.",USD 121K - 186K *
128,Big Data Engineer,Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

About the role

- You’ll be working within an international group of teams which span from the US till India. This group is responsible for building our Audience Builder application and components which is part of Nielsen’s Advanced Audiences in the Nielsen ONE product suite. Your specific team will be responsible to build data pipelines, services and UIs to support our complex entitlement needs for our current and future web applications.

- As a Software Data Engineer you will be responsible for data pipelines to work on both scheduled and real time use cases.  Schedule pipelines run typically in Airflow and real time processing could be airflow or integrated querying in backend services. 
Responsibilities
Work closely with team leads and backend developers to design and develop functional, robust pipelines to support internal and customer needs
Write both unit and integration tests, and develop automation tools for daily tasks
Develop high quality, well documented, and efficient code 
Manage and optimize scalable pipelines in the cloud
Optimize internal and external applications for performance and scalability
Develop automated tests to ensure business needs are met, and write unit, integration, or data quality tests
Communicate regularly with stakeholders, project managers, quality assurance teams, and other developers regarding progress on long-term technology roadmap
Recommend systems solutions by comparing advantages and disadvantages of custom development and purchased alternatives

Domain Expertise
2+ years of experience as a software/data engineer 
Bachelor’s degree in Computer Science, MIS, or Engineering

Technical Skills
Experience with database systems, with knowledge of SQL and NoSQL stores (e.g. MySQL, Oracle, MongoDB, Couchbase, etc.)
Experience developing sophisticated data driven software platforms
Experience with relational databases and/or analytical data stores (e.g., Spark, Presto, Pandas)
Experience delivering, supporting enterprise software
Experience with cloud service technologies, ex: AWS
Experience with container technologies, ex: Docker
Experience with source control systems, ex: GIT
Information visualization
""Big data"" systems and analysis
Experience with data warehouses or data lakes

Mindset and attributes
Strong communication skills with ability to communicate complex technical concepts and align organization on decisions
Sound problem-solving skills with the ability to quickly process complex information and present it clearly and simply
Utilizes team collaboration to create innovative solutions efficiently",USD 30K - 56K *
129,Senior Data Analyst,Experian,"Hyderabad, India",Senior-level / Expert,"Company Description
Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.
We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.
Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group
 Job Description
Experian Consumer Information Service (CIS) is looking for a Delivery Analyst, based in Hyderabad, India to work alongside our UK colleagues to deliver business outcomes for the UK&I region.  
  Background: 
This is an incredibly exciting time for the Experian UKI Region, as we look to build our presence out in Hyderabad and embark on a technology transformation programme to meet our global ambition to significantly scale our business over the next five years. This is an opportunity to join us on this journey and be part of a collaborative team that uses Agile DevSecOps principles to deliver business value.   
  By way of background, the business unit currently comprises of 27 engineering teams who deliver over 70 products achieving $250m revenue per annum.  
  Our unique culture and agile ways of working offer a great opportunity to those seeking to join a talented set of diverse problem solvers to design, build and maintain our products. We pride ourselves in excellence, adopting best practices and holding ourselves to the highest standards. 
  The Role: 
The CIS team is at the forefront of change to digitise customer journeys, helping consumers fulfil their dreams more quickly and easily than ever. You will be working with lenders, fintechs and digital marketplaces to create industry disrupting solutions in one of the biggest financial services markets. 
  The delivery analyst will work from requirements from the client and interpret these and implement the changes in our own solution. They will be responsible for delivery, as well as feeding into design choices for new deliveries and ensuring work is carried out according to business standards. They will work closely with the Client Manager, Data and Analytics teams, and the Go To Market Team to support on executing the pipeline. 
  Key Responsibilities:  
  Line manage a small team of other analysts and guide them in delivering results for clients 
Understand the end to end process for customer delivery, and manage a backlog and pipeline of work for junior analysts 
Maintaining existing solutions and delivering solutions for new clients 
Configuration of products via database tables, using SQL queries 
Configuration of the product to deliver excellent client outcomes 
Using an in-house tool to build scorecards using decision trees and arithmetic logic calculations 
Working according to all regulatory requirements as well as existing change processes and security standards 
Advocate for a culture that achieves business goals, delights customers and acts in a manner conducive to the fair and reasonable treatment of all consumers, irrespective of whether these are Experian UK clients and consumers or not 
Oversee the maintenance and upkeep of documentation for operational processes 
Develop product knowledge 
Accurately Configure product following client requirements 
Develop a constructive working relationship with the client management teams  
Ensure that your delivery Analysis activities are delivered to time, quality and schedule. 
Ensure your delivery meets all the functional requirements provided by product consultants 
Create and maintain any other relevant documentation as required for successful delivery e.g. User Guides, Implementation Guides, Training Guides etc., providing that it is within scope of the role 
Identify any changes needed to product functional documentation in line with any changes made to the product 
Qualifications
Qualifications   
Degree level and / or equivalent level of professional experience, preferably with some element of mathematics, statistics, or computer science. 
Technical knowledge coupled with reasonable understanding of business operating principles 
Communication - Communicate progress of work (progress reports & future plans) to the team and recommend effective corrective actions where necessary, this will be done through retrospectives. 
Customer Service - Pro-actively manage UK internal stakeholder expectations. 
Continuous process improvement - Identify measures to improve delivery and customer satisfaction. 
Networking - use effective working relationships within Experian and third-party suppliers to ensure developments add value and meet business expectations. 
Experience  
Working collaboratively, leads by example and inspires trust of others 
Coordinating with stakeholders, sales teams and leadership teams around feasible achievements and upcoming opportunities 
E - Directing junior analysts  
Required Technical Skills/Knowledge  
Experience using Excel for data manipulation and presentation 
Basic knowledge of SQL to INSERT/UPDATE/DELETE operations 
Statistical & Mathematical Ability
Beneficial Skills/Knowledge  
Experience in the credit industry 
Additional Information
Who are Experian?
We unlock the power of data to create opportunities for consumers, businesses and society. At life’s big moments – from buying a home or car, to sending a child to university, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage their data with confidence so they can maximize every opportunity.
For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done. Our 17,000 people in 37 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.
Could this be the role for you? Apply now to start your journey with Experian.
To learn more about our culture and what it’s really like to work here, check out our LinkedIn and social media channels using the hashtags #ExperianLife and #ExperianWay.
Why choose us?

Our colleagues’ health and wellbeing are a top priority for us, that’s why our reward, benefits and wellbeing programmes are designed so you can come to work feeling your very best self. Our benefits focus on health, money and lifestyle so you can tailor your benefits to your own personal needs. Whether it’s your physical and mental wellness, getting to work or planning for the future, we have a range of flexible options to have you covered!

We are committed to building an inclusive culture and to creating an environment where people can balance successful careers with their commitments and interests outside of work. Our flexible working practices support our belief that this balance brings long-lasting benefits for our business as well as our people. Some roles lend themselves to flexible options more than others, and if this is important to you, we are open to discussing agile working opportunities during the hiring process
Experian Careers - Creating a better tomorrow together
Find out what its like to work for Experian by clicking here",USD 93K - 144K *
130,Computer Vision Algorithm development for ADAS - Technical Architect,Bosch Group,"Bengaluru:, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
We are in the exciting and cutting-edge space of autonomous driving. We are looking forpassionate and experienced engineerswho would join us in this journey and design algorithms fit for Level 3 – Level 5 autonomous systems.A typical day in office would involve:
Looking at the nature of the data
Current AI/DL algorithm performance
Derive insights or patterns in failures
Define a hypothesis for the solution making.
Define Experiments for hypothesis testing
Define/Review the techniques/methods in deep learning for experiments
Analyze the results of experiments
Define the next set of data or experiments forward
Define the targets for the current sprint
Review, Agree on the experiments
Ensure delivery with the right process for quality
Here’s what to expect:
Develop Deep learning-based models for Autonomous driving (Image/Video based perception development)
Do Intense application research for finding suitable network (Models) that tackles typical problem of Object recognition at scale (inferring very large volume of data, optimized memory footprint for edge devices)
Demonstrate the ability to use available solutions/ approach to narrow down to the most probable subset
Demonstrate the intuitive ability to assess available potential approaches to narrow down highest probable approach for solving the problem at hand and hence reduce overall experimentation time
Ability to critically compare models using the right parameters to identify the best suitable model that solves the use caseskills needed
Strong technical background
with Bachelors/Master of Engineering in Computer Science or related areas greater than 5years of industry experience in Computer Vision (AI/Deep Learning based algorithms).In depth understanding of computer vision models including Object detection, SOTA feature extractors & SOTA Supervised & Unsupervised training mechanisms
A team player
. You take ownership and work with the team to deliver exceptional results. You are interested in the performance of the entire system across engineering disciplines.
Ability to build and iterate quickly (AGILE mindset
). You enjoy working fast and smart, and you are comfortable in the earlier stages of developing an algorithm from scratch.
Hands on:
You dig deep into important details such as the sensor driver if it improves the overall system. You like working with production machine learning pipelines, from dataset collection and labeling to training and validation.
Great communicator:
You have experience writing clear, concise, and detailed documentation.Should be able to explain technical solutions clearly to non-technical/different audience
Problem solver:
 Qualifications
B.E/B.Tech
Additional Information
6 years to 10 years",USD 45K - 84K *
131,Lead Data Engineer,Visa,"Bengaluru, India",Executive-level / Director,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Ready to make a global impact by industrializing AI?
Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS powers and automates industrialization of data, models, and applications. Combined with strong governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!
 This position is for a Lead Data Engineer with solid development experience who will focus on creating new capabilities for AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer who can work in a dynamic environment.  Your strong technical skills, leadership, problem-solving abilities, coding, testing and debugging skills is just a start.  You must be willing to go beyond the routine, challenge yourself and be prepared to do a bit of everything.
You will be an integral part of the development team, often investigating new requirements, designing, debating, refactoring, implementing, and documenting continuously, in a continuous effort to provide better solutions to your consumers. You must be a self-organized individual should be flexible and willing to switch tasks based on business needs.
 If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.
This position will be based in Bangalore, India.
 Essential Functions
Collaborate with project teams, data science teams, engineering teams and operations teams to drive the development and implementation of new Data and AI driven solutions.
Drive technical standards and best practices, and continuously improve AI Platform’s engineered capabilities.
Architect and design of AI Platform services using open source and vendor based Distributed Computing Engines, In Memory Computing Systems, Stream Processing Systems, Data Systems and so on.
Help to coordinate the technical implementation among different teams and ensure system performance, security, scalability, and availability.
Act as the technical owner of multiple core modules of the platform, be accountable for technical quality and delivery timeliness.
Coaching and mentoring junior team members.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
• 10+ years of relevant work experience with a Bachelor’s Degree or at least 7 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 4 years of work experience with a PhD, OR 13+ years of relevant work experience.

Preferred Qualifications
• 12 or more years of work experience with a Bachelor’s Degree or 8-10 years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 6+ years of work experience with a PhD
• 10 years or more of experience in leading and mentoring development teams, acting as a lead developer or architect with deep hands on abilities.
• Proven knowledge of successful design, architecture and development of large scale data driven, low latency, high performance real time systems.
• Deep understanding of benefits and drawbacks of different design, architectural and integration patterns.
• Strong development experience in one or more of Golang, Java, Scala, Python, Rust and C/C++
• Experience in big data and other database systems such as MySQL, Redis, Elastic etc.
• Sound knowledge of Real Time Event Driven systems based on technologies like Flink, Kafka, Spark Streaming or similar.
• Well versed with common software development tools such as Git, Maven, SBT, Jenkins, Sonarqube, Checkmarx etc.
• Ability to solve complex software development and design issues and propose, prototype and deliver effective solution.
• Passionate about delivering zero defect code, meet or exceed SLAs and have high sense of accountability for quality and timeliness of deliverables.
• Demonstrated ability to lead and navigate through ambiguity, educate and influence stakeholders.
• Strong interpersonal and effective communication skills both written and verbal.
• Knowledge of Agile methodologies, common scrum practices and tools
• Experience in payments domain and prior experience in large scale ML/AI Model Engineering is a definite plus.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 49K - 91K *
132,Researcher - Data Operations Intern,Findem,India (Remote),Entry-level / Junior,"What is Findem:

Findem is HR 2.0. We’re a fast-growth startup with an ambitious vision and the technology to back it up. Our People Intelligence platform uses true AI and machine learning to provide critical solutions for talent acquisition and people analytics functions. With the deep insights that our platform provides, companies can build more engaged and diverse teams, and close their talent gaps faster. We have an amazing opportunity to establish ourselves as leaders in this space, and we need strong advocates to help us achieve that goal.

We’re backed by top-tier investors including Wing Venture Capital – the same firm that backed Snowflake, Cohesity, and Gong. Findem powers businesses across scaling, pre-IPO, and publicly traded companies who trust us to solve their biggest HR and Talent challenges. We have an incredibly skilled and collaborative team that values curiosity, diversity, openness and building great experiences every day for our customers. By joining Findem, you will have the unique opportunity to help define what the future of HR looks like for every business.

Selected intern's day-to-day responsibilities include:

1. Carrying out data research activities on the internet or our proprietary system
2. Updating data fields using internal tools
3. Performing any other secondary data research activity as required

Work timings: 5-6 hours a day, 5 days a week
Duration- 6 months

Skill(s) required
MS-Excel, Research and Analytics

Who can apply
Only those candidates can apply who:
1. are available for the work-from-home
2. can start the internship immediately
3. are available for 6 months
4. have relevant skills and interests
5. Non BE/ B.Tech graduates
* Women wanting to start/restart their career can also apply.

Perks
Certificate, Letter of recommendation, Flexible work hours, 5 days a week
The role is full-time and comes with full benefits. We are globally headquartered in the San Francisco Bay Area with our India headquarters in Bengaluru, but this role can be fully remote.

Equal Opportunity

As an equal opportunity employer, we do not discriminate on the basis of race, color, religion, national origin, age, sex (including pregnancy), physical or mental disability, medical condition, genetic information, gender identity or expression, sexual orientation, marital status, protected veteran status or any other legally-protected characteristic.",None
133,"Analyst, Data Science (R-15410)",Dun & Bradstreet,Chennai - India,Mid-level / Intermediate,"Why We Work at Dun & Bradstreet
Dun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!

Key Skills
Strong Analytical and Problem-Solving Skills, Statistical Modelling, Data Analysis, Risk Scorecard Development, Machine Learning etc.,

Overview
Dun & Bradstreet Technology and Corporate Services India LLP is looking for candidates for the role of Analyst to support the Data Science team. The candidate needs to work closely with the team based in India and across a range of Analytics leaders who are located globally to fulfill the deliverables on a timely basis.

Primary Responsibilities Include but Are Not Limited To

•Work across range of Analytical Solutions that includes Design, Development, Validation, Calibration, Documentation, Implementation, Monitoring, and Reporting
•Extracting large data from various data sources using multiple tools such as Python/ Pyspark /Hadoop/ SQL/ etc., to perform multiple analysis
•Generate Analytical Insights on various customer portfolios
•Develop Predictive Solutions using advanced statistical techniques to enable better decision making
•Utilize latest data science techniques across both supervised and unsupervised machine learning methodologies, NLP and development of new capabilities
•Serve as a Subject Matter Expert on using Machine Learning techniques
•Collaborate with Technology teams to implement analytical solutions and models
Work with stakeholders in providing additional analysis based on specific needs.

Requirements

•2 – 5 years of relevant experience in Data Analytics / Data Science roles
•Strong programming skills in tools such as Pyspark, Python, R, SQL to manipulate data and conduct statistical analysis
•Knowledge of Python packages and tools
•Sound Knowledge and proven experience on application of Statistical / Machine Learning Techniques
•Experience in BFSI domain / Statistical Modelling & Validation is an added advantage
•Ability to interpret and translate data into meaningful business insights
•Excellent verbal, written communication and presentation skills

All Dun & Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html. Official communication from Dun & Bradstreet will come from an email address ending in @dnb.com.

Notice to Applicants: Please be advised that this job posting page is hosted and powered by Lever. Your use of this page is subject to Lever's Privacy Notice and Cookie Policy, which governs the processing of visitor data on this platform.",USD 110K - 223K *
134,Machine Learning Engineer 5,Adobe,Noida,Senior-level / Expert,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. 

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

 The Opportunity:

The Firefly GenAI India engineering team is looking for an ML Engineer to work on enabling exciting experiences for the Creative Cloud clients.

What you'll do:
Contribute to the backend services for Firefly that power the generative AI features on Firefly website, Photoshop, Illustrator, Express, Stock, Premier and other applications/surfaces
Develop GPU optimized, efficient model pipelines for new Firefly features related to images, video and audio
Ensure a scalable, reliable cloud service with observability, logging and tracing to enable quick detection, understanding and resolution of run-time issues
Contribute to Project Colligo, the AI superhighway for inference that will manage and serve a collection of ML models in a highly scalable and resilient system
Ensure a scalable, reliable cloud service with observability, logging and tracing to enable quick detection, understanding and resolution of run-time issues
Develop high-performance, reliable, testable and maintainable code
Work closely with teams across Adobe, in different geographies. The technology you produce will have visibility at the highest levels of the company and materially affect the positive impact products have on our customers
 What you need to succeed:
B.Tech or M.Tech. degree in Computer Science, Engineering or equivalent
6+ years of experience building, optimizing and operating GPU intensive ML workloads in production environments.
Several years experience architecting cloud services and infrastructure for large scale use (5B+ requests per month)
Understanding of model serving, orchestration, scaling, GPU resource management
10+ years software engineering experience
Experience in distributed computing
Technology Skills: Python, ML, Pytorch, AIT, CUDA, GPU drivers, Kubernetes, AWS
 Bonus Qualifications:
CUDA programming experience
Machine learning models integration into web applications
Scala, Java, C++
Experience with CI/CD systems
Experience with Agile development processes including Scrum
Experience building and training ML models
Experience in Video domain.
Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.
 Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",USD 150K - 232K *
135,"Sr. Manager - Java, Big Data",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Payments are a very exciting and fast-developing area with a lot of new and innovative ideas coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation for the next 5 to 10 years. VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area.
 If you want to be in the exciting payment space, learn fast, and make big impacts, Visa Finance Data Lake(FDL) and Analytics is a great place for you!
The FDL development and analytical group is responsible for building integration pipelines, and customizing and providing financial data to serve reporting and analytical needs at Visa. This includes idea generation, architecture, design, development, and testing of finance data integration and customizing the datasets as per reporting needs.
 This position is ideal for a Senior Engineering Manager who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will drive the Visa FDL platform in Visa's Engineering, Applications, and Analytics(EAA). You will be part of the Visa EAA team to help design, enhance, and build our Finance platform in an agile development environment. You will work with colleagues, who will support and challenge you daily. You will play a part in multiple teams tasked with multiple projects ranging from building highly functional, secure, scalable, and resilient real-time and batching systems.
 If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.
 Primary Responsibilities
Manage a team of Sr. Web, Data and DevOps Engineers building scalable systems.
Defines needs, develop plans, coordinate resources, and implement action plans.
Manages multiple projects simultaneously & to resolve scheduling & other conflicts to meet all deadlines.
Develop business requirements and appropriate statistical analysis/prototypes to meet critical business needs.
Teaches others through informal sessions such as brown bags and tech talks.
Drives engineering strategy and vision for the product working closely with customers and product managers.
Oversees, mentors, and assist engineers in all aspects.
Understand how a project fits into the overall technology roadmap and communicate to the team to help establish buy-in and ownership.
Takes ownership and/or leads the engineering responsibility for multiple components in a project.
Provides consultative work throughout the project lifecycle to ensure the vision and goal of the project is realized through delivery.
Coordinates engineering activities across the delivery of the project.
Supports operational and QA teams in support activities such as troubleshooting, defect research, code promotion, and configuration for projects led by the engineer.
 Secondary Responsibilities:
Helps our client achieve their real goals by understanding the requirements and how it would help them in their business.
Responsible for budgeting, scheduling, contract, and vendor management.
Works with Agile development methodologies with a mature understanding of the strengths and weaknesses of each.
Coaches engineers both on technical and career development.
Collaboration skills and influence cross-functional teams for results.
Focus on building an efficient and collaborative team environment.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.
Qualifications
Basic Qualifications
8+ years of relevant work experience with a Bachelor’s Degree or at least 5 years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 2 years of work experience with a PhD, OR 11+ years of relevant work experience.

Preferred Qualifications
9 or more years of relevant work experience with a Bachelor’s degree or 7 or more relevant years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 3 or more years of experience with a PhD
Prefer 2+ years in a leadership and management role
You have expertise in Big Data Technologies such as Hadoop, Spark, and Hive.
You have expertise in Java, and Python programming languages and frameworks
You have expertise in cloud technologies and platforms
You have expertise in web technologies and frameworks
Understanding of architecture and operations of highly available and scalable applications
Proven track record of hiring and managing diverse, talented & high performing engineering teams
You have experience architecting solutions with Continuous Integration and Continuous Delivery in mind
You have amazing work ethics that will help us all work extremely well together
You have a passion for understanding people and always striving to improve our products and services
Must be detail-focused and have business-oriented thinking
Proven ability to handle multi-tasks in a dynamic environment
Good written and verbal communication skills with the ability to present complex technical information in a clear and concise manner
Successful candidates will have a flair for out-of-box thinking and be passionate about mentoring and coaching junior software engineers. Candidate should also have a passion for engineering excellence.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
136,Senior Data Engineer,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
About BU
Digital wizards and experience creators, our DX team crafts compelling customer journeys across the web. They bring Epsilon teams and technologies together to create immersive experiences that help brands stand out. By leveraging the power of our platforms, cutting-edge digital and marketing cloud tools, the team drives greater engagement for our global clients. Fueled by provocative and new thinking, this talented group of individuals reimagine digital experiences, one customer at a time.
Why we are looking for you.
This position in the Engineering team under the Digital Integration Services organization. We drive the first mile of the customer experience through personalization of offers and content. We are currently on the lookout for a smart, highly driven software engineer.
What you will enjoy in this role
You will be part of a team that is focused on building solutions, pipelines using latest software engineering design principles and tech stacks. You will also be expected to Identify, design, and implement improvements including re-designing infrastructure for greater scalability, optimizing data delivery and automate continuous integration and deployment processes/pipelines.
The incumbent is also expected to partner with various stakeholders, bring scientific rigor to design and develop high quality software.
She/He also must have excellent verbal and written communication skills and be comfortable working in an entrepreneurial, ‘startup’ environment within a larger company.
What you will do
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Develop end-to-end (Data/Dev) pipelines based on in-depth understanding of cloud platforms, and business problems to ensure solutions are delivered efficiently and sustainably.
Collaborate with other members of the team to ensure high quality deliverables.
Learning and implementing the latest design patterns in software engineering
Qualifications
Data Management 
Experience with both structured and unstructured data
Experience building Data and CI/CD pipelines
Experience working on AdTech or MarTech technologies is added advantage
Experience in relational and non-relational databases and SQL (NoSQL is a plus).
Experience with Cloud technologies (AWS or Azure)
Hands on experience building ETL workflows/pipelines on large volumes of data
Good understanding of Data Modeling, Data Warehouse, Data Catalog concepts and tools
Experience with Data Lake architectures, and with combining structured and unstructured data into unified representations.
Able to identify, join, explore, and examine data from multiple disparate sources and formats. 
Ability to reduce large quantities of unstructured or formless data and get it into a form in which it can be analyzed 
Ability to deal with data imperfections such as missing values, outliers, inconsistent formatting, etc.
Ability to manipulate large datasets, (millions of rows, thousands of variables)
Software Development 
Ability to write code in programming languages such as Python, PySpark and shell script on Linux
Familiarity with software development methodology such as Agile/Scrum
Love to learn new technologies, keep abreast of the latest technologies within the cloud architecture, and drive your organization to adapt to emerging best practices
Architecture and Infrastructure
Architectural design experience on AWS
Experience in delivering software with AWS EC2, S3, EMR/Glue, Lambda, Data Pipeline, CloudFormation, Redshift etc.
Good knowledge of working in UNIX/LINUX systems
Bachelor’s Degree in Computer Science with 5+ years of similar experience
Tech Stack: Python, PySpark, Micro services, Docker, Serverless Frameworks and Databricks.
Familiarity with automated unit/integration test frameworks
Familiarity with Airflow and MLFlow tools
Good written and spoken communication skills, team player.
Strong analytic thought process and ability to interpret findings 
In addition, the candidate should have strong business acumen, and interpersonal and communication skills, yet also be able to work independently. He/she should be able to communicate findings and the way techniques work in a manner that all stakeholders, both technical and non-technical, will understand.",USD 121K - 186K *
137,Senior Data Integration Engineer,ShyftLabs,"Hyderabad, Telangana",Senior-level / Expert,"Position Overview:

We are looking for an experienced and versatile Sr. Data Engineer/ Integration Engineer to join our dynamic and fast-growing team. We are looking for an experienced person who has hands-on with data modeling, data warehousing, API integration, and building ETL pipelines. If you are passionate about data and solving complex problems, this role could perfectly fit you! 
ShyftLabs is a growing data product company that was founded in early 2020 and works primarily with Fortune 500 companies. We deliver digital solutions built to help accelerate the growth of businesses in various industries, by focusing on creating value through innovation.

Position Purpose:

The Integration Engineer will be integral part of BI and Analytics team and is responsible for delivering various BI and Analytics initiatives. They participate in defining and delivering the Data and Analytics based insights that can be leveraged by business teams. They align solutions, releases, and sprints consistent with program and project delivery cadence and are responsible for ensuring practical and implementable alignment with the organization and enterprise technological and architectural vision.

This role understands the solution context and actively collaborates with the teams, customers and suppliers to ensure alignment. They are trained and practiced in both traditional and agile delivery models, understand and are able to manage the complexities of large-scale solution development, and will be fluent in English. They also work closely with other offshore and onsite development and QA resources to develop and deliver a high quality product and are expected to typically work outside normal business hours due to the onshore/offshore teaming structure.

Job Responsibilities 

The incumbent must be able to perform all of the following duties and responsibilities with or without a reasonable accommodation.

- This position will work closely with the Scrum masters, Data Architects, QA, Dev/Ops,as well as multiple organizations within the company
- Engineer data/ETL pipelines to bring new data into data warehouse
- Partner with the Data architects, Product managers and Scrum Masters to deliver data integrations and BI solutions required for various projects
- Ability to translate requirements for BI and Reporting to Database design and reporting design
- Ability to engineer solutions using AWS products such as EC2, S3 buckets, Lambda functions, SQS queues, Dynamo DB etc.
- Ability to understand data transformation and translation requirements and which tools to leverage to get the job done
- Ability to understand data pipelines and modern ways of automating data pipelineusing cloud based and on premise technologies
- Enable Continuous Delivery (CD) to production for all data warehousing and BI builds
-Collaborate with DevOps team to align with CI/CD requirements for assigned projects
-Ability to understand end to end data integration requirements and response time SLA’s to build data driven solutions that provide best in class customer experience
- Ability to develop scripts (Unix, Python etc.) to do Extract, Load and Transform data
- Ability to write SQL queries against major databases such as Oracle, Snowflake, SQLServer etc.
- Ability to integrate on premise infrastructure with public cloud (AWS, AZURE)infrastructure
- Actively test and clearly document implementations, so others can easily understand the requirements, implementation, and test conditions.
- Contribute directly to the development of GraphQL APIs ,Design and Build GraphQL schemas and maintain existing APIs.


Education/Experience:
3-5 years’ experience developing ETL, ELT and Data Warehousing solutions
3-5 years’ experience with data engineering using Python based data pipelines
3-5 years’ experience AWS cloud, Azure or Google cloud
3-5 years’ experience in loading source system data extracts into data warehouse
3-5 years’ experience with batch job scheduling and identifying data/job dependencies
Strong in Linux experience to for shell scripting and Python scripting
3-5 years’ experience with REST API development and consumption
Understanding of API design and development on Rest/GraphQL frameworks
Experience creating GraphQL schemas and reusable components
Strong understanding of various data formats such as CSV, XML, JSON etc.
Experience working directly with technical and business teams.
Strong understanding of Agile process and tracking using Jira and ConfluenceIT governance and operations Comprehensive knowledge of hardware, software, and application dependencies.",USD 45K - 84K *
138,"Data Engineering - Senior Consultant (Data Architecture, Python, SQL, PySpark)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Summary:
Data Engineering Senior Consultant role for Asia Pacific Region is based out of Bangalore. The role will work with both internal VISA Consulting/Market data science organizations and with external clients of VISA. This position requires strong technical background in modern data architecture, evaluating and recommending suitable technology stack, building scalable, reliable, and secured data ecosystem and good appreciation of data governance and data management practices. 
 With external clients, the position is responsible for data engineering advisory, design and implementation of comprehensive data platforms and solutions that meets the need of aspiring data organizations. The role is expected to work and collaborate with cross-functional teams within Visa, external clients, and vendors to develop and implement data solutions that support the organization's data-driven initiatives and improve business outcomes while maintaining robust data solutions that align with industry best practices and compliance standards.
 Internally, the role will support design, development, and delivery of data engineering solutions for the client facing market data science teams. The role will take responsibility for building and running data pipelines, designing our local data warehouse, data marts and data frameworks, and catering to different data presentation techniques based on client requirements.
 Principal Responsibilities
•    Act as Data technology SME for both VISA’s external clients and internal market teams for design and implementation of scalable, secure, robust, and interoperable data solutions that support advanced analytics, reporting, and decision-making processes. 
•    Lead Development and implementation of data solutions, data integration, data warehousing, data lakes, data governance and quality, analytics platforms, and reporting tools for both internal and external clients. 
•    Create and maintain optimal data pipelines and data exchange channels (Such as APIs, Secured File Transfer, other custom data exchange capabilities provided by VISA) between VISA and clients.
•    Evaluate and select appropriate technologies, tools, and frameworks to support data solution development and ensure data security, privacy, and compliance alignment with market regulations. 
•    Explore new technology trends leveraging them to modernize our client data ecosystem. Our clients are Banks, Fintechs and Merchant in the region that we operate.
•    Collaborate with partners & stakeholders at varying levels both internally and externally to provide best in class solutions to VISA’s clients. 
•    Strong execution skills in a fast-paced environment using agile methodologies.
•    Experience in Event Driven Architecture, Massive Parallel and Stream processing, Microservices, ELT and micro-batches.
•    Advanced experience in Hadoop, Python, Spark, PySpark and cloud-based data technologies.  
•    Hands on experience with public cloud like Azure, GCP, AWS
•    Driving Innovation and guiding the teams to implement solutions with future thinking.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
•    Bachelor’s or Master’s degree in engineering, Computer Science, Software Engineering, Information Technology, or technical field required.
• 11+ years of experience in data architecture, data engineering, design, development and delivery of large-scale data solutions with 2+ years of experience in AWS/MA/GCP.

Technical Expertise
•    11+ years of experience in data architecture, data engineering, design, development and delivery of large-scale data solutions with 2+ years of experience in AWS/MA/GCP.
•    Demonstrated technology and personal leadership in architecting, designing, and building highly scalable data ecosystems. 
•    Deep knowledge and experience in architecting modern data extraction and ingestion frameworks using open source and emerging data architecture designs/patterns.
•    Certification in Hadoop, Apache Spark and cloud technologies preferred. 
•    Hands-on experience of Hadoop ecosystem and associated technologies such as Hive, Apache Spark, PySpark, MLlib, GraphX. 
•    Advanced experience in writing and optimizing efficient SQL queries and Python/PySpark scripts.
•    Good appreciation of ML engineering and Operationalization.
•    Experience with APIs, container-based software deployments.
•    Experience with DevOps, Continuous Integration and Continuous Delivery technologies.
•    Experience in data governance (process & standards for Metadata Management, Data Lineage, Master/Reference Data Management, Data Quality Management and associated tools/platforms) will be an added advantage. 
•    Experience in Data Visualization (platforms such as power BI and tableau) and data security practices will be an added advantage. 
•    Good appreciation of NoSQL and in-memory data stores
•    Good appreciation of machine learning algorithms, feature engineering, validation, prediction, recommendation, and measurement. 
•    Understanding of Payments, Banking and Financial services domain will be a plus.

Leadership Competencies
•    Demonstrates integrity, maturity, and a constructive approach to business challenges. 
•    Serves as a role model for the organization by implementing core Visa Values 
•    Shows respect for individuals at all levels in the workplace. 
•    Strives for excellence and extraordinary results. 
•    Uses sound insights and judgments to make informed decisions in line with business strategy and needs. 
•    Able to allocate tasks and resources across multiple lines of businesses and geographies. 
•    Able to influence senior management both within and outside Data Science 
•    Successfully persuading internal stakeholders to commit to best-in-class solutions, when required. 
•    Leverages change management leadership as required.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 115K - 193K *
139,Data Scientist - Visa Consulting & Analytics,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Description
About Global Commercial Payments Platform
We are working on multiple technology stacks and want to add a highly motivated Engineer to our Commercial Payments organization in Foster City, CA. Visa's Commercial Payments organization is responsible for managing Visa's B2B Payment Global adoption on Cross-Border funds movement, innovation agenda and the management of strategic partnerships with critical financial institutions. This group is responsible for defining and building the Non-Card based payment innovation and product for Visa Inc. Globally. This includes:
Distributed-Ledger based Cross border payment platform
Near time Settlement 
Enterprise ID stamping to create a digital identity for corporate entities
Hyperledger chain-code development
End-to-End Payment eco-system 
Analytics and Data visualization
 You can learn more about our work here:
Visa B2B Connect Launches in 32 Countries
Visa B2B Connect Launches Globally
 Essential Functions
Work on emerging technologies, building distributed applications
Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.
Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards. 
Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.
Partner with Product on implementation strategy.
Qualifications
Basic Qualifications:

5 years of relevant work experience with a Bachelor’s Degree in Computer Science or related field or an advanced degree in Computer Science or related field

Preferred Qualifications:

MS in Computer Science or related field
2+ years of experience with distributed software development
Hands-on experience with all aspects of software development: data, server-side, UI, and open-source software.
Experience with Linux, Open source, C++ or Java, client-server apps
Expertise in at least two of the following: Java / Go / Scala / Python,
Knowledge of developing Data Pipeline, including Ingestion, Transformation, Extraction etc. is expected
Experience in large Data Pipeline handing is a big plus
Familiar with container strategies and ecosystems such as Docker, Kubernetes
Knowledge of cloud architecture and scalable solutions including orchestration
BlockChain technical expertise is a plus
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 86K - 160K *
140,Power BI Engineer,HARMAN International,IN Bengaluru EOIZ Indust Area Campus HCS,Mid-level / Intermediate,"HARMAN’s engineers and designers are creative, purposeful and agile. As part of this team, you’ll combine your technical expertise with innovative ideas to help drive cutting-edge solutions in the car, enterprise and connected ecosystem. Every day, you will push the boundaries of creative design, and HARMAN is committed to providing you with the opportunities, innovative technologies and resources to build a successful career.
A Career at HARMAN
As a technology leader that is rapidly on the move, HARMAN is filled with people who are focused on making life better. Innovation, inclusivity and teamwork are a part of our DNA. When you add that to the challenges we take on and solve together, you’ll discover that at HARMAN you can grow, make a difference and be proud of the work you do everyday.
Key responsibilities and Skills of Power BI professionals:
Develop operational reports.
Build automated reports and dashboards with the help of Power BI and other reporting tools.
Understand business requirements to set functional specifications for reporting applications.
Be experienced in tools and systems on MS SQL Server BI Stack, including SSRS and TSQL, Power Query, MDX, PowerBI, and DAX
Be able to quickly shape data into reporting and analytics solutions.
Create functional reporting.
Have knowledge of database fundamentals such as multidimensional database design, relational database design, and more
HARMAN is an Equal Opportunity /Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race,color, religion, sex, sexual orientation, gender identity, national origin,disability or Protected Veterans status. HARMAN offers a great work environment, challenging career opportunities, professional training and competitive compensation. (www.harman.com)",USD 37K - 70K *
141,Lead Data Engineer,ShyftLabs,"Hyderabad, Telangana",Senior-level / Expert,"Position Purpose:
As a Ld. Data Engineer, at Petco, you will execute on new Data Engineering products and features in collaboration with Data Science, and Business teams.

Scope:
This role focuses on managing, supporting delivery and strategic initiatives such as data ingestion, integration, transformation, reporting and analytics. Broadly, it will work with every functional area of data engineering, data science teams & multiple Business partners.

Essential Job Functions:

The incumbent must be able to perform all the following duties and responsibilities with or without a reasonable accommodation.

- Lead the data strategy, and own the vision and roadmap of data products at Petco to enable decision making and self-service for business and analytics teams
-Solid experience in emerging and traditional data stack components such as: batch and real time data ingestion, ETL, ELT, orchestration tools, on-prem and cloud DW, Python, structured, semi and unstructured databases.
-Collaborate closely with the Data Engineering and Product team to execute on the set roadmap of data ingestion, integration and data transformation.
-Work cross-functionally with enterprise-wide stakeholders including (but not limited to) Analytics, Data Science, FP&A, Accounting, merchandising, pricing teams.
-Build a continuous monitoring process and tools to track the data management, data quality, and execute cleaning activities.
-Track the overall data transformation initiative and provide feedback or suggestions from a risk management perspective.
-Design, provide training and mentor/coach other team members.
-Work with stakeholders to ensure that data related business requirements for protecting sensitive data are clearly defined, communicated, and well understood and considered as part of operational prioritisation and planning
-Ensure the safe storage and transmission of data in line with privacy and compliance laws, data regulations, and internal company policies

Supervisory Responsibility
Position will manage a team of Data Engineers, Integration & QA engineers.

Education and Experience

Bachelor’s or Advanced degree in Information Systems, Information Management, Engineering, or related field 
5+ years of experience in data management, data warehousing and handling data engineering
3+ years of experience in Lead engineer role managing set of engineers including hiring and performance evaluations.
3+ years managing big data technology stack and restful APIs.
Strong knowledge of designing data pipelines and understanding details around orchestration, integration, data transformations.
Excellent communication skills, both verbal and written, and the ability to build trust- based relationships with business partnersTechnical knowledge in BI tools such as MicroStrategy, Looker.
Proven record of handling, managing, collaborating and delivering data products on time and meeting quality standards.

This position will be in a fast-paced and entrepreneurial environment where you will be handling multiple concurrent projects while working independently and in teams. An ideal candidate will possess strong problem solving and conceptual thinking abilities in addition to communication, interpersonal and leadership skills.",USD 45K - 84K *
142,Data Architect – AWS(Presales ),Rackspace,India - Remote,Senior-level / Expert,"Presales Data Architect – AWS

Exp - 10-20yrs
Notice period - Less than 60days
 In this role you will be helping to grow the Rackspace Cloud data practice.  You will be the expert in the region and support the sales of our data projects on AWS.  Our Presales Data Architects are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with our sales team to propose solutions to customers to achieve business outcomes using Google Cloud.
 This is a solutions pre-sales role that places significant emphasis on consultative engagements with a wide range of customer stakeholders, Business Owners, Business Analytics, Data Engineering teams, Application Development, End Users and Management teams.
 Successful candidates will be adept at evangelizing the Rackspace Data Services value proposition – across Professional Services and Managed Services; aligning it to each unique set of customer challenges and articulating the business benefits that can be delivered.
 A key aspect of the role is to engage with customers early in their transformation journey to establish Rackspace credentials as a partner that can help assess, plan and execute the required data transformation or modernization.
  You Will:
·       Data Architect is client facing, pre-sales technologist that works with designated accounts and acts as a technical advocate for Rackspace clients.
·       You are responsible for understanding clients’ business requirements as they pertain to Data solutions, qualifying opportunities and creating designs that match the requirements with appropriate products, managed and professional services.
·       Is considered a thought leader and develops IP & collateral for data and analytics.
·       Sells and positions implementation and advisory services primarily in their assigned LOB, but also understands and advises clients on where other strategic and advisory services fit their needs.
·       Client Facing Sales Support – Works with sales account team, interfacing directly with the Rackspace prospects and customers.
·       Builds trusted advisor relationships, understanding client’s business challenges and proposing solutions.
·       Develops High Level Designs and Architectures – Creates and documents architectures that address client business problems which can be used to ensure a smooth transition from presales to delivery.
·       Create Proposals – Develop proposals, SOWs (Statements Of Work), business cases and RFP responses,
·       Sales Planning – Work with management and sales teams to develop account prioritization and support strategies that will ensure a long-term trusted relationship status.
·       Partner Relationship Management – Develop healthy and trusted relationships with key partners in the geography.
·       Intellectual Property Development – Contribute to the development of Rackspace intellectual property and industry recognition (white papers, speaking engagements etc.
·       Administrative Overhead – Respond to email, phone calls, complete timesheets in a timely manner, expense reports and status reports as required Administrative Overhead.
·       Training – Develop and execute a professional plan that will enhance skills.
·       Contribute to sales process improvement, including developing knowledge bases, creating sales tools, and mentoring other Solutions Architects
 Technical Requirements:
 ·       2+ years of AWS Data platform experience and 5+ years of experience as a Data Architect with a proven track record and experience leading engagements from design to implementation of data analytics solutions.
·       Advanced SQL skills, including the ability to write, tune, and interpret SQL queries; tool specific experience in the RDBMS listed above is ideal.
·       Strong Spark, SQL, Data Modeling, Data lakehouse concepts.
·       Design and optimize data models on AWS Cloud using Azure data stores such as Synapse, AWS SQL, ADLS Gen2, Purview, Python, Fabric, etc
·       Proven experience in migrating data warehouses from SQL Server, Oracle, Teradata and Informatica to Azure.
·       AWS Data Certifications
 Other Requirements:
·       Highly motivated self-starter and team player and demonstrated success in prior roles.
·       Track record of success working through technical challenges within enterprise organizations
·       Ability to prioritize deals, training, and initiatives through highly effective time management
·       Excellent problem solving, analytical, presentation, and whiteboarding skills
·       Track record of success dealing with ambiguity (internal and external) and working collaboratively with other departments and organizations to solve challenging problems
·       Strong knowledge of technology and industry trends that affect data analytics decisions for enterprise organizations
  
About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
  More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",USD 115K - 193K *
143,Finance Analytics Engineer,Swiss Re,"Bengaluru, KA, IN",Senior-level / Expert,"Corporate Title: Associate 
Division: CFF-Finance Corporate Solutions (50008354)
Department: CFFP-CorSo Global FP&A & Reporting (50012298)
Recruiter: Kunal Ghera
Hiring Manager: Bikash Ranjan Sahu
Copy the below link to share this job posting with your coworkers:
https://performancemanager.successfactors.eu/sf/jobreq?jobId=127949&company=SwissRe 
  About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. At Swiss Re we combine experience with creative thinking and cutting-edge expertise to create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 13,000 employees across the world. We offer a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?
  About the Role
  This position is part of the newly established Financial Data Analytics team within Corporate Solutions' Global FP&A and Reporting department. You will play an important role of driving high quality analytics & insights by combining your outstanding technical and analytical skills with the insurance knowledge of the broader organization. The team's mandate is to be at the forefront of our technical and analytical capabilities to support Finance and the entire Business Unit with highquality financial insights to help better steer our business by developing and exploiting modern prediction and data management techniques or introducing new ways of visually monitoring results. You will work at the direction of senior members of the team and directly with stakeholders. To ensure tangible impacts, you will build a strong foundation between Underwriting, Risk Management and Re Insurance analytics to link the financials to the insurance knowledge of the broader organization. We are looking for a highly motivated candidate who enjoys developing new ideas and who ensures its relevance and value in a very dynamic data analytics' environment. Furthermore, the role is expected to leverage the latest technological developments such as modern prediction and data management techniques or new ways of visually monitoring results. If you are eager to further develop your problemsolving skills and to work with insurance specialists across various functions, you are the right person to join our highly ambitious team! Are you up for the challenge?
  Your key responsibilities will include:
  Extract data from a variety of systems, structuring these into analytic reports for stakeholders, liaise and partner next to Finance with U Risk and Re Insurance. Build and Maintain High Quality Analytical Solutions to support Data Insights Objective of the Organization. Design and Develop Process Improvement Solutions to get Productivity and Quality in to Existing Processes. Develop forward looking views for generating strategic insights and actionable decisions. Full Stack Development experience in providing Analytical solutions from Ideation / POC to Production Ready solutions. Proactively drive new business cases for the analytics hub to expand its scope. Support the development of Key Finance Analytical Products through transformation and Reporting.
  About You
  Do you find this opportunity interesting? We welcome your application if: You have a university degree with a primary or masters’ degree in a quantitative discipline, e.g. Applied Mathematics, Engineering, Computer Science, Finance
Good Knowledge about Insurance / Re Insurance business (Internal / External Retro Cession). You have 4-6 years of relevant working experience in similar roles. Good command of MS Excel including Pivot tables and VBA, Power Automate. Strong Experience in process improvement design and execution Strong experience working on enterprise data platforms (ideally in Spark environment) and performing tasks such as managing data logics. Sound Python, SQL skills with ability to query and analyze data; understand data complexity, models and structures. Well-versed hands-on experience in SparkSql, PySpark and building automated transformation. Strong Experience in Reporting and Visualization Tools like PowerBI, Tableau. Have very good understanding of DB design Concepts and Data warehousing Concepts.
  To apply for this position, you should have also these skills and knowledge:
  Experience in agile working style and create an energized and engaged work environment. Strong analytical skills and ability to deliver quality output to short deadlines and handle details without losing sight of the bigger picture. Ability to come up with solutions to loosely defined business problems. Strong communication skills, particularly the ability to summarize complex technical issues to nonexpert audiences, both written and verbal. Comfortable challenging the status quo and/or senior management. Strong data skills and analytical acumen. Dynamic personality who enjoys taking accountability and ownership. Self-starter and able to work independently. Fluency in English is mandatory.
  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status
                About Swiss Re Corporate Solutions 
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer. We anticipate and manage risks, from natural catastrophes and climate change to cybercrime.

Swiss Re Corporate Solutions is the commercial insurance arm of the Swiss Re Group. We offer innovative insurance solutions to large and midsized multinational corporations from our approximately 50 locations worldwide. We help clients mitigate their risk exposure, whilst our industry-leading claims service provides them with additional peace of mind.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. Swiss Re Corporate Solutions embraces a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
  Keywords:  
Reference Code: 127949 
   ",USD 128K - 190K *
144,Senior Data Architect,ShyftLabs,"Hyderabad, Telangana",Senior-level / Expert,"Position Overview:

ShyftLabs is searching for a versatile and resourceful Data Architect with 5+ years of experience. ShyftLabs is a growing data product company that was founded in early 2020 and works primarily with Fortune 500 companies. We deliver digital solutions built to help accelerate the growth of businesses in various industries, by focusing on creating value through innovation.

As a Data Architect at ShyftLabs, you will collaborate and partner with business and systems analysts and technical leads to define the technical architectural designs, principles, and models that guide solution decisions within a particular domain or complete ecosystems.

This role focuses on modeling technical data designs, supporting delivery, and formulating strategic data initiatives. Broadly, it will work with every functional area of data engineering, data science teams & multiple Business partners. You blend deep expertise and experience in engineering, technical design, systems, and database management with a passion for coaching and mentoring engineering associates.

Job Responsibilities:
Ownership, design, and maintenance of all aspects of data solutions including modeling, developing, technical documentation, data diagrams, and data dictionaries.
Provide expertise in the development of standards, architectural governance, design patterns, and practices, and evaluate the best applicable solutions for different use cases.
Lead the data strategy and own the vision and roadmap of data products at Petco to enable decision-making and self-service for business and analytics teams.
Determines and develops architectural approaches and solutions, conducts business reviews, documents current systems, and develops recommendations.
Solid experience in emerging and traditional data stacks components such as batch and real-time data ingestion, ETL, ELT, orchestration tools, on-prem and cloud DW, Python, and structured, semi, and unstructured databases.
Collaborate closely with Data Engineering and Product team to execute on the set roadmap of data ingestion, integration, and data transformation.
Expert with industry-standard data practices, data strategies, and data concepts.
Evaluates existing or proposed systems for the business, and devise computer systems and related procedures to solve the business need
Devices or modifies procedures to solve problems considering resource capacity, system limitations, and operation time, and continuously strives to improve data team maturity.
Coordinates third-party relationships with outsourced teams and vendors for applications and troubleshoots problems with department users and administrators
Responsible for quality assurance review of assigned projects and the evaluation and documentation of team procedures.
Work with stakeholders to ensure that data-related business requirements for protecting sensitive data are clearly defined, communicated, well understood, and considered as part of operational prioritization and planning
Ensure the safe storage and transmission of data in line with privacy and compliance laws, data regulations, and internal company policies
This position will be in a fast-paced and entrepreneurial environment where you will be handling multiple concurrent projects while working independently and in teams. An ideal candidate will possess strong problem-solving and conceptual thinking abilities in addition to communication, interpersonal, and leadership skills.
 Basic Qualification:
Bachelor’s or Advanced degree in Information Systems, Information Management, Engineering, or related field
5+ Years of design and implementation experience in technology, in roles such as architect, software engineer, application engineer
3+ years developing Big Data Solutions (architectures, deployments, and operations - including design and estimation)
2+ years of public cloud (GCP, AWS, Azure) design and implementation experience
Expertise in data models, data pipeline concepts, and cloud-based infrastructure disciplines such as Kubernetes, containerization, etc.
Deep working knowledge of data technologies such as Snowflake, Kafka, DBT, Airflow, Kubernetes, etc.
In-depth experience in solutions around data ingestion/pipelines, data migration, data testing & validation, data cleansing, data modeling, master data management (MDM), Governance, and others
 Preferred Qualification:
Excellent leadership and interpersonal skills in areas such as storytelling, facilitation, and negotiation
Candidate demonstrates a breadth of diverse leadership experiences and capabilities with a track record of balancing concerns by finding the correct balance between business outcomes, elegance, cost, technical advancement, future agility, and avoidance of technical debt is achieved

We are proud to offer a competitive salary alongside a strong insurance package. We pride ourselves on the growth of our employees, offering extensive learning and development resources. This role can be remote anywhere in India.",USD 115K - 193K *
145,Power BI developer,Marlabs,"Bengaluru, KA, IN",Senior-level / Expert,"Develops and deploys data governance framework/standards consisting of data policies and processes in the areas of data ingestion, data movement, data quality, master & reference data and data life cycle management
Assists in developing and implementing enterprise tools (Collibra, Immuta etc..) to support Data Governance & Data Management, including Data Catalog, Metadata Management, Data Quality, Master & Reference Data Management
Coordinates with various stakeholders across various organizations to apply established data governance framework (developing data stewardship, data custodian roles, data dictionary, metadata management, and access controls).
Ensures remediation plans are implemented where data fails to meet established data governance framework/standards.
Detail oriented with the ability to analyze data and perform in depth data analysis
Work across multiple business and technology teams, with the ability to perform data discovery, build data glossaries and catalogs, perform data analysis and data profiling.
Understand industry standard development life cycle (SDLC) phases, including the ability to provide guidance on how to document business requirements and impacts on process flows.
  Experience
Experience of 5-8 yrs working on data projects
Worked specifically on 2-3 Data Governance Implementation, working closely with business stakeholders on building data catalogs & business metadata
Work very closely with data engineers on reinforcing DG practices into Data Quality Framework & Data Management techniques
Technology stack is mainly, Collibra, Immuta & Monte Carlo, which is leveraged in the DG area",USD 45K - 84K *
146,Lead-Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Following Tesco's Business Code of Conduct and always act with integrity and due diligence
- Engaging with business & functional partners to understand business priorities; ask relevant questions and scope same into a analytical solution document calling out how application of data science will improve decision making
- In depth understanding of techniques to prepare the analytical data set leveraging multiple complex data set sources
- Building Statistical models and ML algorithms with practitioner level competency
- Writing structured; modularized & codified algorithms using Continuous Improvement principles (development of knowledge assets and reusable modules on GitHub; Wiki; etc) with expert competency
- Building easy visualization layer on top of the algorithms in order to empower end-users to take decisions - this could be on a visualization platform (Tableau / Python) or through a recommendation set through PPTs
- Proactively driving consumption of solutions developed by the team and owning the initiative to identify and address areas of improvement in the larger Tesco business
- Keeping up-to-date with the latest in data science and retail analytics and disseminating the knowledge among colleagues
- Mentoring and leading a small team of Applied Data Scientists to deliver high impact analytics projects
Qualifications
- Applied Math: Applied Statistics; Design of Experiments; Regression; Decision Trees; Forecasting; Optimization algorithms; Clustering; NLP
- Tech: SQL; Hadoop; Spark; Python; Tableau; MS Excel; MS Powerpoint; GitHub
- Business: Basic understanding of Retail domain
- Soft Skill: Analytical Thinking & Problem solving; Storyboarding; Stakeholder engagement; Leading team
Additional Information
Last Date of Application- 14th Nov 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
147,Data Engineer (India),ONE,Bengaluru (Hybrid),Senior-level / Expert,"About ONE
ONE's mission is simple — financial progress. We’re doing this by creating simple solutions to help our customers save, spend, and grow their money — all in one place.
The U.S. consumer today deserves better. Millions of Americans today can’t access credit, build savings or wealth, and are left to manage their financial lives through multiple disconnected apps. Almost a quarter of U.S. adults are unbanked or underbanked and roughly 80% of fintech users rely on multiple accounts to manage their finances.
What makes us unique? We are backed by a preeminent fintech investor (Ribbit) and the world’s largest retailer (Walmart), maintain the speed and independence of a startup, and employ a strong (and growing) collection of world-class talent.
There’s never been a better moment to build a business that helps people achieve financial progress. Come build with us!
The role
As a data engineer, your mandate is to build the data transformation pipelines & reporting infrastructure that serve our members and run our company. This role will impact ONE’s vision by writing, reviewing, and shipping code and collaborating with others across the company. You will work closely across the Engineering, Product, Compliance and Customer Support team(s) working with stakeholders as highly technical, communicative, and emotionally intelligent partners. This role reports to Manager, Data Engineering.
This role is responsible for: 
Building and maintaining ONE's data infrastructure.
Developing and owning ONE's streaming data transformation pipeline.
Managing and supporting reporting and analytics tools.
Collaborating closely with our Data Analysts and Data Scientists.
Tracking and defining metrics around performance.
Additional duties as assigned by your manager.
You bring
 Mid Career (5-10 Years)
Experience in Apache Spark, Scala, Python, SQL.
Experience designing and implementing low latency data pipelines using Spark structured streaming.
Experience optimizing SQL queries and lake / warehouse data structures.
Cost-conscience creative problem solving.
Proficient in AWS cloud services and technologies.
Experience building, shipping — and growing — non-trivial products & services. 
Passion for your craft, people, and our mission. You value quality across code, communication, and culture.
A desire to keep growing your skills, and an ability to learn quickly. We hire for slope, not just y-intercept.
Leveling Philosophy
In order to thoughtfully scale the company and avoid downstream inequities, we’ve adopted a flat titling structure at ONE. Though we may occasionally post a role externally with a prefix such as “Senior” to reflect the external level of the position, we do not use prefixes in titles like that internally unless in a position which manages a team. Internal titles typically include your specific functional responsibility, such as engineering, product management or sales, and often include additional descriptors to ensure clarity of role and placement within our organization (i.e. “Engineer, Platform”, “Sales, Business Development” or “Manager, Talent”). Employees are paid commensurate with their experience and the internal level within ONE.
Inclusion & Belonging
To build technology and products that are used and loved by people and solve real-world problems, we need to build a team with many different perspectives and experiences. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We encourage candidates from all backgrounds to apply. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us at talent@one.app.
For additional questions around our interview process, please check out our Candidate FAQs.",USD 121K - 186K *
148,Senior Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Follow Tesco's Business Code of Conduct and always act with integrity and due diligence
- Engage with market leaders to understand problems to be solved; translate the business problems to analytics problems; taking ownership of specified analytical modules and translate the answers back to decision makers in business terms
- Think beyond the ask and develop solutions that will contribute to existing solutions
- Accountable for high quality and timely completion of specified work deliverables
- Write codes that are well detailed; structured; and compute efficient
- Drive value delivery through efficiency gain by automating repeatable tasks; report creation or dashboard refresh
- Collaborate with colleagues to craft; implement and measure analytical solution
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Understands business needs and in depth understanding of Tesco processes
- Builds on Tesco processes and knowledge by applying CI tools and techniques
- Responsible for completing tasks and transactions within agreed metrics
- Solves problems by analyzing solution alternatives
Qualifications
Logical Reasoning; Adv Excel;
Adv Statistical Concepts
Adv SQL; Hive; Phython;Tableau; R shiny;
Basic Statistical Concepts - Central Measures of data; Linear & Logistics regression
Decision Trees – CHAID; CART; RF; XGBoost

2-4 years Experience in analytics delivery in any one of domains like retail; cpg; telecom or hospitality and for one of the following functional areas - marketing; supply chain; customer; merchandising; operations; finance or digital preferred
Additional Information
Last Date of Application-14th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
149,Principal Consultant - ETL,Model N,Hyderabad India,Senior-level / Expert,"Model N is hiring a Principal Consultant, DMT (Data Management Team) for our Business Services team. The purpose of the role is to successfully support DMT processing for our life science customer base. We are looking for an experienced ETL Engineer to join our team, who is passionate about data structures and data modeling. The ideal candidate should be able to design, develop, automate, and provide technical support, troubleshoot, and resolve issues related to Talend ETL processes. This role requires a strong grasp of many ETL products, data integration concepts, and excellent problem-solving abilities.
Job Responsibilities
SME for Talend ETL team, providing technical guidance and support.
Creates and improves data solutions that enable smooth data delivery and is in charge of gathering, processing, maintaining, and analyzing enormous amounts of data.
Designs, automates, and supports sophisticated data extraction, transformation, and loading applications.
Ensures the accuracy data.
Diagnose and resolve problems related to data extraction, transformation, and loading.
Investigate and troubleshoot ETL job failures, data quality issues, and performance bottlenecks in existing data workflows.
For ETL applications, creates logical and physical data flow models.
Data access, transformation, and mobility needs are translated into functional requirements and mapping designs.
Lead customers and partners, including our complex and larger customers and partners, through the definition and design phases of an implementation process.
Coach and guide ETL team members as industry processes evolve. Act as the ETL team lead.
Address performance-related issues.
Create and update knowledge base articles for common support issues.
Maintain detailed documentation of support issues, solutions provided, and troubleshooting steps.
Implement preventive measures to reduce the recurrence of issues.
Conduct regular training sessions to share insights, best practices, and updates with the support team.
Identify opportunities for process improvement within the Talend support function.
Generate regular reports on support activities, issue resolutions, and performance metrics.
Should be flexible in timings, may require having some hours overlap with US team.
Job Qualification
Bachelor’s degree in computer science, Information Technology, or a related field.
Minimum of 7 years of ETL (Informatica, SSIS, Talend, etc.) development or support experience.
Experience in the pharmaceutical and/or medical device industry
Strong understanding of data modeling, data integration concepts, ETL best practices, and troubleshooting techniques.
SQL competence (query performance tuning, index management, etc.) and a grasp of database structure are required.
Knowledge of different SQL/NoSQL data storage techniques and Big Data technologies
Knowledge of the software development life cycle and process improvement methodologies, including iterative development practices.
Excellent problem-solving and analytical skills.
Strong communication and collaboration skills.
Ability to work in a fast-paced environment and prioritize support tasks effectively.
At Model N, we believe our collective success stems from the uniqueness of every individual's diverse backgrounds, experiences, and expertise; we call this the N Factor. So don’t allow uncertainty to keep you from applying to join our team. If you don’t meet the exact criteria but can demonstrate your skillset is the best for the job, we’d love to talk with you. We’re curious to know, what’s your N Factor?    
  About Model N  
 Model N enables life sciences and high tech companies to drive growth and market share, minimizing revenue leakage throughout the revenue lifecycle. With deep industry expertise and solutions purpose-built for these industries, Model N delivers comprehensive visibility, insight and control over the complexities of commercial operations and compliance. Our integrated cloud solution is proven to automate pricing, incentive and contract decisions to scale business profitably and grow revenue. Model N is trusted across more than 120 countries by the world’s leading pharmaceutical, medical technology, semiconductor, and high tech companies, including Johnson & Johnson, AstraZeneca, Stryker, Seagate Technology, Broadcom and Microchip Technology. For more information, visit www.modeln.com. 

We’re constantly growing and may have something for you later on if this is not the right opportunity for you. Check out our career site to learn more about Model N or view other jobs: https://www.modeln.com/company/careers/ ",USD 45K - 84K *
150,Senior Engineer - DataOps,Freshworks,"Bengaluru, India",Senior-level / Expert,"Company Description
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end-user. More than 50,000 companies -- from startups to public companies -- around the world use Freshworks software-as-a-service to enable a better customer experience (CRM) and employee experience (ITSM, HRSM).Headquartered in San Mateo, California, Freshworks has a dedicated team operating from 13 global locations to serve customers, including American Express, Sony, Vice Media, TaylorMade, Sotheby’s, Stitchfix, OfficeMax, Multichoice, Delivery Hero, ITV, and Klarna.Freshworks transforms the way world-class organizations collaborate with customers and co-workers. The suite includes Freshdesk (omnichannel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshteam (HR management system).
Job Description
We are seeking a highly skilled and motivated Senior Data Ops Engineer to join our dynamic team. In this role, you will be responsible for providing Level 2 (L2) support as a Data Engineer, ensuring the availability, reliability, and performance of our data infrastructure. The ideal candidate should possess a strong background in data operations, demonstrate proficiency in troubleshooting and problem-solving, and have the ability to work collaboratively with cross-functional teams.
Job Responsibilities: 
 Provide expert-level support for data-related incidents and issues, ensuring timely resolution and minimal impact on business operations.
Collaborate with support and other teams to investigate, troubleshoot, and resolve complex data-related problems.
Implement and maintain monitoring solutions to proactively identify and address potential issues with data pipelines, databases, and other data infrastructure components.
Continuously optimize data processes for performance, scalability, and reliability.
Design, implement, and maintain robust data pipelines, ensuring efficient data processing and data quality.
Work on data integration projects, collaborating with data scientists, analysts, and other stakeholders to meet business requirements.
Participate in the on-call rotation for handling critical incidents and provide timely resolution or escalation as necessary.
Conduct post-incident reviews to identify root causes and implement preventive measures.
Should be willing to support month/weekends and work in flexible working hours when required 
Qualifications
3+ years of experience and good knowledge of Scala or Python.
Good knowledge of Spark and related big data ecosystems.
Good in SQL.
Good understanding of AWS or any cloud platform
 Data Structures and Algorithms and problem-solving skills.
Willingness to take up new challenges to solve problems.
Willingness to learn new technologies and implement as required based on business needs.
Additional Information
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 45K - 84K *
151,Sr. Data Scientist,Nielsen,"Bengaluru, India",Senior-level / Expert,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

Aim of the position

The Big Data and Panel Integration team within the Data Science organization focuses on improving and enhancing Nielsen’s highly successful audience measurement products out in the marketplace for advertising and content measurement. As part of this exciting team, this position will focus on developing new methodologies to measure audiences across platforms (including on “connected” or “over the top” devices, smart tv’s, or set top boxes) and on evaluating and integrating new data assets and partners into Nielsen’s existing methodologies in order to enhance or expand the data delivered to clients. 

The Senior Data Scientist role provides an opportunity to contribute to methodological innovation in the exciting and fast changing world of media measurement. This position will develop new methodologies to measure audiences across platforms and integrate new big data data assets into Nielsen’s existing methodologies. This is an ideal position to grow as a researcher, contribute to innovative products, and deploy cutting edge methodologies across platforms in audience measurement methodology.

In this role, you will work closely with other members of the team to optimize the current codebase, create simulation environments and pipelines, and have the opportunity to conduct research that will enhance the utility of our data. You will also write new coding packages to support the refinement processes of behavioral media tuning data (e.g. meter crediting rules, big data editing rules, big data refinement models) by producing production ready code (scalable, reusable/modular). In addition, you will have the opportunity to grow your data science skills (coding, statistics) through all aspects of the data science workflow and data product lifecycle. Responsibilities would range from methodology development, analysis, lightweight automation to designing and building robust/scalable code packages.
Responsibilities
Own reproducible data science projects end-to-end
Deploy and maintain data pipelines and models in a production environment
Work with cross-functional teams to productionize, validate, and optimize methodologies
Conduct research and analytics to ensure methodologies are fit for purpose and working as intended; troubleshoot, diagnose, and resolve when they are not.
Provide technical mentorshipCommunicate research findings to varying audiences
Develop, implement and maintain good programming standards and practices across our data science and analytics codebases.
Champion and govern best practices for data use and software development.
Use git and cloud development tools extensively to iterate and improve data science workstreams.
Skills
Bachelor’s or Master’s (preferred) degree in a quantitative research field, such as computer science, data science, statistics, mathematics, biological/physical sciences, etc.
3-5 years code development/research experience in a business setting
Strong proficiency with Java, Python, Spark, SQL, Unix, git, and AWS (S3 and EC2)Excellent verbal and written communication skills
Excellent software engineering fundamentalsExcellent debugging skills
Excellent machine learning fundamentals
Outstanding statistical and analytical skills
Collaborative code development experience, including version control, unit/integration testing, code review and sharing
Curiosity and skepticism",USD 136K - 205K *
152,Data Scientist - AI/ML,Philips,Bengaluru – New PIC Campus,Mid-level / Intermediate,"Job Title
Data Scientist - AI/ML
Job Description
Job title: Data Scientist - AI/ML
Overall responsibilities
Provide support with guidance to solve complex problems in medical image processing and deliver PoC with TRL level ready for NPI program.
Support collaboration with clinical scientists, AD leader and universities to drive advanced development projects on medical image analytics from R&D perspective.
Support NPI development and address time-pressing complex LCM challenges with image processing / IQ using expertise.
Higher degree of learning attitude to absorb newer knowledge on medical image pre- and / or post-processing.
Specific responsibilities
Hands-on work in some of the following tools, packages, technical areas and modeling techniques:
Keras, Tensorflow, Pytorch, Scikit-learn, Scikit-image, OpenCV, pydicom
Matlab, python, R, Java/C/C++
Convolution Neural Networks, other statistical modeling & classification approaches (regression, SVM, PCA)
Opensource medical image visualization and segmentation tools like ITK, VTK
Medical image post-processing techniques such as noise reduction, contrast enhancement, bone suppression, stitching, ranging. Knowledge of overall IQ (image quality) analysis of diagnostic X-ray images is a plus.
Medical image pre-processing (gain, offset correction, EMI/EMC correction)
AI/ML modeling / computer vision using video from 3


About Philips
We are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help the lives of others.
• Learn more about our business.
• Discover our rich and exciting history.
• Learn more about our purpose.

If you’re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our commitment to diversity and inclusion here.",USD 86K - 160K *
153,Data Engineer,Verisk,"Gurugram, India",Mid-level / Intermediate,"Company Description
Wood Mackenzie are the global research, analytics, and consultancy business powering the natural resources industry. For 50 years, we have been providing the quality data, analytics, and insights our customers rely on to inspire their decision making.
Our dedicated oil, gas & LNG, power & renewables, chemicals, metals & mining sector teams are located around the world and deliver a variety of projects based on our assessment and valuation of thousands of individual assets, companies, and economic indicators such as market supply, demand, and price trends.
We have over 1,900 employees in 30 locations, serving customers in nearly 80 countries. Together, we inspire and innovate the markets we serve – providing invaluable intelligence to help our customers overcome the toughest challenges, and make strategic decisions that will, ultimately, accelerate the world’s transition to a more sustainable future.
WoodMac.com
Wood Mackenzie brand video
Wood Mackenzie is the global leader in data, analysis and consulting across the energy, chemicals, metals, mining, power and renewables sectors.
 Hear what our team has to say about working with us:
https://www.woodmac.com/careers/our-people/
Job Description
An exciting opportunity to be part of a cutting-edge enterprise data platform rollout at a global energy research and consulting company. You will be working alongside Data Engineers, Data Analysts and Business Professionals to design, build and deliver an integrated and holistic reporting and analytics solution.
Main Responsibilities
Design, develop and maintain efficient and accurate ETL pipelines.
Requirements Analysis - evaluate and analyse business requirements gathered to gain a clear understanding of the specification and reason for the request.
Analyse business rules and processes defining relationships between separate data sources as required.
Combine data from multiple sources into efficient Power BI datasets for use by departmental Data Analysts.
Develop and maintain knowledge of our Data Lake and core applications, and the functionality they provide, to analyse and meet Business Intelligence requirements.
Report Developer Support.
 #LI-MS1
Qualifications
3-5 years’ experience working with AWS serverless architecture, specifically Glue, Athena and Lambda.
Advanced understanding of SQL, Python, Spark and data munging.
Understanding of Data Warehouse and modern Lake House Architecture. Including Kimball data warehouse concepts.
Experience working on the design, development, and optimisation of Power BI Datasets.
Relevant formal qualification in Business / Computer Science / Information Systems or equivalent relevant work experience
Advanced understanding of SQL, Python, Spark and data munging.
Advanced Data modelling, and ETL concepts.
Strong technical skills and attention to detail.
Strong communication, consultation, and interpersonal skills to support business requirements.
Experience of Data Analytic Expressions (DAX).
Experience using third party PBI tools such as DAX Studio, Tabular Editor, etc.
Exposure to Agile Development practices would be an advantage.     
Expectations
We are a hybrid working company and the successful applicant will be expected to be physically present in the office at least 2 days per week to foster and contribute to a collaborative environment, but this may be subject to change in the future
Additional Information
 Wood Mackenzie is a place where we are committed to supporting our people to grow and thrive. We value different perspectives and aspire to create an inclusive environment which encourages diversity and fosters a sense of belonging. 
Wood Mackenzie values everyone’s contribution and helps them reach their full potential while sustaining an organisational culture of health and well-being.
Our core values are:
Inclusive
Trusting
Customer Committed
Future Focused, and
Curious
We understand the importance of bringing your whole self to work and to achieving balance between work, family and other life commitments.  We are open to considering flexible working arrangements to enable the greatest spectrum of talent to contribute to Wood Mackenzie's success.
Hear what our team has to say about working with us: https://www.woodmac.com/careers/our-people/",USD 110K - 180K *
154,"Junior Analyst, Digital/Data Science – Customer Service & Aftermarket",RTX,"North Gate Business Park Sy.No 2/1, and Sy.No 2/2, KIAL Road, Venkatala Village, Chowdeshwari Layout, Yelahanka, Bengaluru, Karnataka 560064",Entry-level / Junior,"Date Posted:
2023-09-23
Country:
India
Location:
North Gate Business Park Sy.No 2/1, and Sy.No 2/2, KIAL Road, Venkatala Village, Chowdeshwari Layout, Yelahanka, Bangalore, Karnataka  560064
Position Role Type:
Unspecified
Who we are
At Pratt & Whitney, we believe that powered flight has transformed and will continue to transform the world. That’s why we work with an explorer’s heart and perfectionist’s grit to design, build, and service the world’s most advanced aircraft engines. We do this across a diverse portfolio including Commercial Engines, Military Engines, Business Aviation, General Aviation, Regional Aviation, and Helicopter Aviation and as a way of turning possibilities into realities for our customers. This is how we at Pratt & Whitney approach our work, and this is why we are inspired to go beyond.
What Our Expectations Are
In Customer Programs, we believe that everything starts with our people. We foster a learning organization and inclusive culture by providing opportunities for development, growth and empowerment. We establish our products and services as the customer preferred choice by delivering world-class product & service dependability and targeted customer outreach. We enable customer relationships through intense market focus and we develop customized solutions. We augment all of this by using technology, striving for proactivity, committing collectively, and always acting with integrity and respect. The P&WC engine programs are powering 5 engine markets: regional turboprop aircrafts, general aviation aircrafts, business jets aircrafts, Helicopters and auxiliary power systems on larger aircrafts, which help connecting people and economies around the world.
Functional Description
As a Junior Analyst for data science, you will be responsible for working with the data science and digital support team at Pratt & Whitney Customer Service India hub. You will participate in identifying and defining the opportunities which drives and brings added value to the customer service organization. In scenarios, when needed you will be part of integrated product teams (IPT) discussions to understand and build solutions addressing the in-service quality and cost drivers for General aviation, Business aviation, Regionals and Helicopter programs.
Roles & Responsibilities:
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Able to ingest, clean, process and analyze multiple data sources data-at-rest and data-in-motion
Assess the effectiveness and accuracy of data set and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize delivery assurance, inventory reduction and other business outcomes.
Develop testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Interpret and effectively communicate data insights using data visualization
Coordinate with different functional teams to implement models and monitor outcomes.
Qualification / Technnical Experience:
Bachelors / Masters degree / MBA with experience in designing and developing solutions using Big data.
0-2 years of data science experience and good analytical skills.
Coding knowledge and experience with several languages: Python, C, C++, Java, JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, Hive SQL, etc.
Experience in one of the following libraries: TensorFlow, PySpark.
Experience creating and using advanced machine learning algorithms and statistics like: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience with any of the distributed data/computing tools: SAS ViYa, Hadoop, Hive, Spark, Jupyter Notebook, Git etc.
Experience visualizing/presenting data for stakeholders using: PowerBI
Good understanding of aerospace/aeronautics environments is a plus
Fluent in English with excellent written and verbal communication skills
Working experience of SAP
Experience user of the Microsoft Office (Word, Excel, PowerPoint)
Experience of working under dynamic and uncertain business conditions
Other Skills:
Analytical thinking
Adaptability
Business judgment
Focus on results
Teamwork
Work Location:
Bangalore, India
Employment Type:
Full-time
This position requires flexibility to support outside the regular office hours as per the need basis
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms",USD 110K - 185K *
155,Data Scientist,Nielsen,"Bengaluru, India",Mid-level / Intermediate,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

Aim of the position

Audience is everything! Nielsen offers the world’s most complete measurement of media-viewing behavior. Our data scientists leverage the best data assets and modeling methods to build consistent and comparable metrics of the media landscape in multiple countries. We help the world’s biggest brands make better and faster media and marketing decisions. As a Data Scientist you will be responsible for high-quality design, execution and delivery of global analytics solutions, performance dashboards, and analytical studies. Excited? Come join us!This position will support the Data Science team by applying data science methodologies to improve Nielsen's audience measurement capabilities and ability to deliver client impact. The role focuses on the execution of analytical projects, development of predictive models, and extraction of insights from various data sources, fostering growth and innovation within the team.
Responsibilities
Own reproducible data science projects end-to-end
Deploy and maintain data pipelines and models in a production environment
Work with global cross-functional teams to productionize, validate, and optimize methodologies
Conduct research and analytics to ensure methodologies are fit for purpose and working as intended; troubleshoot, diagnose, and resolve when they are not.
Provide technical mentorship
Communicate research findings to varying audiences
Develop, implement and maintain good programming standards and practices across our data science and analytics codebases.
Champion and govern best practices for data use and software development.
Use git and cloud development tools extensively to iterate and improve data science workstreams.
Skills
Bachelor’s or Master’s (preferred) degree in a quantitative research field, such as computer science, data science, statistics, mathematics, biological/physical sciences, etc.
1-2 years code development/research experience in a business setting
Strong proficiency with Python, Spark, SQL, Unix, git, and AWS (S3 and EC2)
Excellent verbal and written communication skills
Excellent software engineering fundamentals
Excellent debugging skills
Excellent machine learning fundamentalsOutstanding statistical and analytical skills
Collaborative code development experience, including version , unit/integration testing, code review and sharingCuriosity and skepticism",USD 86K - 160K *
156,Senior Data Engineer,TechVedika,"Hyderabad, India",Senior-level / Expert,"Company Description
We are an Artificial Intelligence (AI) focused product engineering company, providing our customers in healthcare, retail & e-commerce, manufacturing and hospitality sectors with cutting edge products & solutions, harnessing Big Data Analytics, Vision Analytics, and IoT.
Ever since our inception in March 2010, Tech Vedika has been
Great Place To Work Certified™(May 2023-May 2024) Organization 
Top 50 I Mid-Size India’s Best Workplaces for Women 2022 !
Top 10 Most Disruptive Face & Image Recognition Solution Providers’2020 – Analytics Insights
Top 10 Healthcare Analytics Solution Providers’ 2019- Healthcare Outlook Magazine
Top 20 most amazing AWS Service Providers – CIO Review India 2018
We strive for simple, elegant tech solutions to perform complex tasks. As a scalable technology partner, we enable organisations to improve operational efficiency and unleash new business potential
 Job Description
Having 6+ years of Experience as Data Engineer 
Minimum 4 years to 6 Years of experience in Azure Technologies
2+ years of experience in building data pipelines in Apache spark preferably using pySpark.Programming experience in Python – Pandas.
Experience in designing and building restful data sharing APIs using GraphQL
Must have Strong knowledge of SQL & ETL tools like SSIS, Talend, Azure Data Factory etc.Report building experience SSRS,  Power BI or any other market leading reporting tool.
Microsoft Analysis Services (Tabular model), and knowledge of DAX
Good understanding of Git and Devops.
Ability to quickly learn new technologies as needed and create POCs.
Strong Debugging/Troubleshooting skills.Good communication skills


Hands-on experience and Proficiency in programming languages such as Python, Spark SQL, SQL
Hands-on experience in implementing data ingestion patterns using technologies like Azure Event Hub, Azure Function App or Azure Data Factory
Experience of working with different File formats 
Experience in Design and develop scalable data solutions using Azure data services
Expertise in data engineering concepts and technologies, including data ingestion, ETL/ELT processes, and data integration techniques
Expertise in writing SQL procedures and tuning complex SQL queries
Experience in data modeling is an advantage
Should have knowledge in Optimization techniques like cost and performance
 Other Must Haves
Strong problem-solving and analytical skills, with the ability to troubleshoot complex data issues.
Excellent communication and collaboration skills to work effectively with cross-functional teams Self-Motivator 
Stay up-to-date with the latest developments in Azure, Spark, Python, Scala, and related technologies and apply them to solve business problems
 Qualifications
Strong problem-solving and analytical skills, with the ability to troubleshoot complex data issues.
Excellent communication and collaboration skills to work effectively with cross-functional teams Self-Motivator 
Stay up-to-date with the latest developments in Azure, Spark, Python, Scala, and related technologies and apply them to solve business problems
Additional Information
At Tech Vedika, we are looking for talented individuals who want to work with driven people. Attain success while working on interesting projects with a culturally diverse group of individuals.

Perks & Benefits of joining TechVedika:
Growth driven - an opportunity to learn new skills, and certifications sponsored by the company
Group Insurance
Health Insurance (Including spouse and children)
Accidental Life Insurance
Group Life Insurance
Parental Health Insurance (Optional)
Meal Vouchers (Optional)
Learning Aids
Work on projects that have a huge impact - work with clients all over the world.
Latest tools and technology - always driven by the latest, most efficient ways of working
Process-driven, quality-oriented work
If you want an exciting and dynamic career with unlimited growth potential, then Tech Vedika is the place for you!",USD 121K - 186K *
157,Senior Data Scientist,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Job Description
Atleast 5+ years of experience on Data Science
Good knowledge of advanced statistical methods. Mine and analyze data, applying statistical methods as necessary, pertaining to customers’ discovery, and viewing experiences to identify critical product insights.
Experience in creating statistical models and/or optimization frameworks for improving processes/products/profits
Proactively develop new metrics and studies to quantify the value of different aspects of product.
Translate analytic insights into concrete, actionable recommendations for business or product improvement. 
Partner closely with product and engineering leaders throughout the lifecycle of project. Ensure that necessary data is captured; analytic needs are well-defined up front and coordinate the analytic needs.
Drive efforts to enable product and engineering leaders to share your knowledge and insights through clear and concise communication, education, and data visualization.
Should have independently handled a project technically and provided directions to the other Team Members. 
Experience in turning ideas into actionable designs. 
Able to persuade stakeholders and champion effective techniques through development. 
Ongoing technical authority role with our larger customers.
Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data, to folks across various levels of the company.
Able to lead the project independently.
Technical directions to junior in team, like to sort the respective task for responsible team members 
Technical Skills:
Expertise with any of the below skills:
Python, Tensorflow, Keras, Pytorch
NLP, WordNet, NLTK, OpenCV
Tech savvy and willing to work with open-Source Tools
Applying statistical and machine learning techniques, such as, mean-variance, k-means, nearest-neighbor, support vector, Bayesian time-series and network analysis to identify outliers, classify events or actors, and correlate anomalous sequences of events.
Proven track record and experience with statistical modeling/data mining algorithms such as
Multivariate Regression, Logistic Regression, clustering algorithms, Support Vector Machines, Decision Trees etc
Machine learning, deep learning, graph mining.
DOE, Forecasting, Segmentation, Uncertainty Analysis etc.
Data Mining i.e. Text Mining, Classification Methods – SVM, NN, etc
Vector Space model for Unstructured Texto Sentiment Analysis, Association Mining, Semantic Analysis
Should know some programming language and willing to learn more.
Qualifications
B.E/B.Tech
Additional Information
6 - 10 years",USD 136K - 205K *
158,Principal Data Engineer - India,JumpCloud,"Bengaluru, India - Remote",Senior-level / Expert,"All roles at JumpCloud are Remote unless otherwise specified in the Job Description.

About JumpCloud
JumpCloud® helps IT teams and Managed Service Providers (MSPs) Make Work Happen® by centralizing management of user identities and devices, enabling small and medium-sized enterprises to adopt Zero Trust security models. JumpCloud has been used by more than 200,000 organizations, including GoFundMe, Grab, ClassPass, Beyond Finance, and Foursquare. JumpCloud has raised over $400M from world-class investors including Sapphire Ventures, General Atlantic, Sands Capital, Atlassian, and CrowdStrike. Our teams are growing fast, too, and we're looking for talent across engineering, sales, customer success, marketing, product management, and more. Join our team of dedicated, passionate, and creative people who are eager to change the IT industry forever.

About the Role:

We’re looking for a Principal level Data Engineer in JumpCloud’s Business Data Engineering team to provide technical leadership and strategic direction that supports JumpCloud’s growth strategy. A successful data engineer will exhibit an entrepreneurial spirit and enjoy tackling complex data engineering problems, as well as shaping the future infrastructure of JumpCloud’s data engineering, performance reporting and data governance. Come be a part of an exciting new team where you will be able to work on challenging projects, rich data sets, and continue to develop valuable skills. This role involves frequent engagement with analytics partners and data/platform engineering to mature our data model and pipelines.
What we’re looking for:
A keen sense for identifying business drivers, and ability to propose a strong vision for implementing data solutions
Extensive hands-on experience with building scalable data solutions with complex fast moving data sets
Expert level data architecture and data modeling skills
Extensive experience with batch and streaming data pipelines and ELT/ETL processes
Extensive Experience with Cloud Data Warehouses/Data Lakehouses (preferably Snowflake)
Experience in building from the ground up a modern next generation data lakehouse platform.
Strong experience with AWS data technologies and methodologies
Proven track record of  leading multiple large sized projects simultaneously
Ability to communicate effectively with other engineers, and both technical and non-technical data stakeholders 
Proven ability to quickly integrate new technologies and industry best practices into personal and team skill sets, and to apply these techniques efficiently
Expert level SQL skills
Strong proficiency with the Python programming tools and ecosystem, including Software Engineering techniques
What you will be doing:
As part of the Business Data Enablement team, and as part of the Data Engineering team as a whole here at JumpCloud, you will play a pivotal role in the design and development of our critical data infrastructure and systems for multiple areas of the business, including Business Analysis, Product Development, Engineering, ML Operations, Finance, Sales and Executive Strategy
Develop and implement a comprehensive data engineering vision and cloud data strategy, aligning it with JumpCloud’s business objectives while ensuring data quality, scalability, reliability and security.
You will work with other senior level engineers with the goal to achieve top level proficiency in core data engineering skills and business functions
On a day-to-day basis, as a Principal Data Engineer, you may be asked to:
Develop our long term vision for Data Warehousing, Data Lakehouse, and Data Pipelines
Evaluate and recommend appropriate cloud technologies and services to support our data architecture, and take a hands-on approach to implementing these technologies
Interface and collaborate with stakeholders to define needs and develop strategies for providing data
Plan, build, and maintain data pipelines from internal and external data sources
Implement data observability and monitoring in the pipeline and in the warehouse
Work with appropriate teams to ensure Data Security and Data Compliance
Mentor team engineers, and provide education for our engineering and other stakeholders
Promote Cloud Infrastructure Optimization, collaborate with infrastructure teams to optimize the cloud environment for data storage, processing, and analytics.
Provide guidance on the development of our data standards and data governance
Guide Data Analysts to ensure clean delivery of data
Collaborate with Product and Application architects to develop holistic data solutions
Preferred Qualifications:
Python3 Software Development,  following strong software engineering principles
Expert level SQL for Data Transformation and Analysis, with optimization and tuning in mind
Snowflake Data Warehouses/Data Lakehouses (Or Equivalent)
Experience integrating data from unstructured and semi structured data sources
PostgreSQL, mySQL and MongoDB experience
Event Buses, such as Apache Kafka, and it’s associated technologies and tooling
Experience building highly observable data systems
Experience with Cloud Data Storage techniques
Proficiency with integrating data visualization and reporting tools, such as Tableau
Familiarity with standard data storage formats, such as JSON/Avro/Protobuf/Parquet/Iceberg
Can work effectively both independently and as part of the Data Engineering team as a whole
Experience with Data Governance, including Data Contracts and Schema Management
Experience with techniques for handling regulatory compliance issues across multiple countries
Experience with Data Security standards including RBAC and sensitive data handling
#LI-JW1

Where you’ll be working/Location:
JumpCloud is committed to being Remote First, meaning that you are able to work remotely within the country noted in the Job Description.

This role is remote in the country of India. You must be located in and authorized to work in India to be considered for this role.

Please note: There is an expectation that our engineers participate in on-call shifts. You will be expected commit to being ready and able to respond during your assigned shift, so that alerts don't go unaddressed.

Why JumpCloud?  
If you thrive working in a fast, SaaS-based environment and you are passionate about solving challenging technical problems, we look forward to hearing from you! JumpCloud is an incredible place to share and grow your expertise! You’ll work with amazing talent across each department who are passionate about our mission. We’re out of the box thinkers, so your unique ideas and approaches for conceiving a product and/or feature will be welcome. You’ll have a voice in the organization as you work with a seasoned executive team, a supportive board and in a proven market that our customers are excited about.  
 One of JumpCloud's three core values is to “Build Connections.” To us that means creating "" human connection with each other regardless of our backgrounds, orientations, geographies, religions, languages, gender, race, etc. We care deeply about the people that we work with and want to see everyone succeed."" - Rajat Bhargava, CEO
 Please submit your résumé and brief explanation about yourself and why you would be a good fit for JumpCloud.  Please note JumpCloud is not accepting third party resumes at this time.   
 JumpCloud is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. 
 #LI-Remote #BI-Remote",USD 121K - 186K *
159,Data Engineer,Cargill,"Bengaluru, Karnataka, India, 560087",Mid-level / Intermediate,"Job Purpose and Impact
The Data Engineer II will treat data as an asset to design, build and execute high performance and data centric solutions by using the comprehensive big data capabilities for the company's data platform environment. In this role, you will build and optimize data products to bring data and analytics products and solutions to businesses.
Key Accountabilities
Collaborate with businesses and other stakeholders to participate in product or solution designs.
Develop robust, scalable and sustainable data products or solutions utilizing cloud based technologies.
Provide moderately complex technical support through all phases of product or solution life cycle.
Perform data analysis, handle data modeling and configure and develop data pipelines to move and optimize data assets.
Build moderately complex prototypes to test new concepts and provide ideas on reusable frameworks, components and data products or solutions and help promote adoption of new technologies.
Independently solve moderately complex issues with minimal supervision, while escalating more complex issues to appropriate staff.
Other duties as assigned
Qualifications
Minimum Qualifications
Bachelor's degree in a related field or equivalent experience
Minimum of two years of related work experience
Other minimum qualifications may apply",USD 90K - 151K *
160,Data Engineer,Gainwell Technologies,"Bengaluru, KA, IN, 560100",Mid-level / Intermediate,"Summary
  We’re looking for a high-performing and self-motivated Data Engineer with strong Healthcare software solution expertize to join our product development team and drive critical initiatives at Gainwell technologies. This role requires close collaboration with engineering, infrastructure and product teams, and involves ongoing interaction with a variety of end-users and internal stakeholders. 
  Your role in our mission
Essential Job Functions
Participates in client/project meeting(s) for needs assessment and design review. Analyzes the needs and requirements of users of existing and proposed database systems and develops technical, structural and organizational specifications to include access methods, access time, job control language, statistical methodologies, device allocation, validation checks, protection and security.
Designs, develops, implements and maintains moderately complex database for internal and external users/clients.
Creates, documents and implements standards and/or modeling to monitor and enhance the capacity and performance of the database. Programs and writes codes as necessary. Develops data import and export routines to automate data loading. Builds windows, screens and reports.
Performs analyses and reviews complex applications being released into production. Develops test application code in client server environments to ensure that software conforms to build management practices.
Develops back-up and recovery procedures and data archive/purge procedures. Creates supporting technical documentation.
Remains abreast of and analyzes new and emerging technologies and tools for applicability to field. Prepares reports and/or recommendations of new and/or changing processes/products.
Provides leadership and work guidance to less experienced personnel.
Basic Qualifications
Bachelor's degree or equivalent combination of education and experience
Bachelor's degree in engineering, computer science, business administration, software engineering or related field preferred
Six or more years of database engineering, design, development experience
Experience working with relational data modeling
Experience working with data warehousing
Experience working with relational databases such as SQL, PL/SQL, Oracle, etc.
Experience working with database development methodologies, design and implementation
Other Qualifications
Good analytical and problem solving skills
Good communication skills
Good personal computer and business solutions software skills
Good, demonstrated skills in using a Windows development language, programming or scripting such as VBScript, COM, COM+, XML, Java, Perl, etc.
Good interpersonal and human relations skills to interact with clients and less experienced personnel
Ability to comprehend and integrate business unit/client needs into appropriate database system
  #LI-DNP",USD 110K - 180K *
161,"Lead Data Scientist (CV, DL, MLOps, LLM)",HERE Technologies,"Navi Mumbai, India",Senior-level / Expert,"What's the role?
What's the role? 
HERE is searching for a Lead Data Scientist (AI/ML) for our Foundation Engineering team. Within Foundation Engineering you would be part of the Technology Innovation Lab, a Lead Data Scientist (AI/ML):
You will develop a Tech driven innovation strategy for TIL based on the principles of design thinking.
Identify and Define relevant channels of engagement across HERE for TIL to expand the impact footprint of the business vertical
Define IP monetization strategy that will enable HERE to earn revenue /enter new market
Define startup/university engagement framework for successful collaboration with these bodies, in line with HERE’s business strategy.
Identify the domains in technology where TIL and HERE should engage and defining a strategy for realization of same through development of disruptive prototypes in line with HERE business strategy
Enabling invention of new frameworks /solutions in the domain of AIML, Blockchain, Location intelligence, distributed computing,quantum computing, tinyML, etc
Improving the innovation index of HERE, by getting research papers published in NeurIPS, IEEE, and awarded recognition in international forums like CES, Stevie ,etc
Enabling y-O-y increase in number of patents being filed by the team
Work with the Manager to Identify and Define lead KPIs related to effective assessment of performance at individual level and impact assessment of innovation implementation at business unit level
Support team to design experiments and stay up to date with industry inventions in AIML(esp Computer Vision), blockchain, quantum computing, Location Intelligence , distributed computing LiDAR and Drone processing, 3D modelling , AR/VR
Identify relevant research papers in above mentioned tech domains and enable team to design solutions for the same
Who are you?
Bachelor’s Degree in Engineering Or Master’s degree Or Phd program n Data Science, Machine Learning, Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Physics, or related fields. 
Understanding of statistical analysis of data and mathematical modeling
Knowledge of Clustering, Regression, Decision Trees, Forecasting, RandomForest, XGBoost, SVM, Deep Neural Networks (CNN, GRU, LSTM, Activation and Pooling layers), GAN, Encoders, Transformers, BERT, Graph Neural Network , diffusion models
Experience in Object Detection, Localization, Segmentation using Computer Vision and Deep Learning
Ability to handle large datasets and images of high resolution (4K) using Scala, Hadoop, Pyspark
AND/OR
Candidates with MSc/MS in Mathematics/Computer Science, Machine learning and AI or related quantitative needs 10yrs of experience. Candidates with PhD in related fields may have 5 yrs of experience
The candidate should possess a certified degree in the field of quantum physics and other related fields.
Should have adequate knowledge about machine learning and artificial intelligence.
Prior experience through internships and volunteering with professionals will also be needed to apply for the quantum engineer profile.
Should possess in-depth knowledge about the emerging and simulating fields and approach challenges with unique perspectives.
The candidates should also possess a basic knowledge of the different programming language. 
What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues. 
Who are you?
HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.
Who are we?
HERE Technologies is a location data and technology platform company. We empower our customers to achieve better outcomes – from helping a city manage its infrastructure or a business optimize its assets to guiding drivers to their destination safely.
  At HERE we take it upon ourselves to be the change we wish to see. We create solutions that fuel innovation, provide opportunity and foster inclusion to improve people’s lives. If you are inspired by an open world and driven to create positive change, join us. Learn more about us on our YouTube Channel.",USD 136K - 205K *
162,Customer Data Operation-II,Innovaccer,"Noida, Uttar Pradesh, India",Mid-level / Intermediate,"Your Role
We are looking for a Customer Data Operation-II to help our customers explore their healthcare data, understand how to improve the health of the population and bring down the cost of healthcare.
A Day in the Life
Create world class customer facing documentation which would delight and excite customers
Remove ambiguity in understanding things by documenting things and hence making the teams more efficient and effective
Convert tacit knowledge to implicit knowledge
What You Need
Experience in SQL and ETL / Python / BI support
Analytics Tools (Sisense, Power BI or Tableau) – (Good to have)
Support Processes (SLAs, OLAs, Product or application support)
Collaborating with Product Managers, SMEs &amp; BAs to create clear &amp; concise written material.
Maintaining appropriate versioning of the documents to be synced with the product version.
An ambitious person who can work in a flexible startup environment with only one thing in mind - getting things done.
Excellent communication skill - Written and verbal.
What We Offer
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications.
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic.
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists.
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered.  
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative.
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them. 
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments.
  Full-Time",USD 30K - 56K *
163,Machine Learning Engineer,Wayfair Inc.,"Bengaluru, IND",Senior-level / Expert,"Machine Learning Engineer
About Us:
Wayfair, one of the world's largest online destinations for the home, is looking for a talented and forward-thinking Machine Learning & Artificial Intelligence Engineer to join our innovative technology team. At Wayfair, we are committed to transforming the way people shop for their homes, and our technology plays a pivotal role in achieving that vision.
Position Overview:
As a Machine Learning & Artificial Intelligence Engineer at Wayfair, you will have the opportunity to work on cutting-edge projects that enhance the customer experience and drive business growth. You will collaborate with a team of talented engineers, data scientists, and business experts to develop and implement machine learning and artificial intelligence solutions that shape the future of e-commerce.
Key Responsibilities:
3+ yrs of industry experience as a machine learning and software engineer
Experience building backend systems at scale with a focus on data processing/machine learning/analytics.
Experience with at least one ML model: LLMs, GNN, Deep Learning, Logistic Regression, Gradient Boosting trees, etc. 
Working knowledge in one or more of the following: data mining, information retrieval, advanced statistics or natural language processing, computer vision.
Exhibit our core cultural values: add positive energy, communicate clearly, be curious, and be a builder.
Work closely with cross-functional teams, including data scientists, software engineers, and domain experts, to understand business requirements and deliver effective solutions.
Document code, algorithms, and processes to ensure transparency and maintainability.
Qualifications:
Bachelor's or Master’s degree in Computer Science, Data Science, or a related field.
Proven experience in developing and implementing machine learning algorithms and AI solutions.
Strong programming skills in languages such as Python, R, or Java.
Solid understanding of machine learning frameworks (TensorFlow, PyTorch, scikit-learn) and deep learning concepts.
Proficiency in data preprocessing, feature engineering, and model evaluation.
Experience with big data technologies (Hadoop, Spark) is a plus.
Excellent problem-solving and analytical skills.
Strong communication and collaboration skills.
 Assistance for Individuals with Disabilities
Wayfair is fully committed to providing equal opportunities for all individuals, including individuals with disabilities. As part of this commitment, Wayfair will make reasonable accommodations to the known physical or mental limitations of qualified individuals with disabilities, unless doing so would impose an undue hardship on business operations. If you require a reasonable accommodation to participate in the job application or interview process, please let us know by completing our Accomodations for Applicants form.
Need Assistance?
For more information about applying for a career at Wayfair, visit our FAQ page here. 
About Wayfair Inc.
Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.
No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.
We are interested in retaining your data for a period of 12 months to consider you for suitable positions within Wayfair. Your personal data is processed in accordance with our Candidate Privacy Notice (which can found here: https://www.wayfair.com/careers/privacy). If you have any questions regarding our processing of your personal data, please contact us at dataprotectionofficer@wayfair.com. If you would rather not have us retain your data please contact us anytime at dataprotectionofficer@wayfair.com. ",USD 150K - 232K *
164,Senior Data Engineer,Cargill,"Bengaluru, Karnataka, India, 560087",Senior-level / Expert,"Job Purpose and Impact
The Data Engineer III will design, build and operate high performance data centric solutions utilizing the comprehensive big data capabilities for the company's data platform environment. In this role, you will act as an authority for data access pathways and techniques working with analysts within the functional data analytics team. You will design data structures and pipelines to collect data and design and implement data transformations, combinations or aggregations.
Key Accountabilities
Collaborate with businesses, application and process owners, and product team members to define requirements and design solutions for the company's big data and analytics solutions.
Participate in the decision-making process related to architecting solutions.
Develop technical solutions utilizing big data and cloud based technologies and ensuring they are designed and built to be sustainable and robust.
Perform data modeling and prepare data in databases for use in various analytics tools and configurate and develop data pipelines to move and optimize data assets.
Provide necessary technical support through all phases of solution life cycle.
Build prototypes to test new concepts and be a key contributor of ideas and code that improve the core software infrastructure, patterns and standards.
Help drive the adoption of new technologies and methods within the functional data and analytics team and be a role model and mentor for data engineers.
Independently handle complex issues with minimal supervision, while escalating only the most complex issues to appropriate staff.
Other duties as assigned
Qualifications
Minimum Qualifications
Bachelor's degree in a related field or equivalent experience
Minimum of four years of related work experience
Other minimum qualifications may apply
Preferred Qualifications
Experience developing data or software applications including analysis, design, coding, testing, deploying and supporting of applications.
Experience working with big data platform.
Experience with reporting tools and data sources.",USD 121K - 186K *
165,Senior Data Scientist / Data Scientist 2,CommerceIQ,"Bengaluru, Karnataka, India",Senior-level / Expert,"Company Overview
At CommerceIQ, we help consumer brands accelerate their retail ecommerce market share growth and profitability through machine learning algorithms. We are building the world’s most complete and sophisticated Retail Ecommerce Management Platform, which connects and intelligently automates the management of retail ecommerce channels like Amazon, Walmart, and Instacart, across the entire ecommerce operational chain of retail media management, sales operations, supply chain, and digital self analytics.
We are in hyper growth mode, having recently raised our Series D funding at unicorn valuation (>$1B) and ended our third year of triple-digit revenue growth. Continued acceleration of our growth is fueled by landing new customers, expanding our platform through new products, managing new retail ecommerce platforms, and delivering exceptional customer service to unlock high net retention rates.
Data Scientist - 2 | Location: Bangalore
Roles and responsibilities :
Understand the business problem and provide data science solutions. 
Building data science solutions end to end.
Carry out proof of concept for data science problems.
Collaborate with product and engineering teams to build data science solutions ( end to end ) 
Do exploratory data analysis to support existing and future data science projects
Build dashboards to monitor the data science projects performance and communicate the metrics to the business team.

Preferred Qualifications :
Work Experience : 3+  Years of data science experience
Machine Learning Knowledge : Well versed with Machine Learning concepts and have built ML projects end to en. Understanding of mathematical concepts behind ML models.
Statistical Data Analysis: Proficiency in applying statistical techniques to analyze data and generate useful business insights. 
Data Visualization: Skill in creating meaningful visualizations of complex data sets using tools like Tableau, PowerBI, or Python libraries (e.g., Matplotlib, Seaborn).",USD 136K - 205K *
166,Data Analyst (all genders),HRS,"Chandigarh, Mid-Senior level, IN",Entry-level / Junior,"HRS AS A COMPANY
HRS, a pioneer in business travel, aims to elevate every stay through innovative technology. With over 50 years of experience, their digital platform, driven by ProcureTech, TravelTech, and FinTech, transforms how companies and travelers Stay, Work, and Pay.

ProcureTech digitally revolutionizes lodging procurement, connecting corporations and suppliers in a cutting-edge ecosystem. This enables seamless efficiency and automation, surpassing travelers' expectations.

TravelTech redefines the online lodging experience, offering personalized content from selection to check-in, ensuring an unparalleled journey for corporate travelers.

In FinTech, HRS introduces advancements like mobile banking and digital payments, turning corporate back offices into touchless lodging enablers, eliminating legacy cost barriers. The innovative 2-click book-to-pay feature streamlines interactions for travelers and hoteliers.

Combining these technology propositions, HRS unlocks exponential catalyst effects. Their data-driven focus delivers value-added services and high-return network effects, creating substantial customer value.

HRS's exponential growth since 1972 serves over 35% of the global Fortune 500 and leading hotel chains.

Join HRS to shape the future of business travel, empowered by a culture of growth and setting new industry standards worldwide.
POSITION
We are looking for a Chandigarh based HR Data Analyst (all genders) who is responsible for the analysis, modelling, and implementation of all HR Analytics. Besides formulating requirements for our HRIS System SAP SuccessFactors, you consult Leadership how to improve the level of HR automation and digitization.
  CHALLENGE
Analysis, modelling and documentation of all HR Processes, such as recruiting, business partnering, learning and development
Project leadership in various HR automation and digitization projects. Central coordination and alignment of different SAP SuccessFactors implementation projects 
Monitor HR metrics, analyze and make recommendations for process improvements as well as new initiatives.
Demonstrated expertise in all facets of project management, such as requirements gathering, stakeholder management, budget and risk management, and status reporting
Collaborate, coach and counsel business partners and other stakeholders, such as HR controlling, HR development and Recruitment 
Act as ‘trusted advisor’ to senior management level and among project members
FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
Bachelor’s degree in a related field preferred
At least 3 years’ experience in HR analytics within SaaS and/or digital industry
Experience with HR systems/technology, ideally with SAP successfactors
Strong problem-solving, organization skills
Diligent documentation habits
Very good command of Microsoft Office (in particular Excel and PowerPoint)
Experience and proficiency with Python Programming Language.
Experience and proficiency with Microsoft Office Suite (e.g., Excel, Word, Access, and PowerPoint) and Google Suite
Ability to perform multiple tasks ranging from project management to coaching other team members
A thorough understanding of data transfer to the consolidated financial statements, planning processes, actual business processes and business requirements
Excellent communication skills and the ability to communicate with both technical and non-technical personnel; ability to listen, clarify and respond well to questions 
PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.

Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 53K - 94K *
167,Data Engineer (Java/Spark/AWS),Nielsen,"Mumbai, India",Senior-level / Expert,"At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future. 

We are looking for a Senior Software Engineer with Data Engineering Skills to join our Gracenote Tech team. The ideal candidates would have a passion for Clean Code, scalable architectures, Test Driven Development and DevOps.
Job Purpose
Develop and enhance our flagship Video metadata software solution.
Design applications with a Platform-first mentality where scale, consistency and reliability are at the core of every decision.
Job Description
Design software with a Product-owner mentality: your software is the product and as such you own the product as much as any business person does.
Work within small, highly configurable teams to deliver software in rapid increments using an iterative approach.
Develop applications to catalog and power the world’s largest entertainment metadata repository across the Video vertical.
Immediate focus on building our next generation ingestion pipeline leveraging automation at the core requiring minimal human intervention.
Interact with Product, Editorial and Client Experience teams to constantly refine the Gracenote offering. 
Role Requirements / Desired Skills
2-4 years of experience working in Software Development 
At least 2+ years of experience in Java / Spark
Experience in AWS
Experience with Unix/Linux based platforms.
Experience in Terraform, Ansible and ORM technologies
Experience with databases like Postgre, Cassandra SQL etc. 
Experience in writing unit test code
A solid grasp of computer science fundamentals: data structures, algorithms, memory management and distributed systems
Proficiency in software engineering tools
Have experience with API’s, JSON(P) and XML
Ability to document requirements and specifications
Energetic team player
Experience working in an Agile environment.
Good communication skills and able to share knowledge with the team.
Good knowledge of the English language, both spoken and written.
B.E / B.Tech in Computer Science, Engineering or a related subject.
Additional skill set (Good to have)
Experience in automated testing platforms like Selenium
Experience with containers (docker, containers) and kubernetes.
Experience with Presto, Trino, Spark, Airflow, Prometheus, ELK, or similar technologies.
Have an affinity with Video, Music & Sports domain
Like to understand and brainstorm about architecture
Have knowledge of other technologies like orchestration tools, database optimization, server/application optimization
History of open source contributions
Experience with DevOps practices and software
A passion for exploring new programming languages",USD 121K - 186K *
168,Data Analytics Engineer,Xplor,"Pune, India",Senior-level / Expert,"Company Description
Take a seat on the Xplor rocketship and join us as a Data Engineer to help people succeed across the world.
We’re a global team of builders, listeners and problem-solvers who are relentlessly focused on making life simple, so our customers can get back to growing their business, engaging consumers and doing what they love.
Job Description
As a member of the global data engineering team, reporting to the Data and Analytics Manager, this role has a primary focus on contributing to our enterprise data warehousing and reporting deliverables.
Responsibilities include designing, creating, and maintaining business intelligence assets and reports that drive innovation, client value and business efficiency.
This position will be working across our largest business units and experience with multi-terabyte database systems is required.
Key Responsibilities
The primary tasks, duties, and responsibilities are:
Maintaining and enhancing reporting and Power BI solutions.
Producing reporting stored procedures via T-SQL scripting and DAX.
Data Modelling and Transformation design.
ELT development.
Contribute to cloud migration and ensure system uptime for data warehouse products.
Participate in Agile work planning, testing, and quality assurance.
Qualifications
Technical Skills
Experienced level knowledge - Business Intelligence/reporting tools including Microsoft SQL, SRSS, SSIS, SSAS, Power BI, DAX.
Adept at designing and implementing effective data models and Extract, Transform, Load (ETL) processes slowly changing dimensions for transforming and loading data into the data warehouse.
Experience incorporating data from varied relational systems (e.g. MySQL, Postgres etc), flat-file, API, and No-SQL sources.
Understanding of data governance practices, data lineage, and data quality management to ensure accurate, consistent, and reliable data.
Familiarity with cloud base tooling – Snowflake, DBT or Coalesce, Fivetran.
Education/Qualifications
BA/BS degree in Computer Science, Computer Engineering, or related field, or equivalent practical experience.
Preferred Qualifications include:
Expertise in parallel processing warehouses (Snowflake/Redshift),
high-frequency differential ETL processes,
and Agile development methodology.
Additional Information
Ready to apply?
To start your application, please submit your resume and we will be in touch as soon as we can. Please include the word ""moonshot"" at the top of your message to the Hiring Manager so that we know you took the time to read our job ad.
We understand that diverse candidates have diverse needs. We welcome you to inform us of any additional needs related to completing your job application or participating in the interview process, via talent@xplortechnologies.com. 
We kindly ask you to apply through our careers portal or external job boards (LinkedIn, Naukri, Indeed, etc) only. Please don't send your application via email. They will not be forwarded. 
More about us 
Xplor Technologies is a global platform integrating SaaS solutions, embedded payments, and Commerce Accelerating Technologies to help businesses succeed. Xplor provides enterprise-grade SaaS solutions for businesses in “everyday life” verticals: Childcare & Education; Fitness & Wellbeing, Field Services and Personal Services – and a global cloud-based payment processing platform.
Xplor Technologies serves over 78,000 customers that processed over $36 billion in payments, operating across 20 markets in 2022. 
Good to know
To be considered for employment, you must be legally authorised to work in the location (country) you're applying for. Xplor does not sponsor visas, either at the time of hire or at any later time. 
To learn more about us and our products, please visit www.xplortechnologies.com/us/careers. 
We also invite you to check out our Candidate FAQs for more information about our recruitment process www.xplortechnologies.com/us/recruitment-faqs.
Xplor is committed to providing equal opportunities in employment and creating an inclusive work environment. We provide equal opportunities to all our employees and to all eligible applicants for employment in our company. We do not unfairly discriminate on any ground, including race, religion, color, ancestry, marital status, gender, sexual orientation, age, nationality, ethnic origin, disability or any other category protected by applicable law.
We are a 2024 Circle Back Initiative Employer – we commit to respond to every applicant.",USD 37K - 70K *
169,Director - Engineering (Applied AI),Freshworks,"Bengaluru, India",Executive-level / Director,"Company Description
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion or ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and business.

Freshworks makes it fast and easy for businesses to delight their customers and employees. More than 50,000 companies use Freshworks SaaS to enable a better customer experience (CX, CRM) and employee experience (ITSM, HRSM). Headquartered in San Mateo, California, Freshworks has a dedicated global team operating from 13 locations to serve our customers throughout the world.

Freshworks has received numerous accolades ranking #16 on the prestigious Forbes Cloud 100 and #22 on the Battery Ventures/Glassdoor Best Places to Work lists.
Job Description
Applied AI is taking scientific research and applying it to business problems.
As a leader of Applied AI engineering team,  you  will help drive the application of AI across our suite of products in addition to developing the thinking of our team. This leader will direct and shape the data science philosophy, planning and strategy for the team, as we explore multi-modal, multi lingual use cases through the use of Generative AI.
Responsibilities:
Inspire, lead and grow a team of data scientist, Machine learning engineers, engineering managers
Data Science and Technical leadership for product and across all engineering requirements.
Clarify our Applied AI philosophy and engineering strategy to key stakeholders and drive consensus
Continuously improve and drive engineering best practices around software engineering & lead the craftsmanship, resilience, and scalability of your solutions.
Bring a passion to stay on top of AI  trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community.
Encourage innovation, implementation of cutting-edge technologies, inclusion outside-of-the-box thinking, teamwork, self-organization, and diversity.
As a key member of the product engineering team, work with product management, architecture and professional services to deliver and maintain compelling products to market
Ship great products under stringent deadlines and in the face of ambiguous requirements and changing business priorities.
Be a champion for AI test discipline , and evaluation scores, in order to make AI capabilities more deterministic
Reduce the time-to-insights window for new customers.
Responsible for the overall development and release life cycle.
Qualifications
BE/ B. Tech. in Computer Science /Software Engineering from a reputed
college/university.
15+ years of industry experience with experience leading engineering teams with over 30+ software engineers.
Hands-on experience in building large-scale distributed systems with AWS
5+ years of direct people management experience including managing managers
5+ years of experience of working in the  Generative  AI /  Deep learning
Experience communicating with technical and non-technical stakeholders at all levels across the business.
Experience in building highly scalable Enterprise SaaS software is a big plus
Experience in AWS will be added advantage
Exceptional leadership skills and proven experience in shaping team culture.
Proven ability to headhunt, attract, retain, and coach engineering talent from top companies and universities.
Strong analytical skills and passion for answering questions with data
Bachelor's degree in computer science, engineering, or a related discipline.
Proven record of building, managing, and sustaining product organizations.
Must have the ability to influence people at the business unit level.
Must have the ability to understand the technical and non-technical aspects of product development.
Excellent problem-solving skills.
Excellent verbal and written communication skills.
Additional Information
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 49K - 91K *
170,Data Architect,Bosch Group,"Bengaluru:, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Collaborate with cross-functional teams to understand business requirements and translate them into data architecture solutions.
Implement data integration solutions to aggregate and consolidate data from various sources.
Design and develop scalable and efficient data models, while evaluating and selecting appropriate data storage and processing technologies for big data applications
Collaborate with business stakeholder, data engineers and data scientists to ensure that data is readily available for advanced analytics and machine learning use cases.
Define data governance and security policies to ensure data integrity and compliance with regulatory requirements while enabling seamless data availability and sharing to serve business goals.
Optimize and tune data architectures for performance, reliability, and scalability.
Develop and maintain documentation for data architecture and data flows.
Stay current with industry trends and emerging technologies in big data and data management.
Qualifications
Bachelor's or master’s degree in Computer Science, Information Technology, or a related field.
Proven industry experience (10+ years) as a Data Architect with a focus on big data solutions
In-depth knowledge of data modeling, database design, and data storage concepts.
Proficiency in working with big data technologies such as Hadoop, Spark, Kafka, SQL and NoSQL databases (e.g., Cassandra, MongoDB).
Expertise in Data Lake and Databricks
Expertise in data integration, ETL processes, and data pipeline development.
Expertise with cloud-based data platforms (e.g., AWS, Azure, GCP).
Excellent problem-solving and communication skills.
Ability to work collaboratively in a cross-functional team environment.
Strong analytical and strategic thinking skills.
Data governance and security expertise is a big plus.
Additional Information
Proven industry experience (10+ years) in Data Architecture with a focus on big data solutions",USD 115K - 193K *
171,"Sr. Data Engineer , MLOps, Visa Predictive Models",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Team Summary:
The Risk and Identity Solutions (RaIS) team provides risk management services for banks, merchants, and other payment networks. Machine learning and AI models are the heart of the real-time insights used by our clients to manage risk. Created by the Visa Predictive Models (VPM) team, continual improvement and efficient deployment of these models is essential for our future success. To support our rapidly growing suite of predictive models we are looking for engineers who are passionate about managing large volumes of data, creating efficient, automated processes and standardizing ML/AI tools.
 Job Description:
This is a great opportunity to work with a new Engineering and MLOps team to scale and structure large scale data engineering and ML/AI that drives significant revenue for Visa. As a member of the Risk and Identify Solutions modeling organization (VPM), your role will involve developing and implementing practices that will allow deployment of machine learning models in large data science projects.
You must be a hands-on expert able to navigate both data engineering and data science disciplines to build effective engineering solutions that support ML/AI models. You will partner closely with global stakeholders in RaIS Product, VPM Data Science and Visa Research to help create and prioritize our strategic roadmap.  You will then leverage your expert technical knowledge of data engineering, tools and data architecture in the design and creation of the solutions on our roadmap.
 The position is based at Visa's offices in Bangalore, India.
 Essential functions:
Team members working for this role deploy, manage, and optimize data pipelines and machine learning models in production environments, ensuring smooth integration and efficient operations. The team also takes a data scientist’s model and make it accessible to the software that utilizes it. The essential functions of this role include:
 ETL processes: The role also involves developing and executing large scale ETL processes to support data quality, reporting, data marts, and predictive modeling.
Spark pipelines: The role requires building and maintaining efficient and robust Spark pipelines to create and access data sets and feature stores for ML models.
MLOps processes: The essential function of the role is to execute and manage processes for MLOps, such as deployment, testing, monitoring, alerting, and feature pipelines for ML models.
Model deployment and monitoring: The role entails deploying and reviewing ML models, building test cases, monitoring, alerting, and documentation.
Rapid Model Retraining: Develop processes and tools to perform model re-training, model performance evaluation and score optimization for existing ML models, introducing automation where possible.
Collaboration with Technology teams: The role involves working with Data Science teams, Visa Research, and other Technology teams to leverage and provide feedback on ML systems and tools.
Technical documentation and innovation: The role requires defining and building technical and data documentation, using code version control systems, ensuring data accuracy and consistency, and suggesting new ideas for innovation.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:
• 4-6 years of relevant work experience with a Bachelors Degree or 2-3 years of relevant work experience with a Master's or Advanced Degree in an analytical field such as computer science, statistics, finance, economics or relevant area.
• Working knowledge of Hadoop ecosystem and associated technologies (e.g. HDFS, MapReduce, YARN, Spark, Kafka, MLlib, GraphX, iPython, sci-kit, Pandas etc.)

Preferred Qualifications:
• 4-6 years of relevant work experience with a Master's or Advanced Degree with specialization in Computer science, Information science, Statistics, Data Engineering and Analytics or relevant area.
• Experience working in Linux/Unix environment and exposure to command line utilities.
• Hands-on experience working with large scale data ingestion, processing, and storage in the Hadoop ecosystem.
• Experience with complex, high volume, multi-dimensional data, as well as machine learning
• models based on unstructured, structured, and streaming datasets.
• Experience in writing and optimizing SQL queries in Big data environment.
• Experience creating/supporting production software/systems and have expertise on resolving performance bottlenecks for production systems
• Experience working with scheduling tools (Airflow, Control-M) and building data processing orchestration workflows.
• Strong understanding of development and implementation aspects of ML/AI, especially on billion-scale datasets. Ability to take small-scale developed models as input and implement with requisite configuration and customization, while maintaining model performance.
• Deep understanding of MLOps processes, including building and integrating the code in the defined CI/CD framework.
• Strong written, verbal, and interpersonal skills needed to effectively communicate technical insights and recommendations with business customers and leadership team.
• Experience working with technology and business teams on Data Governance, Data Quality and Data Architecture initiatives.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 186K *
172,BI Developer,Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Job Description
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative, and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies, and people around the world.
You will join our Data & Analytics department
As our new experienced Senior BI Developer, you will be part of a Global team, which is responsible for developing global data driven analytical solutions by both using classic and advanced disciplines supporting Ramboll’s business units globally. With an increased strategic focus on the area in Ramboll, we are currently expanding. The purpose of our department is among others to support the business with excellent data driven solutions. Make sure all solutions in production runs smoothly, train users in the new solutions, handle change request and support incidents etc.
Your key tasks and responsibilities will be:
Understand user requirements
Present your BI solutions to users, stakeholders, and the BI Team
Monitor, improve and constantly optimize existing structures, data flows and processes
Take part in the daily task in our data warehouse and BI solutions
Plan and manage your own BI projects from A to Z
Background in data warehouse design (e.g., dimensional modeling) and data mining
In-depth understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework
Teach users how to create value in Power BI with Ramboll data
Create good customer experiences
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this role, we believe your starting point is:
Several years of experience with Data Analytics
Hold a relevant educational degree
Have expert knowledge in SQL, SQL Server Integration Services and Power BI.
Strong knowledge in Data Visualization, Data Modelling, Query Performance Tuning.
Strong knowledge on writing Stored Procedure, Complex queries, and DAX
Have hands on in Tools like: Power BI, SSMS, Visual Studio
Have Knowledge on SQL Server Analysis Server, Power Query
Good to have knowledge on TFS /GIT
Fluent in English – written and orally
 Additional Information
Personal qualities that will help you succeed in this role include self-driven and analytical in your work approach thriving with transformation and building new BI solutions by challenging status quo. In addition, you are also highly structured and well organized enabling you to maintain the full overview.
Welcome to our Support Organization
In Ramboll’s Support Organization we take pride in keeping Ramboll running smoothly, enabling bright minds throughout the organization to focus on their areas of expertise as we tie together all parts of the business. We provide support within areas like Finance, HR, IT, Legal, Communication, Facility Management and more, coordinating efforts and securing common ground for the development and servicing of clients and markets.
Ramboll in Denmark
Ramboll is the leading engineering, design and consultancy company in Denmark and has more than 3,500 experts working across 13 offices applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health, Energy and Management Consulting. We invite you to contribute to a sustainable future working in an open, collaborative, and empowering culture.
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 106K - 140K *
173,Associate Data Engineer,Zscaler,"Bengaluru, India",Mid-level / Intermediate,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Position: Associate Data Engineer
  Responsibilities/What You’ll Do
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs.
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements.
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake.
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs.
Work with Data Platform Lead to design and implement data management standards and best practices.
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions.
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures.


Qualifications/Your Background:
0 to 3 years of experience in data warehouse design & development.
Proficiency in building data pipelines to integrate business applications (salesforce, Netsuite, Google Analytics etc) with Snowflake
Must have proficiency in data modeling techniques (Dimensional) – able to write structured and efficient queries on large data sets
Must have hands-on experience in Python to extract data from APIs, build data pipelines.
Completely proficient in advanced SQL, Python/Snowpark(PySpark)/Scala (any Object Oriented language Concepts), ML libraries.
Strong hands-on experience in ELT Tools like Matillion, Fivetran, Talend, IDMC (Matillion preferred) , data transformational tool – DBT and in using AWS services like EC2, s3, lambda, glue.
Knowledge of data visualization tools such as Tableau, and/or Power BI
Must demonstrate good analytical skills, should be detail-oriented, team-player and must have ability to manage multiple projects simultaneously.
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 90K - 151K *
174,"Engineer, Data Development",TransUnion,Bengaluru,Mid-level / Intermediate,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are looking for an experienced Data Engineer to join the Transunion Data Engineering team to develop, maintain and optimize applications and services running on Amazon Web Services (AWS). The role will support Financial Services vertical and will be responsible for being part of re-architecture and migration projects. The ideal candidate should have broad SQL/Python development experience, with demonstrated experience in migrating complex data platforms to Cloud. The role requires experience in cloud computing environments, hands on technical skills, passion, and appetite to master new technologies, and excellent communication skills.
What You'll Bring:
Responsibilities • Development of high-quality database solutions.  • Supports of all aspects of the software and database development lifecycle including requirements definition, design, development, test, deployment, documentation, and support. • Writing data warehousing/business intelligence queries. • Building and maintaining multiple database environments, building, and maintaining ETL Routines and numerous other activities that require building data asset for business. • Participate in defining short-term and long-term database services direction and vision, will work with business process owners. • Participate in generating system documentation such as data dictionary, Business Intelligence (BI) reporting, policies, and procedures. • Monitor, resolve and communicate status of outstanding defects/change requests. • Develop and maintain documented processes and procedures to ensure consistent delivery of assigned tasks and responsibilities. • Develop task estimates, report project status, issues, and recommended resolutions to support timely project delivery. • Works with Software Developers to address issues of data migration and integrity (validation, clean-up, mapping, and data modeling). • Collaborate with cross-functional technology teams. • Accountability for quality of code and application development. Requirements: • Masters + 1 years of experience or bachelor’s degree + 3 years of experience. • Strong experience in Phython, PySpark/Spark SQL, SQL Scripts. • Experience with AWS tools and services – Redshift, EMR, AWS Glue. • Good working experience with relational databases – PostgreSQL. • Experience and/or good understanding of Containers and EKS. • Experience with Tableau is a plus. • CI/CD, Jenkins, automation experience. • Experience with version control tools, such as Bitbucket. • Experience working within Agile software development teams is a plus. • Strong analytical, communication, creative and interpersonal skills. • Demonstrated problem solving and root cause analysis skills. • Experience writing data warehousing/business intelligence queries. • Ability to prioritize and manage multiple tasks and assignments. • Effective translation of issue resolution and requirements into technical specifications.
Impact You'll Make:
Data
TransUnion Job Title
Engineer, Data Development",USD 37K - 70K *
175,Associate Data Team Lead,IQVIA,"Kochi, India",Mid-level / Intermediate,"Job Overview
Manage end-to-end delivery of data management services for single/multi-service projects with minimal guidance, ensuring quality deliverables on time and within budget, to customer satisfaction. Provide comprehensive data management expertise to Clinical Data Management (CDM) team to provide high quality data management products that meet customer needs. Provide leadership to the team in the areas of project planning, execution, and close-out; financial management; communications; and milestone deliverables. Perform role of Data Team Lead (DTL). Comply with Good Clinical Practices (GCPs), applicable regulatory guidelines, SOPs, policies, and, where available, CDM guidance documents.
Essential Functions
• Client Management:. serve as primary point of contact for customer on data management deliverables. With minimal guidance, provide project management expertise working with customer data managers, key decision makers, and internal team members to manage continuous process improvements, issue escalation, workload projections, and provide technical expertise. With guidance, provide input for and perform direct negotiations with customer, e.g., timelines, financial, process, resources. Maintain strong customer relationships. Ensure open communications with customer and IQVIA management to manage and meet contractual obligations. Service Management:. Meet with Data Operations Coordinator (DOC) and/or Data Operations team members on a regular basis to ensure milestones meet timelines and quality deliverables. Establish strong communications with Data Operations team, functional leads, project managers and all other stakeholders. With minimal guidance, support DM service delivery with comprehensive DM process and technical expertise in executing projects. Serve as the escalation point for unresolved data issues
• with guidance, work with client data managers, vendors, internal team members for resolution. Work with functional manager(s) to ensure appropriate resources are assigned to meet project deliverables. With guidance, create and/or review and sign-off on all data management plan (DMP) documents. Implement proactive quality management plan. Identify any service and quality issues with agreed upon specifications per the DMP and contract/SOW and work with functional manager(s) to resolve. With guidance, track service performance and provide leadership to identify root causes of issues and implement remedial actions. Continuously look for opportunities to improve efficiency of tasks and quality of deliverables. Identify compliance issues and work with functional manager(s) to ensure timely follow-up and resolution. With guidance, maintain internal tracking databases and systems. Financial Management/Business Development Support:. With guidance, ensure service and quality meet agreed upon timelines and deliverables in contract/Scope of Work (SOW). Manage SOW/budget. - Review financial reports on a monthly basis and participate in project reviews as requested. - Identify out of scope tasks and track change orders to completion. With guidance, may serve as Project Manager for single service DM projects, including financial tracking, revenue recognition, and invoicing. With guidance, participate in and support RFP process (review RFP documents, pricing, attend bid defense). Other:. Provide input on DM process improvements or project solutions to CDM team/CDM department. Provide input on the development and implementation of a new technology or tool. Participate in a focus team or global or local best practice team. Perform other duties as directed by functional manager(s)
Qualifications
• Bachelor's Degree or educational equivalent, in health, clinical, biological or mathematical sciences, or related field
• 1-2 years of direct Data Management experience with a minimum of 6 months as a CDM project lead Pref
• Previous experience and proven competence in managing study delivery through full DM life-cycle (at least 1 medium Phase III). Demonstrated data management skills and thorough knowledge of the data management process (e.g., therapeutic area, extensive knowledge in DM processes, SAE reconciliation, external data vendor reconciliation, management of local laboratory data, and/or new technology). Knowledge of Medical Terminology, Pharmacology, Anatomy, and/or Physiology. Knowledge of operating procedures and work instructions and the ability to apply them in practice. Knowledge of Good Clinical Practices and applicable regulatory guidelines. Excellent communication, interpersonal, customer service, and teamwork skills. Excellent organizational and problem-solving skills. Excellent project management skills. Ability to work with minimal supervision, using available resources, e.g., functional managers, senior DTLs. Comprehensive understanding of clinical drug development process. Ability to establish and maintain effective working relationships with coworkers, managers and customers. Previous experience and proven competence in managing study delivery through full DM life-cycle (at least 1 medium Phase III). Demonstrated data management skills and thorough knowledge of the data management process (e.g., therapeutic area, extensive knowledge in DM processes, SAE reconciliation, external data vendor reconciliation, management of local laboratory data, and/or new technology). Knowledge of Medical Terminology, Pharmacology, Anatomy, and/or Physiology. Knowledge of operating procedures and work instructions and the ability to apply them in practice. Knowledge of Good Clinical Practices and applicable regulatory guidelines. Excellent communication, interpersonal, customer service, and teamwork skills. Excellent organizational and problem-solving skills. Excellent project management skills. Ability to work with minimal supervision, using available resources, e.g., functional managers, senior DTLs. Comprehensive understanding of clinical drug development process. Ability to establish and maintain effective working relationships with coworkers, managers and customers.
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com",USD 30K - 56K *
176,"Assoc Engineer, Data Development",TransUnion,Bengaluru,Mid-level / Intermediate,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are looking for an experienced Data Engineer to join the Transunion Data Engineering team to develop, maintain and optimize applications and services running on Amazon Web Services (AWS). The role will support Financial Services vertical and will be responsible for being part of re-architecture and migration projects. The ideal candidate should have broad SQL/Python development experience, with demonstrated experience in migrating complex data platforms to Cloud. The role requires experience in cloud computing environments, hands on technical skills, passion, and appetite to master new technologies, and excellent communication skills.
What You'll Bring:
Responsibilities • Supports of all aspects of the software and database development lifecycle including requirements definition, design, development, test, deployment, documentation, and support. • Writing data warehousing/business intelligence queries. • Building and maintaining multiple database environments, building, and maintaining ETL Routines and numerous other activities that require building data asset for business. • Participate in defining short-term and long-term database services direction and vision, will work with business process owners. • Participate in generating system documentation such as data dictionary, SOP. • Monitor, resolve and communicate status of outstanding defects/change requests. • Develop and maintain documented processes and procedures to ensure consistent delivery of assigned tasks and responsibilities. • Develop task estimates, report project status, issues, and recommended resolutions to support timely project delivery. • Works with Software Developers to address issues of data migration and integrity (validation, clean-up, mapping, and data modeling). • Collaborate with cross-functional technology teams. • Accountability for quality of code and application development. Requirements: • Master’s degree in computer or Equivalent / bachelor’s degree + 2 years of experience. • Experience in Phython, PySpark/Spark SQL, SQL Scripts. • Exposure working on AWS tools and services – Redshift, EMR, AWS Glue. • Experience with relational databases – PostgreSQL. • Experience and/or good understanding of Containers and EKS. • Experience with Tableau is a plus. • CI/CD, Jenkins, automation experience a plus. • Basic understanding of version control tools, such as Bitbucket. • Experience working within Agile software development teams is a plus. • Strong analytical, communication, creative and interpersonal skills. • Demonstrated problem solving and root cause analysis skills. • Ability to communicate professionally in written responses with extreme detail to customer requirements in support of solution development and delivery.
Impact You'll Make:
Data
TransUnion Job Title
Assoc Engineer, Data Development",USD 30K - 56K *
177,"Manager, Machine Learning 3",PayPal,IND - Tamil Nadu - Chennai - Corp - Old Mahabalipuram Rd,Mid-level / Intermediate,"At PayPal (NASDAQ: PYPL), we believe that every person has the right to participate fully in the global economy. Our mission is to democratize financial services to ensure that everyone, regardless of background or economic standing, has access to affordable, convenient, and secure products and services to take control of their financial lives.
Job Description Summary:
What you need to know about the role:
As an Analytics manager, you will be responsible to work with key product stakeholders to understand, measure and identify opportunities from the myriad of PayPal data. This will be achieved by leading a team of analysts who will support our Merchant onboarding, servicing, marketing & operational teams. In addition, the team will develop data driven assets that enable our broader organization to self-service with readily available data and insights.


Meet our team:
As part of a centralized ML function, the Merchant Product Analytics & ML team works directly with our product experience and marketing teams to identify opportunities to improve experiences to help merchants understand, use and maximize the value of PayPal’s offerings. In this role, you will have access to a wealth of data (transactional, customer, behavioural, web/mobile, etc) in order to measure and identify opportunities for the business. In addition, the team is responsible for developing ML solutions by working with key product, marketing and engineering leads to build products achieve the improvements identified.
Job Description:
Your way to impact
In this role you will get the opportunity to work with skilled and highly product owners to deliver a world class experience for our merchant users. In this role, you will develop data assets, insights and data solutions that enable PayPal to improve our products and services. 
Your day to day
In your day to day role you will
Lead development and delivery of experience measurement at PayPal.
Define, track, and report key experience metrics from diverse data sources.
Analyze customer data to identify trends and propose data-driven improvements.
Present findings to senior leaders and lead initiatives to enhance customer experiences.
What do you need to bring
10-12+ years in Experience Measurement, Customer Insights, and Research.
Bachelor's degree in Business, Statistics, Marketing, Data Analytics, or related field; master's degree is a plus.
Commercial mindset coupled with analytical mindset and high attention to detail
Exceptional at interpreting and drawing business insights from data and analysis
Excellent oral, written, and communication/presentation skills
Excellent knowledge of R/SQL/Python/MS Excel – ability to run queries to extract data from multiple systems – preferred
Work authorization for the India
Additional Job Description:
Subsidiary:
PayPal
Travel Percent:
0
Our Benefits:
At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.
We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com
Who We Are:
Click Here to learn more about our culture and community.

PayPal has remained at the forefront of the digital payment revolution for more than 20 years. By leveraging technology to make financial services and commerce more convenient, affordable, and secure, the PayPal platform is empowering more than 400 million consumers and merchants in more than 200 markets to join and thrive in the global economy. For more information, visit paypal.com.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.
Any general requests for consideration of your skills, please Join Our Talent Community.
As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated.",USD 30K - 56K *
178,Sr Manager - Data Analyst,TransUnion,Mumbai - One World Center,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are one of India’s leading credit information company with one of the largest collections of consumer information. We aim to be more than just a credit reporting agency. We are a sophisticated, global risk information provider striving to use information for good.
We take immense pride in playing a pivotal role in catalyzing the BFSI industry in the country. We got here by tapping into our excitement and passion of wanting to make a difference in the lives of our clients and consumers.
We at TransUnion CIBIL are an equal opportunity employer and are committed to a policy of treating all our associates and job applicants equally. Applicants are evaluated on the basis of job qualification - not race, color, sex / gender, religion, caste, national origin, age, disability, marital status, citizenship status, sexual orientation, gender identity or any other status, whether or not protected. We are committed to taking affirmative action to employ and advance minorities, women, and qualified disabled individuals. We ensure a safe, productive, and harassment-free workplace for all.
Culture and Values
Our culture is welcoming, energetic, and innovative. There’s an overall synergy that flows throughout the company, creating a sense of connect, belonging and unity in knowing that we’re all working to achieve the same overall goal. Our core values which we live by every day are integrity, People, Customer, and Innovation.
https://www.transunion.com/privacy/global-job-applicant
What is excitement and passion for us?
We define it as a blend of curiosity, ability to unlearn and yet continuously learn, able to connect with meaning and finally the drive to execute ideas till the last mile is achieved. This passion helps us focus on continuous improvement, creative problem solving and collaboration which ensures delivery excellence.

Dynamics of the Role
This is an exciting time in TransUnion CIBIL. With investments in our people, technology and new business markets, we are redefining the role and purpose of a credit bureau.
The data analyst will be responsible for data integrity of the data. Will monitor performance and quality control plans to identify any issues or ways to improve data designs. This role requires doing regular analysis, defined as a process, to monitor data performance based on defined metrics. The said analyst will collaborate with database developers to implement effective information processes by developing queries so data can be mined for business need and accuracy, provide periodic updates on data performance and share the said information with the management /decision making teams. councils. This role suits people who enjoy working with numbers and data sets, have an aptitude for computer systems and software, and have strong analytical abilities.
What You'll Bring:
Roles & Responsibilities
Interpret data and analyze the results using statistical techniques.
Examine complex data and turn it into information and insight to influence business decisions.
Provide ongoing reports on the effects of different strategies and observe any trends or issues to raise with senior management.
Working with database developers to implement databases for more effective data collection and storage.
Performing data analytics and other strategies to optimize the efficiency and quality of the data being collected.
Acquire data from primary or secondary data sources to maintain database systems.
Identify and interpret trends or patterns in complex data sets.
Filtering and “cleaning” data and correct de-duplication problems.
Defining business rules for data collection.
Impact You'll Make:
Experience and Skills
Technical expertise – Working with statistical packages and programming codes much of the time, so they must be technically adept and able to work with data models and data mining software
Computer skills – Using different software programs, so strong computer skills are a must, as is the ability to quickly pick up new programs and techniques as technology evolves
Analytical abilities – Work with large and often complex data sets, so they need strong analytical skills and the ability to evaluate and interpret trends and important information
Interpersonal skills – Involves working with different departments and as part of a team, so excellent interpersonal and communication skills are important to work effectively with others
Problem-solving skills – Identifying issues or ways to improve systems that are already in place and be critical thinkers who can successfully troubleshoot and solve problems
TransUnion Job Title
Consultant, Data Analysis and Consulting",USD 93K - 144K *
179,Test Automation Engineer – DH Data analytics,Alcon,Bengaluru - AGS,Mid-level / Intermediate,"Key Responsibilities
Design, develop, and deploy effective test automation solutions leveraging Alcon’s enterprise test automation framework for digital health data & analytics products and applications.
Develop and execute the test plan and test cases.
Collaborate with other software/product teams in building end-to-end verification automation and component-level automation.
Provide inputs to solution architects and product teams from a testing perspective (e.g., ensuring that acceptance criteria are testable, appropriate hooks are built in as part of the solution to enable test automation)
Guide and coach team members on test automation.
Participate in Backlog grooming, Spring Planning and effort estimation.
Evaluate, implement and deploy emerging tools and process for test automation to improve the productivity.  
Foster a culture of creativity, collaboration, speed, innovation, and engineering excellence.  
Key Requirements/Qualifications
Minimum Qualifications
Bachelor’s degree in computer science or a related technical discipline.
2+ years of hands-on experience in developing and implementing test automation for cloud-based software or analytics applications.
2+ years of hands-on experience in testing automation tools (eg. Tricentis Tosca, selenium)
2+ years of experience in creating test artifacts such as Test plan, Test strategy, Test cases.
Proficient with CI/CD
Good communication and analytical skills.
Thrives in dynamic, cross-functional team environments. Possesses a team-first mindset, valuing diverse perspectives and contributing to a collaborative work culture.
Approaches challenges with a positive and can-do attitude. Willing to challenge the status quo, demonstrating ability to understand when and how to take appropriate risks to drive performance. 
A passionate problem solver.
High learning agility
 Preferred Qualifications:
Experience in test automation for data intensive and/or analytics applications
Experience in developing software solutions for healthcare and knowledge of healthcare interoperability standards like HL7, FHIR, and DICOM 
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 30K - 56K *
180,AI Developer 2,IQVIA,"Kochi, India",Mid-level / Intermediate,"Job Overview
Under minimal supervision, designs, develops, implements and updates software systems in accordance with the needs of the organization. Evaluates, schedules, and resources development projects; investigates user needs; and documents, tests and maintains computer programs.
Essential Functions
• Under minimal supervision analyzes, designs, programs, debugs, modifies, and maintains software enhancements and/or new products used in local, networked, or Internet-related computer programs.
• Under minimal supervision, translates detailed design specifications into computer program instructions, debugs routine programs, prepares system test data and prepares program documentation.
• Assists in the preparation of documentation and procedures for installation and maintenance.
• Code may be used in commercial or end-user applications/products.
• Using current programming language and technologies, writes code, completes programming, and performs testing and debugging of applications.
Qualifications
• Master's Degree Master’s Degree in Machine Learning, Statistics, Computer Science, Physics, Math, or related field
• Incumbent possesses and has demonstrated basic knowledge of systems and software development with up to four (4) years experience in software development
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com",USD 74K - 192K *
181,Associate Data Analyst,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"What makes Gartner a GREAT fit for you?
When you join Gartner, you’ll be part of a fast-growing team that helps the world become smarter and more connected. We’re the leader in our industry, achieving double-digit growth by helping clients make the right decisions with business and technology insights they can’t find anywhere else. Our associates enjoy a collaborative work environment, exceptional training and career development — as well as unlimited growth potential. If you like working with a generous, supportive, high-performing team, Gartner is where you want to be.
About this role
We are looking for a highly analytical and detail-oriented Data Analytics Associate to join our growing analytics team who can collaborate and communicate well with Marketing stakeholders. The person will be responsible for developing key reports & insights to support business decision making and help formulate strategy to position Corporate Marketing as an indispensable force fueling Gartner’s revenue growth.
What you will do
Consult with marketing stakeholders to formulate and frame the business questions in the context of business objectives, gather and vet the relevant data, analyze the trends and patterns, construct story lines that will support impactful / implementable insights to the business stakeholders.
Evolve metrics and support reporting automation and visualization across all Corporate Marketing area.
Perform ad-hoc diagnostic analysis to identify operational challenges and promote best practices throughout the organization.
Build and maintain stakeholder relationships across marketing and IT.
Provide consistent, timely, recurring reporting and analysis
What you’ll need:
Graduation+ degree required.
Strong verbal & written communication
Minimum 1-2 years of experience in sales/marketing data analytics
Demonstrable experience with Advanced Excel is a must.
Demonstrable experience with SQL & Power BI is a must.
Experience with Power Automate – Good to have.
Experience with oracle Eloqua will be preferred
Experience with Python / R Studio preferred.
A successful history of processing and extracting business insights from large, disconnected data sets
Experience applying various analytic techniques (segmentation, regression, forecasting, etc.)
Strong ownership, project management and organizational skills with focus on results / timelines
Experience supporting and working with cross-functional teams in a dynamic environment
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84576
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 67K - 110K *
182,Market Data Analyst (Pune),Addepar,"Pune, India",Mid-level / Intermediate,"Who We Are
Addepar is a global technology and data company that helps investment professionals provide the most informed, precise guidance for their clients. Hundreds of thousands of users have trusted Addepar to empower smarter investment decisions and better advice over the last decade. With client presence in more than 40 countries, Addepar’s platform aggregates portfolio, market and client data for over $4.5 trillion in assets. Addepar’s open platform integrates with more than 100 software, data and services partners to deliver a complete solution for a wide range of firms and use cases. Addepar embraces a global flexible workforce model with offices in Silicon Valley, New York City, Salt Lake City, Chicago, London, Dublin, Edinburgh, Scotland and Pune, India.
*Marketplace and brokerage services provided by Acervus Securities, Inc., an SEC registered broker‑dealer and member FINRA / SIPC.
The Role
Part of the broader Addepar Data organization, the Market Data Operations team is responsible for ensuring Addepar's clients have timely and accurate data to make investment decisions. We are in the middle of building new market data capabilities, and this is an exciting join to help shape the future of market data at Addepar!
What You’ll Do
Daily data quality validations on pricing, fundamental and corporate action data
Investigate and Resolve exceptions on a variety of data assets, including Global Security Master, Price Master & Corporate Actions
Research data quality issues, identify resolutions and updating systems as needed
Update Addepar's proprietary Alts Data Management database
Explore new datasets and analytics based on new data sources
Partner with Product and Engineering to design, test, and implement new processes and tooling features that improve data quality as well as increase operational efficiency.
Investigate and troubleshoot market data pipeline processing exceptions
Collaborate with third-party vendors to triage and swiftly resolve issues
Who You Are
2+ years of relevant work experience in the financial investment/advisory industry with deep knowledge of capital markets.
Asset Reference Data- Understanding of various type financial instruments- Equities, Fixed Income, Derivatives and Currencies
Corporate Action (COAC)- Monitor, research and interpret different events impacting the asset
Understanding of pricing process and familiarity with Pricing data vendors
Technical skills preferred - Proficiency with SQL queries, Data mining projects or  Knowing Databricks application are an added advantage.
Excellent interpersonal skills and strong self-motivation needed to work efficiently in a global team
Experience in the financial investment/advisory industry with capital markets
Experience with ICE Data Feeds and Eikon/Refinitiv Workspace and similar data platforms is a plus
Expected to work in various shifts to support EMEA and NAM operations
Our Values 
Act Like an Owner - Think and operate with intention, purpose and care. Own outcomes.
Build Together - Collaborate to unlock the best solutions. Deliver lasting value. 
Champion Our Clients - Exceed client expectations. Our clients’ success is our success. 
Drive Innovation - Be bold and unconstrained in problem solving. Transform the industry. 
Embrace Learning - Engage our community to broaden our perspective. Bring a growth mindset. 
In addition to our core values, Addepar is proud to be an equal opportunity employer. We seek to bring together diverse ideas, experiences, skill sets, perspectives, backgrounds and identities to drive innovative solutions. We commit to promoting a welcoming environment where inclusion and belonging are held as a shared responsibility.
To ensure the health and safety of all Addepeeps and our prospective candidates, we have instituted a virtual interview and onboarding experience.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
PHISHING SCAM WARNING: Addepar is among several companies recently made aware of a phishing scam involving con artists posing as hiring managers recruiting via email, text and social media. The imposters are creating misleading email accounts, conducting remote “interviews,” and making fake job offers in order to collect personal and financial information from unsuspecting individuals. Please be aware that no job offers will be made from Addepar without a formal interview process. Additionally, Addepar will not ask you to purchase equipment or supplies as part of your onboarding process. If you have any questions, please reach out to TAinfo@addepar.com.",USD 67K - 110K *
183,Data Scientist,PayPal,IND - Karnataka - Bengaluru - Corp - Sarjapur Main Rd,Mid-level / Intermediate,"At PayPal (NASDAQ: PYPL), we believe that every person has the right to participate fully in the global economy. Our mission is to democratize financial services to ensure that everyone, regardless of background or economic standing, has access to affordable, convenient, and secure products and services to take control of their financial lives.
Job Description Summary:
What you need to know about the role:

PayPal’s Credit and Operational Risk Strategy (CORS) team is seeking a Data Scientist to support the Model Controls team responsible for managing the end to end approval process of models used across the credit lifecycle in the Global Credit Risk business within PayPal as well as performing ongoing model performance monitoring. The position needs to ensure that the Model Controls function follows the enterprise-wide Model Risk Management (MRM) standards and procedures and external regulatory guidance. These include reviewing statistical model constructs, guiding model developers and model owners in preparing model documentation per the MRM standards, ensuring that the models are approved by all Second Line oversight teams and conduct regular monitoring of model performance.

Meet our team:

PayPal’s Credit and Operational Risk Strategy (CORS) supports the greater Credit organization and is responsible for the management of the Risk Lifecycle activities, ensuring that the Credit organization’s risk is well managed and well controlled. The Controls organization implements control programs throughout the credit lifecycle such as Model Governance, Policy Governance, Issues Management, Testing & Monitoring and Reporting & Automation across all credit products.
Job Description:
Your way to impact:
You will be part of the Controls organization that is key to manage CORS’ model governance and monitoring process accurately and adequately as part of the larger PayPal risk management process.
You will be the critical resource who will be facilitating and helping in reviewing statistical model constructs, guiding model developers and model owners in preparing analyses and model documentation, ensuring that the models are approved by all Second Line oversight teams to make sure all the policy are adhered to and also conduct ongoing monitoring of models to evaluate model performance on a frequent basis.
Your day to day:
In your day to day role you will:
Independently manage the new model governance and monitoring process for all models spanning across the credit lifecycle used in Credit and Fraud Risk, Collections business as-well as CECL/IFRS-9 regulatory models.
Interface with all levels of management to present model approval status including model developers, model owners / users, partner banks, model oversight teams as well as other stakeholders in various forums.
Ability to negotiate to reach appropriate resolutions in varied situations without damaging internal or external partner relationships especially when any bottlenecks are encountered in model reviews.
Perform ongoing performance monitoring set up for credit models and understand the different statistical metrics and generate reports to be disseminated across the organization.
Conduct deep dives into performance monitoring results especially if any threshold breaches are observed.
Identify opportunities and lead efforts for automation of processes across the Controls organization.
What do you need to bring:
Bachelor / master’s degree in quantitative area strongly preferred – including mathematics, statistics, engineering, computer science, economics or finance
4+ years’ experience in model development or model validation / model risk management in consumer and/or business financing credit risk, good to have regulatory model experience.
Strong verbal and written communication skills along with stakeholder management with the ability to clearly articulate questions, provide senior management with relevant information and respond to any questions they may have.
Manage dialogue across multiple business units, functions, geographies, bank partners and second line teams.
Proficient in Python, SQL and have good understanding of statistical techniques used for model development including numerous Machine Learning algorithms.
Excellent written and oral communication skills as well as stakeholder management skills.
Team worker, responsible, delivery oriented.
Additional Job Description:
**We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don't hesitate to apply.
Subsidiary:
PayPal
Travel Percent:
0
Our Benefits:
At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.
We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com
Who We Are:
Click Here to learn more about our culture and community.

PayPal has remained at the forefront of the digital payment revolution for more than 20 years. By leveraging technology to make financial services and commerce more convenient, affordable, and secure, the PayPal platform is empowering more than 400 million consumers and merchants in more than 200 markets to join and thrive in the global economy. For more information, visit paypal.com.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.
Any general requests for consideration of your skills, please Join Our Talent Community.
As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated.",USD 126K - 198K *
184,Lead Data Scientist,Tide,"Hyderabad, Remote",Senior-level / Expert,"Department: Data Science
Who are Tide:
At Tide, we’re on a mission to save businesses time and money. We’re the leading provider of UK SME business accounts and one of the fastest-growing FinTechs in the UK. Using the latest tech, we design solutions with SMEs in mind and our member-driven financial platform is  transforming the business banking market. Not only do we offer our members business accounts and related banking services, but also a comprehensive set of highly connected admin tools for businesses. 
Tide is about doing what you love. We’re looking for someone to join us on our exciting scale up journey and be a part of something special. We are wanting passionate Tideans to drive innovation and help build a best-in-class platform to support our members. You will be comfortable in ambiguous situations and will be able to navigate the evolving FinTech environment. Imagine shaping how millions of Tide members discover and engage with business banking platforms and building this on a global scale. 
What we’re looking for:
Seasoned Lead Data Scientist that can build and embed intelligence into the products that deliver significant business value to Partnership credit services business vertical of Tide
As the Lead Data Scientist you’ll be:
Work closely with our Partnership Credit Services team in order to solve business problems that drive effective decisions for the business. This would be in areas of Lender Behaviour, Lead Priority Engine and Intelligence to match Lenders with Prospective Members 
Come up with High level road map for Data Science initiatives that can aid decisioning and improve Business Performance
Understand business requirements and solutionize data products in order to solve them
Identify creative solutions in order to build relevant training data sets
Train models and optimize hyperparameters
Work closely with our machine learn engineers and data engineers in order to productionize models
Come up with adoption of newer methods and methodologies 
Coach junior data scientists on best practices
What makes you a great fit:
You have 7+ years of experience in Software development or Machine Learning. Strong in Python
You have extensive experience working within financial services, especially Credit Services but not mandatory
You have extensive experience with Machine Learning tools - scikit-learn , TensorFlow, Keras or PyTorch
You have experience with big-data technologies such as Spark, SparkML, Hadoop etc. Strong knowledge of Cloud (AWS or other).
You have excellent leadership skills - you have managed a team of data scientists before and coached them to become better versions of themselves
You have excellent business acumen, you manage to translate business problems into data products 
You have excellent communication skills including the ability to explain statistical concepts and technical tradeoffs to business users
You have experience in training, optimising and deploying a variety of ML-algorithms, such as logistic regressions, boosted trees and neural networks
You’re a self-starter - you take initiative in spotting opportunities and finding ways to solve challenges with data
Ability to deal with ambiguity and competing objectives in a fast paced environment
Experience working in agile teams
Familiarity with basic data table operations (SQL etc.), data transform in warehouse (dbt etc.) and business intelligence softwares (eg. Looker)
Familiarity with model observability and explainability at scale
What you’ll get in return: 
Make work, work for you! We are embracing new ways of working and support flexible working arrangements. With our Working Out of Office (WOO) policy our colleagues can work remotely from home or anywhere in their assigned Indian state. Additionally, you can work from a different country or Indian state for 90 days of the year. Plus, you’ll get:
Competitive salary
Self & Family Health Insurance
Term & Life Insurance
OPD Benefits
Mental wellbeing through Plumm
Learning & Development Budget
WFH Setup allowance
15 days of Privilege leaves
12 days of Casual leaves
12 days of Sick leaves
3 paid days off for volunteering or L&D activities
Stock Options
Tidean Ways of Working 
At Tide, we’re Member First and Data Driven, but above all, we’re One Team. Our Working Out of Office (WOO) policy allows you to work from anywhere in the world for up to 90 days a year. We are remote first, but when you do want to meet new people, collaborate with your team or simply hang out with your colleagues, our offices are always available and equipped to the highest standard. We offer flexible working hours and trust our employees to do their work well, at times that suit them and their team.
Tide is a place for everyone
At Tide, we believe that we can only succeed if we let our differences enrich our culture. Our Tideans come from a variety of backgrounds and experience levels. We consider everyone irrespective of their ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status. We believe it’s what makes us awesome at solving problems! We are One Team and foster a transparent and inclusive environment, where everyone’s voice is heard.  
#LI-NN1 #LI-Remote",USD 56K - 172K *
185,Senior ML Engineer,Quantiphi,IN MH Mumbai Eureka,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Be(come) a Machine Learning expert and lend your skill set to solving tough business problems Interface with client companies to understand their business pain points and identify where data science and analytics can be the solution Develop high-level solution architectures and work with our offshore team to build, test, and assess models to predict and optimize business outcomes Work closely with the offshore delivery manager to ensure a seamless delivery and communication cadence Communicate complex concepts and insights in a clear and interpretable manner Maintain an entrepreneurial spirit as you learn new ways to solve problems
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 174K - 275K *
186,Staff / Sr. Staff Engineer - Big Data Engineering,Netskope,India,Senior-level / Expert,"About Netskope
Today, there's more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security. 
Since 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, St. Louis, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events (pre and hopefully post-Covid) and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive.  Visit us at Netskope Careers. Please follow us on LinkedIn and Twitter@Netskope.
About the role
Please note, this team is hiring across all levels and candidates are individually assessed and appropriately leveled based upon their skills and experience.
The Data Engineering team builds and optimizes systems spanning data ingestion, processing, storage optimization and more. We work closely with engineers and the product team to build highly scalable systems that tackle real-world data problems and provide our customers with accurate, real-time, fault tolerant solutions to their ever-growing data needs. We support various OLTP and analytics environments, including our Advanced Analytics and Digital Experience Management products.
What's in it for you
As part of the Digital Experience Management team, you will work on state-of-the-art, cloud-scale distributed systems at the intersections of networking, cloud security and big data. You will be part of designing and building systems that provide critical infrastructure for global Fortune 100 companies.
What you will be doing
Designing and implementing planet-scale distributed data platforms, services and frameworks including solutions to address high-volume and complex data collections, processing, transformations and analytical reporting
Working with the application development team to implement data strategies, build data flows and develop conceptual data models
Understanding and translating business requirements into data models supporting long-term solutions
Analyzing data system integration challenges and proposing optimized solutions
Researching effective data designs, new tools and methodologies for data analysis
Providing guidance and expertise to other developers on the effective implementation of data models, and building high throughput data access services
Providing technical leadership in all phases of a project, from discovery and planning through implementation and delivery.
Required skills and experience
8+ years experience in designing and coding scalable distributed systems
The ability to conceptualize and articulate ideas clearly and concisely
Experience in building big data pipelines that manage petabytes of data and ingest billions of data items every day.
Experience with big data analytics
Excellent algorithm, data structure, and coding skills with Python, Go, C++ and / or Rust
Proficiency in networking protocols and network security such as TCP/IP, TLS, IPSec/GRE, PKI, etc.
Experience coding with OSS like Kafka, Redis, and Clickhouse, as well as cloud infrastructure, ideally GCP
Excellent written and verbal communication skills
Bonus points for contributions to the open source community
Education
BSCS or equivalent required, MSCS or equivalent strongly preferred
#LI-SK1


Netskope is committed to implementing equal employment opportunities for all employees and applicants for employment. Netskope does not discriminate in employment opportunities or practices based on religion, race, color, sex, marital or veteran statues, age, national origin, ancestry, physical or mental disability, medical condition, sexual orientation, gender identity/expression, genetic information, pregnancy (including childbirth, lactation and related medical conditions), or any other characteristic protected by the laws or regulations of any jurisdiction in which we operate.
Netskope respects your privacy and is committed to protecting the personal information you share with us, please refer to Netskope's Privacy Policy for more details.",USD 45K - 84K *
187,"Lead Engineer, Database Engineering",TransUnion,Bengaluru,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
• Work with Application Development Teams, Project, Testing, and Release Managers, Architects, and IT Management to support fixes, enhancements, and projects.
• Design and develop database schema or evaluate and recommend changes for current or future databases using technical and functional documentation.
• Work with software developers to establish best practices for database storage and organization.
• Provide first-level applications support: Resolve problems and answer questions related to the databases, contact vendor support when necessary. Facilitate application development and client problem resolution with optimum speed and efficiency.
• Performance monitoring and tuning: Closely monitor performance; identify problems and implement solutions; ensure the databases are running at optimum speed and efficiency.
• Reorganize database structures as needed: Create automated processes; use tools to reorganize or defragment database table spaces, tables, and indexes; provide efficient database environment to maximize productivity and improve performance by evaluating system and database performance at regular interval.
• Facilitate application environments refreshes upon request: Help if required with data refresh from one environment to another at the request of the application development staff; define and develop pre, inflight and post execution tasks as necessary to accomplish this, including data masking, data conversion, etc. Provide application development staff with optimal development environment and current data.
• Work closely with Systems Programmers and Systems Administrators to ensure that the database system is operating in accordance with required system usage; help and guide in setting appropriate system parameters.
• Communicate complex technical information in a concise and articulate manner.
• Participate in the evaluation and recommendation of DBA tools and new DBMS technologies.
What You'll Bring:
Skills and Knowledge: • Thorough understanding of the relational and document (NoSQL) database model and solid theoretical knowledge of SQL and noSQL database techniques; skilled in ability to see the big picture and conceptualize and document creative solutions. • Extensive experience in logical and physical database design, hands-on data modeling techniques, and development methodology; physical schema design of table spaces, rollback segments, and data files • Clear understanding and knowledge of setting up NoSQL database cluster, documents collection, tuning indexes, sharding etc. • Excellent oral and written communications skills • Excellent planning, organizational, and time management skills. Ability to multi-task and work on multiple project assignments while under pressure • Ability to deal effectively with a wide variety of other company personnel, including technical personnel from other disciplines, IT Management, business users, outside vendors, and consultants. • Ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution • Extensive knowledge of SQL, PL/SQL programming and ways to optimize SQL code. • Hands on experience with either JavaScript, Python or Java to interact with NoSQL databases. • Ability to quickly learn, adapt to, implement, and migrate current RDBMS implementations to new open-source and cloud database environments. Experience: • Bachelor’s degree or better in Computer Science, Engineering or related discipline • 8+ years in-depth experience in developing, managing, and supporting Enterprise RDBMS databases. • 4+ years of developing and supporting applications for NoSQL (MongoDB) databases. • 3+ years operating knowledge of various UNIX environments, specifically RedHat and AIX • 3+ years using JavaScript, Python, Java, or equivalent programming language. • Hands-on experience with at least one UNIX shell scripting environment. • Demonstrated experience working well with customers of varying levels of technical expertise in high-pressure situations and complex environments. • Knowledge of application development languages such as Perl, PHP, Ruby, C, C++ desired
Impact You'll Make:
Knowledge of application development languages such as Perl, PHP, Ruby, C, C++ desired
TransUnion Job Title
Lead Engineer, Database Engineering",USD 45K - 84K *
188,Data Team Lead,IQVIA,"Kochi, India",Senior-level / Expert,"Job Overview
Manage end-to-end delivery of data management services for single/multi-service projects with minimal guidance, ensuring quality deliverables on time and within budget, to customer satisfaction. Provide comprehensive data management expertise to Clinical Data Management (CDM) team to provide high quality data management products that meet customer needs. Provide leadership to the team in the areas of project planning, execution, and close-out; financial management; communications; and milestone deliverables. Perform role of Data Team Lead (DTL). Comply with Good Clinical Practices (GCPs), applicable regulatory guidelines, SOPs, policies, and, where available, CDM guidance documents.
Essential Functions
Minimum 6 years of CDM experience with 1+ years of study lead experience is mandatory
• Client Management:
• Serve as primary point of contact for customer on data management deliverables
• With minimal guidance, provide project management expertise working with customer data managers, key decision makers, and internal team members to manage continuous process improvements, issue escalation, workload projections, and provide technical expertise
• With guidance, provide input for and perform direct negotiations with customer, e.g., timelines, financial, process, resources
• Maintain strong customer relationships
• Ensure open communications with customer and IQVIA management to manage and meet contractual obligations
• Service Management:
• Meet with Data Operations Coordinator (DOC) and/or Data Operations team members on a regular basis to ensure milestones meet timelines and quality deliverables
• Establish strong communications with Data Operations team, functional leads, project managers and all other stake holders
• With minimal guidance, support DM service delivery with comprehensive DM process and technical expertise in executing projects.
• Serve as the escalation point for unresolved data issues
• with guidance, work with client data managers, vendors, internal team members for resolution
• Work with functional manager(s) to ensure appropriate resources are assigned to meet project deliverables
• With guidance, create and/or review and sign-off on all data management plan (DMP) documents
• Implement proactive quality management plan. Identify any service and quality issues with agreed upon specifications per the DMP and contract/SOW and work with functional manager(s) to resolve
• With guidance, track service performance and provide leadership to identify root causes of issues and implement remedial actions
• Continuously look for opportunities to improve efficiency of tasks and quality of deliverables
• Identify compliance issues and work with functional manager(s) to ensure timely follow-up and resolution
• With guidance, maintain internal tracking databases and systems
• Financial Management/Business Development Support:
• With guidance, ensure service and quality meet agreed upon timelines and deliverables in contract/Scope of Work (SOW)
• Manage SOW/budget
• Review financial reports on a monthly basis and participate in project reviews as requested
• Identify out of scope tasks and track change orders to completion
• With guidance, may serve as Project Manager for single service DM projects, including financial tracking, revenue recognition, and invoicing
• With guidance, participate in and support RFP process (review RFP documents, pricing, attend bid defense)
• Other:
• Provide input on DM process improvements or project solutions to CDM team/CDM department
• Provide input on the development and implementation of a new technology or tool
• Participate in a focus team or global or local best practice team
• Perform other duties as directed by functional manager(s)
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com",USD 45K - 84K *
189,EY - GDS Consulting - D&A - AWS Data Engineer - Senior,EY,"Chennai, TN, IN, 600032",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        EY-Consulting - Data and Analytics – Senior – AWS
EY's Consulting Services is a unique, industry-focused business unit that provides a broad range of integrated services that leverage deep industry experience with strong functional and technical capabilities and product knowledge. EY’s financial services practice provides integrated Consulting services to financial institutions and other capital markets participants, including commercial banks, retail banks, investment banks, broker-dealers & asset management firms, and insurance firms from leading Fortune 500 Companies. Within EY’s Consulting Practice, Data and Analytics team solves big, complex issues and capitalize on opportunities to deliver better working outcomes that help expand and safeguard the businesses, now and in the future. This way we help create a compelling business case for embedding the right analytical practice at the heart of client’s decision-making.
  The opportunity
We’re looking for Senior – Cloud Experts with design experience in Bigdata cloud implementations.
  Your key responsibilities
 AWS
Experience with Kafka, Flume and AWS tool stack such as Redshift and Kinesis are preferred.
Experience building on AWS using S3, EC2, Redshift, Glue,EMR, DynamoDB, Lambda, QuickSight, etc.
Experience in Pyspark/Spark / Scala
Experience using software version control tools (Git, Jenkins, Apache Subversion)
AWS certifications or other related professional technical certifications
Experience with cloud or on-premise middleware and other enterprise integration technologies
Experience in writing MapReduce and/or Spark jobs
Demonstrated strength in architecting data warehouse solutions and integrating technical components
Good analytical skills with excellent knowledge of SQL.
4+ years of work experience with very large data warehousing environment
Excellent communication skills, both written and verbal
7+ years of experience with detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools.
4+ years of experience data modelling concepts
3+ years of Python and/or Java development experience
3+ years’ experience in Big Data stack environments (EMR, Hadoop, MapReduce, Hive)
Flexible and proactive/self-motivated working style with strong personal ownership of problem resolution.
Excellent communicator (written and verbal formal and informal).
Ability to multi-task under pressure and work independently with minimal supervision.
Strong verbal and written communication skills.
Must be a team player and enjoy working in a cooperative and collaborative team environment.
Adaptable to new technologies and standards.
.
Skills and attributes for success
Use an issue-based approach to deliver growth, market and portfolio strategy engagements for corporates
Strong communication, presentation and team building skills and experience in producing high quality reports, papers, and presentations.
Experience in executing and managing research and analysis of companies and markets, preferably from a commercial due diligence standpoint.
Exposure to tools like Tableau, Alteryx etc.
  To qualify for the role, you must have
BE/BTech/MCA/MBA
Minimum 4+ years hand-on experience in one or more key areas.
Minimum 7+ years industry experience
  What we look for
A Team of people with commercial acumen, technical experience and enthusiasm to learn new things in this fast-moving environment
An opportunity to be a part of market-leading, multi-disciplinary team of 1400 + professionals, in the only integrated global transaction business worldwide.
Opportunities to work with EY Consulting practices globally with leading businesses across a range of industries
  What working at EY offers
At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
  Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you
        EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 45K - 84K *
190,Data Analyst - Digital Health,Alcon,Bengaluru - AGS,Mid-level / Intermediate,"Key Responsibilities
Collect and analyze large data sets to identify trends and insights that inform business decisions  
Collaborate with cross-functional teams to develop and implement data-driven solutions that improve business outcomes
Develop dashboards and reports to communicate findings and insights to stakeholders.
Build and maintain databases and data systems to ensure accuracy and accessibility of information for analytics
Creates and modifies computer programs to extract information from company databases
Identify opportunities to improve data collection and analysis processes and make recommendations to optimize workflows
Foster a culture of creativity, collaboration, speed, innovation, and engineering excellence.  
Key Requirements/Qualifications
Minimum Qualifications
Bachelor’s degree in statistics, data science, or a related technical discipline.
2+ years of hands-on experience in data preparation and analysis of large-scale datasets.
2+ years of experience in Dashboard/BI and Data visualization tools (eg. Tableau, Quicksight, power BI)
2+ year of health care and health care data
Proficient in SQL, Python, R and Excel  
Strong analytical and problem-solving skills, with attention to detail and accuracy.
Thrives in dynamic, cross-functional team environments. Possesses a team-first mindset, valuing diverse perspectives and contributing to a collaborative work culture.
Approaches challenges with a positive and can-do attitude. Willing to challenge the status quo, demonstrating ability to understand when and how to take appropriate risks to drive performance.
Strong communication and collaboration skills to deliver business solutions   
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 67K - 110K *
191,Sr. Data Scientist,Highspot,India - Hyderabad,Senior-level / Expert,"About Highspot
Highspot is pioneering the category that is fundamentally changing the way companies increase sales productivity. On a mission to transform the way millions of people work with sales enablement, Highspot is committed to building breakthrough software with a spark of magic. We believe a great place to work is about more than the work – it’s about what the company stands for, and how it authentically represents its values in the real world. To this end, we have put intentional focus on creating equitable workspaces for each of our employees. Our goal is to create a culture where everyone feels a deep sense of belonging and is empowered to be an agent of change, with the ability to transform themselves, their workplace, and their world.

About The Role
We are looking for a skilled and passionate Data Scientist with experience working within the entire analytics lifecycle. As a Senior Data Scientist, you will be responsible for analyzing large and complex data sets to identify patterns, create new metrics, develop predictive models, build dashboards, and generate insights that drive business decisions. You will lead high-visibility high-impact projects and work closely with a skilled and diverse group of domain experts, company leaders, software engineers, data analysts, data engineers, and beyond. 
What You'll Do
Analyze core business topics using Highspot’s product and business data (such as user behavior on the Highspot platform, customer health, and the operations of our internal teams) to gain insights that will drive product development and enhance platform effectiveness. 
Partner with cross-functional teams and identify opportunities where statistics, machine learning, and operations research techniques can be used to make a significant impact and then design, develop, deploy and monitor those solutions. 
Partner with our Data Engineering team to conceptualize data pipelines that can extract data and insights for daily business management in an automated manner. 
Define top-level business, team, and product metrics and build automated reports in close coordination with cross-functional stakeholders. 
Cultivate a nuanced understanding of Highspot's data and lead research to uncover new opportunities for analytics within Highspot’s product and business. 
Your Background
Advanced degree (MS, PhD) in Data Science, Computer Science, Artificial Intelligence, Statistics, or related quantitative fields. 
7+ years of experience using SQL to extract and transform complex structured and semi-structured data from a data warehouse (Snowflake, Postgres, Mongo etc).
3+ years of experience using Tableau to build impactful reports and dashboards.
7+ years of experience in Python and related analytics libraries to wrangle, visualize, analyze, and build statistical/Machine Learning models. 
7+ years of experience in designing, developing and deploying predictive models to address real-world business problems; relevant techniques include regression, classification, clustering, dimensionality reduction, ensemble methods, recommender systems, and linear/integer programs. 
5+ years of experience using git to version control code and collaborate with other Data Scientists and Engineers on projects. 
3+ years of experience working with AWS cloud technology. 
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and solving impactful business problems. 
Excellent written and verbal communication skills to explain complex research to technical and non-technical audiences and to publish insights from your work. 
Driven by empathy to support, learn, and contribute to a team’s success.
Prior experience working remotely with a team based in the U.S. is preferred.
#LI-SG1

Equal Opportunity Statement
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of age, ancestry, citizenship, color, ethnicity, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or invisible disability status, political affiliation, veteran status, race, religion, or sexual orientation.

Did you read the requirements as a checklist and not tick every box? Don't rule yourself out! If this role resonates with you, hit the ‘apply’ button.",USD 136K - 205K *
192,Data Scientist - Image Processing,Philips,Pune - Pimpri PIL,Senior-level / Expert,"Job Title
Data Scientist - Image Processing
Job Description
Overall responsibilities
Ability to solve complex problems in medical image processing and deliver PoC with TRL level ready for NPI program with expert guidance.
Support collaboration with clinical scientists, AD leader and universities to drive advanced development projects on medical image analytics from R&D perspective.
Support NPI development and address time-pressing complex LCM challenges with image processing / IQ using expertise.
Mentor and guide less experienced engineers from the team. Higher degree of learning attitude to absorb newer knowledge on medical image pre- and / or post-processing.
Specific responsibilities
Specialization (hands-on work) in some of the following tools, packages, technical areas and modeling techniques:
Keras, Tensorflow, Pytorch, Scikit-learn, Scikit-image, OpenCV, pydicom
Matlab, python, R, Java/C/C++
Convolution Neural Networks, other statistical modeling & classification approaches (regression, SVM, PCA)
Opensource medical image visualization and segmentation tools like ITK, VTK
Medical image pre-processing techniques such as gain/offset correction, defect correction, EMI/EMC correction, grid correction and calibration depending on detector physics. Knowledge of overall IQ (image quality) analysis of diagnostic X-ray images is a plus.
Medical image post-processing techniques such as noise reduction, contrast enhancement, bone suppression, stitching, ranging. Knowledge of overall IQ (image quality) analysis of diagnostic X-ray images is a plus.
About Philips
We are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help the lives of others.
• Learn more about our business.
• Discover our rich and exciting history.
• Learn more about our purpose.
#LI-EU
#LI-Hybrid",USD 126K - 198K *
193,Digital Health Data Engineering Manager,Alcon,Bengaluru - AGS,Mid-level / Intermediate,"Key Responsibilities
Design, develop and operationalization of a reusable and modular data & analytics platform building upon Alcon’s enterprise IT architecture that enables efficient, consistent, automated value generation from data.
Partner with data architects to develop technical architectures for the data and analytic products.
Build, manage, and mentor a team of high-performing data engineers.
Advise, consult, mentor and coach other data and analytic professionals on data standards and best practices for data governance, data management, and data quality assurance for Digital Health.
Participate in Backlog grooming, Spring Planning and effort estimation.
Perform data modeling, data analysis and providing insights using various tools.
Evaluate, implement and deploy emerging tools and process for data engineering and analytics improve the productivity.  
Foster a culture of creativity, collaboration, speed, innovation, and engineering excellence.  
Manage relationships with third-party technology vendors and data providers to ensure data quality, accuracy, and security.
Key Requirements/Qualifications
Minimum Qualifications
Bachelor’s degree in computer science, data science, or a related technical discipline.
Over 2 years of leadership experience in data and software engineering, demonstrating a proven track record of successfully leading data engineering teams in an Agile/Scrum environment throughout the Software Development Life Cycle (SDLC)
5+ years of hands-on experience in developing data-intensive solutions on AWS, Azure, or GCP for analytics workloads.
3+ years of experience in designing both ETL/ELT for batch processing and data streaming architectures for real-time or near real-time data ingestion and processing.
3+ years of hands-on experience in two or more database technologies (e.g., MySQL, PostgreSQL, MongoDB) and data warehouses (e.g., Redshift, BigQuery, or Snowflake), as well as cloud-based data engineering technologies (e.g., Kafka, PubSub, Apache Airflow, Glue)
5+ years of experience in programming in python, scala or java
Proficient in Dashboard/BI and Data visualization tools (eg. Tableau, Quicksight)
Experience in data privacy and data security-related regulatory requirements, such as HIPAA, GDPR, CCPA, FDA cybersecurity for medical devices, and related security frameworks (e.g., ISO, NIST, HITRUST, SOC II).
Thrives in dynamic, cross-functional team environments. Possesses a team-first mindset, valuing diverse perspectives and contributing to a collaborative work culture.
Approaches challenges with a positive and can-do attitude. Willing to challenge the status quo, demonstrating ability to understand when and how to take appropriate risks to drive performance. 
A passionate problem solver.
High learning agility
 Preferred Qualifications:
Experience in various interoperability data standards in healthcare (e.g., HL7, FHIR, c-CDA, DICOM).   
Experience in building software as a medical device (SaMD), Quality Management System (QMS), and knowledge of ISO-13485, 62304, 21 CFR part 11/820 standards.
Experience in EMR and PACS integration
Experience in MLOps tools (eg. Sagemaker, Vertex AI)
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 90K - 151K *
194,Senior ML Engineer,GoDaddy,India,Senior-level / Expert,"Location Details: India, Remote
At GoDaddy the future of work looks different for each team. Some teams work in the office full-time; others have a hybrid arrangement (they work remotely some days and in the office some days) and some work entirely remotely.
Remote: This is a remote position, so you’ll be working remotely from your home. You may occasionally visit a GoDaddy office to meet with your team for events or meetings.  
Join our Team
At GoDaddy, we are on a mission to revolutionise how small businesses succeed in the digital world. That's why we are thrilled to announce our groundbreaking project: creating a cutting-edge Generative AI infrastructure that will house the largest and most advanced language models ever seen. Imagine being at the forefront of groundbreaking technology, hosting LLMs (large language models), and providing scalable solutions for millions of customers. This position offers the chance to work with world-renowned tools such as OpenAI, AWS Bedrocks, and Azure AI, pushing the boundaries of what is possible. This powerful tool will empower our teams to develop even more innovative products and give small businesses the ability to thrive like never before. Get ready to experience a whole new level of business success with GoDaddy!
Are you interested in learning and growing your skills in Machine Learning and AI? If so, this is the role for you!
What you'll get to do...
Develop and maintain an ML feature store for use across GoDaddy plus the data and, model pipelines
Partner with teams across the company on applications that require ML solutions
Collaborate with a team of experts, including machine learning scientists, to enhance the performance of our services through Prompt Engineering and LLM model fine-tuning
Design and implement improvements to our batch and real-time data streams that feed the feature store
Collaborate on a high-impact, mission-driven Scrum team
Participate in DevOps, release, and on-call activities in support of your code
Contribute to technology working groups and internal open-source
Your experience should include...
5+ years of experience in developing and deploying production software
Experience working with Amazon Web Services (AWS)
Experience with building APIs - RESTful APIs, Web Services with a strong understanding of Microservices architecture
We've got your back...  We offer a range of benefits that may include paid time off, retirement savings (e.g., 401k, pension schemes), incentive eligibility, equity grants, participation in an employee stock purchase plan, and other family-friendly benefits including parental leave. GoDaddy’s benefits vary based on individual role and location and can be reviewed in more detail during the interview process.   
We also embrace our diverse culture and offer a range of Employee Resource Groups (Culture). Have a side hustle? No problem. We love entrepreneurs! Most importantly, come as you are and make your own way. 
About us...  GoDaddy is empowering everyday entrepreneurs around the world by providing the help and tools to succeed online, making opportunity more inclusive for all. GoDaddy is the place people come to name their idea, build a professional website, attract customers, sell their products and services, and manage their work. Our mission is to give our customers the tools, insights, and people to transform their ideas and personal initiative into success. To learn more about the company, visit About Us. 
At GoDaddy, we know diverse teams build better products—period. Our people and culture reflect and celebrate that sense of diversity and inclusion in ideas, experiences and perspectives. But we also know that’s not enough to build true equity and belonging in our communities. That’s why we prioritise integrating diversity, equity, inclusion and belonging principles into the core of how we work every day—focusing not only on our employee experience, but also our customer experience and operations. It’s the best way to serve our mission of empowering entrepreneurs everywhere, and making opportunity more inclusive for all. To read more about these commitments, as well as our representation and pay equity data, check out our Diversity and Pay Parity annual report which can be found on our Diversity Careers page. 
GoDaddy is proud to be an equal opportunity employer. GoDaddy will consider for employment qualified applicants with criminal histories in a manner consistent with local and federal requirements. Refer to our full EEO policy.
Our recruiting team is available to assist you in completing your application. If they could be helpful, please reach out to myrecruiter@godaddy.com. 
GoDaddy doesn’t accept unsolicited resumes from recruiters or employment agencies.",USD 174K - 275K *
195,Data Quality Lead,Elsevier,India-Bengaluru (Helios Business Park),Senior-level / Expert,"Data Quality Lead
Elsevier’s unparalleled collection of data about research is the lifeblood of our business. The scientific community rely on this to keep them appraised of developments in their field, quantify the impact of their work, identify opportunities for collaboration, and discover avenues for new research. The products we build on top of our data enable researchers to work smarter and to deliver high-quality outcomes more quickly.
Our products are only as good as the data that drives them, and we are looking for an innovative and passionate technical Data Quality Lead to help us ensure that the data we hold is as high-quality as the research we publish. You will lead a small team to investigate data quality issues wherever they occur, rapidly build lightweight systems to identify and monitor quality across our systems, and drive improvements to raise the quality bar for the data we process.
You will be:
• Leading a small, tight-knit data quality team to identify, investigate, and resolve data quality issues wherever they occur across our platform
• Working hands-on to design and build tools to measure and ensure the quality of the data in our systems and in our data products
• Raising standards across the group by demonstrating and championing best-practices for ensuring data quality
Our requirements:
• A passionate engineer with a minimum of five years industrial experience on server-side applications
• Excellent programming skills on the JVM, and some experience or interest in Python
• Comfortable both with analysing data at scale with rapid analysis and visualisation tools such as notebooks, and with building robust and reliable enterprise systems to monitor data quality
• Excellent communications skills, comfortable building consensus and driving change across a diverse set of stakeholders
• An advocate of agile practices for rapid development of quality software
• Comfortable learning new technologies, languages, and tools on the job
• An inclusive, positive, collaborative mindset and a desire to deliver real business value to our customers
Nice to have:
• Some interest in or experience of data quality engineering
• Some interest in or experience of big data technologies
• Some experience of data science and testing machine learning models
About us:
We are committed to building cohesive teams where communication, support and innovation thrive. Instead of taking a top-down approach to new ideas, all members of the team are empowered to contribute. Great ideas can come from anywhere.
We’re a truly global company with direct colleagues in all regions of the world. We are expanding our capabilities and offer a stimulating environment, enabling bright, passionate people to do their best work.
Elsevier is a global information analytics company that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity.
Elsevier empowers professionals and institutions to realize the potential of information to improve academic, corporate, and clinical performance, expand human knowledge, and generate positive—often groundbreaking—outcomes in critical domains
-----------------------------------------------------------------------
Elsevier is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. We are committed to providing a fair and accessible hiring process. If you have a disability or other need that requires accommodation or adjustment, please let us know by completing our Applicant Request Support Form: https://forms.office.com/r/eVgFxjLmAK .
Please read our Candidate Privacy Policy.",USD 45K - 84K *
196,Digital Health Data Engineer,Alcon,Bengaluru - AGS,Mid-level / Intermediate,"Key Responsibilities
Design, develop and operationalization of a reusable and modular data & analytics platform building upon Alcon’s enterprise IT architecture that enables efficient, consistent, automated value generation from data.
Partner with data architects to develop technical architectures for the data and analytic products.
Advise, consult, mentor and coach other data and analytic professionals on data standards and best practices for data governance, data management, and data quality assurance for Digital Health.
Participate in Backlog grooming, Spring Planning and effort estimation.
Perform data modeling, data analysis and providing insights using various tools.
Evaluate, implement and deploy emerging tools and process for data engineering and analytics improve the productivity.  
Foster a culture of creativity, collaboration, speed, innovation, and engineering excellence.  
Key Requirements/Qualifications
Minimum Qualifications
Bachelor’s degree in computer science, data science, or a related technical discipline.
2+ years of hands-on experience in developing data-intensive solutions on AWS, Azure, or GCP for analytics workloads.
2+ years of experience in designing both ETL/ELT for batch processing and data streaming architectures for real-time or near real-time data ingestion and processing.
2+ years of hands-on experience in two or more database technologies (e.g., MySQL, PostgreSQL, MongoDB) and data warehouses (e.g., Redshift, BigQuery, or Snowflake), as well as cloud-based data engineering technologies (e.g., Kafka, PubSub, Apache Airflow, Glue)
3+ years of experience in programming in python, scala or java
Proficient in Dashboard/BI and Data visualization tools (eg. Tableau, Quicksight)
Thrives in dynamic, cross-functional team environments. Possesses a team-first mindset, valuing diverse perspectives and contributing to a collaborative work culture.
Approaches challenges with a positive and can-do attitude. Willing to challenge the status quo, demonstrating ability to understand when and how to take appropriate risks to drive performance. 
A passionate problem solver.
High learning agility
 Preferred Qualifications:
Experience in data privacy and data security-related regulatory requirements, such as HIPAA, GDPR, CCPA, FDA cybersecurity for medical devices, and related security frameworks (e.g., ISO, NIST, HITRUST, SOC II).
Experience in various interoperability data standards in healthcare (e.g., HL7, FHIR, c-CDA, DICOM).   
Experience in EMR and PACS integration
Experience in MLOps tools (eg. Sagemaker, Vertex AI)
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 90K - 151K *
197,Data Analyst,AllianceBernstein,"Pune, India",Mid-level / Intermediate,"Company Description:
As a leading global investment management firm, AB fosters diverse perspectives and embraces innovation to help our clients navigate the uncertainty of capital markets. Through high-quality research and diversified investment services, we serve institutions, individuals, and private wealth clients in major markets worldwide. Our ambition is simple: to be our clients’ most valued asset-management partner.
Group Description:
AB is looking for a strong candidate to help grow the use of data analytics within the Internal Audit (IA) Department. The role supports all groups within the audit department and includes the use of various analytic techniques and technologies to automate control testing, isolate anomalies of interest, and gain efficiencies within the audit department and with our auditees. The ideal candidate will have a hybrid of audit, data analytics, and database/developer experience.
Specific Responsibilities:
Develop sustainable and re-useable Data Analytics models and programs to improve the efficiency of control testing. Support audit delivery teams with the identification and delivery of analytics solutions. • Provide training to audit staff on how to develop and execute basic analytics programs. Maintain a library of re-usable data analytics programs and functional specifications. Establish an automated framework to periodically collect, clean, and test datasets from a variety of platforms and applications.  Build self-service tools/dashboards/warehouse/data lakes. Maintain common data used by audit teams. Identify, design, develop, and document analytics that will support audit testing, continuous auditing, continuous monitoring, automation, and fraud identification. Act as a business analyst to collect requirements for audit reviews through interaction with the auditors and assist in building test casts. Create script analytic routines that can be pushed to business partners to maximize return on investment. Build productive relationships with internal audit team members, peers, data owners and IT to ensure proactive availability of data to encourage the development of new analytics within the company.
What makes this role unique or interesting (if applicable)?
Obtain a wholistic understanding of multiple technologies, systems and platforms utilized by AB.
Exposure to AB’s top management and the ability to influence change and mitigate risk across the entire organization.
Learn a variety of technologies in order to test and remediate risks associated with those technologies.
Qualifications, Experience, Education:
This position requires:
Bachelor's (or higher) degree in Accounting, Computer Science, Statistics, Mathematics, Economics, Engineering, Decision Sciences, Data Sciences or related field
2+ years of relevant experience preferably in Internal Audit or other control function.
Advanced MS Excel skills (e.g. pivot tables, vlookups, VBA, etc.)
Proficient with in one or more programming languages (e.g. VBA, SQL, Powershell, Python, R, etc.)
Proficient with common toolsets used for data analysis (e.g. ACL, Tableau, Looker, MS Access, etc.)
Excellent interpersonal and communication skills essential
Experience with leveraging cloud technologies (e.g. Azure, AWS) for data analysis is a plus.
Pune, India",USD 67K - 110K *
198,Senior Data Scientist,Cyara,"Ahmedabad, Gujarat",Senior-level / Expert,"Cyara is the world’s leading Automated CX Assurance Platform provider, enabling leading brands across the globe to build better customer experiences faster. Through automated testing and monitoring, Cyara accelerates the delivery of flawless customer journeys across digital and voice channels while reducing the risk of customer-facing defects. Every day the most recognizable brands, including Airbnb, Tesla, and NAB trust Cyara to deliver customer smiles at scale.  Our promise is Customer Smiles - Delivered at Scale, and as a member of Cyara’s team, you’ll be given the opportunity to bring that mission to fruition alongside our amazing community of fun-loving forward thinkers.  Interested to find out more about us?  Check out:  www.cyara.comWant to know what it’s really like to join Cyara?  Check out this link to meet some real Cyaran’s and read about their individual career journey with us:  https://cyara.com/employee-profiles/
Why you should join us: 
At Cyara you’ll have the opportunity to work with a group of people who share common goals, are driven by a similar passion, and value the expertise of their peers. Cyara is committed to being an  equal opportunity employer, focused on building and maintaining a diverse, inclusive and authentic workplace; and a work environment that is free from discrimination and harassment, based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy. At Cyara we appreciate and welcome the fact that our culture is living and growing as we continue to evolve over time. With this opportunity comes the chance to enjoy a flexible work environment, competitive compensation and a work culture that's results-oriented, fast-paced and focused on continuous improvement, whilst maintaining a family first, team oriented, and ever positive atmosphere.

Cyara cares for its own - you’ll feel that on your first day - and you'll get the chance to work for a global, growing company, and an all-inclusive team of innovators.  We credit our amazing growth and success to the fact that we’ve built our business on four essential values that we live and breathe every day: 

Deliver Excellence
Innovate Boldly
Integrity First
Embrace Curiosity

Interested? Know someone who might be? Apply online now. 

Please note in order to apply for this role you must be based in the USA or Canada and hold all relevant work rights to allow you to live and work within the country this role is based, full time and without restriction.  Cyara are not offering sponsored Visas for this position. 

Cyara are a Global Circle Back Initiative Employer - we commit to respond to every applicant. 

Agencies: Thanks but we’ve got this one!  Please, no phone calls or emails to any employees of Cyara outside of the Talent Acquisition team.  Cyara’s policy is to only accept resumes from Agencies via the Cyara Agency Portal. Agencies must have a valid fee agreement in place and they must have been assigned the specific requisition to which they submit resumes, by the Cyara Talent Acquisition team before submitting any CV's. Any resume submitted outside of this process will be deemed the sole property of Cyara and, in the event, a candidate is submitted outside of this policy is hired, no fee or payment of any kind will be paid",USD 136K - 205K *
199,DW MSBI Developer,Sutherland,"Hyderabad, India",Senior-level / Expert,"Job Description
Primary Skills                    : Strong SQL/PL SQL Development,
Secondary Skills               : DWH/BI Development, any 1 ETL Tool (SSIS), DWH/BI Testing 
 Required Skills:
Overall 4+ years of successful Data Warehouse and/or Business Intelligence (Prefer MSBI) testing experience with large scale data systems 
Must have experience in Microsoft Business Intelligence & Power BI testing, automation experience is a plus 
Experience working with various Microsoft BI and Power BI tools – SSIS, SSAS, and SSRS 
Experience in writing complex SQL statements and deep understanding of various SQL stored procedures 
Hands on experience testing ETL jobs and business and transformation logic 
Thorough understanding of data warehouse and BI concepts including data modelling, multi-dimensional cubes, scripting knowledge of MDX/DAX is required 
Experience with Testing SSRS, SSAS, Tabular-based reporting, and Tabular Data Models 
Strong troubleshooting and fist-level debugging skills 
Hands on experience with one or more test management tools such as HP-ALM, MSTM etc. 
Good experience in test planning, test strategy, test methodology, scope analysis, test assessment, effort estimation, root cause analysis, best practices, and test closure reports etc. 
Good in System, Functional, SIT, Integration & UAT testing 
Highly motivated and resourceful self-starter with a positive, team-focused attitude 
  Additional Information
All your information will be kept confidential according to EEO guidelines.",USD 106K - 140K *
200,Data Quality Analyst,Elsevier,India-Bengaluru (Helios Business Park),Entry-level / Junior,"Data Quality Analyst
Elsevier’s unparalleled collection of data about research is the lifeblood of our business. The scientific community rely on this to keep them appraised of developments in their field, quantify the impact of their work, identify opportunities for collaboration, and discover avenues for new research. The products we build on top of our data enable researchers to work smarter and to deliver high-quality outcomes more quickly.
Our products are only as good as the data that drives them, and we are looking for an innovative and passionate technical Data Quality Analyst to help us ensure that the data we hold is as high-quality as the research we publish. You will work as part of a small team to investigate data quality issues wherever they occur, and will deliver improvements to our processes and systems to raise the quality bar for the data we process.
You will be:
Work as part of a small, tight-knit data quality team to identify, investigate, and resolve data quality issues wherever they occur across our platform
Raising standards across the group by demonstrating best-practices for ensuring data quality
Designing and building tools to measure and ensure the quality of the data in our systems and in our data products
Our requirements:
A passionate engineer with a minimum of three years industrial experience on server-side applications
Strong programming skills either on the JVM or in Python
Strong analytical skills and understanding of statistical tests
Experience with data analysis at scale using rapid analysis and visualisation tools such as notebooks, SQL, and Python
Comfortable learning new technologies, languages, and tools on the job
An inclusive, positive, collaborative mindset and a desire to deliver real business value to our customers
Nice to have:
Some interest in or experience of data quality engineering
Some interest in or experience of big data technologies
About us:
We are committed to building cohesive teams where communication, support and innovation thrive.  Instead of taking a top-down approach to new ideas, all members of the team are empowered to contribute. Great ideas can come from anywhere. 
We’re a truly global company with direct colleagues in all regions of the world.  We are expanding our capabilities and offer a stimulating environment, enabling bright, passionate people to do their best work. 
Elsevier is a global information analytics company that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity.  
Elsevier empowers professionals and institutions to realize the potential of information to improve academic, corporate, and clinical performance, expand human knowledge, and generate positive—often groundbreaking—outcomes in critical domains of human endeavor. 
-----------------------------------------------------------------------
Elsevier is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. We are committed to providing a fair and accessible hiring process. If you have a disability or other need that requires accommodation or adjustment, please let us know by completing our Applicant Request Support Form: https://forms.office.com/r/eVgFxjLmAK .
Please read our Candidate Privacy Policy.",USD 65K - 95K *
201,Data Analyst,Target,"Bengaluru,India",Entry-level / Junior,"Target is an iconic brand, a Fortune 50 company and one of America’s leading retailers.
Behind one of the world’s best-loved brands is a uniquely capable and brilliant team of data scientists, engineers and analysts. The Target Data Science & Analytics team creates the tools and data products to sustainably educate and enable our business partners to make great data-based decisions. We help develop the technology that personalizes the guest experience, from product recommendations to relevant ad content. We are also the source of the data and analytics behind Target’s Internet of Things (IOT) applications, fraud detection, Supply Chain optimization and demand forecasting. We play a key role in identifying the test-and-measure or A/B test opportunities that continuously help Target improve the guest experience, whether they love to shop in stores or at Target.com.
A role with Data Science and Analytics (DSA) means being a part of the team that works closely with the business and identifies problems / opportunities for improved decision-making through better data analysis. This covers the whole gamut from simple descriptive analysis to more complex predictive and prescriptive analytics, using advanced modeling and machine learning techniques primarily using open source technologies and big data platforms. The emphasis is on actionable insights, which is possible through a combination of technical skills and business understanding.
As Data Analyst, DSA you will work closely with business/product teams and understand their priorities/roadmap. Based on this understanding, you are expected to identify appropriate metrics that will drive the right decisions for the business, and then build reporting solutions to deliver these metrics at the required frequency in an optimal and reliable fashion. You will also answer ad-hoc questions from your business users by conducting quick analysis on relevant data, identify trends and correlations, and form hypotheses to explain the observations. Some of these will lead to bigger analytical projects of increasing complexity, where you will work initially as a part of a bigger team, but also work independently as you gain more experience. Finally, you are expected to always adhere to project schedule and technical rigor as well as requirements for documentation, code versioning, etc.
Core responsibilities are described within this job description. Job duties may change at any time due to business needs.
Role is about being passionate about data, analysis, metrics development, feature experimentation and its application to improve both business strategies, as well as  support to GSCL operations team
Develop, model and apply analytical best practices while upskilling and coaching others on new and emerging technologies to raise the bar for performance in analysis by sharing with others (clients, peers, etc.) well documented analytical solutions .
Drive a continuous improvement mindset  by seeking out new ways to solve problems through formal trainings, peer interactions and industry publications to continually improve technically, implement best practises and analytical acumen 
Be expert in specific business domain, self-directed and drive execution towards outcomes, understand business inter-dependencies, conduct detailed problem solving, remediate obstacles, use independent judgement and decision making to deliver as per product scope, provide inputs to establish product/ project timelines
Participate in learning forums, or be a buddy to help increase awareness and adoption of current technical topics relevant for analytics competency e.g. Tools (R, Python); exploratory & descriptive techniques ( basic statistics and modelling)
Champion participation in internal meetups, hackathons; presents in internal  conferences, relevant to analytics competency
Contribute the evaluation and design of relevant technical guides and tools to hire great talent by partnering with talent acquisition
Participate in Agile ceremonies to keep the team up-to-date on task progress, as needed
Develop and analyse data reports/Dashboards/pipelines, do RCA and troubleshooting of issues that arise using exploratory and systemic techniques
About you:
B.E/B.Tech (2-3 years of relevant exp), M.Tech, M.Sc. , MCA (+2 years of relevant exp)
Candidates with strong domain knowledge and relevant experience in Supply Chain / Retail would be highly preferred
Strong data understanding inference of patterns, root cause, statistical analysis, understanding forecasting/predictive modelling, , etc.
Advanced SQL experience writing complex queries 
Hands on experience with analytics tools: Hadoop, Hive, Spark, Python, R, Domo and/or equivalent technologies 
Experience working with Product teams and business leaders to develop product roadmaps and feature development 
Able to support conclusions with analytical evidence using descriptive stats, inferential stats and data visualizations 
Strong analytical, problem solving, and conceptual skills.
Demonstrated ability to work with ambiguous problem definitions, recognize dependencies and deliver impact solutions through logical problem solving and technical ideations
Excellent communication skills with the ability to speak to both business and technical teams, and translate ideas between them
Intellectually curious, high energy and a strong work ethic 
Comfort with ambiguity and open-ended problems in support of supply chain operations",USD 53K - 94K *
202,Data Analyst,Innovaccer,"Noida, Uttar Pradesh, India",Entry-level / Junior,"Your Role
We are looking for a Data Analyst to join the Data Engineering team, who will be responsible for integrating data into our Data Activation Platform from customers’ clinical, claims, and other data sources, executing analytical jobs and powering up the Innovaccer suite of products. You will work closely with customers to build data and analytics solutions to support their business needs, and be the engine that powers the partnership that we build with them.
In this role, you will work closely with a team of Data Engineers, in collaboration with the Product & Engineering teams, to implement the entire end-to-end data and analytics workflows on completely cloud-based environments (AWS or Azure), that will support customer objectives.
You'll work with some of the brightest minds in the industry, work with one of the richest healthcare data sets in the world, use cutting-edge technology, and see your efforts affect products and people on a regular basis. 
A Day in the Life
Guide and mentor the team in best practices for handling the data.
Review and provide feedback before the deliverables are shared with the customer.
Play with and transform data.
Work towards creating easy-to-digest analytical reports for US healthcare customers.
Design and build interfaces that facilitate workflows between Data Activation Platform and client third party systems as scoped while complying with respective standards and industry best practices.
Define and document best practices along with thorough message specifications.
Monitor and tune the configuration of interfaces for high availability once deployed in production environments.
What You Need
1-4 years in an analytics role in data services/product firm.
Data modeling ability - knowledge of different data modeling concepts
Strong knowledge of SQL for ETL, knowledge of scripting languages like Python will be a plus
Self-starter, curious, accountable, enjoys a healthy level of autonomy, strong work ethic, able to succeed in a fast-paced, high-intensity startup environment.
Extensive experience relaying technical and non-technical information in a clear and concise manner
Demonstrated expert problem solving and analytical skills
Excellence in multitasking and managing multiple high-priority customer engagements at once
Ability to assess complex client requirements and arrive at integration solutions that will satisfy seamless experience between our platform and theirs
Competence to mentor junior team members and introduce industry expertise and best practices across data engineering
Bachelor’s degree in Engineering, Computer Science. Advanced degree in any of the areas above would be a plus
What We Offer
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications.
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic.
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists.
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered.  
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative.
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them. 
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments.
 ",USD 53K - 94K *
203,Data Engineer Lead,Bounteous,Chennai,Senior-level / Expert," About Bounteous ( https://www.bounteous.com/ )
Founded in 2003 in Chicago, Bounteous is a leading digital experience consultancy that co-innovates with the world's most ambitious brands to create transformative digital experiences. With services in Strategy, Experience Design, Technology, Analytics and Insight, and Marketing, Bounteous elevates brand experiences through technology partnerships and drives superior client outcomes. For more information, please visit www.bounteous.com
Preferred Qualifications
6+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field. 
Working knowledge of  ETL technology - Talend / Apache Ni-fi / AWS Glue
Experience with relational SQL and NoSQL databases
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Nice to have)
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. (Nice to have)
Experience with cloud services: EMR, RDS, Redshift or Snowflake
Experience with stream-processing systems: Storm, Spark-Streaming, etc.(Nice to have)
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
Work with Project Managers, Senior Architects and other team members from Bounteous & Client teams to evaluate data systems and project requirements 
In cooperation with platform developers, develop scalable and fault-tolerant Extract Transform Load (ETL) and integration systems for various data platforms which can operate at appropriate scale; meeting security, logging, fault tolerance and alerting requirements. 
Work on Data Migration Projects. 
Effectively communicate data requirements of various data platforms to team members 
Evaluate and document existing data ecosystems and platform capabilities 
Configure CI/CD pipelines 
Implement proposed architecture and assist in infrastructure setup 
We invite you to subscribe to our monthly and quarterly newsletters to stay up to date with the latest job openings as well as resources and tips for job seekers here.

Research shows that women and other underrepresented groups apply only if they meet 100% of the criteria of a job posting. If you have passion and intelligence, and possess a technical knack (even if you’re missing some of the above), we encourage you to apply.

Bounteous is focused on promoting an inclusive environment and is proud to be an equal opportunity employer. We celebrate the different viewpoints and experiences our diverse group of team members bring to Bounteous. Bounteous does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, physical or mental disability, national origin, veteran status, or any other status protected under federal, state, or local law.

In addition, you have the opportunity to participate in several Team Member Networks, sometimes referred to as employee resource groups (ERGs), that host space with individuals with shared identities, interests, and passions. Our Team Member Networks celebrate communities of color, life as a working parent or caregiver, the 2SLGBTQIA+ community, wellbeing, and more. Regardless of your respective identity, there are various avenues we involve team members in the Bounteous community.

Bounteous is willing to sponsor eligible candidates for employment visas.",USD 45K - 84K *
204,"Analyst, Business Intelligence",S&P Global,IN - HYDERABAD,Entry-level / Junior,"About the Role:
Grade Level (for internal use):
09
The Role: 
 
As an Analyst in Business Intelligence, you will be responsible for creating, maintaining, and reporting analytical, informative and actionable insights for the commercial organization to help drive sales.  
 
The Team:  
 
We are a truly global team with presence in United States, Pakistan, Philippines and India. You, along with your counterparts will be conceiving, building and maintaining insightful reports and work on projects that impact the whole commercial organization.  
 
The Impact:  
 
The Business Intelligence team provides actionable insight from commercial data in order for stakeholders to make informed decisions. Our stakeholders include Sales, Product and Finance orgs.  
 
What’s in it for you:  
 
Our Company prides itself on being an equal opportunity employer and results faced meritocracy. We set high standards and value accountability for all. At the same time, we seek to identify and reward extraordinary performance with growth opportunities. Based on planned growth & initiatives, you have an opportunity to emerge to more specialized roles and act as a resource for the team. 
 
Responsibilities: 
 
• Use CRM data to produce clear & insightful reports for sales performance. 
• Presenting information and insights using data visualization techniques. 
• Experience in Power BI, Tableau, CRM Analytics or similar BI tool is a plus. 
• Working with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.  
• Coordinate with different functional teams to implement models and monitor outcomes. 
• Keep existing reporting up to date on an annual, monthly, weekly, and daily basis with emphasis on both efficiency and accuracy 
• Conceive, plan and lead projects in line with department’s current and future strategy 
• Manage/assist complex commission payment process 
• Manage, organize, clean up (LEAN) and improve all existing reports significant to the business 
• Own, produce and support ad hoc projects requested by Commercial or Finance orgs 
• Perform and understand data pulls and analysis from various sources. (Salesforce.com, SQL, Snowflake, etc.) 
• Answer reporting, data and workflow questions from stakeholders. Communicate the significance of reports with an understanding of what drives success at S&P Global 
• Work with finance to sync reporting efforts across departments. 
• Proactively identify gaps and errors in reporting and work towards improving those areas 
 
Working Shift: This is a permanent evening/night shift job. 
 
What We’re Looking For:  
 
In order to succeed, the individual should have: 
 
• At least 3-4 years’ experience in sales analysis or relevant field  
• Proficient in Microsoft Excel (complex formulas, pivot tables, charting, power tools). 
• Having expertise in visualization tools like Power BI, Tableau, or any BI solution 
• Knowledge of SQL DBMS / DWH is required 
• Knowledge of Einstein Analytics (CRM Analytics) is a plus  
• Knowledge of statistical concepts with ability to do both quantitative and qualitative analysis 
• Familiarity with Salesforce is required 
• Intermediate to advanced research and analytical skills 
• Excellent verbal and written communication skills 
• Ability to work with multiple stakeholders, on and off-site 
• Ability to work both independently and lead projects as well as a team-member 
• Positive work attitude 
• Ability to work under pressure 
• Critical thinking skills 
• Willingness to work in the evening or night shift 
About S&P Global Market Intelligence

At S&P Global Market Intelligence, a division of S&P Global we understand the importance of accurate, deep and insightful information. Our team of experts delivers unrivaled insights and leading data and technology solutions, partnering with customers to expand their perspective, operate with confidence, and make decisions with conviction.

For more information, visit www.spglobal.com/marketintelligence.
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 -----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), SLSGRP202.1 - Middle Professional Tier I (EEO Job Group)",USD 22K - 42K *
205,Data Analyst - Onboarding and Subscription Management,Arcadia,"Chennai, Tamil Nadu, India",Entry-level / Junior,"Who We Are :
Arcadia is the technology company empowering energy innovators and consumers to fight the climate crisis. Our software and APIs are revolutionizing an industry held back by outdated systems and institutions by creating unprecedented access to the data and clean energy needed to make a decarbonized energy grid possible.
In 2014, Arcadia set out on its mission to break the fossil fuel monopoly and since then we have been knocking down the institutional barriers to unlock decarbonization. To date, we have connected hundreds of thousands of consumers and small businesses with high-quality clean energy options. Fast forward to today, and now, we’re thinking even bigger. We have launched Arc, an industry-defining SaaS platform that empowers developers and energy innovators to deliver their own custom, personalized energy experiences, accelerating the transformation of the industry from an analog energy system into a digitized information network.
Tackling one of the world’s biggest challenges requires out-of-the-box thinking & diverse perspectives. We’re building a team of individuals from different backgrounds, industries, & educational experiences. If you share our passion for ushering in the era of the clean electron, we look forward to learning what you would uniquely bring to Arcadia! Visit www.arcadia.com.
HQ: Washington, DC & Chennai
$1.5B valuation; $380M funding to date
  Job Description – Data Analyst
Position Summary:
The position involves understanding the domain and process of generating, monitoring and delivering energy data to Customers.
Should possess good communication, analytical skills, team interaction and proficiency in using computer systems towards speedy on-boarding of Customers, set-up and initiation of processes as per Customer requirements, delegation of tasks to team members, troubleshooting issues / escalations, verifying and ensuring data accuracy from team, tracking and reporting and customer interaction
The candidates must have knowledge and prior experience using software systems for monitoring / tracking / reporting as well as proficiency in MS Excel (using Pivots, formulae etc.). 
Candidates who have experience with tracking and reporting using SQL queries (any database) would be an added advantage.
  Other Perks and Benefits
Competitive compensation based on market standards 
We are working on a hybrid model.
Apart from Fixed Base Salary potential candidates are eligible for following benefits
Flexible Leave Policy
Office is located in the heart of the city in case you need to step in for any purpose
Medical Insurance (1+5 Family Members)
Flexible Benefit Plan
Annual performance cycle
Quarterly engagement activities
L&D Program to foster professional growth
Eliminating carbon footprints, eliminating carbon copies.
Here at Arcadia, we cultivate diversity, celebrate individuality, and believe unique perspectives are key to our collective success in creating a clean energy future. Arcadia is committed to equal employment opportunity regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, protected veteran status, or any status protected by applicable federal, state, or local law. While we are currently unable to consider candidates who will require visa sponsorship, we welcome applications from all qualified candidates eligible to work in Chennai, India.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Thank you",USD 53K - 94K *
206,Quality Assurance Engineer - Data Quality Operations,Arcadia,"Chennai, Tamil Nadu, India",Entry-level / Junior,"Who We Are                                                        
Arcadia is the technology company empowering energy innovators and consumers to fight the climate crisis. Our software and APIs are revolutionizing an industry held back by outdated systems and institutions by creating unprecedented access to the data and clean energy needed to make a decarbonized energy grid possible.
In 2014, Arcadia set out on its mission to break the fossil fuel monopoly and since then we have been knocking down the institutional barriers to unlock decarbonization. To date, we have connected hundreds of thousands of consumers and small businesses with high-quality clean energy options. Fast forward to today, and now, we’re thinking even bigger. We have launched Arc, an industry-defining SaaS platform that empowers developers and energy innovators to deliver their own custom, personalized energy experiences, accelerating the transformation of the industry from an analog energy system into a digitized information network.
Tackling one of the world’s biggest challenges requires out-of-the-box thinking & diverse perspectives. We’re building a team of individuals from different backgrounds, industries, & educational experiences. If you share our passion for ushering in the era of the clean electron, we look forward to learning what you would uniquely bring to Arcadia! Visit www.arcadia.com.
HQ: Washington, DC
$1.5B valuation; $380M funding to date
  Position Summary:

To ensure that the ongoing processes and software ensure high quality of the end product being delivered to the customers.
2. Needs to make sure that testing / inspection is comprehensive, and products/artifacts pass all relevant tests.
3. Should have attention to detail and good analytic ability to be able to identify issues / risks and prevent QA failures.
4. Will have opportunities to participate and contribute on how quality can be improved further by using new tools or by making process enhancements.
KNOWLEDGE/SKILLS:
A. Good written and verbal communication skill.
B. Knowledge in manual testing / inspection / QA is a must
C. Energy domain / billing / financial or other numeric analysis experience desirable
D. Good MS-Office (Excel) knowledge is a big plus
  Benefits:
Competitive compensation based on market standards 
We are working on a hybrid model with remote first policy
Apart from Fixed Base Salary potential candidates are eligible for following benefits
Flexible Leave Policy
Office is located in the heart of the city in case you need to step in for any purpose
Medical Insurance (1+5 Family Members)
Flexible Benefit Plan
Awards and Bonus
Annual performance cycle
Quarterly engagement activities
    Eliminating carbon footprints, eliminating carbon copies.
Here at Arcadia, we cultivate diversity, celebrate individuality, and believe unique perspectives are key to our collective success in creating a clean energy future. Arcadia is committed to equal employment opportunity regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, protected veteran status, or any status protected by applicable federal, state, or local law. While we are currently unable to consider candidates who will require visa sponsorship, we welcome applications from all qualified candidates eligible to work in India.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
  .
Thank you",USD 37K - 70K *
207,Big Data Engineer,NTT DATA,"Bengaluru, Karnataka, India, KA, IN",Entry-level / Junior,"Req ID: 250771 
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Big Data Engineer to join our team in Bangalore, Karnataka, India, Karnātaka (IN-KA), India (IN).
  •Spark-Scala
•HQL, Hive
•Control-m
•Jinkins
•Git
•Technical analysis and up to some extent business analysis (knowledge about banking products, credit cards and its transactions)
  About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",USD 22K - 42K *
208,Operations Research Engineer IV,Sabre Corporation,India - Bengaluru-Navigator Bldg,Mid-level / Intermediate,"Sabre is a technology company that powers the global travel industry. By leveraging next-generation technology, we create global technology solutions that take on the biggest opportunities and solve the most complex challenges in travel.
Positioned at the center of the travel, we shape the future by offering innovative advancements that pave the way for a more connected and seamless ecosystem as we power mobile apps, online travel sites, airline and hotel reservation networks, travel agent terminals, and scores of other solutions.
Simply put, we connect people with moments that matter.
Team Description
PROFIT MANAGER CALIBRATION TEAM looking for skillful and experienced OPERATIONS RESEARCH ENGINEER
 
Role and Responsibilities
 
What will you achieve?
Leveraging statistical methods and data science tools like R/Python to solve problem statements in the network planning domain of airlines.
Quality delivery from your independent contribution for projects for multiple airlines throughout the year.
Handling customer projects and their delivery independently.
Automate everything that we’d repeatedly, often using heterogeneous tools.
Work with Product Owners and external teams to continuously raise the quality bar of our products.

What's in it for you?
Working with network planning teams of many airlines around the globe and opportunity to solve the challenging network problems. The sky is the limit when it comes to what you can do.
Opportunity to do something that has high impact and game changing in our industry
Be part of one of the world’s largest Travel and Hospitality technology company
Qualifications and Education Requirements
Master’s degree (Preferably M.Sc. (Quantitative Subjects), M.B.A., M.E., M.Tech.) with minimum 2 years of relevant experience (or) Bachelor’s degree holders (Preferably B.E., B.Tech) with minimum 3 years of relevant experience.
 
Must Have Skills:
Ability to understand complex business requirements and define KPIs to measure benefits and communicate complex quantitative analysis in a clear, precise, and actionable manner.
Solid programming skills (expertise in any statistical tools like SQL / SAS / R / Python / other tools)
Experience with applying complex business logics to extract and cleanse large datasets from different data sources (xml, txt, xls, sql, etc)
Skills in Microsoft Tools (Preferably Excel and Power point)
Experience in building Operations Research models
Excellent communication skills, strong problem solving and analytical skills
Excellent Customer Management Skills and Ability to handle multiple projects
Nice To Have Skills:
2-3 years of experience in airline industry.
Bachelor’s degree in Computer Science or Computer Engineering
Solid hands-on experience with framework development and ability to achieve end-to-end automation of workflows.
We will give careful consideration to your application and review your details against the position criteria. You will receive separate notification as your application progresses.
Please note that only candidates who meet the minimum criteria for the role will proceed in the selection process.
#LI-Onsite#LI-SABRE",USD 100K - 200K *
209,"Senior Consultant, Models Development",TransUnion,Pune,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
Sr. Consultant, Data Science & Analytics - Integration & Deployment

As a member of the Global Operations Data Science & Analytics (DSA) management team, Sr. Consultant leads junior and experienced professionals in the design, development, and implementation of custom solutions and products for both external and internal customers. Sr. Consultant drives various Ad-Hoc projects independently and work with other associates to get them to closure. Coordinates and develops advanced program initiatives.
May develop proof of concept or beta versions of the product or service with crossfunctional across the enterprise.

Bachelors Degree or Higher in computer science / software development.  A track record of academic excellence.
Total Experience of around 6-8 years. Five (5) or more years of professional experience performing analytic/scientific software development work in Financial Services, consumer credit, or a related industry
Multiple examples of demonstrated success in client-facing or complex practice leadership roles over a period of at least two (2) years
Strong aptitude and interest in people-management and leadership roles
Experience and a consistent record of success in project lead roles
Hands-on expertise in software development and coding using C/C++, C#. Experience in Java, R or Python a plus
Experience using other programming and data manipulation languages (Ab Initio, SQL, Scala, etc.) also a positive
Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization
A champion of change, able to influence others to adopt new concepts and practices.
An effective time and project manager, able to balance a highly variable workload in a fast-paced environment
A critical thinker and creative problem solver
What You'll Bring:
NA
Impact You'll Make:
NA
TransUnion Job Title
Sr Consultant, Model Development",USD 45K - 84K *
210,Data Engineer,Shell,Bengaluru RMZ-ECO WORLD,Mid-level / Intermediate,", India

Job Family Group:
Information Technology (IT)

Worker Type:
Regular

Posting Start Date:
June 26, 2023

Business unit:
Projects and Technology

Experience Level:
Experienced Professionals

Job Description:
The Role
The Data Engineer will work on data engineering projects for various Shell Businesses, focusing on delivery of complex data management solutions by leveraging industry best practices. They work with the project team to build the most efficient data pipelines and data management solutions that make data easily available for consuming applications and analytical solutions. A Data engineer is expected to possess strong technical skills.
Key Characteristics
Technology champion who constantly pursues skill enhancement and has inherent curiosity to understand work from multiple dimensions.
Interest and passion in Big Data technologies and appreciates the value that can be brought in with an effective data management solution.
Has worked on real data challenges and handled high volume, velocity, and variety of data.
Excellent analytical & problem-solving skills, willingness to take ownership and resolve technical challenges.
Contributes to community building initiatives like CoE, CoP.
Professional Qualifications & Skills
Educational Qualification
University degree in any IT discipline
Minimum 6 - 7years of experience in the IT industry
Required Skills
Experienced in working with relational, Data warehouses databases, query authoring (SQL) as well as working familiarity with a variety of databases (which may include Cosmos, Mongo DB also).
Experienced in Azure, ADF, Creating Data Pipeline, Databrick, PySpark, Python.
Experienced in building and optimizing complex queries. Good with manipulating, processing, and extracting value from large, disconnected datasets.
Good knowledge in working with big data sets and big data technologies
Experienced in working source control technologies (such as GITHUB, Azure DevOps), build and release pipelines.
Experienced in working with AGILE, KANBAN methodologies
Experience supporting and working with cross-functional teams in a dynamic environment
Good project management, requirement gathering and organizational skills.
Self-motivated, Innovative and team player
Excellent communication and interpersonal skills
Nice to have Skills
Experience in working with unstructured data sets
Knowledge regarding reporting tools like SAC (SAP Analytics Cloud), WEBI etc.
Knowledge regarding Cloud technologies such as AZURE.
Good Knowledge with NoSQL databases
Knowledge on Power App, Power BI
Trading and Supply Knowledge in Energy Sector (Power, Gas etc)
-

DISCLAIMER:
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Shell/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell is an Equal Opportunity Employer.",USD 90K - 151K *
211,Engineer Software Engineering - AI/ML,GlobalFoundries,IND - Karnataka - BANGALORE,Mid-level / Intermediate,"Job Title: Engineer Software Engineering - AI/ML
About GlobalFoundries
GlobalFoundries is a leading full-service semiconductor foundry providing a unique combination of design, development, and fabrication services to some of the world’s most inspired technology companies. With a global manufacturing footprint spanning three continents, GlobalFoundries makes possible the technologies and systems that transform industries and give customers the power to shape their markets. For more information, visit www.gf.com.
Your Job:
The AI/ML Solutions team in GLOBALFOUNDRIES has a primary mission of delivering data engineering, advanced analytics, and machine learning systems and applications to improve business operations in any of our business units.   We are involved in the entire application lifecycle from concept to deployment with a primary focus of enabling the distributed data science teams to develop and deploy their workflows.  We also lead or help with building prototype solutions for new project areas.
The successful candidate will help architect and build data flows for advanced analytics and machine learning applications, as well as build custom tools to facilitate the speedy development and release of the applications.
Essential Responsibilities:
Build tools to automate and improve development and release processes, and deploy Machine Learning (ML) to large production environments
Utilize Versioning Repository tools, Continuous Integration Frameworks, Application Containerization, Automation Deployment, Code Quality and Code Security Scanning tools
Design, build, and maintain efficient, reusable, and tested code in Python and other applicable languages and library tools, utilize off-the-shelf solutions where warranted
Design modern data pipeline architectures and build tooling to efficiently tackle Big Data projects in a multi-cloud environment
Able to handle multiple projects
Present project status to peers and the leadership team as needed, collaborate across organizational boundaries
 Required Qualifications:
B.S. in Computer Science, Software Engineering, or equivalent field with 4-6 years industrial experience, or M.S. with 3-5 years experience, or Ph.D. with 1-2 years experience.
Experience with full stack development
Understanding of REST APIs, JSON data format
Experience with ML services in AWS ecosystem
Experience with the deployment of big data ETL pipelines in the cloud, e.g. PySpark
Experience with of SQL and NoSQL databases, Python, Docker containers
Exposure to and/or understanding of ML tools/libraries such as: TensorFlow/Keras, PyTorch, Pandas
Understanding of advanced data analytics and machine learning
Prior experience architecting end-to-end pipeline for ML and Analytics using AWS or Azure services
Understanding of MLOps tools and flow
Preferred Qualifications:
Experience deploying advanced data analytics and machine learning applications
Experience in managing projects
Understanding of AWS Well Architected Framework (6 pillars)
Experience mentoring junior engineers / interns
AWS certifications (e.g. Cloud Practitioner, Machine Learning, Associate Solution Architect)
GlobalFoundries is an equal opportunity employer, cultivating a diverse and inclusive workforce. We believe having a multicultural workplace enhances productivity, efficiency, and innovation whilst our employees feel truly respected, valued and heard.   
As an affirmative employer, all qualified applicants are considered for employment regardless of age, ethnicity, marital status, citizenship, race, religion, political affiliation, gender, sexual orientation and medical and/or physical abilities. All offers of employment with GlobalFoundries are conditioned upon the successful completion of background checks, medical screenings as applicable and subject to the respective local laws and regulations.  
To ensure that we maintain a safe and healthy workplace for our GlobalFoundries employees, please note that offered candidates who have applied for jobs in India will have to be fully vaccinated prior to their targeted start date. For new hires, the appointment is contingent upon the provision of a copy of their COVID-19 vaccination document, subject to any written request for medical or religious accommodation.
Information about our benefits you can find here: https://gf.com/about-us/careers/opportunities-asia
 ",USD 37K - 70K *
212,Senior Data Product Scientist,Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Key Responsibilities:
Responsible for analyzing, designing, and developing data products that meet the needs of stakeholders
Data analysis: Analyzing data products to identify areas for improvement and opportunities for new features or enhancements. This involves analyzing usage data, customer feedback, and other metrics to inform product development decisions.
Product design and development: Working with product managers and engineers to design and develop data products that meet the needs of stakeholders. This includes defining product requirements, creating user stories, and developing product roadmaps.
Mining and analyzing data from company databases using APIs or building ETL pipelines to improve overall business strategies.
Data cleaning using programming languages (e.g. Python, R)
Using statistical techniques like ANOVA, hypothesis testing, inference techniques to identify data properties, pick out key KPIs and attributes to use for models, algorithms and metrics.
Create advanced machine learning algorithms such as in both supervised and unsupervised branches such as classification, regression, simulations, scenario modeling, clustering, decision trees for both business and data product use-cases. Knowledge of NLP, neural network implementation and LLMs are helpful.
Data governance: Ensuring that data products are compliant with data governance policies and procedures. This involves working with data governance teams to ensure that data products are secure, accurate, and compliant with regulatory requirements
Stakeholder engagement: Engaging with stakeholders across the organization to understand their needs and ensure that data products meet their requirements. This includes collaborating with business analysts, other data scientists, and stakeholders to understand their use cases and provide support as needed.
Serves as the Subject Matter Expert on GDD Data & Analytics Solutions and build domain knowledge of the GDD specific area.
Proficiency with database systems, both SQL and NoSQL.
Follow to a consistent approach and adhere to best practices around operational excellence, security, reliability, performance efficiency and cost optimization.
Has End to End ownership mindset in driving initiatives through completion.
Comfortable working in a fast-paced environment with minimal oversight
Mentors other team members effectively to unlock full potential
Prior experience working in an Agile/Product based environment
Provides strategic feedback to vendors on service delivery and balances workload with vendor teams
Qualifications & Experience:
Degree in computer science, mathematics, statistics, computer systems engineering or equivalent quantitative field.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
3-5 years of hands-on experience working on implementing and operating data capabilities and cutting-edge machine learning algorithms, preferably in a cloud environment as a data scientist or similar role
Knowledge of statistics, data sciences and experience using open-source programs/ proprietary packages for analyzing datasets (such as SAS, R, R-Shiny, Dash, matplotlib, ggplot2 etc.)
4-6 year proven working experience as a data analyst or business data analyst.
At least 3 years technical expertise in data modelling, database design development, data mining and visualization techniques
Breadth of experience in technology capabilities that span the full life cycle of data management including data lakehouses, master/reference data management, data quality and analytics/AI ML is needed. 
Strong programming skills in languages such as Python, R, SAS, PyTorch etc.
Knowledge of open-source languages, libraries and MLOps processes to develop, deploy and maintain ML models.
Experience with SQL, NoSQL and database technologies such as MySQL, PostgreSQL, DynamoDB, GraphDB etc.
Knowledgeable with cloud-based data technologies such as AWS, Azure, or Google Cloud Platform
Strong analytical and problem-solving skills
A desire to learn new techniques and technologies.
Excellent communication and collaboration skills Functional knowledge or prior experience in Lifesciences Research and Development domain is a plus
Experience and expertise in establishing agile and product-oriented teams that work effectively with teams in US and other global BMS site.  
Initiates challenging opportunities that build strong capabilities for self and team
Demonstrates a focus on improving processes, structures, and knowledge within the team. Leads in analyzing current states, deliver strong recommendations in understanding complexity in the environment, and the ability to execute to bring complex solutions to completion.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.

#HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
213,Senior Data Engineer,Grab,"Bengaluru, India",Senior-level / Expert,"Company Description
Life at  Grab
At Grab, every Grabber is guided by The Grab Way, which spells out our mission, how we believe we can achieve it, and our operating principles - the 4Hs: Heart, Hunger, Honour and Humility. These principles guide and help us make decisions as we work to create economic empowerment for the people of Southeast Asia.
Job Description
Get to know the Team
We are living in dynamic times. Technology is reshaping how we live, and we want to use it to redefine how financial services are offered. Grab is the leading technology company in Southeast Asia offering everyday services to the masses. Singtel is Asia’s leading communications group connecting millions of consumers and enterprises to essential digital services. This is why we are coming together to unlock big dreams, and financial inclusion for people in our region is just one of them. We want to build a digital bank with the right foundation - using data, technology and trust to solve problems and serve customers. If you have what it takes to help build this new Digibank with us.
Get to know the Role
As the Data Engineer in the Data Technology team, you will be working on all aspects of Data, from Platform and Infra build out to pipeline engineering and writing tooling/services for augmenting and fronting the core platform. You will be responsible for building and maintaining the state-of-the-art data Life Cycle management platform, including acquisition, storage, processing and consumption channels. The team works closely with Data scientists, Product Managers, Finance, Legal, Compliance and business stakeholders across the SEA in understanding and tailoring the offerings to their needs. As a member of the Data Tech team, you will be an early adopter and contributor to various open source big data technologies and you are encouraged to think out of the box and have fun exploring the latest patterns and designs in the fields of Software and Data Engineering.
The Day-to-Day Activities
Build and manage the data asset using some of the most scalable and resilient open source big data technologies like Airflow, Spark, Snowflake, Kafka, Kubernetes, ElasticSearch, Superset and more on cloud infrastructure.
Design and deliver the next-gen data lifecycle management suite of tools/frameworks, including ingestion and consumption on the top of the data lake to support real-time, API-based and serverless use-cases, along with batch (mini/micro) as relevant
Build and expose metadata catalog for the Data Lake for easy exploration, profiling as well as lineage requirements
Enable Data Science teams to test and productionize various ML models, including propensity, risk and fraud models to better understand, serve and protect our customers. Lead technical discussions across the organization through collaboration, including running RFC and architecture review sessions, tech talks on new technologies as well as retrospectives
Apply core software engineering and design concepts in creating operational as well as strategic technical roadmaps for business problems that are vague/not fully understood. Obsess security by ensuring all the components, from a platform, frameworks to the applications are fully secure and are compliant by the group’s infosec policies.
Qualifications
The Must-Haves
At least 5+ years of relevant experience in developing scalable, secured, distributed, fault tolerant, resilient & mission-critical Big Data platforms.
Able to maintain and monitor the ecosystem with 99.99% availability
Candidates will be aligned appropriately within the organization depending on experience and depth of knowledge.
Must have good fundamental hands-on knowledge of Linux and building a big data stack on top of AWS using Kubernetes.
Proficiency in at least one of the programming languages Python, Scala or Java.
Strong understanding of big data and related technologies like Spark, Airflow, Kafka etc.
Experience with NoSQL databases – KV, Document and Graph
Able to drive devops best practices like CI/CD, containerization, blue-green deployments, 12-factor apps, secrets management etc in the Data ecosystem.
Good understanding of Machine Learning models and efficiently supporting them is a plus.
Additional Information
Our Commitment
We are committed to building diverse teams and creating an inclusive workplace that enables all Grabbers to perform at their best, regardless of nationality, ethnicity, religion, age, gender identity or sexual orientation and other attributes that make each Grabber unique.",USD 121K - 186K *
214,Data / ML Engineer-4,CVS Health,"Pune, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data / ML Engineer-4
Mastercard Overview

Mastercard is the global technology company behind the world’s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless®. We ensure every employee can be a part of something bigger and change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.
Join a fast-growing team
As a Data / ML Engineer in the Data Engineering & Analytics team, you will develop data & analytics solutions that sit atop vast datasets gathered by retail stores, restaurants, banks, and other consumer-focused companies. The challenge will be to create high-performance algorithms, cutting-edge analytical techniques including machine learning and artificial intelligence, and intuitive workflows that allow our users to derive insights from big data that in turn drive their businesses. You will have the opportunity to create high-performance analytic solutions based on data sets measured in the billions of transactions and front-end visualizations to unleash the value of big data. You will have the opportunity to develop data-driven innovative analytical solutions and identify opportunities to support business and client needs in a quantitative manner and facilitate informed recommendations/decisions through activities like building ML models, automated data pipelines, designing data architecture/schema, performing jobs in big data cluster by using different execution engines and program languages such as Hive/Impala, Python, Spark, R, etc.

Your Role
• Drive the evolution of Data & Services products/platforms with an impact-focused on data science and engineering.
• Turning unstructured data into useful information by auto-tagging images and text-to-speech conversions.
• Solving complex problems with multi-layered data sets, as well as optimizing existing machine learning libraries and frameworks.
• Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.
• Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
• Discover, ingest, and incorporate new sources of real-time, streaming, batch, and API-based data into our platform to enhance the insights we get from running tests and expand the ways and properties on which we can test Experiment with new tools to streamline the development, testing, deployment, and running of our data pipelines.
• Maintain awareness of relevant technical and product trends through self-learning/study, training classes and job shadowing.
• Participate in the development of data and analytic infrastructure for product development
Continuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations
• Partner with roles across the organization including consultants, engineering, and sales to determine the highest priority problems to solve
• Evaluate trade-offs between many possible analytics solutions to a problem, taking into account usability, technical feasibility, timelines, and differing stakeholder opinions to make a decision
Break large solutions into smaller, releasable milestones to collect data and feedback from product managers, clients, and other stakeholders
• Evangelize releases to users, incorporating feedback, and tracking usage to inform future development
Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
• Work with small, cross-functional teams to define the vision, establish team culture and processes
Consistently focus on key drivers of organization value and prioritize operational activities accordingly
• Escalate technical errors or bugs detected in project work
• Maintain awareness of relevant technical and product trends through self-learning/study, training classes, and job shadowing.
• Support the building of scaled machine learning production systems by designing pipelines and engineering infrastructure.
Ideal Candidate Qualifications:
• Experience and exposure to Python/Scala, Spark(tuning jobs), SQL, Hadoop platforms to build Big Data products & platforms
• Experience with data pipeline and workflow management tools: NIFI, Airflow.
• Comfortable in developing shell scripts for automation
• Proficient in standard software development, such as version control, testing, and deployment
• Demonstrated basic knowledge of statistical analytical techniques, coding, and data engineering
• Curiosity, creativity, and excitement for technology and innovation
• Demonstrated quantitative and problem-solving abilities
• Motivation, flexibility, self-direction, and desire to thrive on small project teams
• Good communication skills - both verbal and written – and strong relationship, collaboration skills, and organizational skills
• At least a Bachelors degree in Computer Architecture, Computer Science, Electrical Engineering or equivalent experience. Postgraduate degree is an advantage
The following skills will be considered as a plus
• Experience with visualization tools like tableau, looker
• Hands-on experience with cloud computing and big data frameworks e.g. GCP, AWS, Azure, Flink, Elasticsearch, and Beam
• Knowledge in MLOps frameworks such as TensorFlow Extended, Kubeflow, or MLFlow
• Experience participating in complex engineering projects in an Agile setting e.g. Scrum
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 174K - 275K *
215,Senior Software Engineer - Data Engineering,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
DENTSU CREATIVE is dentsu's global creative network that transforms brands and businesses through the power of Modern Creativity. Widely reputed for its innovative and creative approach to marketing and advertising. Dentsu Creative has won numerous awards for its work, including Cannes Lions agency of the year 2022, D&AD Awards, and Effie Awards, among others. The company's global network of offices allows it to serve clients across industries and geographies, and it has worked with many of the world's leading brands. With its focus on creativity, innovation, and results, Dentsu Creative is a leading player in the advertising and marketing industry.
Job Description
Design, build, test, and maintain highly scalable data platforms, ensuring that these systems meet business requirements and industry best practices.
Incorporate new data engineering technologies into existing systems, to help move data across systems.
Create custom data pipelines and solution components that extract, cleanse, transform, move, and aggregate data across various enterprise systems
Identify potential opportunities for data acquisition and explore new uses for existing data.
Develop processes and standards for common data models, and data mapping across systems.
Use a range of ETL tools, Data integration platforms, and underlying languages and tools to integrate disparate data systems effectively.
Leverage data virtualization technologies for data aggregation and unification from multiple, disparate data sources, without the use of any ETL.
Recommend ways to improve data reliability, efficiency, and quality.
Foster collaboration with data architects, modelers, and IT team members on project goals.
Provide technical leadership and consultation on complex projects involving data management, data virtualization, and unification.
Qualifications
Bachelor’s/Master’s degree in Computer Science, Data Science, Information Systems, or a related field.
Minimum of 5 years of experience in a data engineering role, with a focus on data management and data pipeline construction.
Demonstrable experience with data engineering solutions, including data aggregation, data transformation, data movement, and data unification strategies.
Proficiency with Data Lakes built on Cloud Services such as Azure and AWS – e.g., ADLS (Azure Data Lake Storage Gen2),
Proficiency with cloud platforms, and cloud services, on at least 1 major enterprise cloud (Azure or AWS Cloud)
Solid exposure to and experience with data virtualization technologies and platforms, particularly the Denodo platform, is highly preferred.
Proficiency with data orchestration services and data workflow platforms – e.g., Apache Airflow, highly preferred.
Proficiency in scripting and data intensive languages like SQL, Python, etc.
Experience with big data frameworks and associated languages / toolsets is nice-to-have",USD 121K - 186K *
216,Phd Data Scientist,Bosch Group,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Description
PhD completed in field of Artificial Intelligence / Machine Learning / Statistics / Data Science / Computer Science
2 to 5 years
of industry experience with innovations in the field of AI/ML, NLP, Computer Vision
Experience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, Computer Vision, NLP, Search Algorithms, Deep Learning Algorithms
Will be responsible for to research and lead architecture, design and implementation
Deep understanding of machine learning/statistical algorithms such as deep learning
Create and Mentor other team members on research papers, journals and patent filings by contributing in research
Experience in analyzing complex problems and translating to data science algorithms with due attention to computational efficiency
Hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data
Ensure models are aligned to Responsible AI principles by exploring statistical frameworks.
Experience in frameworks to depict interpretability of models using libraries like Lime, Shap etc.
Experience in using code versioning tools like GIT, bit bucket to collaborate on projects
Authoritative experience in the field of Data Science to influence stake holders across varied work streams and geographical locations, ability to challenge the status quo to improve the base line models and the models which are already productionized.
Perform literature review, analyzing existing solutions and techniques to identify deficiencies, and coming up with new techniques to improve these deficiencies.
Demonstrated ability to frame business problems into mathematical programming problems, leverage external thinking and tools (from academia and/or other industries) to engineer a solution and deliver business insights.
Ability to work effectively in a team environment
Independent thinker who’s organized, has great attention to detail, and can multi-task
Write code in Python to build, develop models, perform data exploration, analysis, what-if analysis, model comparison
Superior verbal, visual and written communication skills to educate and work with cross functional teams on controlled experiments.
Willingness to learn AIoT, Edge AI, etc. and keep up to date with technologies
 Qualifications
PhD completed in field of Artificial Intelligence / Machine Learning / Statistics / Data Science / Computer Science Research paper submissions, journal publications, IP filings
Additional Information
2 to 5 years of industry experience",USD 86K - 160K *
217,"Sr. Data Scientist - (SciPy, Scikit-learn, SparkM and PyTorch/Keras)",Blue Yonder,Hyderabad,Senior-level / Expert,"Overview:
Leading AI-driven Global Supply Chain Solutions Software Product Company and one of Glassdoor’s “Best Places to Work”
Seeking an astute individual that has a strong technical foundation with the additional ability to be hands-on with the broader engineering team as part of the development/deployment cycle, and deep knowledge of industry best practices, with the ability to implement them working with both the platform, and the product teams.
The Platform Data Science and Machine Learning team works closely with sales, product and engineering teams to design and implement the next generation of retail solutions.
Data Science team members bear the heavy burden of turning both small, sparse and massive data into actionable insights with measurable improvements to the customer bottom line. They use rigorous analysis and repeatable processes to implement both black box and interpretable models.
The Data Science team uses MLOps to operationalize the machine learning pipeline.
Scope:
As a Data Scientist, you serve as a specialist in the engineering team that supports the team with the following responsibilities.
Works closely with product and engineering teams to shape up the final solution
Independently, or alongside junior scientists, implement machine learning models by Procuring data from platform, client and public data sources
Prepare template notebook to demonstrate features of the solution
Use data to understand patterns, come up with and test hypothesis; iterate
Implementing data enrichment and cleansing routines
Implementing features, preparing modeling data sets, feature selection, etc.
Implementing advanced statistics and analytics including segmentation, modeling, regression, forecasting etc.
Evaluating candidate models, selecting and reporting on test performance of final one
Apply Natural Language Processing to understand text from forum reviews, description and interactions between users
Ensuring proper runtime deployment of models, and Implementing runtime monitoring of model inputs and performance to ensure continued model stability
Help prepare sales materials, estimate hardware requirements, etc.
Attend client meetings, online and onsite, to discuss new and current functionality
Our current technical environment:
Software: Python 3*, NumPy, SciPy, scikit-learn, SparkML, pandas, Jupyter Notebook, Matplotlib, Azure ML
Application Architecture: Scalable, Resilient, Reactive, event driven, secure multi-tenant Microservices architecture
Cloud: MS Azure
Frameworks/Others: Snowflake, Kubernetes, Dataflow, Kubeflow, Keras, TensorFlow, PyTorch, FastAPI
What we are looking for:
Bachelor’s degree in computer science or related fields; graduate degree preferred
5+ years of data science experience, retail setting preferred
3+ years of Python programming experience
Strong grasp of data structures and algorithms
Solid understanding of data science and machine learning foundations
Familiarity with deep learning, NLP, reinforcement learning, combinatorial optimization etc.
Experience working with most of the following frameworks and libraries: Pandas, Numpy, sklearn, Keras, Tensorflow, Jupyter, Matplotlib etc.
Solid experience working on major cloud platforms, preferably Azure.
Reasonable knowledge of modern software development tools, and respective best practices, such as Git, Jenkins, Docker, Jira, etc.
Provable experience guiding junior data scientists in official or unofficial settings.
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Diversity, Inclusion, Value & Equality (DIVE) is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural Diversity Report which outlines our commitment to change, and our video celebrating the differences in all of us in the words of some of our associates from around the world.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",USD 136K - 205K *
218,Senior Data Analyst (Finance),Funding Societies,"Bengaluru, Karnataka, India - Remote",Mid-level / Intermediate,"Funding Societies | Modalku is the largest SME digital financing platform in Southeast Asia. We are licensed in Singapore, Indonesia, Thailand, and registered in Malaysia. We are backed by Sequoia India and Softbank Ventures Asia Corp amongst many others and provides business financing to small and medium-sized enterprises (SMEs), which is crowdfunded by individual and institutional investors. And here at Funding Societies | Modalku we live by our core values:
Serve with Obsession: Build win-win relationships for the long-term by having a customer obsession.
Grow Relentlessly: Strive to become our best, most authentic selves.
Enable Teamwork, Disable Politics: Only by forging togetherness, we help each other succeed.
Test Measure Act: Stay curious and reinvent ourselves, through innovation and experimentation.
Focus on Impact: Create impact through bias for action and tangible results.

We are seeking a highly motivated and skilled Finance Data Analyst to join our dynamic team at Funding Societies. As a finance data analyst, you will be part of a fun team which will be working to support all business functions with finance focus in Funding Societies. In short, the function of a data analyst is to understand the needs of the business and use data to derive a solution that you will then present, implement, and track and add value to the company and its performance. In addition to having a knack for problem-solving, it is crucial that you are willing to learn, understand, and hear the needs of our people. We solve challenging problems. As long as you are adding value to the business, you are your own boss. You’ll get loads of support from your friendly, talented and motivated colleagues
Requirements
What will you do:
Develop financial analysis capabilities in the data team, create and conceptualize data models for finance metrics from multiple data sources
Identify valuable data sources, automate and propose to optimise collection processes, design and implement with analytics engineer in our data-warehouse
Collaborate with regional Finance and various business teams, drive projects and propose solutions and strategies to business challenges
Deliver and maintain analytic solutions to support Finance Business Intelligence and other business requirements
Enable and support in timely and accurate closing and revenue testing in audit
Regulatory, management and other BAU reporting
What we are looking for:
Strong enthusiasm for new experiences and to learn new skills
Qualifications Bachelor in finance and/or quantitative related disciplines or equivalent. >2 years of experience in FinTech or financial industries.
Strong logical reasoning and analytical mind, with can-do attitude
Independent learner who enjoys technical challenges (Google is your best friend)
Outstanding communication and teamwork skills, with certain cross-departmental and cross-team projects experience, independently promoting project execution
Experiences in working on performance management, cost allocation, financial statement analysis, building financial model with basic accounting understanding is preferred
Exposure with ELT workflow, query optimisation and/or able to work with data architects/engineers to define warehousing logic
SQL, Python, visualisation tools such as Tableau/Qlik experience required
English is required
Benefits
Time off - We would love you to take time off to rest and rejuvenate. We offer flexible paid vacations as well as many other observed holidays by country. We also like to have our people take a day off for special days like birthdays and work anniversaries.
Flexible Working - We believe in giving back the control of work & life to our people. We trust our people and love to provide the space to accommodate each and everyone's working style and personal life.
Medical Benefits - We offer health insurance coverage for our employees and dependents. Our people focus on our mission knowing we have their back for their loved ones too.
Mental Health and Wellness - We understand that our team productivity is directly linked to our mental and physical health. Hence we have Wellness Wednesdays and we engage partners to provide well-being coaching. And we have our Great FSMK Workout sessions too to keep everyone healthy and fit!
Tech Support - We provide a company laptop for our employees and the best possible support for the right equipment/tools to enable high productivity",USD 67K - 110K *
219,Senior Data Scientist - Generative AI,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
DENTSU CREATIVE is dentsu's global creative network that transforms brands and businesses through the power of Modern Creativity. Widely reputed for its innovative and creative approach to marketing and advertising. Dentsu Creative has won numerous awards for its work, including Cannes Lions agency of the year 2022, D&AD Awards, and Effie Awards, among others. The company's global network of offices allows it to serve clients across industries and geographies, and it has worked with many of the world's leading brands. With its focus on creativity, innovation, and results, Dentsu Creative is a leading player in the advertising and marketing industry.
Job Description
 Collaborate with client teams and stakeholders to understand their requirements and devise Gen AI models to meet these needs.
Design, develop, and deploy custom ML models for Gen-AI solutions
Implement MLOps to automate the deployment, monitoring, and maintenance of ML models.
Hands-on coding to develop AI / ML solutions from scratch
Build end-to-end data pipelines to manage data collection, extraction, pre-processing, cleansing, transformation, processing, and use inside custom built Gen-AI models
Stay informed about the latest advancements in Gen AI, machine learning, and AI technologies to optimize our technical stack.
Have solid knowledge and exposure across Enterprise Gen-AI Platforms and Solutions, as well as Third-party SaaS and Open Source tech leaders / providers in the Gen-AI space
Work through the complete lifecycle of Gen AI model development, from training and testing to deployment and performance monitoring.
Lead R&D initiatives involving Gen-AI Platforms and Services, Large Language Models and existing generative AI systems
Qualifications
8+ years of overall experience in technology.
Minimum 5+ years of overall experience in AL and ML solutions development.
Bachelors degree in computer science, AI, Machine Learning, or related field.
Solid understanding of Generative AI, Machine Learning, and Deep Learning algorithms, Software engineering principles
Super hands-on with ML programming languages such as Python
Experience with related machine learning platforms, libraries and frameworks like PyTorch, PySpark, TensorFlow, Keras, or similar with CUDA
Experience with natural language processing (NLP) patterns such as Text representation, Embeddings, Language Modelling, and Semantic understanding
Experience with libraries such as SpaCy, NLTK, or Stanford CoreNLP
Experience with large language models such as GPT-4, Google PalM-2, and nVidia NeMO.
Experience with Vector Databases for custom data and retrieval
Strong Proficiency in AI Orchestration frameworks such as Langchain and/or Microsoft Semantic Kernel
Prompt Engineering for implementing large language models
Strong Proficiency in at least 1 major Cloud AI Platform / Service, and all of their primary AI services and solutions, across Azure, AWS, and Google Cloud.
Strong Proficiency in working with an AI Cloud Service such as Azure Machine Learning, AWS Sagemaker, or Google Vertex-AI
Strong Proficiency in being able to code and deploy custom AI / ML models on top of AI Cloud platforms such as Azure OpenAI, AWS Sagemaker/Bedrock
Experience with and exposure to nVidia AI Cloud Foundation Service, nVidia NeMo LLM frameworks, nVidia Picasso, and other nVidia services / solutions, highly desirable
Exceptional problem-solving skills and an innovative mindset.
Additional Information
Should have deep hands-on experience with large language models (LLMs) and other generative AI techniques.
Responsible for fine-tuning existing Foundation Models, and adapting existing base ML models.
More importantly, you will also be responsible for coding, training, evaluating, and deploying net-new custom ML models using large datasets, helping create custom AI models for specific use cases, for different dentsu clients and brands.
Must have deep experience of developing and implementing cutting-edge generative AI models and algorithms using state-of-the-art techniques such as GPT, VAE, and GANs.
Must have deep technical experience working with technologies related to multimodal AI, covering text, media, image, video, audio and speech.
Optimizing existing models for improved performance, scalability, and efficiency.
Hands-on development in Python and PyTorch, across a variety of AI / ML frameworks, AI Cloud Services, and Gen-AI platforms, including enterprise Gen-AI tech, open-source Gen-AI tech and SaaS Gen-AI tech.",USD 136K - 205K *
220,Cloud Engineer III- AI/ML,"Insight Enterprises, Inc.","Gurugram Gurgaon HR, IN",Senior-level / Expert,"Requisition Number: 95519 
Job Overview:
We are on the lookout for a seasoned Cloud Engineer with a deep expertise in Artificial Intelligence (AI) and Machine Learning (ML). The ideal candidate will possess robust communication abilities and a knack for resolving complex problems. If you are passionate about pioneering innovative AI/ML models and collaborating with a dynamic team, we would love to hear from you.
  Key Qualifications:
Exp -5-8 Years
• Proficiency in programming languages: C# and Python.
• Hands-on experience with Azure Cognitive Services, including Azure Custom Vision and Azure Cognitive Search.
• Strong command over OpenAI, custom modeling, and model fine-tuning.
• Familiarity with Natural Language Processing (NLP), Linguistic Language Processing (LLP), and advanced Data Science algorithms.
  Primary Responsibilities:
• Research, design, and develop cutting-edge AI/ML models tailored to business needs.
• Collaborate closely with cross-functional teams to gather, analyze, and interpret data.
• Oversee the entire model lifecycle: training, validation, and deployment.
• Provide compelling demonstrations of AI/ML capabilities to stakeholders.
• Maintain clear and effective communication with team members, stakeholders, and external partners.
Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
  Insight India Location:Level 16, Tower B, Building No 14, Dlf Cyber City In It/Ites Sez, Sector 24 &25 A Gurugram Gurgaon Hr 122002 India",USD 45K - 84K *
221,"Sr Engineer, Data Engineer",TransUnion,Pune,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We’re looking for a Data Engineer to join our growing Data Engineering and Analytics Practice. You will be based both from our offices in Leeds and working remotely as part of our ‘flex together’ approach. In this fast-paced role you’ll work with Business Stakeholders to achieve business goals. This exciting role will offer a host of development opportunities as part of a growing global business.
What You'll Bring:
Passion for Technology in the field of Data Engineering and Analytics
Design, build, test and deploy cutting edge Big Data solutions at scale
Extract, Clean, transform, and analyze vast amounts of raw data from various Data Sources
Build data pipelines and API integrations with various internal systems
Work on SAS to Spark migration projects
Work Across all stages of Data Lifecycle
Implement best practices across all Data Analytics Processes
Estimate effort, identify risks and plan execution
Proactively monitor, identify, and escalate issues or root causes of systemic issues
Enable data scientists, business and product partners to fully leverage our platform
Good analytical & problem-solving skills
Good communication and presentation skills
Impact You'll Make:
3-5 years of Total IT Experience
3+ years of experience in Big Data technologies like Hive and Spark
SAS experience is a plus
Hadoop Distributions – Cloudera/Hortonworks/Mapr
Big Data Technologies – Hadoop HDFS, Hive, Spark, Kafka, Sqoop
Cloud - AWS, Azure, GCP
Cloud Big data - AWS EMR, AWS Glue, AWS Kinesis, Azure Data Lake
Excellent communication skills and presentation skills
TransUnion Job Title
Sr Engineer, Data Design and Analysis",USD 121K - 186K *
222,Data Engineer,Increasingly,"Bengaluru, India",Mid-level / Intermediate,"Company Description
About Increasingly
Increasingly is an award-winning, fast-growing retail technology company focused specifically on the automation of cross-selling for online retailers.
Our clients include large global corporations like Samsung & Canon to several small to medium size retailers across the globe. Our AI-based algorithms help a customer buying a TV on Samsung to find the matching sound bar & purchase both together.
Increasingly is headquartered in London with offices in Lisbon & Bangalore. We work with clients in over 30 countries & 20 languages.
We are looking to rapidly expand our technology & product development operations in India. And we need smart, ambitious people like you who enjoy a fun yet challenging work environment.
We believe strongly that diversity & inclusion are the foundations for a lasting, incredible culture. We also believe that it’s important to get the balance right between work & life.
Job Description
Working experience in data integration and pipeline development
Qualifications
3+ years of relevant experience with AWS Cloud on data integration with Databricks,Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems

Strong real-life experience in python development especially in pySpark in the AWS Cloud environment.

Design, develop, test, deploy, maintain and improve data integration pipeline.

Experience in Python and common python libraries.

Strong analytical experience with the database in writing complex queries, query optimization, debugging, user-defined functions, views, indexes, etc.

Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.

 Additional Information
What are the benefits
You'll get to work in one of the hottest & fastest-growing retail technologies in Europe right now.  
You'll get paid a competitive salary & be working directly with a super-experienced team of people.  
You'll get a great place to come to work every day. Varied, complex, challenging & with a great culture that you can shape & change. 
Group Health Insurance",USD 90K - 151K *
223,Data Engineer,Motive,India - Remote,Mid-level / Intermediate,"Who we are: 
Motive builds technology to improve the safety, productivity, and profitability of businesses that power the physical economy. Motive combines IoT hardware with AI-powered applications to connect and automate physical operations. Motive is one of the fastest-growing software companies in the world, serving more than 120,000 businesses, across a wide range of industries including trucking and logistics, construction, oil and gas, food and beverage, field service, agriculture, passenger transit, and delivery.
Motive is built on four foundational attributes; Own It, Less but Better, Build Trust, and Unlock Potential. This has taken our company to great heights, including being recognized by Fortune for Best Workplaces, Forbes Best Startup Employers, and Comparably for our Best Global Culture, Sales Team, Leadership Team, Career Growth, and CEO for Diversity. We’re proud to receive an employee net promoter score of 63 (according to Comparably) which places Motive in the top 5% of companies with 4,000 employees or more. 
Today, our team is made up of more than 3,000 employees, located across the world, providing support to a wide range of customers. While most of our employees are remote, many have the opportunity to work on-site at any of our 8 global office locations. Visit our careers website to learn more about opportunities at Motive. 
About the Role:
As a Data Engineer, you will collaborate with business units to understand and support business analytic needs with reliable, curated data sources. As a member of a team, you will be responsible for the design, implementation and maintenance of data processing pipelines and data assets that support the day-to-day operations and analytic needs of Motive’s business units including Sales, Marketing, Accounting, Finance, Customer Success and Support. You will own driving key data platform initiatives and the life cycle of data management, including requirements management, prioritization, data analysis, data modelling, data ingestion, data processing, data transformation and data publication. 
We are looking for strong engineers to grow our Business Intelligence team. The BI team is responsible for building the foundations of Motive’s organisational data analysis capability by building a data lake and scalable institutional data sources for exploration, analytics, decision-making, reporting and visualisation. We aim to drive business unit self-sufficiency by enabling analysts and leaders to make data-driven decisions
What You'll Do:
Guide and drive requirements gathering, scoping, design, development, testing, deployment and maintenance of new and existing data sources and data processing infrastructure.
Scale up the ingestion pipeline, data quality, and processing systems while maintaining service levels for performance, reliability, and availability.
Measure and continuously improve data processing execution times, measure the cost of running data processing jobs, and improve processing efficiency.
Guide system designs, data architectures, and technology choices to support evolving business needs
What We're Looking For:
You are a data geek with hands-on SQL experience. 
You enjoy using your excellent communication skills to build relationships with and support data analysts across the business with data sets and tools. 
You are a builder with a minimum of 3-5 years of experience in Data Development, Data Warehousing, and Analytics.
You have a strong background in data processing development with experience building and running large-scale data pipelines, using technologies like Snowflake, Fivetran, Spark, and Airflow and languages such as Python, Java or Scala
You have experience performing relational and dimensional data modelling, architecting data sources that are optimized for data warehouse, master data, ad hoc analysis and reporting needs.
You have built distributed systems at scale and demonstrated methodical software development practices.
You enjoy automating, debugging, and troubleshooting in a complex data environment.
   Creating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. 
Please review our Candidate Privacy Notice here.
The applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology. 
#LI-Remote",USD 90K - 151K *
224,Senior Consultant (Business Intelligence-D/W),Model N,Hyderabad India,Senior-level / Expert,"A technical consultant is responsible for activities like, system installation, development of customizations, interface configuration and testing, integration to 3rd party software, and data loading, The Model N LS solution is a transaction-based collaborative price management application, implemented in Java.  We are looking for technical consultants with experience working, in a fast-paced environment.  This position requires excellent verbal and written communication skills.
Roles and Responsibilities:
Participate in implementations of Model N systems as a senior member of the Professional Services Technical Team, involved in leading the technical team.
Design, develop and test customizations and work closely with Solution Architect/Tech Lead and Clients teams.
Create custom applications that support and enhance the Model N LS solution using analytics and data integration tools like Cognos, Looker and Informatica.
Assist customers with technical tasks related to implementations (hardware/software selection and sizing), deployment, and interface strategy.
Drive data loading efforts.  Work with customer to explain format of data, help customer with mapping, analyse content, perform data loading, and report errors to customer.
Participate in the design, development and implementation of analytical applications.
Provide consultation and support when needed to Professional Services colleagues. Mentor junior members of the team.

Job Skills
Experience of 4 to 8 years in advanced Data Warehouse concepts.
Advanced knowledge in Data Analytics and Business Intelligence concepts.
Experience in relational database programming, particularly Oracle and advanced-level SQL and PL/SQL.
Experience with logical database design and SQL query optimization techniques.
Experience in data integration tools like Informatica PowerCenter.
Experience in developing Informatica Mappings, Sessions and Workflows. Monitoring ETL processes and debugging errors and failures.
Experience in Analytics tool - IBM Cognos and Looker.
Experience in Cognos Analytics development, Server Configuration and Administration, Packaging and Deployment, Model generation, Report Authoring and the Cognos Framework Manager (Added Advantage).
Experience in LookML development in Looker that includes developing views, dimensions, measures, filters, models and explores, and dashboards.
Experience in Performance Tuning in Database, Informatica, Cognos and Looker.
Experience in GitHub.
Strong problem-solving skills.
Ability to work independently or in a team environment and effectively meet project deliverables on time.
Ability to effectively change design and development approaches as the business requirements dictate.
Good Communication, Presentation & Documentation skills, Email Etiquette
B-Tech (Computer Science) or equivalent degree.
At Model N, we believe our collective success stems from the uniqueness of every individual's diverse backgrounds, experiences, and expertise; we call this the N Factor. So don’t allow uncertainty to keep you from applying to join our team. If you don’t meet the exact criteria but can demonstrate your skillset is the best for the job, we’d love to talk with you. We’re curious to know, what’s your N Factor?    
  About Model N  
 Model N enables life sciences and high tech companies to drive growth and market share, minimizing revenue leakage throughout the revenue lifecycle. With deep industry expertise and solutions purpose-built for these industries, Model N delivers comprehensive visibility, insight and control over the complexities of commercial operations and compliance. Our integrated cloud solution is proven to automate pricing, incentive and contract decisions to scale business profitably and grow revenue. Model N is trusted across more than 120 countries by the world’s leading pharmaceutical, medical technology, semiconductor, and high tech companies, including Johnson & Johnson, AstraZeneca, Stryker, Seagate Technology, Broadcom and Microchip Technology. For more information, visit www.modeln.com. 

We’re constantly growing and may have something for you later on if this is not the right opportunity for you. Check out our career site to learn more about Model N or view other jobs: https://www.modeln.com/company/careers/ ",USD 45K - 84K *
225,Sr. Threat Research Analyst,OpenText,"Bengaluru, KA, IN",Senior-level / Expert,"Hiring Manager:
Talent Acquisition Advisor: Prathika Shetty
Job Code Level: IKP3 
Refer Your Friends!
The Opportunity: 
  As a Sr. Threat Research Analyst, you will work closely with clients to investigate the threat leads on their systems. You will help to extract data and remove the noise in order to pinpoint the internal and external threats. Our client base is global and in nearly every industry.
  You Are Great: 
  Work with behavioral analytics threat-hunting technologies to analyze and identify threat patterns or indicators that can be used for threat detection on our platform.
Follow the emerging threats and attack techniques by reading detailed analytics anomalies.
Identify, analyze, and define the attack path of advanced intrusions.
Produce reports that can form the basis for new behavioral models.
Maintain situational awareness of cyber activity by reviewing new anomalies and tracking attack campaigns through their attack cycle.
Track threat actors, their tactics, techniques, and procedures (TTPs), and their associated Indicators of Compromise (IOCs) through analytics.
Follow the analytic results leveraging additional search techniques including Kibana and Athena.
Understanding the cybersecurity landscape
Deep knowledge of current and past malware methods, attack methodologies, and TTPs (Tactics, Techniques, Procedures)
Strong understanding of current attacker tradecraft
Define client relationships and understand the critical assets in their environment to develop additional detection patterns.
Experience with common industry EDR/SOAR/Anomaly detection solutions (CrowdStrike Falcon, Microsoft Defender, etc.)
Experience with the incident response process, including detecting advanced adversaries, log analysis using SIEM, and malware triage (Optional)
Knowledge and experience working with the Cyber Kill Chain Model, MITER ATT&CK Matrix. (Optional)
Knowledge of Operating Systems and Network Protocols
Extensive knowledge of Operating System Internals (Windows, *nix, MacOS)
Strong understanding of network security concepts and network protocols, NetFlow, and web proxy.
Scripting knowledge (PowerShell, Python, etc.)
Technical Writing and Reporting Skills
Experience preparing security reports and different technical documents.
  What it Takes: 
  You are persistent and inquisitive. You must understand why things are happening the way they are.
You are determined to understand cyber-attack techniques at a very detailed level.
You are a self-starter who is able to work with minimal management, however, have strong collaboration and interpersonal skills to work together with several other professionals from other information security fields.
You’re a creative thinker who wants to answer the question, “Why?”
Your workstation is a pyramid of monitors that you can't take your eyes off of at the risk of missing something juicy.
You have a desire to learn new technologies.
Your sense of humor, passion and enthusiasm shines through in everything you do
    Micro Focus’ (now OpenText) efforts to build an inclusive work environment go beyond simply complying with applicable laws. Our Employment Equity and Diversity Policy provides direction on maintaining a working environment that is inclusive of everyone, regardless of culture, national origin, race, color, gender, gender identification, sexual orientation, family status, age, veteran status, disability, religion, or other basis protected by applicable laws. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please contact us at hr@opentext.com.",USD 63K - 160K *
226,Lead Data Engineer,S&P Global,IN - GURGAON DLF OFFICE,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
11
S&P Global
The Role: Lead Data Engineer, Agile & PPM Tools
The Team:
The Agile & PPM Tools team is responsible for developing and managing enterprise tools enabling Agile Execution (Azure DevOps), Project Portfolio Management (Solution Business Manager) and Reporting (Tableau), for all the S&P Global Divisions. These tools are used across S&P for Portfolio Management capabilities like prioritizing, executing, and tracking Portfolios, Agile Workflow Execution to enable Agile delivery and Portfolio & Agile Analytics. 
The Impact:
Are you looking for an opportunity to advance your career as an innovative enterprise team member? The Agile & PPM Tools Team is looking for an innovative professional who can bring teamwork, creativity, and business analyst experience to a global team.
What’s in it for you:
As a Data Engineer, you will have the opportunity to work on latest technologies and engage closely with senior stakeholders from all the Business Groups and Divisions within S&P. Overall goal of the Team is to develop and support a common Enterprise toolset for all divisions to enable Portfolio Management, resourcing, execution, and reporting with cutting edge technologies like Azure DevOps, AWS Cloud  Services (S3, EC2, RDS, Lambda, Kinesis, Glue, Redshift etc), Databricks as well as Market leaders in PPM and Agile tools.
Responsibilities:
In the day-to-day operations, you will be working with the Agile & PPM Analytics Scrum team with the goal to develop cutting edge Data Products for consumption of Agile & PPM data by our internal customers which include users from across the S&P Global Enterprise at all levels from senior leadership to individual users. You will also drive Strategic Initiatives that enable us to deliver better products, faster and with world class support. With your acute investigation, troubleshooting and communication skills, you will be championing support best practices and improving our user’s experience.  Some of your areas of ownership will include:
What You'll Do  
Work in a Scrum framework to develop solutions to extract data from various sources into our Data Lake, powered by Databricks and AWS Redshift
Translate the business requirements into technical requirements
ETL development using native and 3rd party tools and utilities
Lead the semantic modelling and development activities
Write and optimize complex SQL and shell scripts
Design and develop code, scripts, and data pipelines that leverage structured and unstructured data
Data ingestion pipelines and ETL processing, including low-latency data acquisition and stream processing
Design and develop processes/procedures for integration of data warehouse solutions in an operative IT environment.
Monitoring performance and advising any necessary configurations & infrastructure changes.
Create and maintain technical documentation that is required in supporting solutions.
Build a deep understanding of the solutions delivered on both platforms to understand utility from our users/customers perspective.
Keep up to date on support and customer experience best practices and suggest or implement improvements in processes or tools.
What We’re Looking For:
Basic Qualifications:
8+ years professional experience as a data engineer or similar role
B.S. / M.S. in Computer Sciences or related field
Hands on experience with one or more ETL tools.
Hands on experience with Industry standard data models and mapping between source systems, core and semantic data structures.
Working knowledge of financial services domain
Good understanding of different dimensional modeling techniques such as Star vs SnowFlake Schemas.
Working experience on creating semantic and reporting mapping documents.
Strong concepts/experience of designing and developing ETL architectures.
Strong RDBMS concepts and SQL development skills
Strong knowledge of data modeling and mapping
Experience with Data Integration from multiple data sources
Working experience in one or more business areas and industries: Financial etc.
Working experience with one or more Cloud environments like AWS, Azure or GCP along with hands on experience with different cloud services.
Hands on development experience on Python/R along with a good knowledge of programming languages such as .NET, Java, AngularJS, etc.
Knowledge of Agile Execution tools like Azure DevOps, JIRA etc.
Experience using any Workflow Management tool like ServiceNow, Solutions Business Manager, VersionOne, etc.
Demonstrable experience in facilitating, leading, influencing, and managing within large-scale matrix, globally distributed organizations
Open to working flexible hours as per business needs
Preferred Qualifications:
Good data analysis skills using Excel and any other BI tools
Prior experience with Power BI/Tableau/Databricks/AWS Services
Experience on PPM tools like Solutions Business Manager (Micro Focus Tool) and/or Agile
10+ years professional experience as a data engineer or similar role
Experience with SQL/NoSQL databases, including MongoDB.
Experience with cloud computing platforms, including Amazon Web Services and Microsoft Azure
Proficiency in Python/R or MATLAB
What You'll Bring 
Excellent communication and presentation skills, both verbal and written
Proven experience in customer facing roles for large engagements and managing solution delivery teams.
Ability to solve problems using a creative and logical mind set
Demonstrated skills in team leadership, coaching, and competency building
Must be self-motivated, analytical, detail oriented, organized and pursue excellence on all tasks.
Good understanding of reporting tools such as PowerBI, Tableau.
Good knowledge of Big Data technologies such as Data lake, Databricks, Redshift, Spark, Kafka
Experience with NoSQL databases, such as HBase, MongoDB
Experience with any of the Hadoop distributions such as Cloudera/Hortonworks
Experience with AWS tools and technologies will be a plus.
Training/Certification on AWS/Agile will be a plus.
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
10 - Officials or Managers (EEO-2 Job Categories-United States of America), IFTECH103.2 - Middle Management Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 45K - 84K *
227,"Technical Support Engineer - Fluid Mechanics, AI/ML",Ansys,"Pune, MH, IN, 411057",Entry-level / Junior,"Requisition #: 13687 
  When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.
  Take a leap of certainty … with Ansys.
  Summary / Role Purpose
Join the Ansys Customer Excellence team to support our customers on all aspects of their real-world engineering simulation projects and integration of Ansys software(s) in their design workflows and grow Ansys’ business. You will use engineering knowledge to provide technical support, find solutions to a wide variety of technical challenges, and create knowledge material for bringing scale to the operation. You will be a part of our positive, dynamic team of enthusiastic and passionate engineers striving to deliver the highest quality solutions to our customers, advancing your knowledge, experience, and your impact on the success of our customers and Ansys.
  Key Duties and Responsibilities
Apply engineering expertise and knowledge of simulation techniques of Ansys Fluids products to provide the highest level of technical guidance to Customers and Channel Partners either through interactions with the users or by creating high-quality knowledge material and ensuring high-quality, timely customer service that results in improved customer satisfaction and productivity. 
Identify the knowledge gap based on the latest industry trends and requirements.
Work with multiple subject matter experts to address the gaps in knowledge.
Create knowledge on the latest Ansys product releases.
Develop technical expertise in one or more simulation areas. 
Submit suggestions for product improvement, when needed. File defect reports and verify fixes adhering to defect reporting processes.
Instruct training classes on the usage of ANSYS simulation products, as required.
Participate in other strategic and company initiatives, as needed.
Be agile and open to new responsibilities based on the business need.
Learn and gain expertise in new technical areas as and when required.
  Minimum Education/Certification Requirements and Experience
Ph.D., Master or Bachelor’s degree in Mechanical / Aerospace / Chemical Engineering
Sound knowledge related to Fluid Mechanics, Heat Transfer and Numerical Methods
Demonstrated problem-solving skills and ability to implement numerical models to obtain practical engineering solutions to difficult problems.
Engaging personality, engineering curiosity, and willingness for continuous learning
Ability to work independently, as well as with others in a diverse team environment.
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English.
Strong organizational and time management skills possesses a sense of urgency.
Projects a professional image and demonstrates business acumen, driven to succeed.
Interested in working with customers and willing to travel, if required
  Preferred Qualifications and Skills
Ph.D. or MS/MTech degree preferred.
Experience in using commercial or in-house CFD software for real-world industry-level applications.
A minimum of 1 year of experience in the use of relevant ANSYS software or other commercial software (Can be obtained in a university setting)
Experience of being part of the engineering product development cycle will be an added advantage.
      At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.
  Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger
  Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results
  OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high – met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.
  At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.
  CREATING A PLACE WE’RE PROUD TO BE 
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).
 
For more information, please visit us at www.ansys.com
  Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.
 
Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.",USD 22K - 42K *
228,Senior Data Engineer - Analytics,Grab,"Bengaluru, India",Senior-level / Expert,"Company Description
Life at Grab
At Grab, every Grabber is guided by The Grab Way, which spells out our mission, how we believe we can achieve it, and our operating principles - the 4Hs: Heart, Hunger, Honour and Humility. These principles guide and help us make decisions as we work to create economic empowerment for the people of Southeast Asia.
Job Description
Get to know our Team
The Data Engineering team runs the code, pipeline and infrastructure that extracts, processes and prepares every piece of data generated or consumed by Grab's systems. We are a diverse team of software developers that strives to solve all kinds of data
related problems faced by teams Grab-wide. Along with the growth of Grab, our team continues to learn, innovate and expand our suite of tools and technology to ensure Grab's continued success.

Get to know the Role
Data Engineers in Grab get to work on one of the largest and fastest-growing datasets of any company in South East Asia. We operate in a challenging, fast-paced and ever-changing environment that will push you to grow and learn. You will be involved
in various areas of Grab's Data Ecosystem, including reporting & analytics, data infrastructure, and various other data services that are integral parts of Grab's overall technical stack.

The Day-to-Day Activities
You are responsible for building, deploying and managing big data solutions that can adequately handle the needs of a rapidly growing data-driven company.
You make an impact by leading the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety).
You streamline data access and security to enable data scientists and analysts to access data whenever they need to.
You develop scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources.
You maintain and optimise the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making.
You lead the movement cleaning and normalizing subsets of data of interest as a preparatory step before more in-depth analysis by the data scientists.
You will work with high-performance analytical databases and computation engines like Spark, Flink, Presto, Synapse, BigQuery, Greenplum, among others.
Qualifications
The Must-Haves
You have a degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.
You have over 5 years work experience
You have demonstrated experience in handling large data sets (multiple PBs) and working with structured, unstructured and geographical datasets.
You are knowledgeable in designing high-performance and scalable infrastructure stacks for Big Data Analytics.
You possess a deep understanding of databases and best engineering practices - include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding how to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning and ensuring a deterministic pipeline.
You have a hunger for consuming data, new data technologies, and discovering new and innovative solutions to the company's data needs.
You possess the willingness and tenacity to get into the thick of the team's work when needed.
You are organized, insightful and can communicate your observations well, both written and verbally to your stakeholders to share updates and coordinate the development of data pipelines.
Additional Information
Our Commitment
We are committed to building diverse teams and creating an inclusive workplace that enables all Grabbers to perform at their best, regardless of nationality, ethnicity, religion, age, gender identity or sexual orientation and other attributes that make each Grabber unique.",USD 121K - 186K *
229,"Associate, Market Data Operations (IDS)- GUR",BlackRock,HA3-Gurgaon - DLF Cyber City,Mid-level / Intermediate,"About this role
BlackRock is one of the world’s preeminent asset management firms and a provider of global investment management, risk management and advisory services to institutional, intermediary, and individual investors around the world. BlackRock offers a range of solutions — from rigorous fundamental and quantitative active management approaches aimed at improving out-performance to highly efficient indexing strategies designed to gain exposure to capital markets. Our clients can access our investment solutions through a variety of product structures, including individual and institutional separate accounts, mutual funds and other pooled investment vehicles, and the industry-leading iShares® ETFs.
Overview:
The Index & Data Solutions team (IDS) is responsible for the index and data strategy for the firm and the management of the commercial relationships with each provider. The Operations team within IDS is looking for an Associate to join our team of market data professionals. This team handles the end-to-end administration of contracts by supporting the IDS relationship managers during the negotiation phase, maintaining an inventory of active contracts, validating invoice payments, declaring data usage to vendors, and partnering with BlackRock’s Finance team to handle market data budget accruals.
This Associate will work for day-to-day market data operations, project work and responding to business inquiries. The ideal candidate will be a high-energy, ambitious & self-motivated individual who is passionate about an opportunity to join a high performing team. We are seeking a critical thinker with strong problem-solving skills who can quickly assess problems and accurately complete solutions. Must be an excellent communicator able to simplify complex matters and tell a concise story !
Key Responsibilities:
Help maintain the market data inventory which includes a catalog of active services, fee schedules, consumers, and cost allocation, as well as address any inventory related inquiries.
Validate invoices and carry out the accrual reconciliation process for assigned vendors to ensure accurate and timely financial reporting and payments. Reconcile and clearly explain to management any differences between BlackRock’s market data inventory and vendor bills.
Support the contractual usage declaration process (i.e. exchange users, external redistribution usage) by partnering with internal business partners to obtain usage data, prepare, analyze and submit declarations to the providers.
Respond to inventory, invoice and reporting inquiries from BlackRock business partners and external vendors.
Handle provider change notifications to services and fees; understand the impact on users, obtain any necessary approvals and execute any required changes.
Execute process improvement projects that increase efficiency and reduce risk.
Requirements:
Graduate or post-graduate degree in related field.
3-5 years relevant work experience; knowledge of the Financial Services industry preferred.
Knowledge of Market and Index Data providers and ability to interpret contract terms and conditions is helpful.
Proficient with Excel and other MS Office applications, and able to quickly learn proprietary systems (BlackRock’s own and third-party platforms).
Experience with SQL, Power BI, Python is a plus.
Strong problem-solving and analytical skills are a must.
Excellent communication skills (written and verbal) are required.
Bold and proactive with a willingness to stretch outside comfort-zone
Self-starter, able to prioritize and deliver multiple assignments with high quality and consistent results.
Proven record of alignment with BlackRock's Principles .
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 30K - 56K *
230,Senior Azure Big Data Engineer,MetLife,"Hyderabad, IN",Senior-level / Expert,"Position Summary:
  Role Value Proposition:
Work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs. You will be using cutting-edge technologies and frameworks to analyze data, to help create the pipeline, and collaborate with the data science team to enable the innovative work in machine learning and AI. Eagerness to learn new technologies on the fly and ship to production. Knowledge in data science is a plus.
  More than just a job we hire people who love what they do!
Job Responsibilities:
  1. Building and Implementing data ingestion and curation process developed using Big data tools such as Spark (Scala/python), Data bricks, Delta lake, Hive, Pig, Spark, HDFS, Oozie, Sqoop, Flume, Zookeeper, Kerberos, Sentry, Impala etc.
2. Ingesting huge volumes data from various platforms for Analytics needs and writing high-performance, reliable, and maintainable ETL code.
3. Monitoring performance and advising any necessary infrastructure changes.
4. Defining data security principals and policies using Ranger and Kerberos.
5. Assisting application developers and advising on efficient big data application development using cutting edge technologies.
6. Lead, coach, support, and mentor team members – set up performance goals, review their work as required, provide adequate guidance, feedback to help them achieve their goals and do right for Enterprise
  Knowledge, Skills and Abilities:
  Experience Required: 
Bachelor's degree in Computer Science, Engineering, or related discipline.
 8 + years of solutions development experience
Proficiency and extensive Experience with Spark & Scala, Python and performance tuning is a MUST
Hive database management and Performance tuning is a MUST (Partitioning / Bucketing)
Strong SQL knowledge and data analysis skills for data anomaly detection and data quality assurance.
Strong analytic skills related to working with unstructured datasets.
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
Experience in any model management methodologies.
  Required:
Proficiency and extensive experience in HDFS, Hive, Spark, Scala, Python, Databricks/Delta Lake, Flume, Kafka etc.
Analytical skills to analyze situations and come to optimal and efficient solution based on requirements.
Performance tuning and problem-solving skills is a must
Hive database management and Performance tuning is a MUST. (Partitioning / Bucketing)
Hands on development experience and high proficiency in Java or Python, Scala and SQL
Experience designing multi-tenant, containerized Hadoop architecture for memory/CPU management/sharing across different LOBs
Preferred:
Proficiency and extensive Experience with Spark & Scala, Python and performance tuning is a MUST
Hive database management and Performance tuning is a MUST. (Partitioning / Bucketing)
Strong SQL knowledge and data analysis skills for data anomaly detection and data quality assurance.
Knowledge in data science is a plus
Experience with Informatica PC/BDM 10 and implemented push down processing into Hadoop platform, is a huge plus.
Proficiency is using tools Git, Bamboo and other continuous integration and deployment tools
Exposure to data governance principles such as Metadata, Lineage (Colibra/Atlas) etc.
  Knowledge and Skills:
• Proficiency and extensive experience in Data analysis
• Solid background on writing SQLs and using other exploratory tools.
• Extensive experience writing Functional requirements and High-level design documents.
• Experience in writing validation scripts to validate the data, data integrations and ETL transformations.
• Analytical skills to analyze situations and come to optimal and efficient solution based on requirements.
• Strong background or experience working in Insurance Industry.
• SQL tuning and DW concepts.
• Strong analytic skills related to working with unstructured datasets.
  MetLife:
  MetLife, through its subsidiaries and affiliates, is one of the world’s leading financial services companies, providing insurance, annuities, employee benefits and asset management to help its individual and institutional customers navigate their changing world. Founded in 1868, MetLife has operations in more than 40 countries and holds leading market positions in the United States, Japan, Latin America, Asia, Europe and the Middle East.
  We are ranked #44 on the Fortune 500 list for 2019. In 2019, we were named to the Dow Jones Sustainability Index (DJSI) for the fourth year in a row. DJSI is a global index to track the leading sustainability-driven companies.      
  MetLife is committed to building a purpose-driven and inclusive culture that energizes our people. Our employees work every day to help build a more confident future for people around the world.
  MetLife is a proud Equal Employment Opportunity and Affirmative Action employer dedicated to attracting, retaining, and developing a diverse and inclusive workforce. All qualified applicants will receive consideration for employment at MetLife without regards to race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, uniformed service member or veteran status, or any other characteristic protected by law.",USD 45K - 84K *
231,"Sr. Software Engineer, Data Operations",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation. #HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
232,Senior Data Engineer-3,CVS Health,"Pune, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer-3
Mastercard Overview

Mastercard is the global technology company behind the world’s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless®. We ensure every employee can be a part of something bigger and change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.

Join a fast-growing team

As a Senior Data Engineer in the Data Engineering & Analytics team, you will develop data & analytics solutions that sit atop vast datasets gathered by retail stores, restaurants, banks, and other consumer-focused companies. The challenge will be to create high-performance algorithms, cutting-edge analytical techniques including machine learning and artificial intelligence, and intuitive workflows that allow our users to derive insights from big data that in turn drive their businesses. You will have the opportunity to create high-performance analytic solutions based on data sets measured in the billions of transactions and front-end visualizations to unleash the value of big data. You will have the opportunity to develop data-driven innovative analytical solutions and identify opportunities to support business and client needs in a quantitative manner and facilitate informed recommendations/decisions through activities like building ML models, automated data pipelines, designing data architecture/schema, performing jobs in big data cluster by using different execution engines and program languages such as Hive/Impala, Python, Java, Kafka, Spark, R, etc.

Your Role

• Hands-on developer who writes good quality, secure code that is modular, functional, and testable.
• Drive the evolution of Data & Services products/platforms with an impact-focused on data science and engineering.
• Design and implement scalable data architecture and data pipelines
• Solving complex problems with multi-layered data sets, as well as optimizing existing machine learning libraries and frameworks.
• Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.
• Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
• Discover, ingest, and incorporate new sources of real-time, streaming, batch, and API-based data into our platform to enhance the insights we get from running tests and expand the ways and properties on which we can test Experiment with new tools to streamline the development, testing, deployment, and running of our data pipelines.
• Participate in the development of data and analytic infrastructure for product development
Continuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations
• Partner with roles across the organization including consultants, engineering, and sales to determine the highest priority problems to solve
• Evaluate trade-offs between many possible analytics solutions to a problem, taking into account usability, technical feasibility, timelines, and differing stakeholder opinions to make a decision
Break large solutions into smaller, releasable milestones to collect data and feedback from product managers, clients, and other stakeholders
• Evangelize releases to users, incorporating feedback, and tracking usage to inform future development
Work with small, cross-functional teams to define the vision, establish team culture and processes
Consistently focus on key drivers of organization value and prioritize operational activities accordingly
• Escalate technical errors or bugs detected in project work
• Maintain awareness of relevant technical and product trends through self-learning/study, training classes, and job shadowing.
• Support the building of scaled machine learning production systems by designing pipelines and engineering infrastructure.

Ideal Candidate Qualifications:

• Working proficiency in using Python/Scala, Spark (tuning jobs), SQL, Hadoop platforms to build Big Data products & platforms.
• Good programming skills in Java and spring boot and Junit.
• Knowledge in software development test approaches & frameworks
• Familiarity with RESTful APIs and micro-services architectures
• Experience in working with CI/CD
• Experience in working with SQL database like Postgres, Oracle
• Preferably with hands-on experience with Hadoop big data tools (Hive, Impala, Spark)
• Experience with data pipeline and workflow management tools: NIFI, Airflow.
• Comfortable in developing shell scripts for automation.
• Good troubleshooting and debugging skills.
• Proficient in standard software development, such as version control, testing, and deployment
• Demonstrated basic knowledge of statistical analytical techniques, coding, and data engineering
• Ability to quickly learn and implement new technologies
• Ability to Solve complex problems with multi-layered data sets
• Ability to innovate and determine new approaches & technologies to solve business problems and generate business insights & recommendations.
• Ability to multi-task and strong attention to detail
• Flexibility to work as a member of a matrix based diverse and geographically distributed project teams
• Good communication skills - both verbal and written – and strong relationship, collaboration skills, and organizational skills

The following skills will be considered as a plus.

• Experience with performance Tuning of Database Schemas, Databases, SQL, ETL Jobs, and related scripts
• Experience in working with Cloud APIs (e.g., Azure, AWS)
• Experience participating in complex engineering projects in an Agile setting e.g. Scrum
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 121K - 186K *
233,"Research Analyst, Corporate Research",Verisk,"Gurugram, India",Entry-level / Junior,"Company Description
Wood Mackenzie are the global research, analytics, and consultancy business powering the natural resources industry. For 50 years, we have been providing the quality data, analytics, and insights our customers rely on to inspire their decision making.
Our dedicated oil, gas & LNG, power & renewables, chemicals, metals & mining sector teams are located around the world and deliver a variety of projects based on our assessment and valuation of thousands of individual assets, companies, and economic indicators such as market supply, demand, and price trends.
We have over 1,900 employees in 30 locations, serving customers in nearly 80 countries. Together, we inspire and innovate the markets we serve – providing invaluable intelligence to help our customers overcome the toughest challenges, and make strategic decisions that will, ultimately, accelerate the world’s transition to a more sustainable future.
WoodMac.com
Wood Mackenzie brand video
Job Description
Role Purpose
We are seeking Research Analyst to join our Corporate Research team. Our global team of Corporate analysts deliver best in class research and data coverage of the world’s leading energy and natural resources companies. Together we serve a range of clients including integrated energy companies, national oil companies, mining companies, utilities and renewables companies, investment banks and institutional investors. Wood Mackenzie’s purpose is to transform the way we power our planet and our Corporate Research team is at the forefront of helping our clients navigate the energy transition.
Main Responsibilities
The focus of this role will be to support senior Corporate team members in developing datasets, models and written content that will provide insightful analysis for our clients. The role holder will closely monitor news flow in the energy and natural resources sector, assess company reported data and commercial developments, and analyse data to contribute to research content for Wood Mackenzie’s growing Corporate offerings.
The successful candidate will support delivery across the three segments of our Corporate coverage: Oil & Gas, Power & Renewables and Metals & Mining. The role offers a great opportunity to learn from some of the world’s leading experts in corporate strategy and the energy transition. A client-centric approach, combined with great attention to detail, will be essential to deliver successfully in this role
Qualifications
About You
We are looking for candidates with some research experience (ideally 1-2 years focus on energy or natural resources) who can demonstrate a genuine passion and potential to grow as a member of Wood Mackenzie’s Corporate Research team. You must have an excellent command of English, both written and spoken.
Your application should showcase your enthusiasm for energy and natural resources sector and demonstrate your ability in the following areas, which we require daily at Wood Mackenzie.
Research and data gathering – we identify and gather intelligence that feeds our industry expertise. We need inquisitive and passionate people with a keen eye for detail. Candidates must have an interest in corporate strategy and the transformation of the energy & natural resources sectors.
Analysis - we provide market-leading research using this data/intelligence and form opinions for, and tell stories to, our customers. We need people with natural curiosity with potential to become experts in their field, and with the ability to articulate – both verbally and in writing – clear, insightful analysis. Successful candidates will have experience working with data using Excel, Python or other big data platforms and programming languages
Internal engagement – we work with colleagues across the Wood Mackenzie business to deliver a compelling, integrated view of the natural resources sector to customers through our cutting-edge products. For this, we need people who are as comfortable working collaboratively as they are independently and who have excellent interpersonal skills. The role will require close collaboration with colleagues across time zones and flexibility is required.
External engagement – we proactively connect with our customers and contacts in the industries we serve, adding value and promoting the Wood Mackenzie brand. This requires people with the potential to become industry experts who have intellectual curiosity, passion, and excellent presentation skills (including experience with PowerPoint).
Continuous improvement – at Wood Mackenzie, we are committed to transform the way we power our planet. The energy transition is here, and this impacts our customer base and how we serve them. We need colleagues with a change mindset, who are flexible, growth-orientated, and proactive.            
#LI-DB1
Additional Information
Wood Mackenzie is a place where we are committed to supporting our people to grow and thrive. We value different perspectives and aspire to create an inclusive environment which encourages diversity and fosters a sense of belonging. 
Wood Mackenzie values everyone’s contribution and helps them reach their full potential while sustaining an organisational culture of health and well-being.
Our core values are:
Inclusive – we succeed together
Trusting – we choose to trust each other
Customer committed – we put customers at the heart of our decisions
Future Focused – we accelerate change
Curious – we turn knowledge into action
We understand the importance of bringing your whole self to work and to achieving balance between work, family and other life commitments.  We are open to considering flexible working arrangements to enable the greatest spectrum of talent to contribute to Wood Mackenzie's success.
Hear what our team has to say about working with us: https://www.woodmac.com/careers/our-people/
WoodMackenzie takes your data privacy seriously, please click here to view our privacy notices: Candidate Privacy Notice | Wood Mackenzie | Wood Mackenzie / Candidate Notice - California",USD 49K - 81K *
234,"Staff Data Engineer, Content Intelligence",Bazaarvoice,Bengaluru,Senior-level / Expert," About Bazaarvoice
 At Bazaarvoice, we create smart shopping experiences. Through our expansive global network, product-passionate community & enterprise technology, we connect thousands of brands and retailers with billions of consumers. Our solutions enable brands to connect with consumers and collect valuable user-generated content, at an unprecedented scale. This content achieves global reach by leveraging our extensive and ever-expanding retail, social & search syndication network. And we make it easy for brands & retailers to gain valuable business insights from real-time consumer feedback with intuitive tools and dashboards. The result is smarter shopping: loyal customers, increased sales, and improved products.
 The problem we are trying to solve : Brands and retailers struggle to make real connections with consumers. It's a challenge to deliver trustworthy and inspiring content in the moments that matter most during the discovery and purchase cycle. The result? Time and money spent on content that doesn't attract new consumers, convert them, or earn their long-term loyalty.
 Our brand promise : closing the gap between brands and consumers.
 Founded in 2005, Bazaarvoice is headquartered in Austin, Texas with offices in North America, Europe, Asia and Australia.
 It’s official: Bazaarvoice is a Great Place to Work in the US , Australia, India, Lithuania, France, Germany and the UK!

Our teams create Bazaarvoice products that help companies understand the competitive positioning of their products.  A big area of business growth for Bazaarvoice will come from the efforts of our data teams.  Across more than 11,500 of the world’s leading brands and retailers, Bazaarvoice sees more 11 million reviews, images and questions added each month across millions of products.  Our data teams leverage these data sets to help our brand and retail clients build better products, build stronger relationships with their shoppers, and make decisions on when and where to offer products. 

Bazaarvoice provides consumer generated content to over 700 million devices and ½ billion unique users every month.  That content is hosted and collected on over 5000 brand and retail websites around the world.  Our Mission: build smarter shopper experiences across the entire customer journey.   We’re looking for candidates who want to build software that impacts over 500 million users, helping them make smart buying decisions, work with TB-scale datasets and globally distributed systems. 
 We are looking for a talented Software Engineer to design, build, and maintain scalable, big data pipelines. The position will focus on building and improving services that make it easier for internal teams to harness the power of existing data pipelines to keep data flowing through Bazaarvoice systems to support client use cases.
 Essential Skills
MSc in Computer Science or equivalent (education or work based)
8+ years building software in a commercial environment (preferably SaaS)
5+ years of experience with highly scalable distributed systems using open source tools.
2+ years working with large data sets using Map/Reduce (AWS EMR experience preferred)
4+ years’ experience with one or more of the following Java, Scala, C#, or similar language
Working knowledge of at least one scripting language – PHP, Python, Bash, JavaScript, etc.
Demonstrated experience with Hadoop
AWS experience including one or more of the following Cloud Formation, EMR, S3, EC2, Cloud Trail, etc.
Experience in the design, implementation, and support of major components of an analytics solution.
Able to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviews

Desired Criteria
Experience with Storm or Spark
Working with TB+ size data sets
Performing large-scale analytics using Map/Reduce
Demonstrated experience in the design and development of large scale, performant, and fault tolerant applications
Experience in defining data to be captured, how it would be aggregated, and how to implement those mechanisms
Experience and passion in working on agile teams using Scrum, Kanban, or similar
Experience building large-scale data processing systems with extensive knowledge in data warehousing solutions. This includes developing prototypes and proof-of-concepts for the selected solutions.
Familiarity withone or more big-data infrastructures such as Hbase, Hadoop, Mongo, Casandra, or RDBMS.
An understanding and experience building high-performance algorithms.
#LI-Hybrid #LI-SR1

Why join Bazaarvoice?
 Customer is key
We see our own success through our customers’ outcomes.  
We approach every situation with a customer first mindset.
 Transparency & Integrity Builds Trust
We believe in the power of authentic feedback because it’s in our DNA. 
We do the right thing when faced with hard choices. Transparency and trust accelerate our collective performance.
 Passionate Pursuit of Performance
Our energy is contagious, because we hire for passion, drive & curiosity. 
We love what we do, and because we’re laser focused on our mission.
 Innovation over Imitation
We seek to innovate as we are not content with the status quo. 
We embrace agility and experimentation as an advantage.
 Stronger Together
We bring our whole selves to the mission and find value in diverse perspectives. 
We champion what’s best for Bazaarvoice before individuals or teams.  
As a stronger company we build a stronger community.
 Commitment to diversity and inclusion
 Bazaarvoice provides equal employment opportunities (EEO) to all team members and applicants according to their experience, talent, and qualifications for the job without regard to race, color, national origin, religion, age, disability, sex (including pregnancy, gender stereotyping, and marital status), sexual orientation, gender identity, genetic information, military/veteran status, or any other category protected by federal, state, or local law in every location in which the company has facilities. Bazaarvoice believes that diversity and an inclusive company culture are key drivers of creativity, innovation and performance. Furthermore, a diverse workforce and the maintenance of an atmosphere that welcomes versatile perspectives will enhance our ability to fulfill our vision of creating the world’s smartest network of consumers, brands, and retailers.",USD 121K - 186K *
235,Data Scientist (Analytic Engineer),Applied Materials,"Bengaluru,IND",Senior-level / Expert,"Roles and Responsibility
7-10 years of experience in the industry
Locates and extracts data from various information systems, such as Hadoop and BPC, for use in analytics solutions.
Provides documentation of Hadoop data taxonomy for key datasets including, but not limited to, schema and attribute descriptions, leveraging existing meta-data on the bigdata.
Performs data de-bugging, validation and testing and makes recommendations on data cleaning and/or transformations to enhance data fidelity.
Prepare clean, transformed data from multiple data sources ready for analysis
Identify opportunities for enriching and integrating data from multiple, diverse sources.
Identify and design new model features and implement them in our product.
Establish standardized data, implement code version control, schedule workflows, and develop business and schema tests.
Able to work both independently and in a team environment
Experience with SQL, Python, or other scripting languages.
Good document tracking strategies
Work with the development team to identify, document, and resolve software issues
Work with a cross-functional agile team that is responsible for multiple projects
Excellent document maintenance procedures
Documenting and communicating results
Knowledge of statistical concepts
Proficiency in conducting exploratory data analysis (EDA) and applying various analytical techniques to uncover insights from data
Effectively visualize and communicate findings using data visualization tools (e.g., Tableau, Power BI)
Qualifications
Education:
Bachelor's Degree: Computer science
Skills
Advanced Data Visualization Techniques, Microsoft Power Business Intelligence (BI) Data Visualization, Python (Programming Language), R language (Inactive), SQL Database Management
Certifications:
Languages:
Years of Experience:
4 - 7 Years
Work Experience:
Additional Information
Travel:
Yes, 10% of the Time
Relocation Eligible:
Yes
Applied Materials is an Equal Opportunity Employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law. ",USD 136K - 205K *
236,Senior Data Scientist,Novo Nordisk,"Bengaluru, Karnataka, IN",Senior-level / Expert,"    Are you enthusiastic about understanding the business and bringing attention to key business challenges? Then we might have the right position for you.
  About the department
You will join our team of architects, developers, analysts, and data engineers in Data Management & Analytics. It’s a global, high performing department with a variety of technical, analytical, and multinational backgrounds. We are expanding our offerings to the global organisation, so we need extra resources to succeed with our journey and ambitious vision.
  We do data acquisition and ingestion; data analysis and data engineering; evangelising the use of data and advanced analytics; and supporting data science users of our platform. We are cloud native and we work primarily on AWS. We deliver solutions using Scrum methodology. We have built and are operating the enterprise data lake, data mesh and data science platform on AWS to support our vision, which is to be able to deliver world class management of data.
  The overarching goal is to use data to gain new understandings and insights, drive optimisations and create true value to Novo Nordisk and the patients we serve. We #BringDataToLife
  The position
Support the development of the Advanced Analytics workstream within Business Finance by driving the identified use cases, translating the business problem into an advanced modelling solutions.
Execution of the projects; partnering with key business and finance stakeholders by acting as the bridge across business and technical subject matter expertise and the key delivery lead throughout Proofs of Concept and Minimum Viable Product / Prototype phase.
Contribute to the awareness and adoption of ML models across Global Finance by gathering and sharing best data science practices and real use case learnings, i.e building a new set of competences in Finance.
Drive the advanced analytics use cases backed up by deep exploratory analysis and data wrangling (both external and internal)
Generate and pivot the main hypothesis and validate the line of experimentation by applying the appropriate quantitative techniques.
Improve learnings of applications and provide recommendations on existing gaps for applications of advanced modelling techniques
Generate and communicate the results and data driven insights aimed at further advancement of business partnering to line of business.
Initiate the development of an MLOps framework, mainly focused on POC projects, ensure analytics models and pipelines are interpretable and replicable.
Support establishing in house capabilities and use of best technology practices through knowledge sharing with colleagues
  Qualifications
We Expect you to hold the below skills and knowledge.
Bachelor's or master’s degree in computer science, Statistics, Mathematics, or related field
3+ years of experience in data science, machine learning, or related field
Strong programming skills in Python, R, or similar languages
proven experience in managing and leading data science projects
Experience with data visualization tools such as Tableau, Power BI, or similar
Proficiency in SQL and working with relational databases
Strong understanding of statistical analysis, experimental design, and hypothesis testing
Experience with deep learning frameworks such as TensorFlow, Keras, or similar
Experience with data cleaning, pre-processing, and feature engineering
Knowledge of big data technologies such as Hadoop, Spark, or similar
Excellent problem-solving skills and ability to work in a team environment
Strong communication skills to present complex analytical findings to both technical and non-technical stakeholders
Strong business acumen and ability to translate business objectives into data science projects
  Working at Novo Nordisk
In Novo Nordisk, you will be met with trust, interesting challenges and rich opportunity for personal and professional growth. You will be investing your unique skills in an environment focused around a competent sharing of knowledge, and where your talent and experience is valued. We are proud to use our dedication and our capabilities to make a difference for millions of people around the world.
  Contact
Please click Apply and follow the instructions.
  Deadline
17 Jan 2024
    We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 136K - 205K *
237,Senior ETL Developer,Guidehouse,"GH Office: Trivandrum, India - Bhavani",Senior-level / Expert,"Job Family:
Software Application & Development (India)

Travel Required:
None

Clearance Required:
None
What You Will Do:
Lead and optimize the development of complex SQL queries, stored procedures, and ETL processes.
Design and implement scalable, maintainable, and high-performance data solutions.
Provide expert guidance in database design, data modeling, performance tuning, and data visualization.
Collaborate closely with stakeholders to understand, analyse and translate complex business data requirements.
Mentor and guide junior developers in best practices, coding standards, and advanced visualization techniques.
Develop and deploy interactive dashboards and reports using advanced visualization tools (e.g., Tableau, Power BI).
Conduct thorough data analysis, identifying trends, patterns, and insights to drive informed decision-making.
Troubleshoot and resolve intricate data issues, ensuring data integrity and reliability.
Evaluate and implement emerging technologies for data management, analytics, and visualization.
Lead initiatives to enhance data quality, governance, and overall data-driven decision capabilities.
 What You Will Need:
5+ years of hands-on experience in advanced SQL development, advanced ETL processes, database design, and data visualization.
Expertise in performance tuning, query optimization, and data modeling.
Proven experience with ETL tools (ADF, Talend, SSIS) and various database systems.
Strong analytical and problem-solving skills with meticulous attention to detail.
Proficiency in creating visually compelling and insightful reports and dashboards.
Excellent communication and collaboration skills, with the ability to convey complex technical concepts to non-technical stakeholders.
 What Would Be Nice to Have:
In-depth knowledge of data warehousing concepts, dimensional modeling, and best practices.
Proficiency in scripting languages such as Python or Java.
Experience with cloud-based data platforms (AWS, Azure, GCP).
Familiarity with big data technologies (Hadoop, Spark).
Advanced certifications in relevant technologies, methodologies, or data visualization tools.
Experience with DevOps Pipeline/GIT/JIRA is preferred.

What We Offer:
Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.
About Guidehouse
Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation.

If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.

Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.",USD 99K - 143K *
238,Associate Data Scientist,MetLife,"Hyderabad, IN",Mid-level / Intermediate,"Position Summary:
Continuing with the tradition of innovation, MetLife, as part of its Data and Analytics function, established a
dedicated center for advanced analytics & research in India. DnA Hyderabad a.k.a
Global Advanced analytics and Research Center (GARC) is part of larger Data and analytics organization (DnA) of MetLife focused on scaling data governance, data management, data engineering, data science/machine learning/ artificial intelligence, visualization, techno-project management capabilities, enabling more cost-effective analytics operating model and increasing data and analytics maturity across the MetLife global community.
  Role Value Proposition:
We are looking for highly motivated and enthusiastic individuals looking to build a career in the field of data science and analytics, to be a part of the data science team and work with amazing peer group that truly values data-driven decisions. DnA Hyderabad will deliver data driven decisions across all critical business functions such as customer engagement, distribution, underwriting, claims operations, risk management, products and tackle hard, open-ended problems.
The position is required to deliver on data science projects under the guidance of Data Scientists and Sr. Data Scientists. Superior problem-solving ability, curiosity, strong coding mindset and attention to detail are the key success factors. Associate Data Scientists are the future of our Data and Analytics Community. We are looking for the smartest folks with insatiable curiosity
Job Responsibilities:
Work with Senior Data Scientists and Data Scientists to understand the business problem and work with them to design effective solutions
Develop appropriate moderate to advanced level statistical and ML algorithms, test the quality and iterate till desired results are obtained
Works independently on intermediate level data preparation, modeling, evaluation, and deployment
tasks, with supervision on advanced level tasks
Test development/deployment code to ensure smooth & accurate Productionisation of ML models
Extract analytical insights and translate them to business insights; validate the insights with Manager and continuously improve upon interpretation skills.
Work with the Sr. Data Scientist/Manager to present the insights and recommendations to stakeholders & create intuitive and detailed documentation as appropriate.
Ensure coding as well as overall development best practices are implemented
Contribute to collaboration and awareness in the global data and analytics community
Knowledge, Skills and Abilities
BS/MS in Math, Statistics, Operations Research, social sciences, or related quantitative field
Up to 3 years of work experience in the field of data and analytics
Hands on knowledge of programming languages like R, Python, and
database query languages like SQL
Machine Learning – Good knowledge of machine learning methods and knowledge on statistical models like regression is an added advantage
Moderate Knowledge of various data structures and open-source data products/technologies for development/deployment of ML models
Proven ability in logical thinking and problem solving
Proven ability to work in teams to deliver results
Good written and oral communication, with the ability to communicate effectively with stakeholders
Conceptual knowledge of Big Data technologies like Hadoop (Spark, Hive, Pig) is a plus
MetLife:
  MetLife, through its subsidiaries and affiliates, is one of the world’s leading financial services companies, providing insurance, annuities, employee benefits and asset management to help its individual and institutional customers navigate their changing world. Founded in 1868, MetLife has operations in more than 40 countries and holds leading market positions in the United States, Japan, Latin America, Asia, Europe and the Middle East.
  We are ranked #44 on the Fortune 500 list for 2019. In 2019, we were named to the Dow Jones Sustainability Index (DJSI) for the fourth year in a row. DJSI is a global index to track the leading sustainability-driven companies.      
  MetLife is committed to building a purpose-driven and inclusive culture that energizes our people. Our employees work every day to help build a more confident future for people around the world.
  MetLife is a proud Equal Employment Opportunity and Affirmative Action employer dedicated to attracting, retaining, and developing a diverse and inclusive workforce. All qualified applicants will receive consideration for employment at MetLife without regards to race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, uniformed service member or veteran status, or any other characteristic protected by law.",USD 86K - 160K *
239,Principal Threat Research Analyst,OpenText,"Bengaluru, KA, IN",Senior-level / Expert,"Hiring Manager:
Talent Acquisition Advisor: Prathika Shetty
Job Code Level: IKP5 
Refer Your Friends!
The Opportunity: 
As a Principal Threat Research Analyst, you will work closely with our senior threat researcher and partner with clients to investigate the threat leads on their systems. You will help to extract data and remove the noise in order to pinpoint the internal and external threats. Our client base is global and in nearly every industry.
  You Are Great: 
Work with behavioral analytics threat-hunting technologies to analyze and identify threat patterns or indicators that can be used for threat detection on our platform.
Follow the emerging threats and attack techniques by reading detailed analytics anomalies.
Identify, analyze, and define the attack path of advanced intrusions.
Produce reports that can form the basis for new behavioral models.
Maintain situational awareness of cyber activity by reviewing new anomalies and tracking attack campaigns through their attack cycle.
Track threat actors, their tactics, techniques, and procedures (TTPs), and their associated Indicators of Compromise (IOCs) through analytics.
Follow the analytic results leveraging additional search techniques including Kibana and Athena.
Understanding the cybersecurity landscape
Deep knowledge of current and past malware methods, attack methodologies, and TTPs (Tactics, Techniques, Procedures)
Strong understanding of current attacker tradecraft
Define client relationships and understand the critical assets in their environment to develop additional detection patterns.
Experience with common industry EDR/SOAR/Anomaly detection solutions (CrowdStrike Falcon, Microsoft Defender, etc.)
Experience with the incident response process, including detecting advanced adversaries, log analysis using SIEM, and malware triage (Optional)
Knowledge and experience working with the Cyber Kill Chain Model, MITER ATT&CK Matrix. (Optional)
Knowledge of Operating Systems and Network Protocols
Extensive knowledge of Operating System Internals (Windows, *nix, MacOS)
Strong understanding of network security concepts and network protocols, NetFlow, and web proxy.
Scripting knowledge (PowerShell, Python, etc.)
Technical Writing and Reporting Skills
Experience preparing security reports and different technical documents.
  What it Takes: 
You are persistent and inquisitive. You must understand why things are happening the way they are.
You are determined to understand cyber-attack techniques at a very detailed level.
You are a self-starter who is able to work with minimal management, however, have strong collaboration and interpersonal skills to work together with several other professionals from other information security fields.
You’re a creative thinker who wants to answer the question, “Why?”
Your workstation is a pyramid of monitors that you can't take your eyes off of at the risk of missing something juicy.
You have a desire to learn new technologies.
Your sense of humor, passion and enthusiasm shines through in everything you do
  Micro Focus’ (now OpenText) efforts to build an inclusive work environment go beyond simply complying with applicable laws. Our Employment Equity and Diversity Policy provides direction on maintaining a working environment that is inclusive of everyone, regardless of culture, national origin, race, color, gender, gender identification, sexual orientation, family status, age, veteran status, disability, religion, or other basis protected by applicable laws. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please contact us at hr@opentext.com.",USD 63K - 160K *
240,Unit Manager-Business Excellence (AI),MetLife,"Noida, IN",Senior-level / Expert,"Position Summary:
  Manager/Unit Manager needs to be a certified Lean Six Sigma Black Belt / Green Belt from a reputed organization along with the proven knowledge of new age technologies such as AI / Generative AI, Machine Learning, Intelligent Automation, Advanced Analytics etc. S/he will be responsible to drive Digital/Six Sigma/Lean Projects. Develop and disseminate Digital / Six Sigma training modules.  S/he should be able to drive large complex initiatives through interpreting and transforming business intelligence/ data into meaningful/ actionable insights that business leaders can refer to drive business outcomes, make business decisions, identify trends etc. The incumbent will also be responsible to drive large programs as project manager.
Job Responsibilities:
  Identify improvement opportunities and ensure effective execution of projects and initiatives.
Drive continuous improvement projects and support/lead functional initiatives.
Lead transformation by building strong rigor and governance to ensure timely closures of gaps and help functions create efficiencies.
Effectively represent the function in the leadership meets by demonstrating strong communication & interpersonal skills
Develop Digital, Lean and other continuous improvement training content.
Contribute to the design and implementation of AI solutions
Assist in the development and implementation of AI models and systems, leveraging techniques such as Large Language Models (LLMs) and Generative AI.
Convert process flows / fact findings into case study / story boards / process flow.
In-depth knowledge of Quality tools, Minitab and Lean & Six Sigma know how.
Analyze data and create reports to gauge continuous improvement.
Good Knowledge of Due Diligence, Project Management, Knowledge Transfer Planning, Risk Management, Customer Engagement and Stake-holder Management
Knowledge, Skills and Abilities
  Minimum 12 years of work experience
Lean Six Sigma Black Belt Certification, with reputed organization, with a sound project execution experience
Ability to analyze gaps and with root cause analysis, and further solution to best partner with stake holders
Should have leadership skills like: relationship management, collaboration, facilitation, and influencing
Must possess planning and analytical skills to facilitate and focus on continuous improvement and innovation within the organization
Must have good communication, interpersonal and project Management skills and be able to interact with senior leadership / business partners / customers, both locally and globally
Excellent knowledge of Project Management approach (PMP, Agile, Prince 2 etc. )
Excellent knowledge of MS Office suite, especially Excel
Strong Presentation Management and Training delivery
Excellent analytical and research skills
Ability to constantly upgrade herself with latest continuous improvement technologies
Result Oriented, with strong negotiation and convincing skills
Ability to find creative and innovative solutions to business problems
MetLife:
  MetLife, through its subsidiaries and affiliates, is one of the world’s leading financial services companies, providing insurance, annuities, employee benefits and asset management to help its individual and institutional customers navigate their changing world. Founded in 1868, MetLife has operations in more than 40 countries and holds leading market positions in the United States, Japan, Latin America, Asia, Europe and the Middle East.
  We are ranked #44 on the Fortune 500 list for 2019. In 2019, we were named to the Dow Jones Sustainability Index (DJSI) for the fourth year in a row. DJSI is a global index to track the leading sustainability-driven companies.      
  MetLife is committed to building a purpose-driven and inclusive culture that energizes our people. Our employees work every day to help build a more confident future for people around the world.
  MetLife is a proud Equal Employment Opportunity and Affirmative Action employer dedicated to attracting, retaining, and developing a diverse and inclusive workforce. All qualified applicants will receive consideration for employment at MetLife without regards to race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, uniformed service member or veteran status, or any other characteristic protected by law.",USD 45K - 84K *
241,Data Scientist,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
About Global Commercial Payments Platform
 We are working on multiple technology stacks and want to add a highly motivated Engineer to our Commercial Payments organization in Foster City, CA. Visa's Commercial Payments organization is responsible for managing Visa's B2B Payment Global adoption on Cross-Border funds movement, innovation agenda and the management of strategic partnerships with critical financial institutions. This group is responsible for defining and building the Non-Card based payment innovation and product for Visa Inc. Globally. This includes:
Distributed-Ledger based Cross border payment platform
Near time Settlement 
Enterprise ID stamping to create a digital identity for corporate entities
Hyperledger chain-code development
End-to-End Payment eco-system 
Analytics and Data visualization
 You can learn more about our work here:
Visa B2B Connect Launches in 32 Countries
Visa B2B Connect Launches Globally
 Essential Functions
Work on emerging technologies, building distributed applications
Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.
Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards. 
Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.
Partner with Product on implementation strategy.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:

2-4 years of relevant work experience with a Bachelor’s Degree in Computer Science or related field or an advanced degree in Computer Science or related field

Preferred Qualifications:

MS in Computer Science or related field
2+ years of experience with distributed software development
Hands-on experience with all aspects of software development: data, server-side, UI, and open-source software.
Experience with Linux, Open source, C++ or Java, client-server apps
Expertise in at least two of the following: Java / Go / Scala / Python,
Knowledge of developing Data Pipeline, including Ingestion, Transformation, Extraction etc. is expected
Experience in large Data Pipeline handing is a big plus
Familiar with container strategies and ecosystems such as Docker, Kubernetes
Knowledge of cloud architecture and scalable solutions including orchestration
BlockChain technical expertise is a plus
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 86K - 160K *
242,"Senior Manager, Business Intelligence & Insights",S&P Global,IN - BANGALORE WHITEFIELD ROAD,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
11
The Role: Senior Manager, Business Intelligence & Insights 
The Team: The Sales Strategy and Operations is a world-class support team leading performance growth and optimization from the heart of the Sales Organization. Our unparalleled commitment to customer-centric operational excellence drives quality, relevancy, and trust through our execution. Our services, initiatives, and programs are a source of competitive advantage, combining data, technology, and insights to empower our people and customers to make informed decisions that accelerate progress in the world. 
Responsibilities:  
We are looking for a business intelligence (BI) senior professional who will be working on designing various analytical reports on company data and delivering them to top management and other interested parties.  
As a BI senior manager, you will be working with business users, collecting their requests, and then updating the set of existing BI reports to accommodate business needs.  
You will be expected to establish company standards and common reporting terminology, and to help align existing and future reporting requests to such standards.  
You will also be interacting with data warehouse architects whenever data schemas need redesigning to accommodate new reporting requirements. 
Work with data warehouse architects, data scientists, and data collection application engineers. Propose data schema and data flow optimization for reporting performance and enhancement as needed  
What We’re Looking For:  
Positive, proactive attitude and ability to work well in teams 
Exceptional skills in listening to leaders & cross functional heads, articulating ideas and complex information in a clear and concise manner 
Proven record of building interactive dashboards in Power BI 
Ideally experienced in data modeling, data schemas and good Understanding data and query optimization, query profiling, and query performance monitoring tools and techniques 
Drive analytics solutions independently and single handedly from scratch to end user communications 
Good time management and communication skills  
Basic Qualifications: 
Master degree required (Business, Finance, Economics or related field preferred) 
Strong MS office (Word, Excel, PowerPoint) skills are required 
Excellent skills with Microsoft Power BI and SQL server databases 
Preferred Qualifications: 
12 plus years work experience in BI and analytics 
More than 5 years’ experience with BI data infrastructure querying  
Good exposure to Snowflake schema & Star schema 
About S&P Global Market Intelligence

At S&P Global Market Intelligence, a division of S&P Global we understand the importance of accurate, deep and insightful information. Our team of experts delivers unrivaled insights and leading data and technology solutions, partnering with customers to expand their perspective, operate with confidence, and make decisions with conviction.

For more information, visit www.spglobal.com/marketintelligence.
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 -----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
103 - Middle Management (EEO Job Group) (inactive), 10 - Officials or Managers (EEO-2 Job Categories-United States of America), SLSGRP103.2 - Middle Management Tier II (EEO Job Group)",USD 45K - 84K *
243,Solution Architect - Power BI,West Pharmaceutical Services,"Bengaluru, Karnataka, IN, Digtl & Tr",Senior-level / Expert,"  Solution Architect - Power BI 
    India (IN) 
Karnataka
Bengaluru 
Estimated Duration Before End Date or Conversion Date:  12 
Pay Rate:  ₹3,600,000.00 
Number of Open Positions: 1 
Shift:   
        West Pharmaceutical Services, Inc. is a leading manufacturer of packaging components and delivery systems for injectable drugs and healthcare products. Working by the side of its customers from concept to patient, West creates products that promote the efficiency, reliability and safety of the world's pharmaceutical drug supply. West is headquartered in Exton, Pennsylvania, and supports its customers from locations in North and South America, Europe, Asia and Australia.  West's 2018 sales of $1.7 billion reflect the daily use of approximately 112 million of its components and devices, which are designed to improve the delivery of healthcare to patients around the world.
  Job Summary:
  The Solution Architect, D&T, Power BI possesses good  knowledge and experience to assist in  overall design, development, and implementation of BI Applications.  The role is involves working in  areas of solution design, development, performance tuning and troubleshooting. 
This role must have hands-on experience in Power BI, M, DAX functions, data warehouse design, SQL databases and SQL statements. 
  Essential Duties and Responsibilities:
•    Assist in  designs, implements, and supports the enterprise BI dashboards and reports.
•    Develops reports, dashboards & KPI scorecards and aggregate data from various sources.
•    Balance functionality look/feel and performance to ensure an excellent user experience which is a strong focus of the role.
•    Work with other teams to gather and document reporting requirements and to use the underlying data sources/data warehouses to meet business requirements.
•    Liaise with the SAP Data Warehouse team to design the data model.
•    Support to conduct training programs and knowledge transfer sessions for junior developers as needed
•    Other duties as assigned.
  Basic Qualification and Experience:
•    Bachelor’s degree or equivalent experience 
•    3-5 years of relevant experience in the areas specified under Essential Duties and Responsibilities.
  Preferred Knowledge, Skills and Abilities:
•    Good experience with and in-depth knowledge of Power BI, M and DAX functions
•    Experience as a Power BI Developer or Data Scientist.
•    Knowledge and experience in development of reports, dashboards, KPI scorecards, aggregating data from multiple sources
•    Experience in designing dashboards on phones and tablets. 
•    Background in data warehouse design (e.g. dimensional modeling) and SQL databases and SQL statements.
•    Good experience in ADF using Linked Services/Datasets/Pipeline/ to Extract, Transform, and load data from different sources like Azure SQL, Blob storage, Azure SQL Data warehouse
•    Understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework.
•    Proven abilities to take initiative and be innovative
•    Analytical mind with a problem-solving aptitude
•    Ability to work autonomously in a fast-paced & complex environment with a self-motivated work ethic; utilize sound judgment with an ability to manage multiple priorities with a sense of urgency
•    Ability to work in a virtual environment in a global organization
•    Able to comply with the company’s safety and quality policies at all times.
  Travel Requirements
•    Office environment 
•    10% of travel requirement.
  Physical and Mental Requirements:
•    Occasional on-call work required
•    Ability to work in a global and virtual environment and to effectively prioritize and execute tasks in a high-pressure environment.
•    Ability to work autonomously in a fast-paced & complex environment with a self-motivated work ethic; utilize sound judgment with an ability to manage multiple priorities with a sense of urgency.
•    Prefer 12pm – 9pm India time. Willingness to work outside of these hours as needed.

 ",USD 45K - 84K *
244,Assistant Manager - Data Analytics,Lenskart,"Gurgaon, Haryāna, India",Entry-level / Junior,"Collect, clean, and analyze customer data, sales metrics, and CRM system data from various sources using Excel, SQL, Python, and other tools.
Design and develop interactive reports using Power BI / Excel to visualize key business metrics and trends.
Identify patterns, trends, and insights from data and communicate findings to stakeholders effectively.
Collaborate with business users, stakeholders, and cross-functional teams to gather and document business requirements for analytical projects.
Perform root cause analysis to identify factors influencing business performance and propose solutions.
Use statistical techniques and data modeling to identify correlations and trends in large datasets.
Present complex data and analysis in a clear and concise manner to both technical and non-technical audiences


Requirements
Minimum Qualifications
Bachelor's degree in Business Administration, Economics, Computer Science, or a related field.
4 - 7 years of proven experience as a Business Analyst or Data Analyst, with a focus on data analysis and visualization of a marketing or consumer focused database.
Strong proficiency in Google Analytics, Power BI and advanced Excel functions
Solid understanding of data modeling, SQL, and relational databases, R or Python
Excellent analytical and problem-solving skills with a detail-oriented mindset.
Strong written and verbal communication skills, with the ability to present complex data and analysis to stakeholders.
Familiarity with statistical analysis and data mining techniques is a plus.
Ability to work independently and collaborate effectively in a team environment.
Preferred Qualifications
Experience or understanding of data engineering principles and technologies.
Experience working in an E-commerce or D2C company.
Worked previously in ambiguous and fast paced environments",USD 22K - 42K *
245,Staff Data Scientist,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
Company
Work matters. It’s where we spend a third of our lives. And the workplace of the future is going to be a great place. We’re dedicated to bringing that to life for people everywhere. That’s why we put people at the heart of everything we do.
People matter. Our people have a passion for learning, building, and innovating. Whether you’re an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.
What you get to do in this role:
Interact with stakeholders in departments across the company, identify opportunities for predictive analytics to enhance our business, match the optimal machine learning techniques to the specific business need, and then build the models that get the job done. This is an opportunity for the right candidate to go from end-to-end in the process, from recognizing a problem to implementing the solution, and integrating it with the business teams.
Your initial assignment would be to collaborate with HR business partners, analysts, and other stakeholders to develop and implement AI solutions that improve the effectiveness of our HR/Talent programs and initiatives. You will:
Solicit requirements for predictive models, including what data they will use and how the company will use them after they are built
Define the variables and their structure, and extract the data from our data warehouse and/or guide specialists to do so
Build predictive models that are accurate, robust, and informative in ways that help our business grow even faster
Qualifications
In order to be successful in this role, we need someone who has:
An advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in business, programming, or science and significant experience with predictive analytics
Successful project experience with two or more of the following: regression, decision trees / random forests, Bayesian methods, neural networks / deep learning, support vector machines, associative rules methods, k-nearest neighbor, or NLP / text analytics
Six or more years of experience in building predictive models, defining variables, variable selection, and measuring model quality.
Expertise with scripting in R, Python, Databricks, Snowflake or similar tools.
Three or more years of working with business teams to design an appropriate model structure and integrate the results into the business process
Either database query experience or demonstrated experience working with specialists to retrieve and transform data
Experience with working on datasets related to HR, such as employee demographics, performance, compensation, and engagement data is a plus.
Knowledge of HR policies, procedures, and practices, and their impact on business outcomes is a plus.
Desired skills:
Skills in profiling data and model results for quality assurance and informational purposes
Expertise in developing “reason codes” that explain model results/recommendations
Experience with Azure ML, Azure ML Pipelines, Databricks is a plus.
Experience with developing ML models using Servicenow’s predictive intelligence option is a plus
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.
 JV20
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
246,HR Data Analyst (all genders),HRS,"Chandigarh, Mid-Senior level, IN",Entry-level / Junior,"HRS AS A COMPANY
HRS, a pioneer in business travel, aims to elevate every stay through innovative technology. With over 50 years of experience, their digital platform, driven by ProcureTech, TravelTech, and FinTech, transforms how companies and travelers Stay, Work, and Pay.

ProcureTech digitally revolutionizes lodging procurement, connecting corporations and suppliers in a cutting-edge ecosystem. This enables seamless efficiency and automation, surpassing travelers' expectations.

TravelTech redefines the online lodging experience, offering personalized content from selection to check-in, ensuring an unparalleled journey for corporate travelers.

In FinTech, HRS introduces advancements like mobile banking and digital payments, turning corporate back offices into touchless lodging enablers, eliminating legacy cost barriers. The innovative 2-click book-to-pay feature streamlines interactions for travelers and hoteliers.

Combining these technology propositions, HRS unlocks exponential catalyst effects. Their data-driven focus delivers value-added services and high-return network effects, creating substantial customer value.

HRS's exponential growth since 1972 serves over 35% of the global Fortune 500 and leading hotel chains.

Join HRS to shape the future of business travel, empowered by a culture of growth and setting new industry standards worldwide.
POSITION
We are looking for a Chandigarh based HRIS People Analytics (all genders) who is responsible for the analysis, modelling, and implementation of all HR Analytics. Besides formulating requirements for our HRIS System SAP SuccessFactors, you consult Leadership how to improve the level of HR automation and digitization.
 CHALLENGE
Analysis, modelling and documentation of all HR Processes, such as recruiting, business partnering, learning and development
Project leadership in various HR automation and digitization projects. Central coordination and alignment of different SAP SuccessFactors implementation projects 
Monitor HR metrics, analyze and make recommendations for process improvements as well as new initiatives.
Demonstrated expertise in all facets of project management, such as requirements gathering, stakeholder management, budget and risk management, and status reporting
Collaborate, coach and counsel business partners and other stakeholders, such as HR controlling, HR development and Recruitment 
Act as ‘trusted advisor’ to senior management level and among project members
FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
Bachelor’s degree in a related field preferred
At least 3 years’ experience in HR analytics within SaaS and/or digital industry
Experience with HR systems/technology, ideally with SAP successfactors
Strong problem-solving, organization skills
Diligent documentation habits
Very good command of Microsoft Office (in particular Excel and PowerPoint) and project modelling software (e.g. Signavio, Visio)
Experience and proficiency with Microsoft Office Suite (e.g., Excel, Word, Access, and PowerPoint) and Google Suite
Ability to perform multiple tasks ranging from project management to coaching other team members
A thorough understanding of data transfer to the consolidated financial statements, planning processes, actual business processes and business requirements
Excellent communication skills and the ability to communicate with both technical and non-technical personnel; ability to listen, clarify and respond well to questions 
PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.

Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 53K - 94K *
247,Data Engineer,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Work with business partners and team members to fully understand business requirements and desired business outcomes.
Assist in scoping and designing analytic data assets, implementing modelled attributes, and contributing to brainstorming sessions.
Build and maintain a robust data engineering process to develop and implement self-serve data and tools for Visa’s data scientists.
Find opportunities to create, automate and scale repeatable analyses or build self-service tools for business users.
Implement data engineering projects ranging from small to large either individually or as part of a project team.
Ensure project delivery within timelines and budget requirements.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:

• 6+ years of relevant work experience with a bachelor’s degree or 5 years of relevant work experience with an advanced degree (e.g. Masters).

Preferred Qualifications:

• Knowledge of successful design, and development of data driven real time and batch systems.
• 6+ years of development experience in one or more the following: Java, Scala.
• 2+ years of relevant experience with any of the cloud technologies AWS, GCP, or Azure, preferably in an AI/ML production environment.
• Hands-on with Kubernetes/EKS is considered a significant advantage.
• Good to have working experience with messaging queue like Kafka.
• Familiarity in building large scale distributed, high performance systems in payments or other domains.
• Well versed with common software development tools, CICD, Agile methodologies and scrum practices.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 186K *
248,Senior Data Engineer - Glide,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:   
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.
We’re disruptive. We work hard but try not to take ourselves too seriously. We are highly adaptable and constantly evolving. We are passionate about our product, and we live for our customers. We have high expectations and a career at ServiceNow means challenging yourself to always be better.
What you get to do in this role:
We are building a modern Data Platform for AI at ServiceNow. This platform will evolve to address various data needs from AI practitioners, both from teams inside of ServiceNow and from end customers of ServiceNow. We are in the early phase of defining and developing this platform and the vision is to grow into a comprehensive platform that addresses 
AI development (by the Advanced Technology Group and the various Business Units within ServiceNow)
Production solutions - to build/tune AI solutions based on customer specific data.
End customers - to enable customers to effectively build their own AI solutions.
This is a strategic initiative at ServiceNow and it will have a significant impact in accelerating AI solution development on the ServiceNow platform.
We are in the early stages of this journey and are looking for Technical leadership to drive various aspects of the Data Platform. Significant areas of responsibility are listed below. The expectation is to independently pursue these open-ended areas, investigate, propose, design and implement ideal solutions for ServiceNow. We are looking for strong technical leads who can conceive and develop new systems and lead the evolution of the Solution Architecture with a strong business focus.
Core Data Platform  & Interfaces for data – 
Explore Open Table formats (delta-lake, Apache Iceberg, Apache Hudi) & execution engines (spark SQL / trino),  
Expose suitable Data models and APIs for Data.
Data Pipelines – Data Extraction improvements. Optimized data pipelines. Orchestration of pipelines. 
Governance/Security/Auditing – Establish data governance and security policies as per requirements. End to end security, governance, access control, audit etc.
Drive large features all the way from design to implementation.
Due diligence with respect to functional and test coverage is a given.
Data Catalog/Data Discovery & Lineage
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.
 Qualifications
To be successful in this role you have:
Significant exposure to Data engineering.
Bachelor's degrees in Computer Science or Computer Engineering
4+ Years of experience typically.
Strong experience in Data Engineering & Big Data technologies. Building robust and resilient data pipelines, Data modeling (Dimensional etc.) for Analytic workloads.
Ability to learn and work with multiple technologies in a fast paced environment, to effectively build large scale end-end Analytics solutions.
Expertise in Glide, SQL, PLSQL, Java, Python, Performance tuning to build effective large scale systems is a must. Versatility in using various programming languages, tools and frameworks with effective judgement and focus on the eventual end-end solution is required.
Good understanding of Cloud architecture, security, networking, monitoring and deployments
Hands on experience on any one cloud – AWS, Azure, Google or Oracle is desired. Experience building scalable, highly available and secure distributed multi-tiered systems experience with relational databases
Good knowledge in Rest API development and usage is desirable.
Strong communication and interpersonal skills
Knowledge/experience with data-science techniques is desirable.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
249,Senior Data Engineer,Palo Alto Networks,"Bengaluru, India",Senior-level / Expert,"Company Description
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
Our Approach to Work
We lead with flexibility and choice in all of our people programs. We have disrupted the traditional view that all employees have the same needs and wants. We offer personalization and offer our employees the opportunity to choose what works best for them as often as possible - from your wellbeing support to your growth and development, and beyond!
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!
Job Description
Your Career
As a Data Engineer, you will be an integral member of our Data & Analytics team responsible for design and development of pipelines using cutting edge technologies in Cloud.
Disruption “Take risk fearlessly” - Delivering data and insights in realtime to execs in new ways
Collaborate “Work together, win together” - Ability to partner  with cross functional teams in delivering data and key insight
Execute “Strive tirelessly for simplicity and usability” - Deliver data models which are simple to be used by consumer and scale for future
Your Impact
You will be responsible to build data models which provide highest business value and are certified, scalable 
Conduct deep data analysis to discover actionable business insights from the data models 
You will be constantly challenged by tough data engineering and design tasks
Build quality metrics part of pipeline to ensure the pipelines which are resilient and replayable
As a team player you will be Partnering with data analysts, product owners and data scientists, to better understand requirements, finding bottlenecks, resolutions, etc.
Quick to learn and adapt new technologies in data engineering
Qualifications
Your Experience
BE/ B.tech Engineering or Technical Degrees or equivalent military experience required
5 to 8 years of relevant experience with data and analytics 
Expert level in writing optimized SQL code
Experience in building data models from SAP ECC & Salesforce systems
Should have worked in Bookings, AWS/ GCP Cloud Provider Billings , Revenue / Annual Recurring revenue and product usage analytics data model 
Able to explain the business process and how analytics supported both strategic & operational requirements
Mid level experience in building pipelines using Spark
Experience in building ETL using data from Big Query is a Plus
Familiarity with GCP services, preferably having supported deployments on one or more of GCP services
Experience in Managing code using Github 
Should have worked in agile(scrum) development methodology
Strong development/automation skills
Can-do attitude on solving complex business problems, good interpersonal and teamwork skills
This is Bangalore office based job opportunity
Additional Information
The Team
This is not a traditional IT department !! We continuously challenge the status quo and build solutions to make IT services better. We also partner closely with our security, engineering and product teams, to secure our state of the art cyber security solutions
Working at a high-tech cybersecurity company within Information Technology is a once in a lifetime opportunity. You’ll be joined with the brightest minds in technology, creating, building, and supporting tools that enable our global teams on the front line of defense against cyberattacks. We’re joined by one mission – but driven by the impact of that mission and what it means to protect our way of life in the digital age. Join a dynamic and fast-paced team that feels excitement at the prospect of a challenge and feels a thrill at resolving technical gaps that inhibit productivity.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
Is role eligible for Immigration Sponsorship?: No. Please note that we will not sponsor applicants for work visas for this position.
Covid-19 Vaccination Information for Palo Alto Networks Jobs
Vaccine requirements and disclosure obligations vary by country.
Unless applicable law requires otherwise, you must be vaccinated for COVID or qualify for a reasonable accommodation if:
The job requires accessing a company worksite
The job requires in-person customer contact and the customer has implemented such requirements
You choose to access a Palo Alto Networks worksite
If you have questions about the vaccine requirements of this particular position based on your location or job requirements, please inquire with the recruiter.",USD 121K - 186K *
250,"Sr Architect, Data Development",TransUnion,Bengaluru,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are looking for an experienced Senior Application Architect to join the Transunion Data Engineering team who will drive the design and development of data on-boarding, maintenance of data, integrated data analytics and benchmarking platforms supporting the Financial Services vertical. The ideal candidate will have broad architecture experience, both application and infrastructure, with proven experience in migrating complex data platforms to AWS. The Solutions Architect will assess existing platforms on AWS Cloud native solutions, optimize the current state and design the future state of applications. The role requires solid experience in cloud computing environments, hands on technical skills, passion, and appetite to master recent technologies, and excellent communication skills. Looking for someone to help optimize solutions to be built in a consistent framework, provide technical consultation to the Product Management and Enterprise Architecture to assure the integration of business requirements. Mentor other team members in all technical aspects during all phases of the project development lifecycle.

The team needs a strong technical leader in GCC who can lead a team of offshore developers and testers who would effectively execute the implementation and delivery of business requirements and help achieve the time to market goals.
What You'll Bring:
Responsibilities • Analyze and architect the migration of large data processing pipelines, business intelligence and analytics platforms and client delivery interfaces to AWS cloud native solutions • Create blueprints and components that can be shared across multiple DevOps teams • Ensure adherence to architectural tenets through coaching, guidance and reviews of application solutions • Optimize solution architectures to maximize performance and minimize costs; implement cost control mechanisms • Support application architects to design secure solutions that use cloud services and are aligned to enterprise security requirements and best practices • Continuously manage, monitor, and update operations architectures as business needs evolve and other cloud services become available • Work collaboratively with project teams to implement the technology direction, vision, and strategy to enable cloud technology adoption • Coordinate with product owners to incorporate the voice of the customer. • Design, implement and improve core software frameworks and infrastructure required to effectively secure and maintain the platform (i.e. Logging, Error Handling) • Collaborate with different teams involved in defining and implementing the CI/CD pipeline for cloud deployment. • Define strategies for technical challenges and provide appropriate solution based upon the viability of different options. • Effectively resolves problems and roadblocks as they occur. Pro-active in identifying risks and issues. • Excellent consulting skills with strong analytical ability to work effectively with clients, product management and enterprise architecture. • Ability to interpret internal/external business challenges and recommends best practices to improve platform, processes, or services. • Responsible for the entire Software Development Lifecycle of a project • Ensure high standards of code quality using static and dynamic application scanning/testing tools. • Perform code reviews and provide technical guidance to team members. Requirements: • Minimum of 15 years of architecture experience • Minimum of 10 years of software development/coding experience • Experience architecting cloud infrastructures on AWS for small, medium scale and enterprise level applications • AWS Certified Professional Level • AWS coding/design experience; good understanding of AWS concepts and services • Strong experience in Phython, PySpark/Spark SQL, SQL Scripts. • Experience with AWS tools and services – Redshift, EMR, AWS Glue. • Good working experience with relational databases – PostgreSQL. • Hands-on experience with cloud adoption and migration from assessment through cloud native implementation • Experience with container orchestration platforms and serverless • Experience and/or good understanding of Containers and EKS • Experience coding in higher level programming language: Python, Java or Go • Technical knowledge of infrastructure components (network, storage, Linux, Windows), security and application development (e.g., .Net) • Experience in automated build platforms/continuous integration (Jenkins, Ansible) • Experience with relational database, SQL performance monitoring and performance tuning. • Experience with security testing methodologies (SAST, DAST), code scanner tools (checkmarx, blackduck, sonar, appscan) and experience in remediating security vulnerabilities • Experience working within Agile software development teams • Familiarity with full stack development frameworks • Creative and innovative approach to problem solving and passion for continuous improvement • Comfortable working in cross functional and multidisciplinary teams • Ability to interact with all levels of an organization. • Excellent verbal and written communication skills with keen attention to detail and accuracy • Experience in financial services and an understanding of the related regulatory requirements is a plus but not needed. • Ability to translate and present complex technical data across technical and non-technical groups. • Demonstrates team leadership, mentoring capability, self-leadership, strong communication skills, and strong project management capability in working with others.
Impact You'll Make:
TransUnion Job Title
Sr Architect, Data Development",USD 45K - 84K *
251,Sr. Software Engineer - PySpark Job,Yash Technologies,"Pune, MH, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire PySpark Professionals in the following areas :
  Experience
7 - 9 Years
Job Description
7 to 9 years of experience in designing, implementing, and managing cloud data solutions on AWS.
Experience working with wide variety of AWS services like ETL, Glue Data Catalog, Athena, Redshift, RDS, DynamoDB, Step Function, Event Bridge, Lambda, API Gateway, ECS, and ECR.
Strong experience in designing and developing solutions in Databricks using Python and PySpark.
Excellent experience in SQL query and commands in any RDBMS
Strong data concepts and fundamentals like DWH, Datamart, Lakehouse, Delta Lake, CDC, SCD etc.
Strong  communication skills (verbal and written) and customer handling skills
Good to have exposure in semantic layer tools like AtScale and Cube.dev
Good problem solving skills and Analytical capabilities
Certifications
Good To Have
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
252,"Data Analyst, Fraud & Payments Reporting",Groupon,Chennai,Mid-level / Intermediate,"Groupon is an experiences marketplace that brings people more ways to get the most out of their city or wherever they may be. By enabling real-time mobile commerce across local businesses, live events and travel destinations, Groupon helps people find and discover experiences–big and small, new and familiar–that make for a full, fun and rewarding life.
Groupon helps local businesses grow and strengthen customer relationships resulting in strong, vibrant communities. With employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. Our culture encourages employees to embrace change, adapt to new circumstances, and find creative solutions to the challenges we face. Does that sound like a great way to grow your career? Let’s get into the details.
We are seeking a highly skilled and motivated Data Analyst to join our dynamic Fraud & Payments Reporting team. As a crucial member of the team, you will play a key role in developing reports, queries, and dashboards in collaboration with business stakeholders to support our 24/7 global fraud mitigation and payment optimization efforts.
Key emphasis will be placed on your expertise in SQL, Tableau (or similar visualization tools), and your ability to work independently in conducting business and data analysis. You will be responsible for providing valuable outcomes from your analyses and proactively suggesting data-driven solutions and decisions.
You’ll spend time on the following:
Deepen understanding of our fraud & payments data processes and continuously improve them to enhance our overall capabilities.
Collaborate closely with operational stakeholders to identify gaps in existing fraud & payments reporting and take the lead in suggesting and implementing optimizations.
Frame complex and ambiguous business questions and leverage data analytics to deliver actionable insights that drive effective decision-making.
Handle high-priority, ad-hoc analysis swiftly in response to the rapidly changing environment of fraud and payments.
Engage with other analysts to share knowledge and collectively guide reporting strategies based on previous project outcomes and deliverables.
Design and create dashboards to provide historical data insights to product and business stakeholders.
Your work product will encompass queries generating reports, presentations, forecasts, and the delivery of data insights to address specific business inquiries.
We’re excited about you if you have:
At least 3 years of experience in creating and evaluating multi-step SQL statements involving multiple tables with complex relationships.
Background in Finance, Payments, or Fraud Prevention will be highly valuable in this role.
Demonstrated proficiency in building and maintaining dashboards using Tableau or any other Business Intelligence (BI) tools is essential.
1+ year of experience with typical tools, including G-suite, Excel, and Data Warehouse, is a must.
Fluent English
Knowledge of Teradata, Python, Optimus Prime will be considered a plus
The ability to thrive in an environment with deadlines and shifting priorities is crucial for success in this role.
Your interpersonal skills, both written and verbal, must be strong, enabling you to concisely communicate complex information to management with confidence.
#LI-hybrid
Groupon’s purpose is to build strong communities through thriving small businesses. To learn more about the world’s largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don’t take our word for it. Hear from real Groupon team members and learn more about our inclusive employee groups. If all of this sounds like something that’s a great fit for you, then click apply and let’s see where this takes us.",USD 67K - 110K *
253,"Manager, Statistical Programming",Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Summary: Managers of Statistical programming provide programming expertise to clinical project teams to support the development, regulatory approval and market acceptance of  Bristol Myers Squibb (BMS) products. This position is primarily responsible for the design, development and implementation of technical solutions for analyzing and reporting clinical data.  Managers of Statistical Programming  develop collaborative relationships and work effectively within  Global Biometrics & Data Sciences (GBDS), with external vendors and members of cross-functional development teams. 
Key Responsibilities:
Create SAS programs to generate derived analysis datasets and content for tables, listings, and figures; Perform programming validation to ensure quality of analysis datasets and programming outputs 
Provides programming support for project teams, including development of programming strategies, standards, specifications and programmed analysis 
Support the electronic submission preparation and review 
Reviews key planning documents (e.g., statistical analysis plan, data presentation plan, data review plan) to ensure alignment with development team objectives and clarity and completeness of programming assumptions and requirements; Assesses impact on programming activities 
Interacts with vendors regarding project standards, programming conventions, programming specifications and file transfers 
Provides leadership for ensuring quality of Global Biometric and Data Sciences (GBDS)  deliverables by consistently applying standards and complying with regulatory requirements, guidance and corporate and departmental SOPs and work practices  
Identifies opportunities for increased efficiency and consistency within GBDS and our interactions with strategic vendors 
Independently leads and / or performs programming assignments with minimal supervision 
Support improvement initiatives 
Minimum Requirements: 
Bachelor’s degree in statistics, biostatistics, mathematics, computer science or life sciences required. 
At least 3 years programming experience in industry recommended. 
For US positions: US military experience will be considered towards industry experience.  
Demonstrated proficiency in using SAS, R or other programming languages to produce derived analysis datasets and TFLs. 
Understanding of clinical data structure (e.g. CDISC standards) and relational database. 
Demonstrated skills in using software tools and applications, e.g., MS office, XML. 
Demonstrated ability in the handling and processing of upstream data, e.g., multiple data forms, workflow, eDC, SDTM. 
Demonstrated ability in providing outputs to meet downstream requirements, e.g., ADaM, Data Definition Table, e-submission. 
Have good understanding of regulatory, industry, and technology standards and requirements. 
Have good knowledge of statistical terminology, clinical tests, medical terminology and protocol designs. 
Demonstrated ability to work in a team environment with clinical team members. 
Preferred Requirments: 
• Minimum of 3 years clinical / statistical programming experience within pharmaceutical clinical development  
• Knowledge of the drug development process, clinical trial methodology, statistics and familiarity with global regulatory requirements 
• Experience in other software packages (e.g. R) 
Experience with the Linux operating system 
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 30K - 56K *
254,Senior Data modeler,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Convert business requirements to concept/ technical specification
Develop Oracle PL/SQL based on technical specification
Work along with source system experts in finalizing ETL and report design
Work with other data modeler in preparing the data/ dimensional models
Coordinate with central team to replicate tables from source system to data lake
Support Oracle developer and Report designers in design and development
Creation of activity plan as per the agreed concept with timelines
Design, Develop and Deploy solution
Unit & Integration testing
Support customers during the stabilization phase
Qualifications
Degree or equivalent
Additional Information
Overall 8+ years of experience in IT Industry4+ years experience on Oracle Database programming in Data Warehousing systems4+ years experience on Dimensional Modelling in Data warehousing solutionsExperience in working at least 2 end-to-end projectsRich Experience in with Database Packages, Stored procedure, Functions , procedures, Triggers and data transformation activities using SQL and PLSQLStrong expertise on RDBMS fundamentalsGood knowledge in SQL loader, Data pump and Import/Export utilitiesKnowledge on Performance Tuning for Oracle RDBMSGood oral communication skill",USD 100K - 155K *
255,"Engineer, Data Services",S&P Global,IN - HYDERABAD ORION,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
09
S&P Global Ratings is looking for a Senior Big Data Engineer to join the Data Lake team within Data Services group, a team of data and technology professionals who define and execute the strategic data roadmap for S&P Global Ratings. The successful candidate will participate in the design and build of S&P Ratings cutting edge data services and analytical solutions. 
The Team 
The Data Lake team is responsible for data ingestion from internal source systems in batch/real-time modes, curation and governance of the data assets created in the platform. The team also works towards adopting the new features of the Databricks product and optimizing the operational aspects of the platform to enhance the user community experience.  The team has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy.  
 The Impact: You will be an expert contributor and part of the Rating Organization’s Data Services Product Engineering Team with a unique opportunity to build and evolve S&P Ratings next gen data and analytics platform. 
 Our Hiring Manager Says 
If you are an individual that brings demonstrated experience of delivering big data projects as a data engineer, this is an excellent opportunity. We are looking for someone who is passionate about data wrangling and analysis and is a polyglot in data analysis related programming languages.  
 Responsibilities:                
·                Design & Build data pipelines with an emphasis on scale, performance and reliability. 
·                Provide technical expertise in the areas of design and implementation of Data Lake solution powered by Databricks on AWS cloud. 
·                Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data 
·                Partner with the data teams, enterprise architecture organization to ensure best use of standards for the key data domains and use cases 
·                Continuous learner with an eye on emerging trends around data lake architecture and enterprise data solutions. 
·                Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards 
  Experience & Qualifications: 
·                BE, MCA or MS degree in Computer Science or Information Technology 
·                4+ years of experience building solutions in big data technologies. 
·                3+ years of experience in data transformation and analysis with one or more of Scala, Python, Spark and related libraries. 
·                Strong foundational understanding on data models and query languages. 
·                Experience in continuous delivery through CI/CD pipelines, containers and orchestration technologies.  
·                Experience building streaming data pipelines using Kafka, Confluent etc is an added advantage.  
·                Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib) is an added advantage. 
·                Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally. 
·                Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management 
·                Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners 
·                Financial services industry experience is an added advantage. 
·                Databricks experience or certifications is an added advantage. 
·                AWS or any public cloud certification is an added advantage. 
 About S&P Global Ratings
At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.
S&P Global Ratings is a division of S&P Global (NYSE: SPGI).  S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.  
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 45K - 84K *
256,Senior Software Development Engineer 2 (Data Analyst),Sopra Steria,"Noida, Uttar Pradesh, India",Senior-level / Expert,"Company Description
About Sopra Banking Software
Our teams consist of exceptional people with Entrepreneurship, Diversity, Respect, and Collaboration as values at the core. We bring together people from different lifestyles, backgrounds and cultures to partner with more than 1,500 leading Financial institutions worldwide. The rich variety of our solutions, the strength of our conviction and our passion for innovation enable us to support our clients on a daily basis and in their future projects, as well as in their goals regarding Financial inclusion. Our customers, based in over 80 countries, benefit every day from our technologies and software, as well as the expertise of our 5,000 employees. Sopra Banking Software is a subsidiary of the Sopra Steria Group, a European leader in consulting, digital services and software development. With more than 46,000 employees, the Sopra Steria Group generated a turnover of €4.7 billion in 2021. And with the power of our parent group, Sopra Steria, behind us, anything is possible for our teams and our partners.
Job Description
Minimum Qualification
Bachelor's or higher engineering degree in Computer Science, or related technical field, or equivalent additional professional experience.
Preferred Qualification
Expert level exposure on Salesforce Apex
Good to have Salesforce DEV01 certification.
Expert level exposure in GIT source management or similar
Expert level exposure on confluence JIRA
Expert level exposure in Salesforce components (objects / metadata). Good knowledge of Salesforce development using Visual studio.
Participate in the entire development lifecycle from design through deployment
Exposure to Salesforce deployments on Sandbox and production.
Good knowledge of SQL (queries) and fundamental understanding of database design concepts.
What you will do
A good team player responsible for handling the CRM development based on the business rules.
Think critically about the deliverables and plans for projects to ensure they align with the goals.
Ability to write detailed user stories acceptance criteria.
Communicating effectively with stakeholders
Knowledge of the configuration Management tools like Git
Developing customized solutions within the Salesforce platform
Technical Design, coding, and implementing Salesforce changes
Integrating third-party platforms • Designing the CRM workflows in Salesforce
Testing the stability and functionality of the application
Follow the standard development guidelines
Providing custom solutions for specific business requirements
Troubleshooting technical issues
Collaborating with colleagues in Sales, Marketing and Other departments that collaborate using CRM
Developing user documentation
Total Experience Expected: 06-08 years
Additional Information
At our organization, we are committed to fighting against all forms of discrimination. We foster a work environment that is inclusive and respectful of all differences.
All of our positions are open to people with disabilities.",USD 93K - 144K *
257,Data Engineer,Miles,"Bengaluru, Karnataka, India",Senior-level / Expert,"Miles helps foster greener travel and rewards you for it. We've built a great product that's simple, engaging, and tailored to each user. Join now to have the biggest impact while we're small and growing fast.
You will be working with a great team from diverse backgrounds in a collaborative and supportive environment. We solve a wide variety of interesting technical challenges, and continually build up our platform to power the next generation of scale and features. We partner closely with Product, Design, and UX teams to build and ship the most impactful
You want to join an early startup on a fast growth trajectory. You are self motivated, take end to end ownership, communicate effectively, and are a fast learner.
Responsibilities
Work with product managers and data analysts to build data products that power our business.
Build and maintain data analytics reports, ETL pipelines, data lakes, and streaming solutions.
Analyze new data sources and work with stakeholders to understand the impact of integrating new data into existing pipelines and models
Develop & maintain critical data pipelines, using tools such as Apache Airflow, to ensure highly accurate and reliable business reporting
Perform ad-hoc analysis and provide insights to stakeholders within the organization such as Marketing, Growth & Sales teams to drive prioritization.
Create data visualizations and analytic reports using various tools such as Tableau, Databox, etc
Optimize database queries to improve and maintain performance on very large data sets.
Work closely with the business and data science team for the deliverables.
Requirements
5+ years of relevant experience.  Masters or Bachelors degree in CS/ML/AI or equivalent discipline.
Experience with building stream-processing systems, using solutions such as Kinesis, Kafka, Storm or Spark-Streaming.
Expertise with coding with Pyspark, Pandas, Scipy and visualizations with Tableau & Databox. Scheduling/orchestrating pipelines using Databricks and Airflow.
Expertise with data querying (SQL, Redshift, Spark) and analyzing billions of rows of data points.
Familiarity with SQL, especially within cloud-based data warehouses like Snowflake, Google BigQuery, and Amazon Redshift
Strong understanding of relational DB such as MySQL/PostgreSQL, document-based storage systems such as MongoDB or CouchDB, key-value stores (Memcached, Redis), Column-oriented stores (HBase, Cassandra), graph-oriented stores; their distinct advantages, disadvantages, and trade-offs.
Experience building machine learning, statistical, and analytical model, and tuning parameters.
Experience designing experiments and extracting insights.
Knowledge of various ETL techniques and frameworks
Bonus Points
You have worked extensively with location and trips data at scale.
Specialization in spatiotemporal clustering in the presence of noise.
Worked on a successful product that has touched millions of consumers.
Prior startup experience.
Benefits
Competitive salary based on experience
Opportunity to create impact in a high growth startup environment
Employee healthcare benefits includes medical, dental, vision insurance
Paid time off
Employee Referral bonus
Monthly team-building activities and happy hours
Stock in an early-stage fast-growing startup company
Our Commitment to Inclusivity and Diversity
Miles is committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, marital, veteran, physical or mental disability status.",USD 121K - 186K *
258,Healthcare Research & Data Analyst,Clarivate,R131-Bengaluru,Mid-level / Intermediate,"There is an opportunity for a motivated individual in the role of Data Analyst in our Bangalore, India office. The Product Support Analyst will play an integral role in supporting Clarivate’s market research teams to produce syndicated and custom market research offerings for clients in the healthcare industry. In this role, you will be responsible for the production and quality control of market research reports and other key deliverable for Clarivate clients. In addition, you will be responsible for synthesizing primary and secondary data that is consumable by clients and Clarivate research teams. The Product Support team works closely with our market research analyst group and other internal departments to produce high-quality products for clients.
This entry-level position offers an excellent opportunity for a highly motivated university graduate or early-career professional (with 2+ years of experience) to work in market research and analytics while developing an understanding of the healthcare industry. 
We are looking for an Analyst to join our Data Visualization team in Bangalore. This is an amazing opportunity to work on Primary market research data and analysis. The team consists of 12 and is reporting to the Senior Manager. We have a great skill set in SPSS and we would love to speak with you if you have skills in Statistics and SPSS.
About You – experience, education, skills, and accomplishments  
Work experience (At least 1 year of experience in SPSS, PowerPoint, and Excel) 
Knowledge, skills, or abilities (Process PMR data, including conducting cross-tabulations, statistical analysis (e.g., t-test, z-test, ANOVA, Chi-square) and frequency table (e.g., frequencies, counts, percentages, mean, median, standard deviations) generation)
Undergraduate degree (e.g. Bachelor’s degree in statistics) with a proven record of academic success is required
It would be great if you also had . . .  
Knowledge of pharmaceutical and/or medical device industries an asset but not required
Advanced degree (MA, MBA, MS in life sciences, social sciences, or statistics) and/or relevant experience in the biopharma, healthcare, or market research sector a plus, but not required
What will you be doing in this role? 
Populate databases (e.g., drug information, company deals, pricing, launch dates, global market access statistics) with information provided from various sources including secondary data from information resources or research teams or data procured by the research services analyst team
Process PMR data, including conducting cross-tabulations, statistical analysis (e.g., t-test, z-test, ANOVA, Chi-square) and frequency table (e.g., frequencies, counts, percentages, mean, median, standard deviations) generation
Creation and population of PowerPoint and Excel templates (including leveraging technology such as e-tabs to produce), tables, figures, and graphics, in support of building final client deliverables
Interpreting data and bulleted text provided by Analysts and other staff and translating them into carefully crafted presentations and other professional deliverables
About the Team   
This role is in Data Viz team who supports the therapy teams in multiple domains. The team consists of 12 people (including manager).
Hours of Work  
12 pm – 9 pm IST
At Clarivate, we are committed to providing equal employment opportunities for all persons with respect to hiring, compensation, promotion, training, and other terms, conditions, and privileges of employment. We comply with applicable laws and regulations governing non-discrimination in all locations.",USD 67K - 110K *
259,Sr. Software Engineer - Microsoft Power BI Job,Yash Technologies,"Hyderabad, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Microsoft Power BI Professionals in the following areas :
  Experience
4-6 Years
Job Description
Power BI Report development, with 4-6 years of experience in data-specific roles.
Building Analysis Services reporting models.
Developing visual reports, KPI scorecards, and dashboards using Power BI desktop.
Connecting data sources, importing data, and transforming data for Business intelligence.
Analytical thinking for translating data into informative reports and visuals.
Capable of implementing row-level security on data along with an understanding of application security layer models in Power BI.
Should have an edge over making DAX queries in Power BI desktop.
Expert in using advanced-level calculations on the data set.
Responsible for design methodology and project documentaries.
Should be able to develop tabular and multidimensional models that are compatible with data warehouse standards.
Very good communication skills must be able to discuss the requirements effectively with the client teams, and with internal teams.
Mandate to have experience with BI tools and systems such as Power BI 
Knowledge in Microsoft BI Stack
Grip over data analytics. Should possess software development skills
Required Behavioral Competencies
Accountability: Takes responsibility for and ensures accuracy of own work, as well as the work and deadlines of the team.
Collaboration: Participates in team activities and reaches out to others in team to achieve common goals.
Agility: Demonstrates a willingness to accept and embrace differing ideas or perceptions which are beneficial to the organization.
Customer Focus: Displays awareness of customers stated needs and gives priority to meeting and exceeding customer expectations at or above expected quality within stipulated time.
Communication: Targets communications for the appropriate audience, clearly articulating and presenting his/her position or decision.
Drives Results: Sets realistic stretch goals for self & others to achieve and exceed defined goals/targets
Certifications
Good To Have
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
260,Data Modeler,Bechtel,"Haryana-New Delhi, N/A, IN",Mid-level / Intermediate,"Requisition ID: 273775 
 Relocation Authorized: National - Family 
Telework Type: Part-Time Telework 
Work Location: New Delhi 
Company Overview:
Since 1898, we have helped customers complete more than 25,000 projects in 160 countries on all seven continents that have created jobs, grown economies, improved the resiliency of the world's infrastructure, increased access to energy, resources, and vital services, and made the world a safer, cleaner place.

Differentiated by the quality of our people and our relentless drive to deliver the most successful outcomes, we align our capabilities to our customers’ objectives to create a lasting positive impact.

We serve the Infrastructure; Nuclear, Security & Environmental; Energy, and Mining & Metals markets. Our services span from initial planning and investment, through start-up and operations. Core to Bechtel are our values – ethics, safety, quality, people, culture, relationships, innovation and sustainability, and our covenants – integrity, respect, collaboration, trust, and delivery. They are what we believe, what customers can expect, and how we deliver.          
  Bechtel India is a global operation that supports execution of projects and services around the world. Working seamlessly with business line home offices, project sites, customer organizations and suppliers, our teams have delivered more than 125 projects since our inception in 1994.
  Our offices in Gurgaon, Vadodara and Chennai will grow significantly and sustainably with exciting career opportunities for both professionals and young graduates who are passionate about creating a cleaner, greener, and safer world; building transformational infrastructure; making decarbonization a reality; and protecting people and the environment.
  Position Summary
The Digital Enterprise Program (DEP) has been envisioned as a Corporate Initiative to facilitate a transformation of the company from a departmental, document-centric, and function/discipline optimized EPC execution model to an integrated, data-centric, and TIC optimized EPC execution model. Key aspects of DEP are: Digital (Data Centric), Enterprise (Integrated & Standardized) and Program (Transformative). Data-Centric Execution (DCE) is the methodology of creating, processing, managing, controlling and delivering information in the medium of data rather than via documents. The focus of DEP is the transformation of EPC Work Process, Tools, team member roles and responsibilities to support the transfer of trust and authority of information from documents to data resulting in a step change in project performance.
  Job Roles:
The Data Modeler will be responsible for creating knowledge graphs and linked metadata designs for data interoperability, data integration and data storage of enterprise platforms and application systems.
The Data Modeler will work with Data Architects, Data Engineers, Data Analysts, Data Scientists, Product teams and other business stakeholders to develop and extend the Enterprise Ontology and Enterprise Digital Architecture.
The Data Modeler will implement Semantic Web standards and assist in the establishment and development of the data modeling practices and skills as a new discipline within a digitally transformed EPC organization.
  The Job Roles shall be, but not be limited to, the below:
The Data Modeler shall have Civil, Structural engineering domain knowledge and be proficient with applications like Tekla and Revit.
The selected Data Modeler shall perform specialized operations in a family of tools after receiving requisite on-the-job skill sets training.
The Data Modeler will understand and implement Semantic Web standards while assisting in the establishment and development of data modeling practices and skills as a new discipline within a digitally transformed EPC organization.
  Job Responsibilities:
The Data Modeler will assess business information and data requirements and extend the Enterprise Ontology and develop Enterprise Canonical Models.
Develop and implement ontologies, data architecture and data management techniques in consultation with stakeholders.
Contribute to data integration and mapping efforts to harmonize taxonomy from multiple domains and incorporate metadata into the Enterprise Ontology and associated Canonical Models.
Assess and implement knowledge organization strategies using tools capable of metadata management, ontology management, and semantic enrichment.
Keep abreast of competitor and industry developments related to ontology usage.
Understand document and graph database principals for maintaining object attributes and relationships. Identify implementation strategies for effectively and efficiently searching and querying data.
Influence and participate with governance bodies to standardize canonical models.
Research and provide solutions for complex problems.
Work through a variety of technical challenges that will require creativity and close collaboration across internal teams, customers, and stakeholders.
Able to multitask and know where to add business value, and when to delegate, guide or take ownership.
  Job Requirements:
Bachelor’s degree or equivalent EPC work experience.
Over 5 years of project, functional, IS&T or automation experience in EPC industry.
Programming/scripting skills
Familiarity of functional work processes and application systems for engineering and construction methods and materials, usage of engineering applications to produce deliverables.
General understanding of the information lifecycle of project data – how information is exchanged between functions/disciplines and ownership of data transitions throughout the life of a project.
Business understanding for data usage and consumption patterns.
Excellent problem-solving and analytical skills, naturally curious and strong desire to solve problems.
Intuitive ability to assess and integrate data to solve analytical problems.
Shaping tomorrow together
Bechtel is one of the most respected global engineering, construction, and project management companies. Together with our customers, we deliver landmark projects that foster long-term progress and economic growth. Since 1898, we’ve completed more than 25,000 extraordinary projects across 160 countries on all seven continents. We operate through five global businesses: Infrastructure; Nuclear, Security & Environmental; Energy; Mining & Metals; and Manufacturing & Technology. Our company and our culture are built on more than a century of leadership and a relentless adherence to our values, the core of which are safety, quality, ethics, and integrity. These values are what we believe, what we expect, what we deliver, and what we live.  
www.bechtel.com
Bechtel is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity and expression, age, national origin, disability, citizenship status (except as authorized by law), protected veteran status, genetic information, and any other characteristic protected by federal, state or local law.

Bechtel employees are required to be vaccinated for COVID-19 or show proof of a negative test result prior to accessing Bechtel sites/facilities to the extent required by applicable law or by customer requirements.",USD 73K - 140K *
261,Data Engineer,Deutsche Bank,Pune - Margarpatta,Mid-level / Intermediate,"Job Description:
Job Title:  Data Engineer
Location: Pune (India)
Corporate Title: AVP
Role Description
This role is required to form part of the IT delivery team building Anti Financial Crime applications. The platform would be used predominantly by AFC – Sanctions & Embargoes users. The engineer should be able to work independently on medium to large sized projects with strict deadlines.  Should be able to work in a cross-application, mixed-technical environment. Must demonstrate solid hands-on development track record working on an agile methodology. The role demands working alongside a geographically dispersed team consisting of development and QA vendor teams, FAs and BAs.
What we’ll offer you
As part of our flexible scheme, here are just some of the benefits that you’ll enjoy
Best in class leave policy
Gender neutral parental leaves
100% reimbursement under childcare assistance benefit (gender neutral)
Sponsorship for Industry relevant certifications and education
Employee Assistance Program for you and your family members
Comprehensive Hospitalization Insurance for you and your dependents
Accident and Term life Insurance
Complementary Health screening for 35 yrs. and above
Your key responsibilities
This individual will be responsible for the following:
Operate as a team member of a Scrum Agile/Kanban team
Design, development and peer review new functionality in various code languages
Design and implement the enterprise data models for the Firm’s Federated Data Architecture
Create models across conceptual, logical, and physical dimensions for your subject areas
Own modeling solutions to meet data requirements from publisher and consumers
Design and build data pipelines using GCP
Build strong partnerships with business SMEs, architects, data modelers, data stewards, publishers and consumers in your given subject areas
 Your skills and experience
Must have
Extensive experience with data analysis, data flows, data sourcing and publishing concepts
Develop and manage data pipelines in Google Cloud Platform (GCP) using DataFlow, Cloud Composer, Cloud Storage, and DataProc. Optimize data pipelines for performance and scalability. Automate data processing tasks using scripting languages like Python or Shell.
Hands on development experience on large ETL/Big Data system/HDFS.
Strong in data modelling using UML framework
Proficiency in data modeling and data governance tools such as Collibra and PowerDesigner
Experience in any RDBMS
Understanding of data storage & transport protocols such as XML, JSON, AVRO etc
Create plans to source, curate, integrate data from sources
Create data structure for publishing data to downstream systems
Good to have
Able to gather requirements on data, liaise with publishers of data, create map and gap to identify the right data class and data elements from various publishers
Identifying the authorized data sources and authorized data distributors
Basic understanding of data security on public cloud.
Basic understanding of Data Quality dimensions like Consistency, Completeness, Accuracy, Lineage etc.
Experience
Has more than 10 years of experience in reputed organization.
Financial experience, cross product, or regulatory knowledge.
Data visualization experience
Hands on business and systems knowledge gained in a regulatory delivery environment
Education and qualification:
Degree
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 110K - 180K *
262,Manager–Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Follow Tesco's Business Code of Conduct and always act with integrity and due diligence
- Accountable for engaging with markets to understand their key outcomes; identifying and implementing analytics projects that will result in disproportionate returns
- Drive value realization through delivery of high impact projects and efficiency gain by automating repeatable tasks
- Track and measure return on investment for Analytical Investments
- Accountable for achieving teams objectives; partner management and issue management
- Institutionalize robust ways of working through reusable frameworks; code and knowledge management
- Develop analytical assets that are deployed in production and will deliver value on sustained periods of time
- Collaborate with colleagues to craft; implement and measure analytical solution
- Develop and lead an impactful team; crafting an environment for success by setting direction and mentoring them to succeed through inspiring conversations every day
- Hands-on problem solving. You will be required to get hands dirty with data and applied math
- Initiates and crafts continuous improvements initiatives to drive performance within their teams
- Diagnose and recommends solutions to operational challenges; using specialist knowledge and operational expertise.
Qualifications
- Understanding of machine learning techniques - Linear & Logistics regression; Decision Trees; Random Forest; XgBoost and Neural Network
- Knowledge of Python; SQL; Hive and one of the visualization tools (Tableau)
- Stakeholder management; Operations Delivery; Analysis and Judgment; People Policies and Processes; Foundational Statistics & Math
Additional Information
Last Date of Application- 14th Nov 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
263,Lead Software Engineer - Data Engineering,Freshworks,"Bengaluru, India",Senior-level / Expert,"Company Description
About Freshworks
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end user. Headquartered in San Mateo, California, Freshworks has a global team operating from 13 global locations to serve more than 65,000 companies -- from startups to public companies – that rely on Freshworks software-as-a-service to enable a better customer experience (CRM, CX) and employee experience (ITSM). 
Freshworks’ cloud-based software suite includes Freshdesk (omni-channel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshchat (AI-powered bots), supported by Neo, our underlying platform of shared services.
Freshworks is featured in global national press including CNBC, Forbes, Fortune, Bloomberg and has been a BuiltIn Best Place to work in San Francisco and Denver for the last 3 years. Our customer ratings have earned Freshworks products TrustRadius Top Rated Software ratings and G2 Best of Awards for Best Feature Set, Best Value for the Price and Best Relationship. 
Job Description
The Analytics Platform Team is looking for a Lead System/Data Engineer  who can implement the  technology roadmap in coherence with the asks from business and evolve our Platforms into cutting edge technology offerings in the industry. You will work with an energetic and talented team of engineers to own and iteratively build one or more of our platform services, while partnering with architects and Product Managers from our many Products who will directly consume your work. You will be building scalable and reliable distributed systems that are milli-second efficient, always available and working at internet scale. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. All our Data Engineers wield end-to-end ownership of their platform services - from design, to development and testing, to deployment, and all the way to nurturing the systems in production. The future includes not only new business problems to add into the mix and new levels of scale to achieve, but also the overall technology vision of the Freshworks Platform as a whole related to not just how we build but also who we build for.
Qualifications
Responsibilities
Independently able to Design, Develop, and Maintain data intensive applications
Implementing ETL pipelines to bring data from distributed data sources 
Responsible for availability, scalability, reliability, and performance of the big data system
Ensure 99.99% availability and 99.999% uptime of your production systems
Plan and execute goals, proven track record
Strong opinions on engineering best practices
Assist Product Owners with planning and roadmaps
Leads will communicate and coordinate with other teams across Freshworks
Mentoring other engineers in the team
Platform teams tend to be small but self-sufficient.  You will have a large scope of responsibilities.  They also tend not to have any QA or Ops personnel
Skills and Qualifications
Experience in building big data ETL data pipelines and Streaming applications using Spark (PySpark), Kafka and other big data frameworks.
Experience in Data Warehousing, and OLAP databases like Snowflake, Redshift, and Lakehouse architectures
Strong SQL expertise, data modeling, optimizing complex joins and database concepts
Strong programming development experience in languages like Python and Java.
Extensive experience building and operating scalable, fault-tolerant, distributed systems in the area of large scale data intensive applications.
Experience with Infra Scaling and Cost Optimizations
Strong documentation skills — translate product requirements into feasible high-level design documents with technical implementation descriptions
Strong track record with handling Production workloads and troubleshooting challenging issues
Cloud/SaaS experience
Strong analytical and problem solving skills
Minimum of 8 years relevant experience
Additional Information
Experience in Analytics and  Business Intelligence domain is a plus
Knowledge of Snowflake, Databricks, Apache Kafka, Apache Flink, Query Engines (Trino, Presto), Apache Airflow  etc. is a plus
Experience influencing product roadmaps by demonstrating the art of the possible through exploration and POCs
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 121K - 186K *
264,Data Scientist and Senior Data Scientist,Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Data
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good– you’ve come to the right place.
Role Description
We are looking for a top-notch machine learning scientist/data scientist to join the machine learning science team. Our team is tasked with producing performant machine learning models to enhance and personalize the shopper experience through search, product recommendations, content personalization, promotion selection, and much more. In addition, we augment and automate the work of the merchandiser and admins to enable them to react faster and better to changing markets, trends, and customer demands. You will be responsible for transforming business needs into machine learning solutions that we can deploy to production in collaboration with our engineering teams. To achieve this, you will research, design, prototype, and build machine learning systems, with large-scale training and offline/online tuning and experimentation.
The successful candidate will work with world-class database gurus, software and machine learning engineers, research scientists, and fellow machine learning scientist. We are looking for someone who gets a kick out of staying on top of the latest machine learning literature/tools/techniques and figuring out the best way to apply these for practical solutions. We encourage contribution to tools and knowledge sharing within the team, the company, and the industry.
Your Impact
As a Data Scientist, your job responsibilities will include:
Work with product management and leadership to translate business problems to data science problems
Research, prototype, and build demonstrations of machine learning ideas for quick validation and feedback
Design and build machine learning systems to hit accuracy and performance metric targets
Productize machine learning systems in collaboration with engineering teams
Design and conduct experiments to ensure optimal performance of machine learning systems
Educate engineering and product teams about data science during collaboration
Mentor and collaborate with other members of the data science team
Share technical innovations to the team and across the company
Create new innovations and contribute to conferences and/or open-source tools
Required Skills:
Practical experience in machine learning or personalization
MS or PhD in a quantitative discipline with 2+ years of experience or a BS in a quantitative discipline with 5+ years of experience
Fluent in building/prototyping machine learning models and algorithms and wrangling large datasets
Knowledgeable about standard machine learning approaches (Regression, Cross-Validation, Boosting, Matrix-Factorization, Decisions Trees, Clustering, CNNs, RNNs, Transformers, GANs)
Proficient in using Python (e.g., Numpy, Pandas, PyTorch, SciPy, scikit-learn, JAX) to implement machine learning models and algorithms
Proficient in SQL, shell scripting and Unix/Linux command-line tools
Preferred Skills:
Demonstrated experience with actually shipping code, getting data science into production
AWS experience
Some low-level programming experience ( C/C++/Fortran/Java/Go/Julia/Rust etc.)
Have built and trained various deep learning algorithms from scratch, including reinforcement learning
Can explain how inverse propensity scoring helps offline training and how to handle the increased variance
Comfortable using profiling tools to make algorithms more scalable or faster
Achieved a top rank in machine learning competitions like Kaggle or KDD Cup
Presented a paper at RecSys (or a similar conference)

 BENEFITS & PERKS
Comprehensive benefits package including well-being reimbursement, generous parental leave, adoption assistance, fertility benefits, and more!
World-class enablement and on-demand training with Trailhead.com
Exposure to executive thought leaders and regular 1:1 coaching with leadership
Volunteer opportunities and participation in our 1:1:1 model for giving back to the community
For more details, visit https://www.salesforcebenefits.com/
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 136K - 205K *
265,Data Analyst I,Philips,Bengaluru - M0,Mid-level / Intermediate,"Job Title
Data Analyst I
Job Description
Job Responsibilities
Managing and ensuring data quality, integrity, normalization and accuracy of available datasets. Improve data quality as per data quality framework and working with data owner. Internal and external benchmarking to establish things influencing data quality.
Managing and designing the reporting environment, including data sources, security, and metadata. Generate business insights using BI dashboards that shall provide clear directions/actions to senior managers to support decision-making.
Support digitization to improve quality of data. Root cause analysis by using quality analysis tools, machine learning and statistics.
Helping organization to take key decisions based on integrated analytics involving different datasets. Perform predictive data analysis, generate indications for focus area and target the improvements proactively.
Maintain and re-engineer existing ETLs to increase data accuracy, data stability, and pipeline performance.
Advanced statistical techniques for complex data analysis. Interpreting data, analysing results using statistical techniques, developing analytical reports.
Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.
Sufficient business acumen to understand business objectives & dynamics
As a data analyst, you will work with data from a wide range of sources. You will be taking responsibility for exploring the data, recommending actionable insights, building visualizations/dashboard to provide information that matters to business. This will involve automating data quality checks, data extraction and pre-processing. You will be the person who turns data into information, information into insights and insights into business decisions. You should also have a very fine eye for detail and deep understanding of the popular data analysis tools and databases. As data analyst you will create compelling reports using database-stored procedures and triggers. As the analytics team is chartered to be the one stop shop for all data needs, you will play an integral role in analytics team for the holistic growth of the businesses.
Job Qualifications:
Bachelor’s or master's degree in Computer Science, Information management, Statistics or related field
5+ years of experience in the Consumer or Healthcare industry in an analytical role with focus on querying data, analyzing and clearly presenting analyses to stakeholders across the organization.
Working experience on Python, R Programming, Scala, Apache Spark, AWS Redshift is must.
Mandatory working experience in QlikView, Adobe analytics, Google 360. Knowledge in analytics tools like Tableau, Power BI, Excel VBA Macros, RSPSS, SAS is an added advantage.
Proven working experience as a data analyst or business data analyst. Experience in working on Business intelligence tools/platforms and systems.
Strong knowledge in data pre-processing and EDA by using various tools. Thorough in analytics/visualization tool setup, configuration and administration.
Having knowledge of classification (Random Forest, SVM, Boosting and Bagging techniques) and clustering algorithms is desirable
Hands on in Descriptive/Predictive/Prescriptive Analytical techniques. Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Results driven with analytical and numeric skills. Convey data story through the visualization.
A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.
Ability to work effectively and independently in a fast-paced agile environment with tight deadlines
A flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.",USD 67K - 110K *
266,Data Scientist II (Detection + ML),HERE Technologies,"Mumbai, India",Mid-level / Intermediate,"What's the role?
HERE is searching for a Data Scientist (AI/ML) for our Foundation Engineering team. Within Foundation Engineering you would be part of Street Level Imagery (SLI) Dashcam Extraction team, a Data Scientist (AI/ML):
• Development or invention of new frameworks/ solutions for Feature extraction or detection of SLI images in the domain of AIML.
• Focus on machine learnin model development including full development cycle: Dataset preparation (with Labeling team), model architecture, model training, model evaluation and model deployment.
• Work on multidisciplinary teams of data engineers, software engineers, data scientists, and business subject-matter experts to deliver complex projects on time and within budgets.
• Support team to design experiments and stay up to date with industry inventions in AIML(esp Computer Vision), Location Intelligence , distributed computing LiDAR and Drone processing, 3D modelling , AR/VR
• Identify relevant research papers in above mentioned tech domains and enable team to design solutions for the same
• Improving the innovation index of HERE, by getting research papers published in NeurIPS, IEEE, and awarded recognition in international forums like CES, Stevie ,etc
Who are you?
Bachelor's Degree in Engineering Or Master's degree Or Phd program n Data Science, Machine Learning, Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Physics, or related fields.
• Understanding of statistical analysis of data and mathematical modeling
• Experience developing and testing machine learning or statistical projects, with strong background in supervised, unsupervised, semi-supervised and reinforcement learning algorithms and modelling.
• Strong background in Computer Vision including image/video processing, object detection, classification, and tracking. Knowledge and experience on using deep learning tools (e.g. TensorFlow, MXNet, PyTorch, etc.) for image/video analytics
• Proficiency in Python (e.g., pandas, scikit-learn, bokeh, matplotlib, NumPy)
• Ability to handle large datasets and images using Scala, Hadoop, Pyspark
Who are we?
HERE Technologies is a location data and technology platform company. We empower our customers to achieve better outcomes – from helping a city manage its infrastructure or a business optimize its assets to guiding drivers to their destination safely.
  At HERE we take it upon ourselves to be the change we wish to see. We create solutions that fuel innovation, provide opportunity and foster inclusion to improve people’s lives. If you are inspired by an open world and driven to create positive change, join us. Learn more about us on our YouTube Channel.
  HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.",USD 86K - 160K *
267,Data Scientist 2,Publicis Groupe,"Bengaluru, India",Mid-level / Intermediate,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
The Automotive practice within Epsilon accelerates and drives growth for major players of the automotive industry, from Original Equipment Manufacturers (OEM) to Dealers big and small in the US and Canada. Part of a 1,600-member global team, the practice offers the automotive world’s largest service reminder platform along with agency services and digital media solutions. A leader in the automotive space, the team supports over 50% dealers in the US and manages 280M+ customer vehicle relations.
The Automotive Data Science team within Epsilon partner with both internal and external clients and data providers, leverage predictive analytics and advanced modeling techniques to drive strategic thought and effective decision making. The core work charter includes supporting Retail and After Sales Service businesses for all the OEMs by developing solutions across the Customer Journey to drive Acquisition, Engagement, Retention using Advanced Analytics, Machine Learning, Deep Learning Capabilities and Data Platforms.
The Data Scientist, II would support stakeholders by deploying projects from inception to insights and enable business strategy and impact for the clients. Contributes towards automation, process improvement and efficiency. Demonstrates innovative thinking, passion, and cross team collaboration. Establish strong working relationship with stakeholders.
Roles and Responsibilities
Deliver end to end Data Science projects including understanding of business requirements, exploratory data analysis, data processing, aggregating data, feature engineering, building, and validating predictive models, explaining model results and insights.
Use AI, ML, DL techniques such as regression, classification, clustering, tree-based algorithms, support vector machine, and neural networks, recommender system, attribution modeling to address business problems.
Improve upon existing methodologies by developing new data sources/features, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytical capabilities, platforms, and pipelines.
Present insights and recommendations to audiences of varying levels of technical sophistication
Automate processes to ensure scalability of solutions by collaborating with cross-functional teams.
Perform the extraction, transformations, and loading from the source systems and the data lake to the analytics products using independently developed logic.
Enhance data maturity and integration for Epsilon projects by interacting with operations to standardize the core value-add functionality, enabling a multiplier effect experience working within a collaborative team.
Challenge the status quo with entrepreneurial innovation in curating new data sources, elevating analytics beyond data reporting and dashboarding to delivering actionable insights.
Qualifications
Master’s or Bachelor’s Degree in a quantitative discipline (Statistics, Economics, Mathematics, Data Science, Business Analytics).
2-4 years of experience as a Data Scientist deploying Data Science projects.
2+ years of coding skills in Python, SAS, SQL, and YAML.
Deep understanding and hands-on experience with ML and DL Algorithms.
Experience of working with large data sets and developing scalable solutions.
Knowledge of Automotive, Marketing Business, E-Commerce, Digital transformation is preferred.
Ability to work independently and deal with ambiguity.
Strong analytical and problem-solving skills.
Excellent presentation and communication skills.
Strong written and verbal communication skills.
Highly motivated and collaborative team player with strong interpersonal skills.",USD 126K - 198K *
268,Sr/ Staff/Sr. Staff/Principal Engineer(Python | Spark | BigData | Kubernetes |SQL),Zscaler,"Hyderabad, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
The ZPA Advanced Analytics team at Zscaler is looking for a Bigdata/Spark Engineer who will help us in the analysis of vast amounts of data, write production grade pipelines, and infrastructure optimization.
  What You Will Do
You will be responsible for product features related to data transformations, enrichment, and analytics
You will discuss with product managers, UI, and other backend teams to understand requirements and translate the same into functional specifications 
You will seize every opportunity to refactor code in the interests of maintainability and reusability
Lead and provide technical direction and mentorship to junior engineers and bring out the best in them
The ideal candidate has a proven track record of building large scale enterprise products, and is a creative thinker, problem solver, learner, and a fantastic manager of people, and is motivated with engineering excellence.
  Responsibilities
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Ad-hoc analysis and presenting your results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
  Skills and Qualifications
BTech/MTech in CSE or relevant field from a reputed university.
5+ years of experience in developing and deploying Big data solutionsExperience with Python, PySpark (PySparkSQL), Spark (SparkSQL), SQLExperience with Data visualization tools / Data visualization algorithms
Understanding and sense of data-warehousing and data-modeling techniques
Strong understanding of distributed systems, real-time analytics
Experience with stream-processing technologies like Apache Kafka and Apache Flink
Skill of self/unit testing and feature verification
Experience with data engineering tasks or working with data engineers
Good interpersonal skills and positive attitude
Experience with cloud environments AWS/Azure/GCP
Experience with Kubernetes, DockersBasic knowledge of Java and Microservices
(Plus+ and optional) Pipeline orchestration tool Kubeflow
(Plus+ and optional) basic ML/AL knowledge and experience working with ML engineers or Data scientists
#LI-MS6

By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 45K - 84K *
269,Trading BI Developer,Sportradar,"Mumbai, India",Senior-level / Expert,"Company Description
We’re the world’s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.
Job Description
Are you passionate about Data Visualization?
Sportradar is seeking a curious and motivated BI Developer to join the fast paced and dynamic Trading Services Unit Operations team.
You will be responsible for the design, creation, and implementation of the reporting layer for our global Trading Services Operations. You will implement creative approaches to solving complex problems with ambiguous paths to resolution. In addition to building new features, you will constantly be improving and expanding existing reporting interfaces.
The role is a key member of the team that will help develop the vision for and architect for our Trading Services Data Infrastructure. The Trading Services Unit Operations team drives innovation and operational excellence through the projects they support across the Unit.
You will report directly to the Head of Trading Services Unit Operations and collaborate with management of our Trading Operations and Core BI/Data teams to surface the answers to key operational and business questions.
 What You Will Do
Consolidate data from various sources via ETL processes
Dashboard Development
Pro-actively Identify opportunities for new projects, using existing tools in new ways, using existing data differently, and generally demonstrating the value of data
Reining-in and centralizing reporting interfaces that have been developed in silo.
Driving best practices and technical excellence
Engaging with Trading BI/Data projects throughout their lifespan; from conception, development, launch, and beyond
Being the main liaison with the Core BI/Data Team for Trading Services
Lead the translation of business requirements into technical tasks.
Responsible for articulating tasks that cover a user interface and reporting capabilities.
Creating Technical documentation for BI Tools
Maintenance of existing documentation for BI Tools
Participate in Departmental knowledge transfer Programmes in order that they can transfer their knowledge to others in the Unit who will benefit
Plan self-training and education in order to ensure that technical knowledge is developed so that appropriate new technology and techniques can be suggested in order to effectively meet business needs
 Basic Qualifications
Experience of working in data engineering or BI Developer roles in support of BI and Analytics
Deep Understanding of SQL
Strong Data Visualization skills
Ability to present to senior stakeholders
Excellent communication skills
 Preferred Qualifications
Strong experience using Data Visualization tools (i.e. Qlik Sense, Tableau)
Track record of having earned the trust of leadership by challenging norms and improving efficiency.
Ability to dive deep into data, existing processes, people, and technology challenges to identify risks and opportunities.
Demonstrated ability to meet deadlines while working on multiple complex projects.
Demonstrated ability to work in global environments and with people/teams from different cultural backgrounds.Experience working with AWS (Redshift)
Additional Information
Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ",USD 81K - 135K *
270,Sr Staff Data Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
 This position reports to: Director, Data Engineering and Data Science
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.  
As a member of the Product Operations Analytics team, you’ll focus on driving operational awareness to our Executive Team while partnering with leaders throughout ServiceNow to fundamentally improve how we run our business. With a combination of exceptional analytical skills, an insatiable curiosity, and an entrepreneurial “get stuff done” mindset, you’ll help us better understand our customers, partners, and products, and drive important changes that will shape the future of ServiceNow.
What you get to do in this role:
We are looking for a Rock Star with a winning track record in Big Data, Data Warehousing, Visualization and Data Web Services.  The Staff Data Engineer will be a core technical contributor to the team with deep expertise in manipulating and structuring large, complex datasets that feed central data warehouses.  S/he will be responsible for helping stand up and maintaining daily data transfer jobs, database structures, identifying data integrity issues, and developing documentation on data assets. The Staff Data Engineer will also work closely with ServiceNow data analysts and data scientists to help prep data for models and dashboards. 
 The ideal candidate should have a background in Engineering, Statistics, Mathematics, Computer Science, equivalent quantitative field or related practical experience with an obsession on data quality. S/he should have an outstanding ability to foster relationships with staff across departments and be motivated to continuously achieve positive results.  Extensive understanding to the needs of data visualization is a must for this role.  S/he should also be able to effectively handle ad hoc requests and multitask with ease and little guidance.
 Examples Of Day-to-Day Responsibilities
 Enforcing company data policies and procedures to ensure data quality and reduce discrepancies
Securing approvals for data access based on business needs
Developing scalable automated ETL jobs and maintain them
Identify any data integrity issues and deep dive to find root cause
Develop and manage Python and API calls to stand up master data sets and merge datasets across disparate systems
Training analysts and data scientists alike on available data sources
Ensuring very large databases and compute clusters operate optimally
Implementing and maintaining database structures and governance
Developing / maintaining documentation on databases and production tables
Collaborating across the company’s multiple data teams to meet analytics deliverables
 Qualifications
In order to be successful in this role, we need someone who has:
Bachelor’s degree in Engineering, Computer Science, Statistics, Mathematics, a related quantitative field, or equivalent practical experience.
14+ years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with advanced experience in SQL and an additional object-oriented programming language (e.g., Python, Java, JavaScript)
Experience with Jenkins & Git a PLUS
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders
Proven track record for developing/maintaining performance optimized data models for production analytics
Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs
Passion for analyzing large and complex data sets and converting them into the information which drive business decisions
Attention to detail, organization and effective verbal/written communication skills
Experience in big data instances: Cloudera, Azure, Snowflake, and the like.
Proven track record in rolling out self-service analytics solutions (e.g. Tableau Server Ask Data, etc)
Solid decision making, negotiation, and persuasion skills, often in ambiguous situations
Must be able to work in fast paced environment and be able to adapt to changing requirements.
Understanding of technology development projects and the full technology development lifecycle
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business. 
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
271,Bigdata Java Developer -Manager,State Street,"Bengaluru, India",Mid-level / Intermediate,"FX Front Office Senior Bigdata Java Developer
Senior Java Engineer
Role Summary & Role Description
Global Markets business has embarked on a technology transformation project to replace legacy front office applications with an extensible new applications. This role is responsible for development of this application closely working as part of global team.
We are looking for a Senior Java Developer with experience in building high-performing, scalable, enterprise-grade applications.
You will be part of a talented software team that works on mission-critical applications. This includes roles and responsibilities of managing Java/Java EE application development while providing expertise in the full software development lifecycle, from concept and design to testing.
Java developer responsibilities include designing, developing and delivering high-volume, low-latency applications for mission-critical systems.
The role will be based out of Bangalore, reporting into front office development lead in India.
Responsibilities:
Design and develop Java core code to ingest data from different data sources, transform using data frames (in memory processing), write sink processes to write data into multiple targets (RDBMS, Hive, HDFS, Hbase etc.)
Develop solutions in Java using best practices around enterprise architecture such as dependency management, design patterns, complexity estimation & persistence layers.
Deliver high quality code deliverables for modules, lead validation for all types of testing and support activities related to implementation, transition and warranty.
Required Qualifications:
Technology Leader : 12+ years of related technology and domain experience with technology degree from tier1 college. Strong technologist with hands-on experience in leading Enterprise grade mission critical front office application development.
Solid understanding in functional and/or object-oriented programming language using Java and/or Scala
Multi-threaded applications; Concurrency, Parallelism, Locking Strategies and Merging Datasets
SQL, Relational and NoSQL databases
Creating and consuming RESTful services
Memory Management, Garbage Collection & Performance Tuning
Experience and working knowledge of distributed/cluster computing concepts
Experience in Linux environments; strong knowledge of shell scripting and file systems
Knowledge of CI tools and build tools like Git, Maven, SBT, Jenkins, and Artifactory/Nexus
Self-managed and results-oriented with sense of ownership is required
Excellent analytical, debugging and problem-solving skills is required
Core/Must have skills
JDK-11 and above. Java, Spring Boot, Spring Framework,Scala, Python, Apache Spark
Webservices – Rest API, Kafka
DataLake - DataBricks
GIT, Jenkins, Perforce
JDBC, Oracle, Catalog/Delta tables
SQL tuning
Good to have skills
DevOps, Testing Frameworks
Experience working in cloud-based environment like AWS
Work Schedule
Hybrid
Keywords (If any)
Java, Spring, Webservices, Apache Spark, Databricks, Python
Our technology function, Global Technology Services (GTS), is vital to State Street and is the key enabler for our business to deliver data and insights to our clients. We’re driving the company’s digital transformation and expanding business capabilities using industry best practices and advanced technologies such as cloud, artificial intelligence and robotics process automation.
We offer a collaborative environment where technology skills and innovation are valued in a global organization. We’re looking for top technical talent to join our team and deliver creative technology solutions that help us become an end-to-end, next-generation financial services company.
Join us if you want to grow your technical skills, solve real problems and make your mark on our industry.
About State Street
What we do. State Street is one of the largest custodian banks, asset managers and asset intelligence companies in the world. From technology to product innovation, we’re making our mark on the financial services industry. For more than two centuries, we’ve been helping our clients safeguard and steward the investments of millions of people. We provide investment servicing, data & analytics, investment research & trading and investment management to institutional clients.
Work, Live and Grow. We make all efforts to create a great work environment. Our benefits packages are competitive and comprehensive. Details vary by location, but you may expect generous medical care, insurance and savings plans, among other perks. You’ll have access to flexible Work Programs to help you match your needs. And our wealth of development programs and educational support will help you reach your full potential.
Inclusion, Diversity and Social Responsibility. We truly believe our employees’ diverse backgrounds, experiences and perspectives are a powerful contributor to creating an inclusive environment where everyone can thrive and reach their maximum potential while adding value to both our organization and our clients. We warmly welcome candidates of diverse origin, background, ability, age, sexual orientation, gender identity and personality. Another fundamental value at State Street is active engagement with our communities around the world, both as a partner and a leader. You will have tools to help balance your professional and personal life, paid volunteer days, matching gift programs and access to employee networks that help you stay connected to what matters to you.
State Street is an equal opportunity and affirmative action employer.
Discover more at StateStreet.com/careers",USD 30K - 56K *
272,EDE3-Senior Data Engineer-Hyderabad,Bosch Group,"Telangana, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Responsibilities: As a data engineer, you are involved in the design, development, deployment and ongoing operations of data pipelines to bring data from multiple data sources into a data-lake using tools for extract, transform and load operations. You are responsible for ensuring data quality monitoring and the proper management of metadata to support business objectives.
Scalable datalake: ·You will play a crucial role in building a scalable and efficient data lake ecosystem that enables the project to store, manage, and analyze vast volumes of structured and unstructured data. As part of data lake optimization, you will be responsible for monitoring the performance of the data lake, identifying and solving bottlenecks as well as optimizing data storage and processing.
Data Catalogue: ·Establishing and maintaining the data catalog and best practices for data management to facilitate data discovery and understanding.·Implement data lineage tracking to ensure data traceability and reliability.
Collaboration: ·You would get to work closely with other data engineers, data scientists, business analysts to ensure efficient functioning of the data lake. Collaborate with data stewards to enforce data quality standards and ensure data consistency across the data lake. Participate in data governance initiatives and support data compliance efforts. Communicate effectively with stakeholders to gather requirements and provide updates on data lake implementation. Document data lake processes, configurations, and best practices for future reference and knowledge sharing.
Cloudmanagement: Ability to provision and manage cloud resources and have strong DevOps experience with Terraform in Microsoft Azure
Requirements Master’s or a bachelor’s degree in computer science engineering, or a related field. Proven experience as a Data Engineer, Big Data Engineer, or related role with a focus on data lake development and management. Hands-on experience with big data technologies such as Hadoop, Spark or equivalent. Proficiency in programming languages like Python, Golang or Java for ETL and data processing. Familiarity with cloud-based data lake solutions (Azure Data Lake Storage, AWS S3) and cloud computing platforms (Databricks).·Strong understanding of data modeling, ontologies, data warehousing, and data integration concepts. Experience with data governance, data security, and data privacy practices. Excellent analytical and problem-solving skills. Strong communication and collaboration abilities to work effectively in a team-oriented environment. Deep experience with SQL and NoSQL databases. Certification in relevant big data technologies and cloud platforms.
Qualifications
Master's degree/ bachelor's degree in computer science OR Information Science or equivalent engineering stream
Additional Information
8 years - 10 years",USD 121K - 186K *
273,Senior Data scientist,Saviynt,Bengaluru,Senior-level / Expert,"Saviynt’s Enterprise Identity Cloud helps modern enterprises scale cloud initiatives and solve the toughest security and compliance challenges in record time. The company brings together identity governance (IGA), granular application access, cloud security, and privileged access (PAM) to secure the entire business ecosystem and provide a frictionless user experience. The world’s largest brands trust Saviynt to accelerate digital transformation, empower distributed workforces, and meet continuous compliance.

Responsibilities:
Lead the design, development, and implementation of generative AI and ML models and algorithms for various applications, including image generation, natural language processing, and data synthesis.
Collaborate with cross-functional teams, including data scientists, software engineers, and product managers, to gather requirements and define technical specifications for AI-based projects.
Architect scalable and efficient ML solutions, leveraging state-of-the-art algorithms and frameworks to achieve high-performance and accuracy.
Mentor and guide junior team members, providing technical expertise and ensuring best practices in AI and ML development.
Research and experiment with the latest advancements in generative AI and ML, and apply cutting-edge techniques to solve complex challenges.
Design and optimize data pipelines for training and deploying AI models using large-scale datasets.
Implement and maintain the codebase for AI applications, ensuring code quality, modularity, and reusability.
Conduct thorough testing and debugging of AI models to ensure robustness and reliability in real-world scenarios.
Collaborate in the development of APIs and user interfaces to integrate AI capabilities into products and services.
 Requirements:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
6+ years of experience in programming languages like Python, Java.
3+ years of experience with proficiency in popular ML frameworks (TensorFlow, PyTorch, Keras, etc.)
proven track record of successful AI and ML development projects, with a focus on generative models.
Deep understanding of neural networks, deep learning, and generative models (e.g., GANs, VAEs, etc.).
Hands-on experience with distributed computing, cloud platforms, and GPU acceleration for AI development.
Strong analytical and problem-solving skills, with the ability to think creatively to address complex challenges.
Solid understanding of software development best practices, version control systems, and agile methodologies.
Excellent communication and interpersonal skills, with the ability to collaborate effectively within a team and with stakeholders.
Demonstrated ability to work on multiple projects simultaneously and deliver high-quality results within tight deadlines.
A passion for continuous learning and a drive to push the boundaries of AI and ML technologies.
Saviynt is an amazing place to work. We are a high-growth, cloud software company with phenomenal people, that is building the most innovative identity platform in the world. Your time at Saviynt will be worthwhile. You will experience tremendous growth and learning while being part of something you are helping to define and build from the ground up. Through challenging yet rewarding work, you will be able to directly impact our clients, all within a welcoming and positive work environment. If you're resilient and enjoy working in a dynamic high-growth environment you belong with us!",USD 136K - 205K *
274,"Senior Manager, Data Product Engineer",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Key Responsibilities:
Developing data engineering: Working with stakeholders to collaborating on the overall strategy for the organization's data architecture. This includes defining data structures, metadata, data models, and data integration processes.
Defining data product strategy: Working with stakeholders to define the overall strategy for the organization's data products. This involves understanding business goals, identifying data sources, and determining the appropriate technology stack.
Designing data products: Creating conceptual, logical, and physical data models for the organization's data products. This includes defining data structures, schema, and data processing pipelines. Designing data systems: Developing and implementing data systems that support the organization's business needs. This may involve working with various technologies, including data warehouses, data lakes, data marts, and data APIs.
Data modeling: Developing logical and physical data models that reflect the organization's data needs. This includes defining data elements, data relationships, data flows, and data transformation rules.
The Principal Data Engineer will be responsible for designing, building, and maintaining the data products, evolution of the data products, and utilize the most suitable data architecture required for our organization's data needs to support Portfolio & Trial Operations Data functions.
Accountable for delivering high quality, data products and analytic ready data solutions for GDD.
Develop and maintain ETL pipelines for ingesting data from various sources into our data warehouse
Develop and maintain data models to support our reporting and analysis needs.
Proficiency with database systems, both SQL and NoSQL.
Follow to a consistent approach and adhere to best practices around operational excellence, security, reliability, performance efficiency and cost optimization.
Optimize data storage and retrieval to ensure efficient performance and scalability.
Familiarity with machine learning algorithms and their applications.
Collaborate with data analysts and data scientists to understand their data needs and ensure that the data infrastructure supports their requirements
Ensure data quality and integrity through data validation and testing
Implement and maintain security protocols to protect sensitive data
Stay up-to-date with emerging trends and technologies in data engineering and analytics
Accountable for the development of KPIs to assess health of the portfolio including time, financial & quality at the study, program, and portfolio level.
Closely partner with the Enterprise Data and Analytics Platform team, other functional data teams and Data Community leads to shape and adopt data and technology strategy.
Serves as the Subject Matter Expert on GDD Data & Analytics Solutions and build domain knowledge of the GDD specific area
Accountable for evaluating GDD Data enhancements and projects, and assessing capacity and prioritization along with onshore and vendor teams
Knowledgeable in evolving trends in Data platforms and Product based implementation
Manage and provide leadership for the resources supporting projects, enhancements, and break/fix efforts
Has End to End ownership mindset in driving initiatives through completion
Comfortable working in a fast-paced environment with minimal oversight
Mentors other team members effectively to unlock full potential
Prior experience working in an Agile/Product based environment
Provides strategic feedback to vendors on service delivery and balances workload with vendor teams
Qualifications & Experience:
Degree in Computer Science, Mathematics, Engineering, Biotechnology, or a related field.
5-7 years of hands-on experience working on implementing and operating data capabilities and cutting-edge data solutions, preferably in a cloud environment.  Breadth of experience in technology capabilities that span the full life cycle of data management including data lakehouses, master/reference data management, data quality and analytics/AI ML is needed. 
Strong Experience in modern scripting or programming language, such as Python (PySpark), R, Scala
Hands-on experience developing and delivering data, ETL solutions with with SQL, NoSQL and database technologies such as MySQL, PostgreSQL, DynamoDB, GraphDB etc.
3-5+ years of experience in data engineering or software development
Create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Experience with cloud-based data technologies such as AWS, Azure, or Google Cloud Platform
Strong analytical and problem-solving skills
Excellent communication and collaboration skills Functional knowledge or prior experience in Lifesciences Research and Development domain is a plus
Experience and expertise in establishing agile and product-oriented teams that work effectively with teams in US and other global BMS site.  
Initiates challenging opportunities that build strong capabilities for self and team
Demonstrates a focus on improving processes, structures, and knowledge within the team. Leads in analyzing current states, deliver strong recommendations in understanding complexity in the environment, and the ability to execute to bring complex solutions to completion.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.

#HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
275,EDE3 - Data Management Solution Engineer - Bangalore,Bosch Group,"Bengaluru:, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Job Description:
As a data management solution engineer you will design, develop and operate cloud native data management solutions with data pipelines for ingest, processing and transforming data from the vehicle fleet to feature development teams.
As a data management solution engineer you will follow design principles to enable high scalability of the solution for handling large data volumes seamlessly and in a cost-efficient manner.
As part of the data management solution, you would also be required to identify and develop value added services based on the data collected using efficient data analysis methods & practices.
As a data management solution engineer, you would be required to identify and enable new features into existing data management system for multi project variants.
The data management solutions shall enable function development teams to seamlessly make use of the collected and derived data for use in their feature development viz. MLOps workflow.
You will be part of an agile development team to define, develop and deploy the solutions.
Qualifications:
Master's degree/ bachelor's degree in computer science or information science OR equivalent engineering stream
Experience: 6+ Years' experience in large scale Data management domain
Additional information: Mandatory Skills & experience in:
Very strong programming skills in Python
Hands-on experience with architecting and development of features using service application principles.
Hands-on experience with cloud native deployment of Services viz. Docker, k8s, etc.
Experience with DevOps, data pipelines and various messaging systems (Kafka) on a Cloud native setup (preferably Azure)
Experience with storage technologies (NoSQL, etc.) and cloud native data base and optimization methods.
Experience in designing data models & data formats.
Preferred Skills & experience in:
Good working knowledge in Azure
Good understanding of cloud native database solutions (e.g. CosMosDB)
Experience with data collection from fleets and data ingestion, processing and transformation in data loop for deep learning
Motivating attitude, profound communication, strong interpersonal skills, structured and analytical.
Qualifications
Master's degree/ bachelor's degree in computer science OR Information Science or equivalent engineering stream
Additional Information
6+ years",USD 45K - 84K *
276,Lead BI Analyst – Data Engineering,Shell,Bengaluru RMZ-ECO WORLD,Senior-level / Expert,", India

Job Family Group:
Information Technology (IT)

Worker Type:
Regular

Posting Start Date:

Business unit:
Finance

Experience Level:
Experienced Professionals

Job Description:
Applies techniques such as business intelligence (BI), reporting and data modelling, analytical techniques and big data processing to provide the business with relevant information to increase revenues, improve operational efficiency, optimise customer programs, respond quickly to emerging market trends and gain a competitive edge in the market. Provides operational and functional support to the business on creating, storing, managing and maintaining information in all its forms, including the ability to incorporate policies and procedures for centrally managing and sharing information among different individuals, organisations and information systems throughout the information life cycle.
General Position Definition
Finance Operations Data Science Team is tasked with delivering tangible value to business units within Shell through data-driven decision making.
This position is part of Process Analytics team leading a team of business analysts supporting process mining projects for different businesses within Shell. The individual will join a growing global data science organization spanning both on/offshore.
Incumbent is responsible for leading and executing data analysis projects in a business, collaborating with different business stakeholders and other partners, support the implementation of insights to realize tangible value for Shell, manage a team of BI Analysts (up to 5) and working across a range of technologies and tools.
The ideal candidate has strong background in business analytics, storytelling, quantitative skills, brings domain expertise, has applied those skills in solving real world problems across different businesses / functions and has managed small teams in delivering insights.
Exposure to process mining tools like Celonis EMS/UI Path/PAFNow is preferred
Support the Data Science Manager in design & execution of projects and play proactive role in data model enhancements for Celonis Execution Management Systems (EMS) platform and building the opportunities pipeline.
Purpose
Lead the execution and management of Celonis Execution Management Systems (EMS) with focus on Extraction, Transformation, Data Modelling, Action Flows, Global reporting.
Design and effectively coordinate development of ETL/data warehouse best practices needed to support new and evolving sources of data
Establish methodology to gather, qualify, prioritize, and facilitate data model requirements; Design and deliver process models to ensure seamless analytics delivery
Articulate the insights from the analysis in business-friendly language and explain the workings of the analysis outcomes for business adoption
Provide support to the Data Science Manager in managing the portfolio
Skills
Reporting and Technology Skills
Deep expertise in analytics tools and technologies including (but not limited to): Data Engineering: Scripting Tools like SQL/Python
SAP Data Models and SAP Table Structures (across SAP Modules).
Data Analysis & reporting: Data collection, Data cleaning, Data Quality Analysis, Exploratory data analysis, Reporting Automation
Storytelling: Data visualization, Data Storytelling, Dashboard maintenance
Strong experience in BI tools and technologies (including, but not limited to) Spotfire, Tableau, Qlikview
Awareness of Agile / Scrum ways of working
Should be strong at understanding data architecture or frameworks and effectively coordinate development of ETL/data warehouse best practices needed to support new and evolving sources of data used in reporting and process analytics
Identify the right modeling approach(es) for given scenario and articulate why the approach fits
Design data warehouse flows and schemas and reporting models in the semantic layer
Assess data availability and reporting/modelling feasibility Review interpretation of analysis results
Experience in Celonis (On-Prem/EMS), UI Path, PAFNow preferred
Industry / Functional Expertise
Provide deep business expertise preferably Oil & Gas - Upstream or Downstream businesses. (If these are not available, willing to consider other industries that are similar or related - manufacturing, mining, power generation, etc.) functional expertise in any one or more of the following industries / functional areas
Functional Analytics: Order-to-cash, Procure-to-Pay, Record-to-Report, Tax (Direct & Indirect), Financial Risk and Assurance (controls and governance), Master Data Management
Manufacturing / Supply Chain: Maintenance Scheduling & Optimization, Inventory optimization, Spend Analytics, Vendor Performance, Logistics optimization, Contract Compliance
Stakeholder Management Skills
Forming close relationships with business stakeholders across businesses / functions to comprehensively understand their areas of operation and apply those in project execution
Effective coordination with IT & Data Experts to ensure design & management of data pipelines to support Process Mining
Clearly articulate the challenges / opportunities in business / function that can be supported by analytics
Deliver actionable insights that directly address challenges / opportunities
Guide articulation of business insights and recommendations based on understanding of business / function and respective stakeholders
Understanding of business governance and control structures & selecting the right analytical approaches which are consistent with businesses control/governance framework
Understanding business KPI's, frameworks and drivers for performance
Project Management
Execute end-to-end analytics projects - Project scoping, sourcing data, managing modeling, translating model results into business insights, and helping business partner understand insights and make decisions accordingly (help generate value for organization through data analysis)
Creating project management plan, running status update meetings, coordinating deliverables and timelines, and managing risks to project delivery Manage different moving parts - business stakeholders, IT, Analytics Resources, Data Experts, SMEs, etc. for the successful execution of the projects (executing multiple projects at a time will be considered a plus)
Solves most problems independently and articulate issues across functions and businesses, ensure collaboration to bring about solutions
Special Challenges
Deliver practical working solutions from a new and developing conceptual area.
Coach and mentor BI Analyst and Sr BI Analysts team members
Virtual working with network of colleagues located throughout the globe.
-

DISCLAIMER:
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Shell/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell is an Equal Opportunity Employer.",USD 110K - 150K *
277,Operations Specialist (Data Quality Managment-3),Deutsche Bank,"Bengaluru, Velankani Tech Park",Executive-level / Director,"Job Description:
Job Title - Data Analyst, AS
Location – Bangalore, India
Role Description
Today, markets face a whole new set of pressures – but also a whole lot of opportunity too. Opportunity to innovate differently. Opportunity to invest responsibly. And opportunity to make change.
Join us at DWS, and you can be part of an industry-leading firm with a global presence. You can lead ambitious opportunities and shape the future of investing. You can support our clients, local communities, and the environment.
We’re looking for creative thinkers and innovators to join us as the world continues to transform. As whole markets change, one thing remains clear; our people always work together to capture the opportunities of tomorrow. That’s why we are ‘Investors for a new now’.
As investors on behalf of our clients, it is our role to find investment solutions. Ensuring the best possible foundation for our clients’ financial future. And in return, we’ll give you the support and platform to develop new skills, make an impact and work alongside some of the industry’s greatest thought leaders. This is your chance to achieve your goals and lead an extraordinary career.
This is your chance to invest in your future.
The COO Division is a key enabler for DWS and is integral to the future success of the company by delivering world-class services across a set of key functions. It covers essential Technology and Operations capabilities, including our data programs and digital transformation. The COO aims to deliver a platform which is efficient, scalable, resilient and agile.
Within the COO Division Data Management is responsible for designing and driving the execution of the data strategy at Group and Divisional/functional level as well as coordinating adherence to Data related processes and policies and any applicable local regulations.
What we’ll offer you
As part of our flexible scheme, here are just some of the benefits that you’ll enjoy
Best in class leave policy
Gender neutral parental leaves
100% reimbursement under childcare assistance benefit (gender neutral)
Sponsorship for Industry relevant certifications and education
Employee Assistance Program for you and your family members
Comprehensive Hospitalization Insurance for you and your dependents
Accident and Term life Insurance
Complementary Health screening for 35 yrs. and above
Your key responsibilities
As a Data Quality Management Analyst you will
Ensure adequate data quality controls so that data can effectively support business processes
Ensure data activities are in line with DWS’s Data Management framework and operational activities are aligned to the target state of data quality standards
Conducting the monitoring and reporting on data quality levels to impacted stakeholders and engaging with business and leadership to quantify and articulate the business impact of data quality issues and identify and track remediation plans
Ensuring adequacy of data sharing, access, retention and disposal for area of accountability, in accordance to DWS’s defined processes
Assessing the current state of data quality to impacted stakeholders and engaging with business and leadership on remediation plans
Establishing target goals for data quality improvement and identify optimal approaches for resolving data quality issues to achieve targets
Ensuring adequacy of data sharing, access, retention and disposal for area of accountability, in accordance to defined processes
Your skills and experience
Proven experience in data quality management concepts in a global financial services environment
Ability to collaborate effectively with cross-functional teams
Strong analytical skills utilising tools including as SQL/Excel with experience of creating reports and dealing with large volumes of data
Expertise of managing data and processes in a global enterprise environment with an understanding of database and schema design
Strong conceptual and problem-solving skills, with an ability to develop creative and structured solutions
Degree educated in a science or quantitative finance discipline
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 49K - 91K *
278,Sr Associate Data Analyst - Workday Success Plans,Workday,IND.Pune,Mid-level / Intermediate,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
Workday Success Plans is a subscription-based offering that includes education, tools, and Workday expertise to help customers reach their business objectives faster by focusing on continuous adoption and driving business value from their Workday applications. The WSP Product Management team focuses on developing content for our customers to adopt new functionality and use Workday more effectively. This is an exciting time to be a part of a rapidly growing part of Workday's business!
About the Role
As a member of the WSP Product Management team, you will develop digital tools, content, and dashboards for our global WSP team and customer base. Your role will involve collaborating with the team to find opportunities for business scaling. You will prototype innovative applications using your expertise in programming, web technologies, and collaboration tools. Your attention to detail and commitment to continuous improvement will be crucial in creating engaging content tailored to the unique needs of each Workday Success Plans customer.
Responsibilities include:
Automating the generation of customer facing presentations and spreadsheets
Supporting the existing toolset and solving problems within Google and Smartsheet applications.
Automating the creation of learning paths for individual customers by analyzing data and identifying what interests them.
Gathering and documenting requirements for new tools.
Prototyping new applications using Python, Google Apps, Excel, etc.
Creating and updating documentation and enablement assets used within the team.
About You
Basic Qualifications
2+ years of relevant work experience.
2+ years experience with web technologies such as HTML/CSS, RESTful APIs and web services.
2+ years experience with Python
Excellent communicator in English with solid attention to detail with all customer facing materials.
Excellent collaborator - we are a team of dedicated individuals with very strong comradery.
Other Qualifications
Bachelor's degree or equivalent practical experience.
Experience with Tableau or other reporting tools, including experience with data modeling, data management, ETL processes, and working knowledge of SQL.
Experience developing automation solutions within Google Workspace using Google Apps Script (Spreadsheets, Slides, Drive).
Strong drive for continuous learning and continuous process improvement.
Ability to communicate technical information to non-technical audience.
Experience working in very small development teams and working independently on efforts from requirements to test and launch.


Our Approach to Flexible Work
 With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!",USD 67K - 110K *
279,Sr/ Staff/Sr. Staff/ Principal Engineer (Machine Learning | Data Science | Python),Zscaler,"Hyderabad, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Job Description
The ZPA Advanced Analytics team at Zscaler is looking for a data scientist who will help us in the analysis of vast amounts of data. The primary focus will be on data mining, statistical analysis and developing ML-based tools that would be deployed on product-grade systems.
  Responsibilities
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Ad-hoc analysis and presenting your results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Skills and Qualifications
BTech/MTech in CSE or relevant field from a reputed university.
5+ years of experience in developing and deploying ML applications.
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Excellent proficiency in Python.
Experience with common data science toolkits, such as NumPy, SciPy or similar frameworks.
Great communication skills.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases, such as MongoDB, Cassandra.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Working knowledge of AWS Cloud.
Knowledge of Agile methodology and Jira.
Knowledge of versioning systems like BitBucket and Git.
Basic understanding of PySpark, Kafka.
#LI-MS6
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 95K - 160K *
280,Senior / Principal Engineer - Roads (Noida/Gurgaon/Hyderabad/Mumbai) Civil3d,Ramboll,"Noida, India",Senior-level / Expert,"Company Description
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies and people around the world.
 Job Description
We invite you to bring your strong knowledge and experience in Roads/Highways design and knowledge in Civil 3D into play as you will be responsible to provide engineering and basic drafting support to technically challenging projects. You would create 2D drawings and 3D models and shall be responsible for the technical quality of your own work and would focus on compliance with project objectives and quality standards. To succeed in this role you must have B.Tech in Civil Engineering Are you our new Senior Design Engineer/Engineer - Roads? Click the apply-button to send your application.
You will join our REC department
As our new Engineer/Senior Design Engineer – Roads you will be part of a world class, innovation driven engineering design center owned by an independent trust and its employees. REC is a highly sophisticated center of engineering excellence and based in our India head office in Gurgaon. Working in partnership with all our established offices globally, the Ramboll Engineering Centre (REC) is a center for excellence in design by offering optimized solutions to the rest of the organization
Your key tasks and responsibilities will be:
 ·         Sound Knowledge of Geometric Design of Roads, 3D Modelling etc.
·         Good communication skills with the ability to liaise confidently and professionally with a diverse range of people.
·         Focused on Delivering, Quality and Results, Applying, Understanding.
·         Proven ability to work collectively within a team environment. Managing small teams of Jr Engineers and CAD Technicians.
·         Software driven person who loves to explore new commands and invest time in development of new tools. Willingness to learn new software's/techniques.
·         BIM competence especially a good command on either Navisworks/Infraworks is added advantage.
·         Knowledge and Expertise, Analyzing, Learning and discovering, Documenting and reporting.
·         Perform QA/QC by verifying design methodology, calculations, outcomes, etc.
·         Preferably have an exposure to the projects in Nordic region.
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this role, we believe your starting point is:
 ·         BE/B. Tech degree in Civil Engineering from an institute of repute. ME/ M. Tech would be desirable
·         Experience required 5 to 15 Years.
·         Knowledge of design codes like VGU/Euro Code/DMRB/AASHTO/any other international standards would be desirable.
·         Knowledge of understanding of the analysis and design principles of roads design.
·         Intermediate to Advanced skills in Civil 3D software is a must. Knowledge of Inroads/Openroads is added advantage.
·         Knowledge of other related software like AutoTURN/AutoTrack/ Pathplanner etc. would be desirable.
·         Should have knowledge of AutoCAD and preparing drawings in accordance with internationally recognized standard formats.
·         In addition to technical / functional acumen, he should have good communication skills and should be able to present their work.
·         Should be a good team member and should coordinate with other team members and the project manager for timely delivery of project.
·         Professional English language skills (written and verbal).
Qualifications
Must have experience in Civil3d and B.Tech/B.E in Civil Engineering 
Additional Information
Personal qualities that will help you succeed in this role include: Flexible attitude, in an environment with frequently changing deadlines can be relied on to meet deadlines, committed to both their work and personal development, with a willingness to widen their experience Knowledge of Microsoft applications Good level of written and spoken English  
Welcome to our Transport division
Ramboll is a global transportation consultancy, and we work on some of the biggest and most innovative infrastructure projects in the world. We are close to 3,000 bright minds working within Transport worldwide, creating practical, sustainable and economic solutions for national transport authorities, private contractors and municipalities alike.
 How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.
 ",USD 45K - 84K *
281,Data Analyst II,Bristol Myers Squibb,Hyderabad - Mindspace,Entry-level / Junior,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Summary: The Field Medical Business Analyst I role is an individual contributor role that focuses on measuring and analyzing key performance indicators and generating insights for the global Field Medical teams. He/She must be able to collect, analyze and present data to facilitate strategic decision-making across the Field Medical organization. The Field Medical Business Analyst should collaborate with the broader Field Medical Analytics, cross functional BI&A teams and Field Medical stakeholders to enhance Field Medical execution and contribute to successful product launches.
Roles & Responsibilities-
Collaborate with stakeholders to understand business needs and goals to develop analytical frameworks
Define and develop key performance indicators (KPIs) to measure the success of business initiatives
Meet with cross-functional teams to gather and consolidate relevant data from various sources
Analyze Field Medical data to identify trends, patterns, and key insights surrounding Field Medical execution and product launches
Design and develop comprehensive dashboards and reports that provide actionable information for Launches, Field Medical Initiatives & Quarterly Business Reviews
Translate data-driven insights into actionable recommendations and opportunities for improving business performance
Ensure the accuracy, completeness, and reliability of data through thorough quality assurance processes
Stay updated on emerging trends and technologies in data analysis, tools and insights generation
Skills & Competencies-
Strong analytical and problem-solving skills with attention to detail
Analytical mindset with the ability to leverage data for strategic decision-making
Excellent communication and interpersonal skills to effectively engage with diverse stakeholders
Strong verbal and written communication skills to collaborate effectively with cross functional teams
Excellent organizational skills and ability to work on multiple priorities simultaneously
Excellent time management skills with a proven ability to meet deadlines
Ability to work independently and as part of a cross-functional team
Exp-
We welcome candidates with a wide range of degrees & background, though sustained success with a significant volume of analytic & quantitative coursework is required. Successful applicants have a bachelor’s or master’s degree in Engineering, Operations Research, Management Science, Applied Mathematics, Statistics or similar.
Proven experience of 3-5 years in data analysis and reporting, pharmaceutical industry experience is a plus
Proficiency in data analysis tools such as Python, R, SQL, or others
Proficiency in data visualization tools (e.g., Tableau, Qlikview, Power BI) and advanced MS Excel skills
Proficiency in MS Office tools (e.g. Microsoft Word, Excel, PowerPoint, Outlook, Teams, OneNote, SharePoint)
Excellent communication skills to effectively present and explain visualizations to diverse audiences
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 53K - 94K *
282,Data / ML Engineer-4,Mastercard,"Pune, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data / ML Engineer-4
Mastercard Overview

Mastercard is the global technology company behind the world’s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless®. We ensure every employee can be a part of something bigger and change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.
Join a fast-growing team
As a Data / ML Engineer in the Data Engineering & Analytics team, you will develop data & analytics solutions that sit atop vast datasets gathered by retail stores, restaurants, banks, and other consumer-focused companies. The challenge will be to create high-performance algorithms, cutting-edge analytical techniques including machine learning and artificial intelligence, and intuitive workflows that allow our users to derive insights from big data that in turn drive their businesses. You will have the opportunity to create high-performance analytic solutions based on data sets measured in the billions of transactions and front-end visualizations to unleash the value of big data. You will have the opportunity to develop data-driven innovative analytical solutions and identify opportunities to support business and client needs in a quantitative manner and facilitate informed recommendations/decisions through activities like building ML models, automated data pipelines, designing data architecture/schema, performing jobs in big data cluster by using different execution engines and program languages such as Hive/Impala, Python, Spark, R, etc.

Your Role
• Drive the evolution of Data & Services products/platforms with an impact-focused on data science and engineering.
• Turning unstructured data into useful information by auto-tagging images and text-to-speech conversions.
• Solving complex problems with multi-layered data sets, as well as optimizing existing machine learning libraries and frameworks.
• Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.
• Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
• Discover, ingest, and incorporate new sources of real-time, streaming, batch, and API-based data into our platform to enhance the insights we get from running tests and expand the ways and properties on which we can test Experiment with new tools to streamline the development, testing, deployment, and running of our data pipelines.
• Maintain awareness of relevant technical and product trends through self-learning/study, training classes and job shadowing.
• Participate in the development of data and analytic infrastructure for product development
Continuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations
• Partner with roles across the organization including consultants, engineering, and sales to determine the highest priority problems to solve
• Evaluate trade-offs between many possible analytics solutions to a problem, taking into account usability, technical feasibility, timelines, and differing stakeholder opinions to make a decision
Break large solutions into smaller, releasable milestones to collect data and feedback from product managers, clients, and other stakeholders
• Evangelize releases to users, incorporating feedback, and tracking usage to inform future development
Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.
• Work with small, cross-functional teams to define the vision, establish team culture and processes
Consistently focus on key drivers of organization value and prioritize operational activities accordingly
• Escalate technical errors or bugs detected in project work
• Maintain awareness of relevant technical and product trends through self-learning/study, training classes, and job shadowing.
• Support the building of scaled machine learning production systems by designing pipelines and engineering infrastructure.
Ideal Candidate Qualifications:
• Experience and exposure to Python/Scala, Spark(tuning jobs), SQL, Hadoop platforms to build Big Data products & platforms
• Experience with data pipeline and workflow management tools: NIFI, Airflow.
• Comfortable in developing shell scripts for automation
• Proficient in standard software development, such as version control, testing, and deployment
• Demonstrated basic knowledge of statistical analytical techniques, coding, and data engineering
• Curiosity, creativity, and excitement for technology and innovation
• Demonstrated quantitative and problem-solving abilities
• Motivation, flexibility, self-direction, and desire to thrive on small project teams
• Good communication skills - both verbal and written – and strong relationship, collaboration skills, and organizational skills
• At least a Bachelors degree in Computer Architecture, Computer Science, Electrical Engineering or equivalent experience. Postgraduate degree is an advantage
The following skills will be considered as a plus
• Experience with visualization tools like tableau, looker
• Hands-on experience with cloud computing and big data frameworks e.g. GCP, AWS, Azure, Flink, Elasticsearch, and Beam
• Knowledge in MLOps frameworks such as TensorFlow Extended, Kubeflow, or MLFlow
• Experience participating in complex engineering projects in an Agile setting e.g. Scrum
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 174K - 275K *
283,Senior Electrical Engineer (Chennai/Noida/Mumbai),Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Ramboll was founded in 1945 in Denmark. Today, we employ 16,000 engineering, design and consultancy specialists. We hold a leading position in the Nordic market (Denmark, Sweden, Norway, and Finland) and have more than 300 offices in 35 countries.
Job Description
We invite you to bring your Electrical System experience into play as you will provide electrical engineering services on projects to Ramboll and its Clients, in coordination with Architects and structural consultants, for all stages; i.e concept, schematic, detailed design, tender & construction. This shall include technical and project leadership within the electrical engineering team. To succeed in this role you must have B.Tech/ M.Tech in Electrical Engineering with 8 to 10 years of professional experience in the relevant field. Are you our new Senior Engineer- Electrical, Buildings? Click the apply-button to send your application.
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies and people around the world.
You will join our Buildings Department
As our new Senior Engineer– Electrical, Buildings you will be part of our global High-Rise department, Ramboll’s dedicated team of high-rise experts which have designed over 150 tall building projects globally, including some of the most technically challenging. You would be responsible for coordinating with project managers and/or engineers for design and draughting work in the High-Rise department in India offices and supporting the global department which also has offices in Copenhagen, Dubai and Singapore.
Your key tasks and responsibilities will be:
As a Senior Electrical Engineer, you shall be responsible for the design and delivery of all electrical and associated ELV systems of a wide range of projects in the building services. Key responsibilities and duties are listed, but not limited to, the below:
Technical engineering of all electrical systems and including:
Lead discipline on projects.
Developing and guiding junior engineers.
Applying policies relating to health & safety, quality, and training.
Preparation of load estimation for the project and conducting primary technical calculations, drawings, reports, specifications and reviews on design deliverables related to electrical system design.
Develop a thorough design philosophy, effectively contributing to the inception, development, and detailed delivery of projects across all stages.
Coordinate and liaise with all other design team members, including architects and structural engineers plus client, project managers and QS.
To act as discipline lead on projects to successfully deliver high quality discipline projects in accordance with corporate and client requirements.
Capability of leading MEP for small to medium sized projects.
Attend external meetings and prepare design presentations and design reports.
Where design on middle east projects is being performed remotely with other Ramboll offices or by subconsultant, collaborate closely with those remote design teams and ensure compliance with local requirements and where directed, assist and represent the satisfactory performance of their services to local clients and stakeholders.
Provide electrical engineering technical support and engage personally where required to successfully enable Local Authorities’ approvals on all projects.
Support client and sustainability sub-consultant in studies, calculations and reports for sustainability options within the project.
Mentor and coach junior and graduate engineers.
Check and review electrical design work undertaken by junior and graduate engineers.
Responsible for the correctness, accuracy, and complete multi-disciplinary coordination of the design documentation in accordance with QA/QC review processes.
Have a good knowledge of buildability & construction techniques.
Demonstrated critical thinking skills, ability to work methodically and analytically in a quantitative problem-solving environment.
Forecast, plan and manage own workload and progress against agreed plan and criteria.
Evaluate and advise to project lead engineer on electrical related design changes to ensure change management.
Strong attention to detail, team working, collaboration, organization, and problem-solving skills.
Have a basic understanding of the financial and commercial management of projects.
Provide technical support to respond to prequalification documents, RFPs, and other client inquiries.
Excellent written and verbal communication skills.
Ensure that Health & Safety is embedded into all work practices in line with company policies.
Maintain and participate in Continuing Professional Development (CPD) events to develop own expertise.
Qualifications
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this Senior Electrical Engineer role, we believe your starting point is:
B.E /M.E in Electrical with 8 to 10 years of professional experience, out of which a minimum of 4 years should be in Middle East projects as an added advantage.
Proven track record in building services design with different types of sectors, including high rise, commercial, residential, retail, healthcare, industrial, educational, refurbishment, etc.
Proven record as a Project Engineer on several projects.
Experienced in working within teams on multi-disciplinary projects and interacting with a wide range of architectural, engineering and planning disciplines.
Advanced knowledge of electrical engineering principles for LV, Lighting, ELV and FA/FLS designs.
Good system overview knowledge of buildings mechanical and public health systems.
An ability to adapt to different working styles and the unique business culture of the Middle East.
Excellent knowledge of local and international design standards, including BS-EN, CIBSE, ASHRAE, NFPA etc.
An excellent knowledge and experience of local statutory authorities’ regulations and submission requirements across Middle East, mainly UAE and KSA, such as DEWA, ADDC, SEC, SBC, Etisalat, Du, Civil Defence etc and procedures for Local Authority approvals.
Proven ability to carry out both manual and computer aided calculations, problem solving, technical analyses, etc.
Proficient in LV power system modelling and analysis software such as Amtech (or similar), lighting software (Dialux Evo, Relux, or similar), Lightning Protection (Strike Risk or similar) and generator sizing.
Competent use of relevant software such as MS Office suite.
Knowledge and experience of AutoCAD, Autodesk Revit and Navisworks would be recommended.
Detailed knowledge of BIM automation / digitalisation techniques and standards.
Knowledge of sustainable design practices and technologies, preferably having worked on LEED or Estidama certified projects.
Personal qualities that will help you succeed in this role include: self-motivated, team player and able to work independently with minimum supervision and a flexible attitude in an environment with frequently changing deadlines and can be relied on to meet deadlines.
Additional Information
Welcome to our Buildings division
As one of the top 10 building designers in the world, Ramboll works on more than 10,000 building projects each year. 5,000 experts across the world specialise in creating more innovative, sustainable and liveable buildings. We place particular emphasis on our liveable buildings concept where we balance the cultural, social and physical values of buildings, to improve the quality of life for building users.
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 45K - 84K *
284,Sr Applied Research Scientist/Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a critical mission to power AI based workflows and solutions.
As part of Core LLM Team, we build and evolve Generative AI based solutions, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
Applied research scientists/engineers are expected to find innovative and cost-effective solutions to key problems, deliver high quality code, and work with product managers/machine learning engineers/performance, quality engineers to take the product to market.
 Qualifications
To be successful in this role you have:
5+ years of relevant experience
Solid software development skills in Python/C++/Java
Experience in training transformer-based language models and their variants (T5, BART, BERT etc)
Knowledge of transformer architecture and the impacts of modifying the same
Experience in using GPUs to train deep learning models
Good knowledge of solving industrial problems using deep learning models with NLP-related use-cases
Strong understanding & Hands-on at model compression via parameter quantisation, distillation, teacher-student training techniques
Strong understanding of large language models(LLM), and prompting approaches
Strong understanding & Hands-on at AI quality evaluation metrics
Experience in reading papers and implementing algorithms described in papers
An advanced degree in computer science (MS/PhD) with a major in Natural Language Processing
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
285,Data Analyst and Test Automation Expert EAC 2024,Bosch Group,"Coimbatore, India",Senior-level / Expert,"Company Description
We are Bosch Digital. Our mission is to shape the digital future of Bosch together with our customers and partners in the Bosch divisions. We work with and for almost all Bosch units when it comes to collaboration on digital projects. We create, innovate, operate and maintain differentiating products, services and solutions that fascinate our customers and provide outstanding business value for Bosch. Bosch Digital is home to more than 10,000 unique and diverse talents around the world. Our agile mindset and working culture are a key driver of digital transformation at Bosch and gives both our associates and their ideas room to grow.
Job Description
Designing and developing test automation scripts
Write, design, and execute automated tests by creating scripts to test functions automatically
Performance measurements and benchmarking of own and competitor sensor system solutions
Perform statistical measure of the data sets using Six Sigma and other data analytic techniques using MATLAB
Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for datasets
Collaborating with QA Analysts and Software Developers to develop solutions
Reporting of reliable and consistent results to stakeholders
Requirements:
Over 8 years of experience as test engineer includes test strategy defining and preparing test automation scripts
Three or more years of experience in mining data as a data analyst includes developing and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality
Work closely with project managers to understand and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers
Strong expertise in Python as a test automation engineer and in building test automation frameworks
Strong expertise in MATLAB for data wrangling and analysis
Good experience in Python (modules like numpy, pandas, etc.) programming for data visualization and validation
Good experience in Power BI, Tableau, or any dashboard publishing tool for statistical report generation
Good experience in Confluence, Bitbucket and Agile methodologies (JIRA, Scrum ceremonies, etc)
Know how of MEMS sensors (Accelerometer, Gyroscope, etc) and its application throughputs is an added advantage
 Qualifications
B.E/B.Tech
Additional Information
8+ years of relevant experience",USD 93K - 144K *
286,Data Analyst III,Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Summary: The Data Analyst will play a crucial role in supporting data-driven decision-making, generating insights, and providing strategic guidance to optimize business operations in Field Strategy and Analytics. This position requires expertise in Go-To-Market (GTM)/sales force sizing, customer valuation, segmentation, targeting & alignment, decision science/statistical analysis, real-world data analysis, digital analytics, and measurement. Analyst will collaborate with cross-functional teams and utilize advanced analytical techniques to enhance sales force effectiveness to drive business performance.
Roles & Responsibilities
Conduct analysis and interpret complex data sets to derive meaningful insights and recommendations
Familiarity with forecasting models, and techniques to project sales, demand, and market trends for biopharma products
Collaborate with stakeholders to identify business problems, goals, and KPIs to develop analytical frameworks
Perform statistical analyses, data mining, and predictive modelling to uncover trends and correlations
Work closely with cross-functional teams to design and implement initiatives, and measurement frameworks to optimize customer engagement
Collaborate with IT teams to develop and enhance data infrastructure, data pipelines, and analytical tools for efficient data collection, processing and analysis
Stay up-to-date with industry trends, best practices, and emerging technologies
Provide training, guidance, and mentorship to junior analysts and team members
Manage multiple workstreams with varying priorities and deadlines. Help junior members prioritize work accordingly to deliver timely, and high-quality work
Create, and maintain sound process documentation and SOPs
Oversee overall direction, and quality of analyses performed by junior members. Ensure work is focused on impactful business questions with an eye towards accuracy and efficiencies
Skills & Competencies-
Strong analytical thinking, and problem-solving skills with the ability to analyze complex data sets, and draw meaningful conclusions
Proficiency in statistical analysis techniques, MS-Excel, and predictive modeling
Strong project management skills, and the ability to work independently or as part of a team
Solid understanding of digital/visual analytics tools and platforms (e.g., Tableau, Spotfire)
Familiarity with the biopharma industry, including knowledge of relevant data sources and KPIs
Strong communication skills with the ability to present complex information to non-technical stakeholders in a clear manner
Strong business acumen, and strategic thinking capabilities. Ability to translate analytical findings into actionable insights, and recommendations
Experience-
We welcome candidates with a bachelor’s or master’s degree in Technology or Engineering with a strong record of analytic and quantitative work.
Proven experience (typically 5+ years) in a similar data analyst role, preferably within the biopharma or pharmaceutical industry.
Experience in working with real-world data (including clinical and healthcare), large datasets (SQL, R, Python), data visualization tools (Microstrategy, Tableau, Spotfire, etc).
Familiarity with regulatory requirements and compliance in the biopharma industry is a plus.
Experience with real-world data analysis, digital analytics, and market research methodologies.
Certification or training in relevant analytics or business intelligence tools is a plus.
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 93K - 144K *
287,AVP- Data Analytics Microstrategy,Citi,NIRLON KNOWLEDGE PARK GOREGAON (EAST) MUMBAI,Executive-level / Director,"The Data Analytics Senior Analyst is a seasoned professional role. Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flow for the area or function. Integrates subject matter and industry expertise within a defined area. Requires in-depth understanding of how areas collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the function and overall business. Evaluates moderately complex and variable issues with substantial potential impact, where development of an approach/taking of an action involves weighing various alternatives and balancing potentially conflicting situations using multiple sources of information. Requires good analytical skills in order to filter, prioritize and validate potentially complex and dynamic material from multiple sources. Strong communication and diplomacy skills are required. Regularly assumes informal/formal leadership role within teams. Involved in coaching and training of new recruits. Significant impact in terms of project size, geography, etc. by influencing decisions through advice, counsel and/or facilitating services to others in area of specialization. Work and performance of all teams in the area are directly affected by the performance of the individual.
Key Responsibilities:
Creating visualizations for the data extracted with the help of Tableau/Microstrategy
Identifying patterns and meaningful insights from data by analyzing it
Designing dashboards
Analyzing SQL queries for improving performances
Examining glitches in business processes and resolving them
Finding the key areas of automation to make the business processes smooth
Developing reference documents or reports for the finalized project
Day-to-day engagement with the various  tech teams across countries
Involved in  project kick-offs, issue management discussions, project reviews and go-live reviews
Manage multiple tasks and dependencies effectively in order to deliver quality, on-time solutions
Competencies:
Strong background in designing and implementing enterprise scale solutions
Ability to excel in a team environment as well as work independently
Good written and verbal communication skills
Strong analytical and problem solving skills
Passion for technology and self- starter
Skills
BS/MS in Computer Science or Information System. Besides that, one needs to have considerable work experience in similar fields.
Experience of 10+ years in data preparation, data gateway and data warehousing projects.
Experience of 8+ years and familiarity in handling all Tableau products (Desktop, Pre,Public, Server, Online, and Reader)
5 to 8 years of experience working with a self-service tool, preferably Tableau/ microstrategy
Have significant experience in Tableau Prep or Microstrategy cubes and data blending.
Familiarity with JavaScript, CSS, and other JavaScript libraries.
Should be familiar and experienced in SQL.
Hands-on experience with implementing technology solutions.  Be comfortable introducing new technologies and new ideas as required.
With GIT and Agile Scrum delivery experience. 
Education:
Bachelor’s/University degree or equivalent experience
-------------------------------------------------
Job Family Group:
Technology
-------------------------------------------------
Job Family:
Data Analytics
------------------------------------------------------
Time Type:
Full time
------------------------------------------------------
Citi is an equal opportunity and affirmative action employer.
Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.
View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.
View the EEO Policy Statement.
View the Pay Transparency Posting",USD 49K - 91K *
288,Data Analytics Associate,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"What makes Gartner a GREAT fit for you?
When you join Gartner, you’ll be part of a fast-growing team that helps the world become smarter and more connected. We’re the leader in our industry, achieving double-digit growth by helping clients make the right decisions with business and technology insights they can’t find anywhere else. Our associates enjoy a collaborative work environment, exceptional training and career development — as well as unlimited growth potential. If you like working with a generous, supportive, high-performing team, Gartner is where you want to be.
About this role
We are looking for a highly analytical and detail-oriented Data Analytics Associate to join our growing analytics team who can collaborate and communicate well with Marketing stakeholders. The person will be responsible for developing key reports & insights to support business decision making and help formulate strategy to position Corporate Marketing as an indispensable force fueling Gartner’s revenue growth.
What you will do
Consult with marketing stakeholders to formulate and frame the business questions in the context of business objectives, gather and vet the relevant data, analyze the trends and patterns, construct story lines that will support impactful / implementable insights to the business stakeholders.
Evolve metrics and support reporting automation and visualization across all Corporate Marketing area.
Perform ad-hoc diagnostic analysis to identify operational challenges and promote best practices throughout the organization.
Build and maintain stakeholder relationships across marketing and IT.
Provide consistent, timely, recurring reporting and analysis
What you’ll need:
Graduation+ degree required.
Strong verbal & written communication
Minimum 1-2 years of experience in sales/marketing data analytics
Demonstrable experience with Advanced Excel is a must.
Demonstrable experience with SQL & Power BI is a must.
Experience with Power Automate – Good to have.
Experience with oracle Eloqua will be preferred
Experience with Python / R Studio preferred.
A successful history of processing and extracting business insights from large, disconnected data sets
Experience applying various analytic techniques (segmentation, regression, forecasting, etc.)
Strong ownership, project management and organizational skills with focus on results / timelines
Experience supporting and working with cross-functional teams in a dynamic environment
#LI-SA2
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:83902
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 30K - 56K *
289,Lead Data Scientist,Freshworks,"Bengaluru, India",Senior-level / Expert,"Company Description
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end user. Headquartered in San Mateo, California, Freshworks has a global team operating from 13 global locations to serve more than 65,000 companies -- from startups to public companies – that rely on Freshworks software-as-a-service to enable a better customer experience (CRM, CX) and employee experience (ITSM). 
Freshworks’ cloud-based software suite includes Freshdesk (omni-channel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshchat (AI-powered bots), supported by Neo, our underlying platform of shared services.
Freshworks is featured in global national press including CNBC, Forbes, Fortune, Bloomberg and has been a BuiltIn Best Place to work in San Francisco and Denver for the last 3 years. Our customer ratings have earned Freshworks products TrustRadius Top Rated Software ratings and G2 Best of Awards for Best Feature Set, Best Value for the Price and Best Relationship. 
Job Description
About the role:
As a Lead Data Scientist with a focus on GenAI (Generative Artificial Intelligence), you will be at the forefront of pioneering innovative applications of data science and machine learning in employee engagement. In this role, you will lead efforts to leverage GenAI techniques to address unique challenges within our company, including building a state of the art conversational servicebot that should scale across a million MAU, developing cutting edge production AI/ML solutions to complex Text2Action problems, time series data to look for anomalous behavior. Imagine the next generation of IT services being offered not via dashboards or clicks or filters but in an interactive, conversational manner, backed by real time analysis of the entire streaming data into an operating center. This vision is what you would make into a reality. You will build algorithms that analyze these millions of streaming data points, build a distributed, scalable, and high-performance system to serve the insights to the customer through a next-gen conversational UI/UX.  
Responsibilities:
Strategic Collaboration: Collaborate closely with product and business teams to gain a comprehensive understanding of the challenges and opportunities within the GenAI landscape, aligning data science initiatives with the organization's objectives.
Metric Definition: Define key performance metrics that accurately reflect the value delivered to end-users through GenAI solutions.
Intelligent System Design: Apply deep expertise in machine learning, statistics, and advanced mathematics to conceptualize, experiment, and design intelligent systems powered by GenAI.
Big Data Processing: Develop efficient systems capable of processing vast volumes of data, demonstrating proficiency in distributed programming frameworks like Hadoop and Spark.
ML/AI Architecture: Collaborate closely with ML Engineers to design scalable systems and model architectures that enable real-time ML/AI services.
End-to-End ML Pipelines: Take ownership of ML pipelines from end to end, encompassing data pre-processing, model generation, cross-validation, and feedback sharing.
Qualifications
Qualifications:
A Bachelor’s degree or higher in Computer Science, Statistics, Mathematics, or a related field, with a minimum of 7 years of relevant work experience.
Strong problem-solving and programming skills, coupled with a profound understanding of the mathematical foundations underpinning machine learning algorithms, including probability, statistics, linear algebra, calculus, and optimization.
Proven track record of successfully deploying ML projects in production systems with substantial individual contributions.
Experience with natural language processing tasks utilizing prompt engineering, LLMs, transformers, and knowledge graphs is highly advantageous. 
Proficiency in time series analysis, NLP, Distributed Systems, large-scale computing, and Big Data technologies such as and Spark is a plus.
A solid background in at least 2 of the following areas: Natural language processing, statistical ML techniques, graph algorithms, constraint optimization, signal processing (speech or vision), deep learning, and distributed systems.
Proficiency with database systems and schema design, encompassing both SQL and NoSQL databases.
If you are a forward-thinking data scientist with a passion for pushing the boundaries of GenAI and envision yourself driving the transformation of IT services through interactive, conversational experiences, we encourage you to apply and join our dynamic team. Your expertise will play a pivotal role in turning our GenAI vision into a reality.
Additional Information
All your information will be kept confidential according to EEO guidelines.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 56K - 172K *
290,AWS  Data Engg Specialist,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Mandatory RequirementOverall 8+ years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR.Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processesMust Have skills : AWS Glue, Databricks (DB), AWS Redshift(SQL DW), AWS Athena, AWS EMR, AWS Kinesis, AWS S3,
AWS RDS(SQL DB), SQLExperience with NoSQL databases such as DynamoDB, Cassandra, MongoDB.Experience in Real-Time Data Processing using AWS Kinesis, AWS IoT, Apache Kafka ,Structured Streaming and Stream analytics.Experience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, DynamoDB, Kafka, AWS Glue, S3, Kinesis.Sound Knowledge on AWS DevOps and CI/CD tools like Jira, Confluence, Bamboo, Bitbucket.Hands on experience in RDBMS like MSSQL,Oracle,Mysql ,Teradata
Qualifications
BE, MS, M.Tech or MCA
Additional Information
Overall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR.",USD 45K - 84K *
291,HR Data Specialist,Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Reports To
AD WFA and HRA APAC

Position Summary:
The WFA Associate works closely with the HR Capability Center team to ensure the integrity of the data entered into the Workday Human Capital Management System (HCM), supporting the growth in India for Bristol Myers Squibb. This position will process new hire transactions, review job change transactions generated from the ATS, and process time off and absence transactions, employee/manager direct access submissions to ensure that all data is accurately actioned on a timely basis. Additionally, this role will be responsible for basic foundational data maintenance including Supervisory organizations, Cost Center assignments, and Position Titles. The Capability Center team will rely on the WFA Associate to complete reports, documents, and forms that require specific data from the HCM system, including People Doc processes.
 Detailed Position Responsibilities:
Maintain and/or approve all data pertaining to employee records (i.e., transfers, personal information, title changes, etc.) that are entered in Workday through Manager or Employee Direct Access.
Complete pending new hire transactions in Workday HCM after the candidate is in Ready to Hire status in the ATS
Support execution of employee movement, employee status, time off and leave absence, payroll, benefits/leaves, Performance Check-ins, and compensation processes, by maintaining the accurate and on time data in Workday, relevant for the above processes
Support the integrity of employee records and Workday data, assuring legal and regulatory compliance.
Maintain supervisory organizations, organization assignments, and position titles in the Workday system
Participate in the review of integration kickout reports from various systems and process updates in Workday based on the identified discrepancies
Participate on ad-hoc projects and perform other duties as assigned.
Directly participate to enhance and improve the content/FAQ/LWI based on the feedback received via case resolution, by collaborating with functional teams to achieve this
Identify and troubleshoot issues and escalate as appropriate
Make process recommendations to achieve operational excellence
Participate in scheduled and ad hoc training or other forms of learning opportunities in order to improve process acumen, and apply the learnings in executing their role, and to develop their own skills as per needed
Work collaboratively within the HR team to share ideas, ownership, and accountability for driving improvements and consistency of execution for key HR processes, across regions and functional areas
Identify and report cases trends or product trends to the management team and Senior WFA and work collaboratively with them or other HR functional teams to improve the HR service we provide to our workforce.
Collaborate with all functional teams in order for People Service to collectively achieve TAT and FLR
Desired Experience & Skills
Must have experiences:
Bachelor’s Degree / equivalent qualification in HR or min of 1 year of working with HRIS/HCM systems
Strong written and verbal communication skills, strong interpersonal skills
Ability to work successfully in a fast paced and continuously changing work environment
Detail oriented with a focus on accuracy and quality
Advanced proficiency with MS Excel and a proven ability to manipulate data and an ability to learn required business systems
Ability to learn quickly and apply knowledge effectively
Collaborates effectively in a team environment
Ideal Candidates Would Also Have:
Knowledge of Workday
Language requirements beyond English: Fluent in other languages would be an advantage
Experience working within an HR Shared Services delivery model
Have worked in a multi-cultural/multi-country work environment
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 70K - 109K *
292,Senior Analyst-Data Analysis,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
Calculate and analyse commercial income using latest Business Intelligence tools; data modelling techniques and Commercial Retail Calculations expertise. Work with Technology & Finance ensure accurate commercial income invoicing. Work across all functions irrespective of geography to support to define and solve business problems using Big data & Teradata
-Operates promotion funding invoicing solution operations consisting of Calculation engine; Audit Engine & VBA
-Draw Entity Relationship diagrams by exploring & mining data required for Solution building & analysis
-Monitor the databases and tables containing supporting Entity Relationship data
-Assist in Designing the Data modelling; Data engineering & work flow automations
-Continuously Audit the data from different sources and using analytics to detect leakages & flaws in the Engines
-Detect; Investigate & Troubleshoots issues in the data model solutions & automations and provide detailed analysis
-Validate Tables data; Promotion Agreement Funding Tool for inaccuracies and missing data to ensure accuracy
-First Level Support for all the inbound Commercial income calculations and Analysts queries & disputes
-Solves complex operational problems by analysing solution alternatives
-Functional: Accurate Weekly and Ad hoc Promotion funding calculations
-Functional: Monitors the Team Generic mailbox; allocates work & ensure operational SLA TAT is met
-Process mentoring; on the job training; coordinating and presenting
-Maintain relationships with multiple partners; handle partner concerns within process
-Responsible for constantly updated process documentation and compliance in execution
-Following our Business Code of Conduct and always acting with integrity and due diligence
-Knows and applies fundamental work theories/concepts/processes in own areas of work
- Understands business needs and in depth understanding of Tesco processes
- Builds on Tesco processes and knowledge by applying CI tools and techniques.
- Responsible for completing tasks and transactions within agreed KPI's
- Solves problems by analyzing solution alternatives
Qualifications
Programming language for Tech Roles: VBA; Python; Linux/Unix Commands
Data Technology – SQL; ERD; Data warehousing in Teradata; Hadoop; Hive
Functional: Expert in Accounts Receivable calculation processes in an International Retailer
Proven ability to work creatively; numerically and analytically in a problem-solving environment
Business Process knowledge in the Retail Industry
Additional Information
Last Date of Application-3rd Jan2024
 Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
293,Data Analyst,S&P Global,IN - BANGALORE WHITEFIELD ROAD,Entry-level / Junior,"About the Role:
Grade Level (for internal use):
08
The Role: Data Analyst
The Team: You will be part of the Data Team, which deals with the collection, processing, and analysis of data from the energy and agriculture industries. The team provides and maintains accurate, complete, and timely datasets, taking into account the global interests and needs of business units internally and externally. 
The Impact: We provide the highest quality content that is essential for our clients to make decisions with conviction. As a Data Analyst, you will use our internal tools to support the integrity and comprehensiveness of the data set obtained from internal and external public research sources, such as government and regulatory documents, industry journals, and analyst reports.
Responsibilities:
• Work with SQL and Python tools to solve problems and ensure database quality
• Collecting, analyzing, extracting, and entering high-quality data (financial and non-financial data) into work tools in accordance with the guidelines' criteria
• Filter Data by reviewing reports and performance indicators to identify and correct code problems
• Have a solid working understanding of the processes, the dataset's operation, and the available work tools
• Providing input and ideas for new collection methods and product enhancements related to the dataset
• Achieve predetermined individual and team objectives, including providing results at the highest level.
What We’re Looking For:
• Bachelor’s degree in information technologies, computer science or equivalent
• A drive to learn and master new technologies and techniques
• Strong mathematical & numeracy skills.
• Strong analytical and communication skills
• Good understanding of Python and SQL languages
• Intermediate understanding of databases such as SQL Server or Snowflake
• Understanding of reporting & data visualization tools such as PowerBI and Tableau.
• Understanding of ETL framework and ETL tools (e.g. Alteryx)
• Problem-solving skills
• Strong attention to detail
• Ability to work in an agile team environment
Flexible Working: We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.  
Return to Work: Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.
About S&P Global Commodity Insights
At S&P Global Commodity Insights, our complete view of global energy and commodities markets enables our customers to make decisions with conviction and create long-term, sustainable value.
We’re a trusted connector that brings together thought leaders, market participants, governments, and regulators to co-create solutions that lead to progress. Vital to navigating Energy Transition, S&P Global Commodity Insights’ coverage includes oil and gas, power, chemicals, metals, agriculture and shipping.
S&P Global Commodity Insights is a division of S&P Global (NYSE: SPGI). S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit http://www.spglobal.com/commodity-insights.
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 -----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
ANLYTC203 - Entry Professional (EEO Job Group)",USD 53K - 94K *
294,Staff Data Engineer,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Perform market research to find global or individual market opportunities for implementing new solutions or add features to existing solutions.
Be able to compare multiple solutions and create a detailed solution analysis report from a functionality perspective.
Create an end to end business case with required validations performed, create prioritization framework for the list of business cases and checklists for business case submission (market revenue, new user growth, compliance, competency etc.)
Come up with a solution design including design mockups, RACI matric based on the product requirements, initial sizing, dependencies and feasibility assessment.
Collaborate with the engineering team to come up with effort estimates, detailed implementation plans with regular milestones releases
Be able to perform data quality checks on the solution being built
Take lead in setting up discussion with clients/regional leads for feedback, legal review and socialize with regions.
Work in collaboration with the Engineering leads to define a MVP version, Risk assessment, Initial GTM plan, UAT with end users, Internal demos and commercialization strategies.
Define performance measuring metrics, FAQ’s, user guide, define end user personas and key use cases.
Lead the Go-To-Market activities to make the solution ready for market, create sales pitch/market campaign activities, user support/training, artefacts for sales enablement and create pricing updates or new price sheets.
Own the solution enhancement process by collating the end user feedback, enhancement requests, prioritization exercises with internal and external stakeholders and plan ongoing maintenance from a business perspective
Define and own the product roadmap by creating a long term roadmap with quarterly planned short term goals with monthly review of roadmap for updates, product release calendar, etc.
Lead a 2-3 member team of Data, scientists and visualization engineers to implement the solution following the agile methodology.
Regularly monitor the solution usage, create usage reports and collect necessary information to retire the solution or identify enhancements to the solution to increase the usage
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
• 8+ years successful post college product or business experience. Masters/MBA degree is a plus.
• 3-5 years combined experience in product and building data solutions, with preferably 2-3 years in payment systems and/or financial services.
• Good business acumen to orient data analysis to business needs of clients and key stakeholders.
• Ability to translate data and technical concepts into requirements documents, business cases and user stories.
• Ability to write SQL or PySpark codes to perform both frontend and backend data validations.
• Experience working with technology teams using Agile methodologies to drive product development and delivery
• Ability to work some flexible hours due to varying time zones across Visa’s regions. We are a global product.
• Ability to work cross-functionally and influence decisions and actions without complete authority over the teams.
• Good communication and presentation skills with ability to interact with different cross-functional team members at varying levels
• Ability to prioritize, manage and deliver on multiple projects simultaneously - highly motived and able to work against aggressive schedules
• Experience gathering the ‘voice of customer’ and translating it into product feature requirements
• Superior analytical and problem-solving skills to synthesize and communicate complex information effectively
• Ability to set the vision, strategy, define success metrics and make decisions around product growth
• Skill to dissect a data file, read file specs and author both technical documentation and marketing collateral
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
295,Data Scientists 2024,Bosch Group,"Coimbatore, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Design and develop algorithms to perform various analysis with datasets.
Research for new possibilities/ideas to improve the various analytics we perform as per customer requirements.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to datasets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Required Skills
Strong knowledge in Digital signal processing concepts and Algorithm development.
Strong analytical and problem-solving skills.
Strong mathematical and statistical background.
Experience using statistical computer languages like R, Python, etc.to manipulate data and draw insights from large data sets.
Strong knowledge in PySpark, IMPALA & Tableau
Experience working with and creating data architectures.
Good in conventional SQL skills
In depth knowledge about Data Storage technologies withfocus on Apache Hadoop Cluster Systems.
Working knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Working knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Good communication skills, interpersonal skills and ability to work independently on problems.
Fast learner withability to adapt to changing requirements and provide solutions.
Being an effective team player and willing to accept challenges and responsibilities.
QualificationsBachelor's or master's degree in Computer Science, Electronics, Electrical, Digital Signal Processing or in a similar discipline.
Qualifications
M.E/M.Tech
Additional Information
4+ years of experience",USD 136K - 205K *
296,Operations Specialist (Data Quality Managment-4),Deutsche Bank,"Bengaluru, Velankani Tech Park",Executive-level / Director,"Job Description:
Job Title - Data Analyst, AS
Location – Bangalore, India
Role Description
Today, markets face a whole new set of pressures – but also a whole lot of opportunity too. Opportunity to innovate differently. Opportunity to invest responsibly. And opportunity to make change.
Join us at DWS, and you can be part of an industry-leading firm with a global presence. You can lead ambitious opportunities and shape the future of investing. You can support our clients, local communities, and the environment.
We’re looking for creative thinkers and innovators to join us as the world continues to transform. As whole markets change, one thing remains clear; our people always work together to capture the opportunities of tomorrow. That’s why we are ‘Investors for a new now’.
As investors on behalf of our clients, it is our role to find investment solutions. Ensuring the best possible foundation for our clients’ financial future. And in return, we’ll give you the support and platform to develop new skills, make an impact and work alongside some of the industry’s greatest thought leaders. This is your chance to achieve your goals and lead an extraordinary career.
This is your chance to invest in your future.
The COO Division is a key enabler for DWS and is integral to the future success of the company by delivering world-class services across a set of key functions. It covers essential Technology and Operations capabilities, including our data programs and digital transformation. The COO aims to deliver a platform which is efficient, scalable, resilient and agile.
Within the COO Division Data Management is responsible for designing and driving the execution of the data strategy at Group and Divisional/functional level as well as coordinating adherence to Data related processes and policies and any applicable local regulations.
What we’ll offer you
As part of our flexible scheme, here are just some of the benefits that you’ll enjoy
Best in class leave policy
Gender neutral parental leaves
100% reimbursement under childcare assistance benefit (gender neutral)
Sponsorship for Industry relevant certifications and education
Employee Assistance Program for you and your family members
Comprehensive Hospitalization Insurance for you and your dependents
Accident and Term life Insurance
Complementary Health screening for 35 yrs. and above
Your key responsibilities
As a Data Quality Management Analyst you will
Ensure adequate data quality controls so that data can effectively support business processes
Ensure data activities are in line with DWS’s Data Management framework and operational activities are aligned to the target state of data quality standards
Conducting the monitoring and reporting on data quality levels to impacted stakeholders and engaging with business and leadership to quantify and articulate the business impact of data quality issues and identify and track remediation plans
Ensuring adequacy of data sharing, access, retention and disposal for area of accountability, in accordance to DWS’s defined processes
Assessing the current state of data quality to impacted stakeholders and engaging with business and leadership on remediation plans
Establishing target goals for data quality improvement and identify optimal approaches for resolving data quality issues to achieve targets
Ensuring adequacy of data sharing, access, retention and disposal for area of accountability, in accordance to defined processes
Your skills and experience
Proven experience in data quality management concepts in a global financial services environment
Ability to collaborate effectively with cross-functional teams
Strong analytical skills utilising tools including as SQL/Excel with experience of creating reports and dealing with large volumes of data
Expertise of managing data and processes in a global enterprise environment with an understanding of database and schema design
Strong conceptual and problem-solving skills, with an ability to develop creative and structured solutions
Degree educated in a science or quantitative finance discipline
How we’ll support you
Training and development to help you excel in your career
Coaching and support from experts in your team
A culture of continuous learning to aid progression
A range of flexible benefits that you can tailor to suit your needs
About us and our teams
Please visit our company website for further information:
https://www.db.com/company/company.htm
Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.
Visit Inside Deutsche Bank to discover more about the culture of Deutsche Bank including Diversity, Equity & Inclusion, Leadership, Learning, Future of Work and more besides.",USD 49K - 91K *
297,"Mgr, Machine Learning Engrg Mgmt",ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
8+ years of related experience with a Bachelor's degree; or 6 years and a Master's degree; or a PhD with 3 years' experience; or equivalent work experience
A minimum of 1-2 years of management experience, proficiency in providing feedback to work group strategies, policies and plans
Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms
Experience building new products that use challenging algorithms
Expertise in coding efficient, object-oriented, modularized and quality software
Knowledge of core AI/ML techniques and algorithms
Knowledge of unit testing, profiling, and code tuning
 Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
298,Manager (DB/ETL),dentsu international,"Thane, India",Mid-level / Intermediate,"Company Description
Merkle, a dentsu company, is a leading data-driven customer experience management enterprise specializing in delivering unique, personalized customer experiences across platforms and devices. With over 30 years of experience, Merkle partners with Fortune 1000 companies and non-profit organizations to optimize their customer portfolios. Its expertise in data, technology, and analytics enables it to gain insights into consumer behavior, driving hyper-personalized marketing strategies. Merkle's consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions capabilities combine to drive improved marketing results and a competitive edge. With over 14,000 employees, Merkle is headquartered in Columbia, Maryland, with more than 50 additional offices worldwide. Its innovative solutions enable brands to build meaningful customer relationships and enhanced customer experience.
Job Description
Experience : 8 to 12 Years
Must Have Skills : 
Database (Oracle / SQL / Teradata / Redshift / Big query etc)
SQL / PL SQL query writing
ETL tool (Talend or Informatica or any one ETL tool)
Python and UNIX shell scripting
Tidal (any scheduling tool), Matillion (ETL)
Stakeholder Management
Good communication skills
Good to Have Skills : 
MS Office, Client-facing skills
Databricks
Snowflake DB / RedShift
Cloud computing (one or more of AWS, Azure, GCP)
Roles & Responsibilities : 
Play solo role which requires coding being part of internal product team
Design simple to medium processes for clients
Work on Data warehousing, data mart, databases, and data ingestion and transformation
Opportunity to be on a learning part to be a Data Engineer
Use DB skills (Oracle, SQL server, Teradata, Vertica, redshift, Big query, Azure DW etc)
Collaborate with local leadership as well as our global teams to build best in class solutions.
Provide full support to Client, Data Scientists and Analytical Consultants working on marketing solution
Will work on Unix scripting &/or Python as well as ETL (Training will be provided for ETL such as Talend)
Cross functional team work internally and with external clients
Code management systems which includes code review and deployment",USD 30K - 56K *
299,Data Engineer 3,Amadeus,Bengaluru,Mid-level / Intermediate,"Job Title
Data Engineer 3
Key responsibilities
 Design, implement, deploy, and maintain data marts, ETL (extract, transform, load) processes and systems. A.k.a. as our assets.
 Ensure the reliability, scalability, and performance of our data assets.
 Design and maintain quality indicators as well as the corresponding monitoring and alerting means.
 Troubleshoot and document issues respecting Amadeus standards.
 Continuous improvement mindset applied to data related issues, systems, and processes.
 Technical and expertise awareness to keep up with industry standards, security recommendations and best practices within Offer organization.
About the ideal candidate:
 Hands-on experience writing Production quality code in Scala (preferred) or PySpark or Java.
 Hands-on experience on big data technologies, including the mapr filesystem, Apache Spark, Hadoop, Kafka & Impala.
 Proven experience with the Apache Spark Architecture and components.
 Hands-on experience on scripting languages including Bash scripting and Python.
 Knowing different kinds of database technologies, including of course SQL.
 Previous work with no-SQL databases, like MongoDB will be a plus.
 Solid knowledge of build tools and in particular Maven and SBT.
 Experience on building and maintaining DevOps pipelines will be a plus.
 Familiarity with analytics platforms like Tableau will be a plus.
Cloud:
Familiarity with Azure cloud technologies.
Familiarity with Azure Databricks and Databricks SQL.
Familiarity with Snowflake Data Cloud will be a plus.
Qualifications
Education: University degree in computer science or related field or relevant experience
Professional experience of 2 – 9 Yrs
Proven track record of experience working in data engineering domain.
Strong experience defining ETL processes.
Experience with data modeling and data visualization concepts and tools.
Knowledge of Software Design under Agile frameworks (Scrum, Kanban, SAFe, …).
Proven experience on design and maintaining applications using Scala, (Py)Spark, MAPR distribution, Hadoop ecosystem, Kafka, Impala.
Hands-on experience on Microsoft Azure, Databricks.
Other:
Good English verbal and written communication skills
Strong team player with collaborative mindset
Excellent problem-solving and analytical skills.
Fast, thorough, and autonomous learner who also understands prioritization
Innovative thinker
Ability to maintain a proactive and positive attitude in a fast paced, changing environment
Thrives in a multi-cultural, global organization
Open-minded, should be able to adapt to working in a multi-cultural team atmosphere
Flexible to adapt to changing project needs driven by the customers
Ability to think out of the box, develop tools to enhance productivity
What we can offer you:
The opportunity to work for one of the world’s top leading travel tech companies; a company that originated in technology innovation and sees the world with a technology-first perspective
Skills development and opportunities to try new ideas
A global diverse work environment
Diversity & Inclusion
We are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.",USD 110K - 180K *
300,Robotics Intern,HAMMOQ,"Indore, India",Entry-level / Junior,"Job Description
Responsibilities:
Design and Development: Conceptualize, design, and develop robotics systems with a specific emphasis on motors, conveyors, and camera integration.
Motorized Systems: Select, integrate, and optimize various types of motors and actuators for efficient robotic movements and operations.
Conveyor Systems: Design, implement, and troubleshoot conveyor systems for material handling and process optimization within robotic setups.
Camera Integration: Integrate and configure camera systems for vision-based applications in robotics, including object recognition, tracking, and navigation.
Programming and Control: Develop control algorithms and software interfaces to synchronize motors, conveyors, and cameras for seamless operation.
Testing and Validation: Conduct rigorous testing, analysis, and validation of robotics systems to ensure functionality, reliability, and safety.
Collaboration: Collaborate with cross-functional teams including mechanical engineers, software developers, and quality assurance to achieve project objectives.
Documentation and Reporting: Create comprehensive documentation, reports, and manuals for developed systems and provide regular progress updates.
Qualifications
 Bachelor's/Master's degree in Robotics, Mechanical Engineering, Electrical Engineering, or a related field.
2 years of experience (specific to the level of the position - junior, mid-level, senior) in robotics development and implementation.
Proficiency in motor selection, control systems, and programming (C/C++, Python, etc.).
Hands-on experience with conveyor systems design, implementation, and optimization.
In-depth knowledge of camera systems, computer vision, and image processing.
Strong problem-solving skills and the ability to troubleshoot complex robotic systems.
Experience with robotic simulation software (such as ROS, Gazebo, etc.) is a plus.
Excellent communication skills and ability to work effectively in a team environment.
Preferred Qualifications:
Experience with industrial robotics or automation projects.
Familiarity with machine learning and AI techniques for robotics applications.
Knowledge of safety standards and protocols in robotics.
Additional Information
Benefits:
Competitive salary and benefits package.
Opportunities for professional growth and development.
Work in a collaborative and innovative environment at the forefront of robotics technology.",None
301,Software Development Engineer II - Big Data,Groupon,Bengaluru (Gopalan Axis SEZ),Mid-level / Intermediate,"Grow as a developer by building things that help local businesses around the world thrive
Are you a passionate, energetic and technology enthusiast eager to work at a rapid pace with the flexibility to work across our suite of technologies? Are you a problem solver; someone who enjoys debugging code, resolving issues, and creating solutions for common problems?
Groupon is an experiences marketplace that brings people more ways to get the most out of their city or wherever they may be. By enabling real-time mobile commerce across local businesses, live events and travel destinations, Groupon helps people find and discover experiences––big and small, new and familiar––that make for a full, fun and rewarding life. Groupon helps local businesses grow and strengthen customer relationships––resulting in strong, vibrant communities. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success.
As a global company that works with both local businesses and consumers, Groupon has a wealth of data, which is stored and processed on our ever-evolving data platform. Parsing and analyzing vast amounts of data is a centrally meaningful part of Groupon’s business: it helps us gain better insights into our customers’ needs as well as understand our own processes and identify ways in which we can improve. Our Data Pipeline is the heart of this system and we are looking for someone to join us and help us shape the growth of this business-critical function.
For this specific role, you’d be joining a team of like minded engineers on a follow the sun model. You will be contributing to all aspects of an agile software development life cycle including design, architecture, coding, documentation, testing and operations. Supporting data pipeline operations globally while defining your own development roadmap to automate and simplify your work. You’ll also build and improve the cloud infrastructure supporting the global data pipelines. You’ll be able to build tools and services to enhance monitoring & observability of global data pipelines and also to detect and provide early warning, self healing systems over Data Pipelines to improve and streamline operations. In this role, you will own and improve the data infrastructure supporting the global data and ingestion pipelines.
You’ll spend time on the following:
Proactively manage delivery of service level objectives for Data Pipelines and related Systems
Implement early warning, detection and self healing systems
Designing and implementing tools to optimize processes and simplify your work
Reduce toil and support requests, make the platform easy to use.
Collaborate with teams to troubleshoot issues and propose solutions
Actively contribute to the adoption of strong software architecture, development best practices, and new technologies. We are always improving the process of building software; we need you to help contribute.
Work closely with other engineers within your group and across the product  and engineering organization to identify problems and build effective technical solutions.
Seek maximum cost efficiency out of the Cloud platforms
Facilitate emergency and Incident response
Be part of a follow the sun model to ensure Data Pipelines and Infrastructure reliability
We’re excited about you if you have:
Having 3+ years of hands-on experience with all aspects of design, developing, testing, and implementing ETL solutions.
Software development experience in a major language (Java/Python/Scala)
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Demonstrable full lifecycle ownership (development, testing, deployment, operations).
Strong knowledge of SQL and data warehousing concepts
Deep understanding of Linux/Unix Operating systems
Experience with any scheduling tools such as Airflow, Control-M, Opswise, Job scheduler etc. is a plus.
Experience in ETL Development & Support.
Excellent troubleshooting and problem-solving skills.
Desire to troubleshoot problems and automate solutions.
Work with big data and distributed systems using technologies such as Hadoop, Hive and Spark.
Knowledge of cloud platforms such as AWS and GCP is a plus.
Experience with Terraform is a plus.
Work in a fast paced environment and collaborate with multiple teams.
We value engineers who are:
Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward.
Obsessed with Quality: Your Production code Just Works & scales linearly
Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve.
Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems.
Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability.
Owners: Engineers at Groupon know how to positively impact the business.
Beware of Fraudulent Offers
We would like to bring to your notice that Groupon follows a merit-based employee recruitment practice with extensive screening steps. Groupon does not charge/accept any amount or security deposit from job seekers during the recruitment process. It was observed that there has been an increase in recruitment fraud involving scammers who post fraudulent job openings, or who contact job-seekers with fake job offers. These individuals sometimes even conduct fraudulent interviews with an attempt to obtain personal information or money from the applicants. We have also noticed that certain individuals claiming to be from the Groupon Talent Acquisition function are contacting prospective candidates pretending to represent Groupon with job offers. In case you or any candidate receives any unsolicited or fraudulent communication regarding a job offer or an interview call against payment of money, please stay alert and recognize it as a scam. We are not liable for any loss or damage incurred as a result of dealing with such entities. To prevent falling victim to the same, please visit grouponcareers.com to verify the job opening. All our genuine job openings are posted on the official Groupon careers website. 
Groupon’s purpose is to build strong communities through thriving small businesses. To learn more about the world’s largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don’t take our word for it. Hear from real Groupon team members and learn more about our inclusive employee groups. If all of this sounds like something that’s a great fit for you, then click apply and let’s see where this takes us.",USD 30K - 56K *
302,Robotics Engineer,HAMMOQ,"Indore, India",Entry-level / Junior,"Company Description
HAMMOQ is leading the resale revolution with advanced AI Automation — our innovative Sorting, Photography, and Listing solutions automate tasks, optimize workflows, and drive revenue growth. Our solution helps clients unleash the true potential of their resale operation.
Job Description
As a Robotics Systems Engineer, you will play a key role in the design, development, and implementation of cutting-edge robotics systems. Your primary focus will be on motors, conveyors, and camera integration, ensuring seamless operation and optimal performance. Collaborating with cross-functional teams, you will contribute to the advancement of robotics technology and be at the forefront of innovation.
Responsibilities:
Design and Development: Conceptualize, design, and develop robotics systems, emphasizing motors, conveyors, and camera integration.
Motorized Systems: Select, integrate, and optimize various types of motors and actuators for efficient robotic movements and operations.
Conveyor Systems: Design, implement, and troubleshoot conveyor systems for material handling and process optimization within robotic setups.
Camera Integration: Integrate and configure camera systems for vision-based applications, including object recognition, tracking, and navigation.
Programming and Control: Develop control algorithms and software interfaces to synchronize motors, conveyors, and cameras for seamless operation.
Testing and Validation: Conduct rigorous testing, analysis, and validation of robotics systems to ensure functionality, reliability, and safety.
Collaboration: Collaborate with cross-functional teams, including mechanical engineers, software developers, and quality assurance, to achieve project objectives.
Documentation and Reporting: Create comprehensive documentation, reports, and manuals for developed systems and provide regular progress updates.
Qualifications
Bachelor's/Master's degree in Robotics, Mechanical Engineering, Electrical Engineering, or a related field.
1+ years of experience (level-dependent) in robotics development and implementation.
Proficiency in motor selection, control systems, and programming (C/C++, Python, etc.).
Hands-on experience with conveyor systems design, implementation, and optimization.
In-depth knowledge of camera systems, computer vision, and image processing.
Strong problem-solving skills and the ability to troubleshoot complex robotic systems.
Experience with robotic simulation software (such as ROS, Gazebo, etc.) is a plus.
Excellent communication skills and ability to work effectively in a team environment.
Preferred Qualifications:
Experience with industrial robotics or automation projects.
Familiarity with machine learning and AI techniques for robotics applications.
Knowledge of safety standards and protocols in robotics.
Additional Information
Benefits:
Competitive salary and benefits package.
Opportunities for professional growth and development.
Work in a collaborative and innovative environment at the forefront of robotics technology.",USD 22K - 42K *
303,SystemTester AutonomousDriving EXM 2024,Bosch Group,"Bengaluru:, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Job Description:Mandatory Skills set:
Experience with ADAS feature testing in ADAS embedded domain
Should possess very good skills in Black box and White box testing
Experience in creating test design, Test spec & test case preparation and testing methodologies
Experienced in Verification and Validation, Software In Loop (SIL)
Experience in Functional, regression and System testing. Unit and Integration testing experience is an added advantage
Exposure and Handling of Defects through Bug life cycle.
Good Knowledge in C/C++, Perl, CAPL and Python and its usage in automotive embedded area
Excellent communication and problem solving skills
Good organizational skills and detail-oriented mindset
Experience with agile development & Testing (SCRUM, KANBAN or scaled versions in Agile)
Work Experience in Requirement & Configuration Management tools - DOORs, Bitbucket, ALM, RQM, JIRA
Work Experience in VTD/ CarMaker/CARLA/SUMO/LabCAR or any similar Simulation Environment is must
Good knowledge on ASPICE
Good communication skills and ability to interface with stake holders
Responsibilities:
Reviewing of software/System requirements and designing of test scenarios.
Executing tests, Analyzing test results on impacts, usability of Software and errors or bugs
Preparing reports on all aspects related to the software testing carried out and reporting to the SW Development team.
Analyzing product requirements with Requirement Engineers/ SW Dev Team
Participating in design reviews and providing input on requirements, product design, and potential problems
Added advantage skills:
Working experience in Embedded Automotive System/SW Testing & Test Automation Test Experience in HIL/ Debugger testing/ Environmental Testing / EMC Test/ Network Protocol Testing
Automotive Test Tools (e.g.: Vector CANoe, CANape, CANstress, vFlash , Debugger (UDE) etc
Test Automation Tools/ Platforms like vTestStudio, Jenkins, Data Visualization (Power Bi) etc
Experience in Automotive Communication Protocols (CAN, CAN-FD, FlexRay & Ethernet)
Experience in Flashing / Reprogramming/ FBL Testing
Hands on experience in Automotive Safety Standards (ISO26262)
ISTQB FL/AL certifications will be an added advantage, but ISTQB foundation Level testing knowledge is must
Qualifications
Candidate with B.E/B.Tech degree in Computer Science, Electronics Communication, Electrical Engineering, Instrumentation
Additional Information
6 to 8 years",USD 45K - 84K *
304,Senior Data Engineer,Swiss Re,"Bengaluru, KA, IN",Senior-level / Expert,"Corporate Title: Vice President 
Division: CCR-Group Data Services (51002466)
Department: CCRI-Data Corpus & Foundation (50005489)
Recruiter: Sidharth Khanna
Hiring Manager: Rahul Bakhshi
Copy the below link to share this job posting with your coworkers:
https://performancemanager.successfactors.eu/sf/jobreq?jobId=127902&company=SwissRe 
  About the Master Data Management (MDM) Team 
  • We are a team of expert business analysts and software engineers, spread across multiple locations around the globe, driving the MDM function at Swiss Re. 
• We are responsible for driving all stages of software development including business analysis, solution design, application architecture, development, testing, roll-out and operational platform management for nearly 1000 master and reference data sets.  • We are the main contact for our internal clients and business partners for the MDM processes, technology platform and knowledge. 
  
About the Role 
 
•    The role requires a hands-on Tibco EBX developer.  
•    Support software releases, coordination of user testing and trainings.  
•    Ensure smooth collaboration with business requestors and other MDM engineers 
•    Keep up to date on emerging technology trends, standards and tools in areas relevant to MDM; and present new solutions and advise the business on value of the proposition. 
•    You would be working with internal business partners across the globe to analyse their business processes and requirements and translate them into functional and technical specifications, for the development team. 
•    Collaborating with various partners to define new processes, develop data models, drive the information governance frameworks and improve data quality. 
•    You will be required to own and handle incidents, problems and change requests for the data assets under your ownership. 
 
 
About You 
 
•    If you are an experienced Tibco EBX Developer who is passionate about working with new technologies and finding optimal solutions for demanding situations we would like to speak to you about joining our dynamic, customer centric team and brand new on site team. 
•    You have a master's or bachelor's degree in information management, computer science, business administration or equal. 
•    Over 5-7 years of working experience as Software Engineer, preferably in a data function (MDM, Data-Warehouse, Data Governance, Meta-Data, Data Catalog etc.). 
•    Marvellous social skills and a good grasp of the English language (spoken and written). 
•    Problem solving comes naturally to you. With your outstanding analytical skills, you consider multiple dimensions and perspectives before arriving at the most optimum solutions to the challenge at hand. 
•    Proficient in navigating databases to perform data analysis, data profiling and good data modelling expertise. Working experience with UI/UX design, data integration, using ETL/batch jobs and Web Services (REST/SOAP) is a bonus. 
•    A phenomenal teammate, with experience working in an agile software development environment (SCRUM). 
    About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127902 
   ",USD 121K - 186K *
305,Master Data Management Specialist,Burckhardt Compression,"Pune, MH, IN",Mid-level / Intermediate,"Career Opportunity with Burckhardt Compression
  We are seeking motivated and experienced professional who can effectively contribute to the role deliverables connected with position below. In this position you can actively participate to our growth and make a significant impact in a fast-paced environment as;
  Position:   Master Data Management Specialist
  Location:  Pune
  Your contributions to organisation's growth
Creation of material codes for the need of customer projects after Engineering defined technical characteristics
Data quality and consistency checks on the received inputs
Upon receipt of a material creation verification of a standard catalogue item or ""better"" alternative
Accessory tasks functional to the completion of activities to lead to procurement: linking of materials to projects, initiation of purchase requisition, updates of specifications with actual material codes, storing of supplier documents when needed to describe the material
Update of material codes periodically or along the duration of the project (example: weight when determined)
On request creation and maintenance of project material codes
Creation of Bills of Materials where applicable
Creation and Maintenance of material templates
Creation and Maintenance of material catalogues in line with defined strategies
    Expertise you have to bring in along with
Mechanical, electrical or I&C diploma or degree
2+ year experience similar role in Industry
Experience in an industrial environment preferably in a projects driven business
Has established relevant experience in SAP handling as in other business software using material codes (eg CAD, ERPs, NX)
    We Offer
We have a very free culture, inspiring employees to involve in various activities of their interests.
Our flexible working models will allow you to combine private interests with work
Employee Connect, Engagement events and feedback culture enhances our reach and gives us an opportunity to continuously improve.
Performance and appreciation awards
Sports activities and Klib Library to energize you.
We proudly do encourage diversity and inclusion in thoughts and in spirit.
A winner of GreenCo Gold and other various ISO certifications, we encourage you to inhibit the same to contribute in a much greener tomorrow!
We do aspire to be Great Place to Work soon to provide you an enticing career with us. 
  HR Team
Burckhardt Compression India
      Burckhardt Compression creates leading compression solutions for a sustainable energy future and the long-term success of its customers. The Group is the only global manufacturer that covers a full range of reciprocating compressor technologies and services. Since 1844, its passionate, customer-oriented and solution-driven workforce has set the benchmark in the gas compression industry.
 ",USD 30K - 56K *
306,Senior Gen-AI Data Scientist,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
The ideal candidate will have a strong background in artificial intelligence, machine learning, natural language processing, deep learning, image recognition, and computer vision, with the ability to apply all these skills, in service of creating Innovative and Immersive Experiences, that leverage AI and Gen-AI, to revolutionize how brands engage with consumers.
• You should have deep hands-on experience with large language models (LLMs) and other generative AI techniques.
• You will be responsible for fine-tuning existing Foundation Models, and adapting existing base ML models.
• More importantly, you will also be responsible for coding, training, evaluating, and deploying net-new custom ML models using large datasets, helping create custom AI models for specific use cases, for different dentsu clients and brands.
• You must have deep experience of developing and implementing cutting-edge generative AI models and algorithms using state-of-the-art techniques such as GPT, VAE, and GANs.
• You must have deep technical experience working with technologies related to multimodal AI, covering text, media, image, video, audio and speech.
• Your role will also involve optimizing existing models for improved performance, scalability, and efficiency.
• You will be responsible for hands-on development in Python and PyTorch, across a variety of AI / ML frameworks, AI Cloud Services, and Gen-AI platforms, including enterprise Gen-AI tech, open-source Gen-AI tech and SaaS Gen-AI tech.
Responsibilities:
•Collaborate with client teams and stakeholders to understand their requirements and devise Gen AI models to meet these needs.
•Design, develop, and deploy custom ML models for Gen-AI solutions
•Implement MLOps to automate the deployment, monitoring, and maintenance of ML models.
•Hands-on coding to develop AI / ML solutions from scratch
•Build end-to-end data pipelines to manage data collection, extraction, pre-processing, cleansing, transformation, processing, and use inside custom built Gen-AI models
•Stay informed about the latest advancements in Gen AI, machine learning, and AI technologies to optimize our technical stack.
•Have solid knowledge and exposure across Enterprise Gen-AI Platforms and Solutions, as well as Third-party SaaS and Open Source tech leaders / providers in the Gen-AI space
•Work through the complete lifecycle of Gen AI model development, from training and testing to deployment and performance monitoring.
•Lead R&D initiatives involving Gen-AI Platforms and Services, Large Language Models and existing generative AI systems
Qualifications
Key Requirements
•8+ years of overall experience in technology.
•Minimum 5+ years of overall experience in AL and ML solutions development.
•Bachelors degree in computer science, AI, Machine Learning, or related field.
•Solid understanding of Generative AI, Machine Learning, and Deep Learning algorithms, Software engineering principles
•Super hands-on with ML programming languages such as Python
•Experience with related machine learning platforms, libraries and frameworks like PyTorch, PySpark, TensorFlow, Keras, or similar with CUDA
•Experience with natural language processing (NLP) patterns such as Text representation, Embeddings, Language Modelling, and Semantic understanding
•Experience with libraries such as SpaCy, NLTK, or Stanford CoreNLP
•Experience with large language models such as GPT-4, Google PalM-2, and nVidia NeMO.
•Experience with Vector Databases for custom data and retrieval
•Strong Proficiency in AI Orchestration frameworks such as Langchain and/or Microsoft Semantic Kernel
•Prompt Engineering for implementing large language models
•Strong Proficiency in at least 1 major Cloud AI Platform / Service, and all of their primary AI services and solutions, across Azure, AWS, and Google Cloud.
•Strong Proficiency in working with an AI Cloud Service such as Azure Machine Learning, AWS Sagemaker, or Google Vertex-AI
•Strong Proficiency in being able to code and deploy custom AI / ML models on top of AI Cloud platforms such as Azure OpenAI, AWS Sagemaker/Bedrock
•Experience with and exposure to nVidia AI Cloud Foundation Service, nVidia NeMo LLM frameworks, nVidia Picasso, and other nVidia services / solutions, highly desirable
•Exceptional problem-solving skills and an innovative mindset.",USD 136K - 205K *
307,"Senior Data Engineer, e-commerce solutions-1",Mastercard,"Gurgaon, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer, e-commerce solutions-1
Senior Data Engineer, e-commerce solutions
Overview

Data and Analytics team build internal analytic partnerships, strengthening focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market strategies.
• Are you excited about Data Assets and the value they bring to an organization?
• Are you an evangelist for data driven decision making?
• Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across 6 continents?
• Are you interested in proactively looking to improve data driven decisions for a global corporation?

The ideal candidate has a knack for seeing solutions in sprawling data sets and the business mindset to convert insights into strategic opportunities for our company.

Role
• Work closely with global analytics teams to architect, develop, and maintain advanced reporting solutions on large volumes of data to support analytics and reporting needs across products, markets, and services.
• Translate business requirements into tangible solution specifications and high quality, on time deliverables.
• Create repeatable processes to support development of reporting needs.
• Effectively use tools to manipulate large-scale databases, synthesizing data insights. Provide 1st level insights/conclusions/assessments and present findings via Tableau/PowerBI dashboards, Excel, and PowerPoint.
• Apply quality control, data validation, and cleansing processes to new and existing data sources.
• Provide guidance and mentorship to junior team members.

All About You

• 7+ years’ experience in data engineering and management, data mining, data analytics, data reporting, data product development and quantitative analysis.
• Financial Institution or a Payments experience a plus
• Proactive self-starter seeking initiatives to advance.
• Data architecture experience and experience in building data models.
• Experience with data validation, quality control and cleansing processes to new and existing data sources.
• Advanced SQL skills, ability to write optimized queries for large data sets.
• Expert in writing stored procedures, functions and views is preferable.
• Experience on Platforms/Environments: Cloudera Hadoop, Big data technology stack, SQL Server, Microsoft BI Stack, Cloud, Snowflake, and other relevant technologies
• Exposure to Python, Scala, Hive, Impala, Spark, Cloud, and other related technologies.
• Experience in data pipeline creation via tools such as Alteryx, SSIS etc.
• Advanced knowledge of any of the job scheduling tools such as Apache Airflow, NIFI, and other related tools.
• Experience with data visualization tools such as Tableau, Domo, and/or PowerBI is a plus.
• Experience presenting data findings in a readable and insight driven format. Experience building support decks.
• Must be able to interact with management, internal stakeholders and collect requirements.
• Must be able to perform in a team, use judgment and operate under ambiguity.
• Experience for leading the entire project and manage timely execution of the plan, provide regular update to key stakeholders.

Education

• Bachelor’s or master’s degree in a Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred.

Additional Competencies
• Excellent English, quantitative, technical, and communication (oral/written) skills.
• Analytical/Problem Solving
• Team player, excellent communication skills
• In depth technical knowledge, drive, and ability to learn new technologies.
• Strong attention to detail and quality
• Creativity/Innovation
• Self-motivated, operates with a sense of urgency.
• Project Management/Risk Mitigation
• Able to prioritize and perform multiple tasks simultaneously.

Corporate Security Responsibility

Responsibilities

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must.
• Abide by Mastercard’s security policies and practices.
• Ensure the confidentiality and integrity of the information being accessed.
• Report any suspected information security violation or breach, and
• Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 121K - 186K *
308,Sr Data Engineer,Aryng,"Chennai, Tamil Nadu, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a Senior Data Engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 186K *
309,"Engineering Manager - Machine Learning, Computer Vision and AI",Motive,India - Remote,Mid-level / Intermediate,"Who we are: 
Motive builds technology to improve the safety, productivity, and profitability of businesses that power the physical economy. Motive combines IoT hardware with AI-powered applications to connect and automate physical operations. Motive is one of the fastest-growing software companies in the world, serving more than 120,000 businesses, across a wide range of industries including trucking and logistics, construction, oil and gas, food and beverage, field service, agriculture, passenger transit, and delivery.
Motive is built on four foundational attributes; Own It, Less but Better, Build Trust, and Unlock Potential. This has taken our company to great heights, including being recognized by Fortune for Best Workplaces, Forbes Best Startup Employers, and Comparably for our Best Global Culture, Sales Team, Leadership Team, Career Growth, and CEO for Diversity. We’re proud to receive an employee net promoter score of 63 (according to Comparably) which places Motive in the top 5% of companies with 4,000 employees or more. 
Today, our team is made up of more than 3,000 employees, located across the world, providing support to a wide range of customers. While most of our employees are remote, many have the opportunity to work on-site at any of our 8 global office locations. Visit our careers website to learn more about opportunities at Motive. 
About the Role: 
As Engineering Manager - Machine Learning & Perception at Motive, you will be a part of a passionate team whose mission is to bring intelligence to the world’s trucking fleets. Our team is focused on building technology to understand driving behavior, identify risk factors, and intelligently suggest coachable events that makes roads safer, improves fleet safety and potentially saves millions of dollars for our customers.
You will have a unique opportunity to work with a high caliber and fast-paced team of experienced and well-published researchers and engineers in AI, Machine Learning, Deep Learning, and Computer Vision, with a track record of delivering highly performant safety products for the physical economy. 
You will be responsible for leading a talented team of machine learning, computer vision and embedded engineers, fostering innovation, and ensuring the successful delivery of projects aligned with Motive’s business objectives. You will also build pipelines with edge processing, large and scalable MLOps infrastructure and vast amounts of in-house data to train, test, and validate production quality AI systems.
The role covers the entire lifecycle of AI products from conception to development, deployment and completion and Motive’s AI pipeline from camera to customer. Successful candidates will bring their technical expertise in AI, machine learning or computer vision and project management experience to design, plan, execute and deliver AI products.
What You’ll Do: 
Lead teams that architect and deliver on multiple projects with cross-functional dependencies
Lead technical design of the next-generation of AI-driven Motive products
Be a subject matter expert in one or more AI, ML, deep learning or computer vision domains & provide high-level scientific and technical leadership for the Motive AI team
Partner with leadership to understand product needs, identify priorities and drive AI/ML/CV roadmap and strategy for Motive’s product and platforms
Be a highly technical as well as effective people manager, set clear expectations & goals, measure team performance and impact
Increase visibility of Motive AI and help grow the team
What We’re Looking For: 
5+ years of experience in developing products with machine learning, AI, deep learning, or another related technical area 
3+ years of experience as a technical project manager or scientific lead for AI/ML projects from concept to product, managing a team of 5-10 individual contributors
Bachelor’s degree in Computer Science, Electrical Engineering, mathematics or related field 
Experience in one or more of Python, C/C++, ML & deep learning frameworks (e.g., TensorFlow/Keras, PyTorch, Keras, scikit-learn, H20)
Ability to solve problems analytically and creatively
Strong communication (written and oral) skills
Familiarity/experience with hands-on development in computer vision with applications in the automotive domain is a strong plus
Familiarity/experience with containerizing using Docker and/or other environments; deployment on AWS, Kubernetes/Kubeflow, CI/CD pipelines or other distributed/cloud platforms is a plus
Familiarity/experience with embedded machine learning and/or optimizing and deploying ML models on embedded devices  is a strong plus
Creating a diverse and inclusive workplace is one of Motive's core values. We are an equal opportunity employer and welcome people of different backgrounds, experiences, abilities and perspectives. 
Please review our Candidate Privacy Notice here.
The applicant must be authorized to receive and access those commodities and technologies controlled under U.S. Export Administration Regulations. It is Motive's policy to require that employees be authorized to receive access to Motive products and technology. 
#LI-Remote",USD 21K - 39K *
310,Senior Enterprise Solution Engineer - AI Software,NVIDIA,"India, Bengaluru",Senior-level / Expert,"We are now looking for an experienced engineer to help build our Bangalore NVIDIA Enterprise Support (NVES) team.  This individual should have solid grasp of platform and systems engineering who also can triage customer software issues, resolve customer problems and maintain great customer relationships. This highly technical engineering enterprise support team will not only be providing critical support to NVIDIA’s enterprise customers, they will also have the chance to create enhancements and tools for the DGX Platform Software, Container Orchestrators, Deep Learning containers, and potentially other Enterprise related system software enhancements and tools related to our DGX software and Container deployments. This team will work closely with the other NVIDIA development organizations located in Bangalore, as well as the other NVIDIA Enterprise Support Teams worldwide (Santa Clara, Europe, South Korea, China, and Japan). If you have a real passion for technology, and you are interested in a role that you can make a difference in and contribute at all different levels, this may be a great position for you.  This team supports some of NVIDIA’s most groundbreaking technology, like the DGX/HGX product lines. 
The DGX architecture features a modular design that works seamlessly in existing data centers around the world, offering hyperscale facilities a quick, simple path to AI and deep learning. To do an extraordinary job in this role, we will be looking for a dynamic engineer, with a diverse set of skills in software programming and scripting skills, Linux debugging and troubleshooting skills (you will be a creative problem solver) and knowledge of large enterprise server and container deployments. We are also looking for someone who has superb interpersonal and communication skills, given you would be working closely with our customers and engineers to understand, explain and resolve issues, and collaborate with the team to build scalable and reliable software.  Does this type of role intrigue you?  If it does, we would love to hear from you!
What you'll be doing:
You will develop software tools and product features to support all Enterprise Service offerings including, but not limited to NGC, Container Orchestrators (such as Kubernetes), GPU accelerated applications, and Deep Learning frameworks
Work with NVIDIA Enterprise customers and internal users to enhance the availability, reliability, and overall experience of working with NVIDIA Deep Learning Framework containers on NVIDIA GPUS
Take ownership and drive customer issues on servers, containers, Deep Learning frameworks, and Cloud deployment from inception to resolution
Actively work with customers and develop internal relationships to bring to bear NVIDIA's internal expertise on Deep Learning Containers and Deployment
Build upon the opportunity to research new use cases with GPUs for emerging container technologies and Deep Learning frameworks
Bring independent analysis, communication, and problem-solving to customer experience
What we need to see:
Minimum of a BS in Computer Science, Electrical Engineering, Computer Engineering, or related or equivalent experience
10+ years software development and troubleshooting experience, ideally with some customer facing
Intellectual curiosity, positive attitude, flexibility, analytical ability, self-motivation, and team-oriented
Excellent Python and scripting skills, with strong computer science concepts
Deep understanding of at least two of the following:  data centers, servers, distributed systems, virtualization, deep learning frameworks, containers/containerization (ie Docker, Kubernetes), hybrid cloud (ie AWS, GCP)
You'd have cultivated a deep Linux knowledge, and be very comfortable working in various Linux environments as well as with Windows OS’s
Professional-level communication skills, with ability to adjust communication to technical level of audience
Excellent follow-up and organizational skills, with a passion for solving problems
Ways to stand out from the crowd:
Exposure to debug and triage experience on Linux and Containers and deep learning frameworks
Experience working with distributed systems especially container orchestrators
Any exposure to system level debug and triaging experience
With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant and talented people on the planet working for us and, due to unprecedented growth, our world-class engineering teams are expanding fast. If you're a creative and autonomous engineer with a genuine passion for technology, we want to hear from you.
With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant and talented people in the world working for us and, due to unprecedented growth, our elite engineering teams are rapidly growing. If you're a creative and autonomous engineer with a real passion for technology, we want to hear from you. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",USD 45K - 84K *
311,"Software Engineer - NLP , Machine Learning",Gartner,Gurgaon - Cyber Park,Senior-level / Expert,"About Gartner IT :
Join a world-class team of skilled engineers who build creative digital solutions to support our colleagues and clients.  We make a broad organizational impact by delivering cutting-edge technology solutions that power Gartner.  Gartner IT values its culture of nonstop innovation, an outcome-driven approach to success, and the notion that great ideas can come from anyone on the team.
About this role:
Software Development (NLP) position having experience in NLP and responsible for design, implementation, and support of Python based applications to help fulfill our Research & Consulting Delivery strategy.
What you’ll do: 
Establish methodologies for quickly rolling out new data analysis capabilities for standalone data-driven products and services to support our associates using ML and NLP.
Participate in architecture and technical design discussions to ensure NLP solutions align with the organization's strategic objectives.
Continuously improve NLP models through experimentation and optimization techniques.
Stay up to date with the latest advancements in NLP and machine learning to contribute to the continuous improvement of the organization's technical capabilities.
What you’ll need:
2 – 4 years of experience in algorithms and statistics and experience in data mining, machine learning, deep learning and natural language processing.
Must have:
Experience in Machine learning models and techniques like NLP, BERT, Transformers, Deep learning.
Knowledge of Gen AI models like Open AI, Large Language Models like LLAMA 2, Vicuna etc.
Experience working with Python libraries like Pandas, Scikit-Learn, Numpy, NLTK, Spacy and Scipy is required.
Experience building scalable data models and performing complex relational databases queries using SQL (Oracle, MySQL, PostgreSQL).
Knowledge of MLOps Frameworks like Kubeflow, MLFlow, DataRobot, Airflow etc.,
Who you are:
Effective time management skills and ability to meet deadlines.
Excellent communications skills interacting with technical and business audience’s.
Excellent organization, multitasking, and prioritization skills.
Must possess a willingness and aptitude to embrace new technologies/ideas and master concepts rapidly.
Intellectual curiosity, passion for technology and keeping up with new trends.
Delivering project work on-time within budget with high quality.
Don’t meet every single requirement? We encourage you to apply anyway. You might just be the right candidate for this, or other roles
#LI-SS9
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84089
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 37K - 70K *
312,Sr Data Operations Engineer,Wabtec,Bengaluru - KA - IND (ITC Greens),Senior-level / Expert,"Wabtec Corporation is a leading global provider of equipment, systems, digital solutions and value-added services for freight and transit rail. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation and Faiveley Transport, the company has unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems. Wabtec is focused on performance that drives progress, creating transportation solutions that move and improve the world. Wabtec has approximately 27,000 employees in facilities throughout the world. Visit the company’s new website at: http://www.WabtecCorp.com.

It’s not just about your career… or your job title…it’s about who you are and the impact you are going to make on the world. Do you want to go into uncharted waters…do things that haven’t been done to make yours and someone else's life better? Wabtec has been doing that for decades and we will continue to do so! Through our people, leadership development, services, technology and scale, Wabtec delivers better outcomes for global customers by speaking the language of industry.
Summary:
Wabtec IT Data & Analytics (DnA) Team…at the forefront of the business priorities in building a next generation data and analytics ecosystem…is looking for a Sr. Operations Engineer to lead the operations of large-scale data analytics solutions and platform operations.
This hands-on position is responsible for DevOps support to provide technical expertise and lead a team of data operations contractors in maintaining our Data Lake platform, application support and maintenance operations. We expect this person is self-motivated, a quick learner and who has worked on AWS & has experience on working with cloud platform hosting BigData / Hadoop distributed data environment. This Operations Engineer is a technical professional responsible for participating in the design, development, testing, implementation, and the support of the Cloud platform ecosystem. This role also supports efforts to create infrastructure to streamline development and deployment of applications using modern Cloud DevOps practices.
If you are enthusiastic and passionate about NextGen platform hosting and maintaining infra- operations, then we are looking for you!
Duties and Responsibilities: 
Responsible for maintaining large scale production EMR cluster.
Well versed with setup and provisioning AWS services (EMR, IAM, S3, RDS, ELK, Redshift, Application etc.) and other AWS services and dashboards. Preferred - AWS certification for EMR cluster management.
Strong knowledge of Kerberos for operation and debugging issues in Hadoop
Improve scalability, service reliability, capacity, and performance of the cluster and applications running in the cluster.
Triage production issues when they occur with other operational teams.
Conduct ongoing maintenance across our large-scale deployments across the time zones and countries.
Identify ways to improve infra reliability, efficiency, and quality.
Minimum Qualifications & Eligibility Requirements:   
Bachelor's degree in information systems, Information Technology (IT), Computer Science, or Engineering from an accredited college or university
Overall 8+ Years of Professional experience in Information Technology with Platform Operations or DevOps or similar
Minimum of 4+ years of experience working with cloud-based platforms in an enterprise environment with large scale Data hosting on Bigdata technologies or Data Lake process
Any Scripting Knowledge - Shell, Perl, python, groovy, terraform, ansible.
Strong Experience in Linux OS
Experience on AWS services/network - Instances, Security Groups, Bootstrap actions, S3 Buckets, VPC/Subnet
Strong Experience with Hadoop security and Governance - LDAP Integrations, Kerberos.
Strong Performance tuning experience on Hive, Presto and MapReduce/Yarn.
Strong Experience in monitoring, debugging, and troubleshooting of services.
Knowledge on Datadog
Familiarity or expertise with various tools & technologies include Python/ Spark / Scala / Sqoop & scalar, terraform, ansible, Jenkins, CICD, and S3/ Glue /EMR/ RedShift/ RDS/ Kinesis/ Elastic search etc. is a plus.
Knowledge, Skills and Abilities:
Critical thinking, decision making, troubleshooting and problem-solving skills.
Ability to support multiple initiatives simultaneously and work in a fast-paced environment.
Excellent verbal & written communication skills, including communicating technical issues to non-technical audiences.
Ability to acquire any specialized domain knowledge required to be more effective in all platform operations activity.
Ability to operate in a fast-paced environment with a sense of of urgency, ownership, and accountability.
Adaptable/Flexible: being open to change in response to new information, different or unexpected circumstances, and having the ability to navigate ambiguous situations. 
Highly self-motivated with the ability to work independently, passionate about business & attention to details.
Wabtec Corporation is committed to taking on the world’s toughest challenges. In order to fulfill that commitment we rely on a culture of leadership, diversity and inclusiveness. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We believe in hiring talented people of varied backgrounds, experiences and styles…people like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.",USD 125K - 238K *
313,"Data Product Manager, BI Tools",Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
About the team: As part of the IT group, we are responsible for executing our enterprise data strategy which emphasizes data management maturity, fosters a robust data culture, and architects a best-in-class enterprise data platform.  We have the ultimate goal to provide trusted data and insights at scale which enable corporate and functional data-driven decision making. We are fueled by organic innovation, internal collaboration and adoption of data visualization, data management, reporting automation, AI/ML and integration tools. We leverage best practices and alignment through our Enterprise Data Community to deliver speed to insight, scale, control and enablement. The team is distributed across the United States and India and is composed of data engineers, data analysts, visualization developers, and infrastructure specialists. 
  What You’ll Do
Drive vision and strategy for the business intelligence and analytics tools and systems
Drive cross-functional collaboration with technical and business teams on design and technical architecture tradeoffs, including platforms, frameworks, scalability, and performance
Own the delivery of customer requirements, including definition, prioritization, and execution of release goals
Collaborate on the vision, roadmap, and capabilities for internal data products (in snowflake, salesforce, Tableau) to ensure availability of high-quality data 
Elevate user-experience for internal analytics products and enable self-service through our analytics platforms and automation
Thoroughly understand, research, and follow technical business intelligence and analytics trends in the industry
Extensively focus on setting the UI standards for internal data product development and enforcing such standards in collaboration with the business partners 
Administer internal business intelligence platforms like Tableau and Salesforce CRMA including groups and user setup/maintenance 
Act as the Tableau and Salesforce CRMA product expert to the rest of the organization
Extensively focus on scaling our internal data products to be more accessible, trustworthy, and easy-to-consume for all internal use-cases
Qualifications
5+ years of product management experience focused on building and administering internal data products, data platforms (Tableau, Salesforce CRMA), and self-service capabilities 
8+ years of technical experience in: Advance SQL, data pipeline & data modeling, visualization tools (Tableau, Salesforce CRMA, others), building data roadmaps, and data analysis. Leverage these skills to visualize the solution, build the quarterly roadmap and sprint plans, resource allocation, and timelines
Extensive experience building and deploying Tableau dashboards and Salesforce CRMA dashboards
Experience with platforms like Salesforce, Marketo, NetSuite (or ERP), Snowflake
Experience launching internal data products based on cloud data analytics platform, modern data warehousing technologies, and business intelligence tools   
Strong experience in agile or scrum product development and analytics/engineering frameworks
Solid Product Management experience and knowledge, Design Thinking, and Customer Discovery
Experience supporting multiple initiatives in parallel in a fast-paced environment
Experience leading through influence across functional lines
Bachelor’s degree in an analytical or related field
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 120K - 151K *
314,Research Engineer I (Civil/Structural),Verisk,"Hyderabad, India",Entry-level / Junior,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
Verisk EES is a leading catastrophe modeler providing risk assessment tools to the insurance and reinsurance companies. Our models simulate occurrences of natural perils over countries and even continents and for thousands of years under the current climate conditions. This is necessary to account for the simultaneous individual damages and the estimate of the aggregate economic losses and their distributions for arbitrary collections of individual properties (portfolios) the number of which usually counts to millions.
This position is responsible for developing, enhancing, and managing the vulnerability component and overall model performance of Verisk Extreme Event Solutions’ water peril catastrophe models that cover worldwide regions. The candidate will work closely with a team of structural engineers, hydrologists/hydraulic engineers, statisticians, and specialists in financial application of probabilistic risk assessment. The candidate is expected to be a highly motivated, detail oriented, well organized, have a good set of programming skills, and an independent worker and collective team player. However, your effort will be paid off by a very reasonable salary and excellent benefits and by the fact that hundreds of people will use the result of your work. Your innovative thinking as researcher and model developer will be very highly appreciated and participation in scientific conferences and publications in peer reviewed journals encouraged.  
Data acquisition, visualization and analysis to understand building inventory and its vulnerability subjected to flood (coastal and precipitation induced) hazards at any interested region worldwide
Development/calibration/validation of vulnerability functions and monetary loss curves for structural and non-structural components subjected to hazards such as storm surge, precipitation induced flooding for the regions of interest
Implement the research of building vulnerability into Verisk Extreme Event Solutions’ portfolio risk assessment models, and validate the output
Investigate property damage in the aftermath of flooding, including statistical analysis of historical damage and insurance claims data
Provide technical support regarding model development and communicate results to clients
Technical writing for internal and external publications
Qualifications
Education Qualification:
Master’s in Civil/Structural Engineering or related fields
Total Experience: 0-2 years
Must-Have skills:
Strong background in construction practices as it relates to flood vulnerability, and on the effects of water damage on structures
Excellent proficiency in C/C++, SQL, Python, R, MATLAB
Experience in probabilistic and stochastic risk assessment and modeling, particularly in the field of engineering
Knowledge of structural design
Excellent communication skills to convey findings to internal and external stakeholders
Experience in working with GIS applications preferably ARCGIS
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 98K - 160K *
315,Sr. ETL Developer,Avantor,IND-Pune(GBC),Senior-level / Expert,"The Opportunity:
Avantor is looking for a dynamic, forward-thinking, and experienced Senior ETL Developer, delivering results against some of the most complex business and technology initiatives.  
This role will be a full-time position based out of our Pune or Coimbatore office.
If you are passionate about solving complex challenges and driving innovation – let’s talk!  
Our organization is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. 
The Senior ETL Developer drives data-driven strategies and delivers impactful insights to optimize content, user experience, and conversion rates. This role requires analytical expertise, strategic thinking, and strong leadership skills.
What we’re looking for
Education: Bachelor’s Degree in Engineering (computer science or other equivalent majors).
Experience:
15+ years of overall experience in IT.
12+ years of experience in SAP Data Services.
12+ years of experience in SQL 
Thorough Knowledge of SAP BODS Architecture
Expertise in Designing ETL Flows in SAP BODS
Should have worked on the preparation of Technical Specification documents.
Strong hands-on experience in SAP Data Services (BODS) as a technical developer
Working Knowledge with SAP systems as Source
Experience with all transformations in BODS
Very Good analytical skills to analyze ETL and SQL issues and to fix them independently
Able to provide the estimation on BODS work efforts
Should be able to connect to customers and gather requirements and work independently on those requirements.
Should have basic knowledge of Data Warehousing concepts on schema formation
Knowledge of Dimensional Modeling Concepts
Experience of BODS scheduling and Management Console.
Experience in Installation and configuring BODS.
Experience in Snowflake Cloud Database Architecture, good to have.
SAP BODS Admin Knowledge, good to have.
SAP Functional Knowledge, good to have.
Why Avantor? 
Dare to go further in your career. Join our global team of 14,000+ associates whose passion for discovery and determination to overcome challenges relentlessly advances life-changing science.   
 The work we do changes people’s lives for the better. It brings new patient treatments and therapies to market, giving a cancer survivor the chance to walk his daughter down the aisle. It enables medical devices that help a little boy hear his mom’s voice for the first time. Outcomes such as these create unlimited opportunities for you to contribute your talents, learn new skills and grow your career at Avantor.   
 We are committed to helping you on this journey through our diverse, equitable and inclusive culture which includes learning experiences to support your career growth and success. At Avantor, dare to go further and see how the impact of your contributions set science in motion to create a better world. Apply today!
Disclaimer:

The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position. Avantor is proud to be an equal opportunity employer.
Why Avantor?
Dare to go further in your career. Join our global team of 14,000+ associates whose passion for discovery and determination to overcome challenges relentlessly advances life-changing science.
 
The work we do changes people's lives for the better. It brings new patient treatments and therapies to market, giving a cancer survivor the chance to walk his daughter down the aisle. It enables medical devices that help a little boy hear his mom's voice for the first time. Outcomes such as these create unlimited opportunities for you to contribute your talents, learn new skills and grow your career at Avantor.
 
We are committed to helping you on this journey through our diverse, equitable and inclusive culture which includes learning experiences to support your career growth and success. At Avantor, dare to go further and see how the impact of your contributions set science in motion to create a better world. Apply today!
EEO Statement:
We are an Equal Employment/Affirmative Action employer and VEVRAA Federal Contractor. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, color, religious creed, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by federal, state/province, or local law.
If you need a reasonable accommodation for any part of the employment process, please contact us by email at recruiting@avantorsciences.com and let us know the nature of your request and your contact information. Requests for accommodation will be considered on a case-by-case basis. Please note that only inquiries concerning a request for reasonable accommodation will be responded to from this email address.
3rd party non-solicitation policy:
By submitting candidates without having been formally assigned on and contracted for a specific job requisition by Avantor, or by failing to comply with the Avantor recruitment process, you forfeit any fee on the submitted candidates, regardless of your usual terms and conditions. Avantor works with a preferred supplier list and will take the initiative to engage with recruitment agencies based on its needs and will not be accepting any form of solicitation",USD 99K - 129K *
316,Sr Data Engineer - Territory Innovation,Gartner,Gurgaon - Cyber Park,Senior-level / Expert,"About this role:
The Territory Planning & Analytics (“TP&A”) team is at the centre of delivering against our CEO’s top priorities – rapidly-growing the sales force and increasing sales productivity.  We provide strategic advice to corporate and senior Sales leaders across the globe to ensure the best return on the company’s substantial annual investment in incremental sales professionals.  
The Territory Planning & Analytics Innovation team is focused on making sure we understand the needs of the sales force to help create scalable products, solutions that help increase the sales productivity, overall experience utilizing both data and technology.
We are searching for top talent that will help us in building cutting-edge products that solve the most challenging problems in the IT world. You will have access to large sets of complex data and utilize your skills in developing/supporting high performance data ingestion pipelines, data modelling, integrations with services, automating processes using python and collaborating with business teams to create scalable solutions as per business requirements.
What you’ll do:
Develop and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Created backend functions that help automate some of the complex data related processes.
Build and configure web services, pub-sub queues, Event Driven Architecture components.
Follow best practices and industry standards while implementing Data Engineering and Mastering functions.
Analyze business requirements and lead the effort in solutioning the product design including creating architecture that is scalable.
What you will need:
5+ years of working experience.
Experience in OOPS concept, Data structure and design (architecture, design patterns and scaling)
Strong SQL skills, ability to create Functions/Stored Procedures and effective querying involving multiple tables and subqueries.
Experience creating detailed architecture diagrams and solutioning for data-based products.
Experience working with Bigdata using libraries like PySpark, Hadoop.
Strong Python programming experience and knowledge of Python Frameworks like Pandas, Numpy and Python data processing libraries.
Experience with Data Pipelining, Data Transformation, ETL and creating custom Python data pipelines.
Good experience working with AWS Cloud and it’s services related to Data engineering like Athena, AWS batch jobs etc.
Proven ability to use data, analytics, and business knowledge to solve complex business problems.
Experience of data modeling and working with data warehouses.
 Good to have:
Data visualization experience with tools like PowerBI, Tableau.
Experience working with PostgreSQL database.
Familiarity with HBase, MapReduce, and other suitable platforms.
What you will get:
Competitive salary, generous paid time off policy, charity match program, Group Medical Insurance, Parental Leave, Employee Assistance Program (EAP) and more!
Collaborative, team-oriented culture that embraces diversity
Professional development and unlimited growth opportunities
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84435
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 121K - 186K *
317,MSBI with Power BI Developer | 6 to 9 years | PAN India,Capgemini,"Mumbai, MH, IN",Senior-level / Expert,"Job Description
MSBI Full stack developer with experience in SSAS SSIS SSRS
Knowledge in Power BI will be an added advantage
Extensive experience in SQL is mandatory
Experience in SSAS Tabular Modelling        
Experience in writing and optimizing SQL DAX queries        
Experience in Power BI development using semantic layer
Primary Skills
SQL, SSAS, Tabular Modelling, Power BI 
Extensive experience in Power BI Visualization Data Modeling and Semantic layer implementation
Experience in Tabular model implementation
Experience in Client interactions and requirement analysis.
Secondary Skills
Good communication and comprehension skills
Experience in requirement documentation
Good presentation and coordination skills",USD 106K - 140K *
318,Data Analyst,SKF Group,"Bengaluru, IN",Entry-level / Junior,"JOB DESCRIPTION
  JOB TITLE:     Data Analyst
Role Type:     Individual Contributor
Location:      Bengaluru
    Purpose of the role:
  We are seeking a highly skilled and detail-oriented Data Analyst to join our dynamic team. The successful candidate will be responsible for collecting, processing, and analysing large sets of data to provide valuable insights that will drive informed decision-making within the organization.
                                Responsibilities
Create and maintain rich interactive visualizations through data interpretation and analysis, with reporting components from multiple data sources.
Define and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution.
Develop and maintain databases by acquiring data from primary and secondary sources and build scripts that will make our data evaluation process more flexible or scalable across datasets.
Collaborate with various teams within SKF to understand their data needs and provide actionable insights.
  Metrics
Data Interpretation: Ability to interpret and analyze complex data sets to provide actionable insights and recommendations.
Statistical Analysis: Proficiency in statistical methods and tools for analyzing and interpreting data.
Data Visualization: Experience in creating visual representations of data to communicate findings effectively.
Data Cleaning and Preprocessing: Proficiency in cleaning and preprocessing data to ensure accuracy and consistency.
Proficiency in Tools: Familiarity with data analysis tools such as Excel, Tableau, Power BI, or other relevant software.
  Required skills and qualifications.
Proven experience as a Data Analyst or in a similar role (Minimum 3 years
Strong proficiency in data analysis tools and programming languages (e.g., Python, R, SQL).
  Preferred skills and qualifications
Bachelor’s degree (or equivalent) in mathematics, computer science, economics, or statistics
Experience with database and model design and segmentation techniques
Strong programming experience with frameworks, including XML, JavaScript etc
Practical experience in statistical analysis through the use of statistical packages, including Excel and SAS
Proven success in a collaborative, team-oriented environment
     ",USD 54K - 94K *
319,Data Science (Generative AI) – Senior Manager – ANI,PwC,Bengaluru (SDC) - Eagle Ridge at Embassy Golf Links Business Park,Senior-level / Expert,"Line of Service
Advisory
Industry/Sector
Not Applicable
Specialism
Data, Analytics & AI
Management Level
Senior Manager
Job Description & Summary
A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.
Years of Experience: 12 + Years
Must have :
Experience in developing machine learning and deep Learning models in local and cloud environments (At least 1 of the 3: Azure , GCP, AWS )
Must Have below skills:

● Solid knowledge and experience of supervised, unsupervised and reinforcement learning machine
learning algorithms. For e.g: classifiers, cluster analysis, dimension reduction, regression, and
models CNN, RNN, DQN, GAN, temporal difference methods, sequence modeling, NLP/NLU,
word/doc embeddings, collaborative filtering, self-attention, transformers, etc.
● Experience with the current state of AI/ML, Large Language Models, and Generative AI
● Fine-tune language models to specific domains using LLM to improve the accuracy and
effectiveness of text-based applications
● Build generative AI models that can generate original content, such as text, images, or music
● Experience with model explainability and interpretability techniques
● Experience in machine learning frameworks and tools ( For e.g: scikit-learn, mlr, caret, H2O, TensorFlow,
MXNet, Pytorch, Caffe/Caffe2, CNTK, MLlib)
● Advanced level programming in SQL and Python/Pyspark to guide teams
● Lead and manage a team of data scientists and engineers working on generative AI projects
● Identify and evaluate new AI technologies and tools that could be leveraged for generative AI projects.
Understand the nuances between traditional Machine Learning lifecycle and Generative AI modeling
lifecycle
● Develop and implement ethical guidelines and standards for AI development and deployment
● Stay up to date with the latest research and trends in the field of generative AI and apply them to the
company's projects and goals
● Communicate effectively with stakeholders at all levels of the organization to explain the benefits and risks
of generative AI solutions

Nice to have:

● Strong hands-on skills for data pipeline orchestration (For e.g: Airflow)
● Expertise with visualization tools For e.g: Tableau, PowerBI, AWS QuickSight etc.
● Multi-task and manage multiple deadlines. Responsible for incorporating client/user feedback into the
Product
● Ability to think through complex user scenarios and design simple yet effective user interactions
● Good Communication and presentation skills
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
Not Specified
Available for Work Visa Sponsorship?
No
Government Clearance Required?
No
Job Posting End Date",USD 95K - 160K *
320,Lead Data Analyst,SKF Group,"Bengaluru, IN",Senior-level / Expert,"JOB DESCRIPTION
    JOB TITLE:     Lead - Data Analyst
Role Type:     Team Leader
Location:       Bengaluru
  Purpose of the role:
  The person will be responsible for overseeing a team of data analysts and ensuring the efficient and accurate execution of data-related projects. The person will play a crucial role in driving data-driven decision-making within the organization and supporting the development and implementation of data strategies.
  The ideal candidate should possess strong analytical and leadership skills, along with a deep understanding of data analysis techniques, tools, and technologies, who can think and work independently and deliver quick results, while demonstrating a team-player attitude.
                                Responsibilities
It will include:
Team Management:
The person will lead a team of data analysts and foster a collaborative and innovative team culture. Responsible to identify training needs within the team and facilitate skill development.
Data Strategy Development:
Partners with the business to identify the appropriate data sources and analysis methodology and presents the results of data analyses and recommendations to management.
Quality Assurance:
Implement and enforce data quality standards and the best practices, also conduct regular audits to ensure data accuracy and integrity.
Reporting and Visualization:
Develop and maintain reports and dashboards and ensure data visualizations are clear, concise, and actionable.
Cross Functional Collaboration:
Collaborate with stakeholders to define project goals, scope, and deliverables and provide data-driven insights and actionable recommendations to the stakeholders. Convert business requirements into technical specifications and decide timeline to accomplish.
Also work closely with IT teams to ensure data security and integrity.
  Metrics
Data Accuracy and Quality: Monitor the accuracy and quality of the data and implement regular data quality checks and improvements.
Data Visualization Effectiveness: Evaluate the effectiveness of data visualizations and assess whether visualizations are clear, insightful, and align with stakeholder needs.
Project Efficiency: Ensure that projects are delivered within agreed-upon timelines and measure the success rates of completed projects.
Data Governance Adherence: Ensure that the team adheres to data governance policies and standards and monitor compliance with data security and privacy regulations.
Innovation and Process Improvement: Track the implementation of new tools or methodologies to enhance efficiency.
  Required skills and qualifications.
10+ years of experience as a data analyst with minimum of 3 years of experience in managing the team.
Proven analytics skills, including mining, evaluation, and visualization.
Technical writing experience in relevant areas, including queries, reports, and presentations.
Strong SQL or Excel skills, with aptitude for learning other analytics tools
  Preferred skills and qualifications
Bachelor’s degree (or equivalent) in mathematics, computer science, economics, or statistics
Experience with database and model design and segmentation techniques
Strong programming experience with frameworks, including XML, JavaScript etc
Practical experience in statistical analysis through the use of statistical packages, including Excel and SAS
Proven success in a collaborative, team-oriented environment",USD 45K - 84K *
321,Senior Consultant (AI),Springer Nature Group,"Pune, IN",Senior-level / Expert,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow. 
Visit: group.springernature.com and follow @SpringerNature
  Senior Consultant, AI Center of Excellence
  Reporting: Director of Technology, AI
Location: Pune
  Position Summary
We are looking for a candidate to join our AI Center of Excellence within Springer Nature Operations. You will be driving how Springer Nature uses AI that serves as an enabling force within Springer Nature and the external world of scientific research. You will be involved in the development and execution of AI related projects within Springer Nature, driving research and development activities, and leading the team in building and deploying AI solutions.
  The role is reporting to the Director of AI and will be based in Pune (India). There will be travel involved to our global offices
  We are an equal opportunities employer. We work in a relaxed, friendly environment and we operate in a hybrid model
Key Responsibilities
Contribute to and drive the vision for AI within the AI Center of Excellence, setting priorities and aligning the activities of the team with business objectives
Lead research and development projects, leveraging AI and related technologies to deliver innovative solutions to business challenges
Oversee the development of AI models, algorithms, and applications, ensuring quality, accuracy, and scalability as an SME
Identify and implement best practices to ensure the security and privacy of data used in AI applications
Build and maintain relationships with external stakeholders, including AI researchers, technology providers, and other partners
Develop and present reports, presentations, and other deliverables to executive management
Guide cross functional teams of AI engineers, data engineers, and data scientists
Monitor the AI industry to identify trends, opportunities, and threats
Required Qualifications and Skills
Bachelor's degree in a related field (e.g. Computer Science, AI, Machine Learning, Data Science, Electronics, Electrical, Instrumentation, Telecommunications, etc.)
Mid to Senior experience in either a professional data science position or a quantitative academic field
Strong programming skills as evidenced by earlier work in data science or software engineering. Prior experience with Python (preferable), R, or Julia is mandatory
If versed in Python, an excellent command of the basic libraries for data science (e.g. NumPy, Pandas, Scikit-Learn) and familiarity with a deep-learning framework (e.g. TensorFlow, PyTorch, Caffe) is required
A high level of mathematical competence and proficiency in statistics
A solid grasp of essentially all of the standard data science techniques, for example, supervised/unsupervised machine learning, model cross validation, Bayesian inference, time-series analysis, NLP, effective SQL and NoSQL database querying, using/writing simple APIs for models.
An appreciation for the scientific method as applied to the commercial world; a talent for converting business problems into a mathematical framework; resourcefulness in overcoming difficulties through creativity and commitment; a rigorous mindset in evaluating the performance and impact of models upon deployment
Enthusiasm for working in a collaborative and dynamic culture
Experience acting as the key technical resource for cross functional teams and/or a team of data scientists (to deliver innovative work according to a strict timeline) as well as experience in composing a project plan, in assessing its technical feasibility.
Excellent communication and presentation skills
Ability to work in a fast-paced environment
Some commercial experience, particularly if this involved client-facing work or project management; eagerness to work alongside our clients; business awareness and an ability to gauge the commercial value of projects; outstanding written and verbal communication skills; persuasiveness when presenting to a large or important audience
  At Springer Nature, we value the diversity of our teams and work to build an inclusive culture, where people are treated fairly and can bring their differences to work and thrive. We empower our colleagues and value their diverse perspectives as we strive to attract, nurture and develop the very best talent.
Springer Nature was awarded Diversity Team of the Year at the 2022 British Diversity Awards. Find out more about our DEI work here.
  If you have any access needs related to disability, neurodivergence or a chronic condition, please contact us so we can make all necessary accommodation.",USD 45K - 84K *
322,Lead Data Engineer,Srijan Technologies,"Gurgaon, Bengaluru, Delhi NCR",Senior-level / Expert,"Location: Gurgaon, Bangalore, Delhi NCR,None,None
About US:-
We turn customer challenges into growth opportunities.
Material is a global strategy partner to the world’s most recognizable brands and innovative companies. Our people around the globe thrive by helping organizations design and deliver rewarding customer experiences.
We use deep human insights, design innovation and data to create experiences powered by modern technology. Our approaches speed engagement and growth for the companies we work with and transform relationships between businesses and the people they serve.
Srijan, a Material company, is a renowned global digital engineering firm with a reputation for solving complex technology problems using their deep technology expertise and leveraging strategic partnerships with top-tier technology partners. Be a part of an Awesome Tribe
About the Role:
As a Data Engineer at Material, you will play a crucial role in building and maintaining our advanced data infrastructure. You will be responsible for designing, implementing, and optimizing data solutions that are critical to the success of our data-driven initiatives. This role requires a deep understanding of cloud technologies, particularly AWS, and a strong foundation in data processing and workflow management tools like Airflow and PySpark. You should be comfortable jumping into existing codebases and maintaining pre-defined coding standards and frameworks.
 Key Responsibilities:
· Design, build, and maintain scalable and reliable data pipelines using AWS services, Airflow, and PySpark.
· Develop and optimize data models to support our data warehousing and analytics needs.
· Implement and manage continuous integration and deployment (CI/CD) pipelines for data operations using Git and Docker.
· Collaborate with cross-functional teams to understand data requirements and deliver solutions that meet these needs.
· Lead the automation of data processes and contribute to the development of best practices in data engineering.
· Provide mentorship and guidance to junior data engineers and contribute to the team’s skill development.
· Stay updated with emerging technologies and industry trends to continuously improve our data infrastructure.
 Minimum Qualifications:
· Minimum of 6 years of experience in data engineering or a related field.
· Strong proficiency in Python, PySpark, AWS cloud services, and Docker.
· Expertise in designing and implementing data workflows using Airflow.
· Experience with Git or similar version control systems.
· Proven ability to design and implement large-scale data solutions in a cloud environment.
· Excellent problem-solving skills and the ability to work independently or as part of a team.
· Strong communication skills and the ability to work effectively with both technical and non-technical stakeholders.
 Additional nice-to-haves:
· Experience in leading data engineering projects and teams.
· Familiarity with other cloud platforms like Azure or GCP.
· Knowledge of advanced analytics and machine learning concepts.
 What We Offer:-
Professional Development and Mentorship.
Hybrid work mode with remote friendly workplace. (6 times in a row Great Place To Work (Certified).
Health and Family Insurance.
40+ Leaves per year along with maternity & paternity leaves.
Wellness, meditation and Counselling sessions.
Apply to this job",USD 45K - 84K *
323,Senior Business Intelligence Developer,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
Who we are looking for
At Epsilon, we run on our people’s ideas. It’s how we solve problems and exceed expectations. Our team is now growing and we are on the lookout for talented individuals who always raise the bar by constantly challenging themselves
What you’ll do in Epsilon
Design, Develop and maintain BI solutions across multiple domains primarily using Tableau. Independently engage the stakeholders and develop complex Tableau dashboards with advanced visualizations.
Duties and responsibilities
Understand client requirements and create technical specification to materialize into Tableau Dashboards.
Develop complex Tableau Dashboards with multiple sources and advanced visualizations.
Strong skills in Tableau data preparation, Tableau advanced viz, complex calculations, Tableau server and extract automation skills
Hands on experience in Optimizing queries and Performance tuning at both Database and Tableau dashboard level.
Possess strong analytical skills with the ability to collect, organize, analyze data and present to stakeholders
Implement product out of the box reports and customization for Epsilon CRM and loyalty solution
Troubleshoot production issues and adhere to SLA’s based on client needs
Collaborate with BSAs, DB Developers, Architects, PMs etc. and provide suggestions/ideas to support reporting needs
Communicate timely issues and delivery risks to relevant stakeholders
Ensure to develop dashboards based on industry best practices and Epsilon standards.
Adapt to supporting multiple BI engagements with an as a service mindset
Qualifications
Minimum of 6+ years of development experience utilizing Tableau Desktop, Tableau Server and Tableau Prep Builder.
Must have 5+ years of experience of design, development of Tableau live/extract data-source keeping in mind the self-service BI enablement.
Should have SQL query optimization skill set on any of the databases like Oracle/ Amazon RedShift and must be able to recommend the DBA for performance improvement.
Good to have exposure to BI tools like SAP Business Objects.
Must have the understanding on the BI architecture , server components configurations. user and content management.
Good to have data visualization skills along with Knowledge on other BI tools and latest trends in BI.
Excellent oral and written communication along with a positive attitude towards getting the work done.",USD 76K - 140K *
324,Data Operations - Emerging Lead,State Street,"Bengaluru, India",Senior-level / Expert,"The primary responsibility for the incumbent will be to work closely with the Billing Department and business units to understand the requirements related to new demand and developing solutions that meet the business needs. 
Secondary responsibilities critical to the role include support and development activities that ensure corporate initiative demands are met such as Corporate Information Security and other corporate control processes.
Solutions designed to meet the business needs can result in the development of small stand-alone capabilities or enhancements to current applications supported by the Billing Department.  
The candidate must have a strong database background, Hands-on expertise with SQL, ETL, Data Analysis, Any one Programing Language
Responsibilities:
Evaluate and challenge business processes, uncover opportunities for improvement, and develop and implement solutions.
Document and communicate ideas and findings.
Gathering critical information from meetings and producing useful analysis, actionable events and output.
Prioritizing tasks based on business needs and requirements.
Monitoring deliverables and ensuring timely completion of tasks and projects.
Requirements:
A bachelor’s degree in Technology or finance or experience working in financial sector.
Strong analytical and conceptual thinking skills.
Database analysis and design experience,
Any Relational Database (E.g. SQL SERVER or ORACLE etc.)
Any ETL Tool (e.g. SSIS or Informatica etc.)
Any Programming Language (e.g. Python, C# or Java)
Any Reporting Tool (e.g. SSRS or Crystal Report or Power BI or SPOTFIRE etc.)
Production Support Experience (Change Management or Incident Management or Application Support)
Nice to have experience with GitHub, Artifactory and BCP or DR Activity Support
Good Communication Skills
A track record of following through on commitments.
Excellent planning, organizational, and time management skills.
A history of leading and support of successful projects.",USD 45K - 84K *
325,Data Engineer (Python) - Territory Innovation,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About this role:
The Territory Planning & Analytics (“TP&A”) team is at the centre of delivering against our CEO’s top priorities – rapidly-growing the sales force and increasing sales productivity.  We provide strategic advice to corporate and senior Sales leaders across the globe to ensure the best return on the company’s substantial annual investment in incremental sales professionals.  
The Territory Planning & Analytics Innovation team is focused on making sure we understand the needs of the sales force to help create scalable products, solutions that help increase the sales productivity, overall experience utilizing both data and technology.
We are searching for top talent that will help us in building cutting-edge products that solve the most challenging problems in the IT world. You will have access to large sets of complex data and utilize your skills in developing/supporting products that solve complex data problems, automate existing processes using python. Along with this you will also be collaborating with business teams to create scalable solutions as per business requirements that cater to the large volumes of data used within Gartner.
What will you do:
You will be responsible for the execution of our data strategy through design and development of the data-based products.
Participate in architecture design and implementation of high-performance, scalable, and optimized data solutions.
Integrate data from a wide variety of sources, including on premise databases and external data sources with rest APIs and harvesting tools.
Work with business stakeholders to support their data needs and work with other technical teams to bring product ideas to life.
What you will need:
Bachelor’s degree in computer science or information systems
2-5 years hands-on experience in solutioning and developing scalable Cloud based products.
Expert in programming using Python having experience with AWS and services like EC2, Lambda, AWS Glue, AWS Batch
Experience with Python Frameworks like Django, Flask, FastAPI, Pandas, Numpy
Extensive technical experience with SQL on RDBMS (Oracle/MySQL/PostgreSQL).
Intermediate experience with creating Functions, Stored procedures in SQL.
Experience in OOPS concept, Data structure and design (architecture, design patterns and scaling)
Strong analytical skills with ability to synthesize data to design and deliver meaningful solutions.
Experience integrating with API’s to build cloud based products and services.
Good to have experience in HTML, Angular/React or other frontend technologies to create basic UI of products.
What you will get:
Competitive salary, generous paid time off policy and more!
India: Group Medical Insurance, Parental Leave, Employee Assistance Program (EAP)
Collaborative, team-oriented culture that embraces diversity
Professional development and unlimited growth opportunities
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84437
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 90K - 152K *
326,Senior Lead - Big Data Engineer,S&P Global,IN - MUMBAI HIRANANDANI BUSINESS PARK UNIT NO 201,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
11
The Team
The Data Lake team is responsible for data ingestion from internal source systems in batch/real-time modes, curation and governance of the data assets created in the platform. The team also works towards adopting the new features of the Databricks product and optimizing the operational aspects of the platform to enhance the user community experience.  The team has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. 
The Impact
You will be an expert contributor and part of the Rating Organization’s Data Services Product Engineering Team with a unique opportunity to build and evolve S&P Ratings next gen data and analytics platform.
Our Hiring Manager Says
If you are an individual that brings demonstrated experience of delivering big data projects as a data engineer, this is an excellent opportunity. We are looking for someone who has in-depth technical knowledge around data lake systems, is completely hands-on and worked on transformational initiatives for the business.
Responsibilities:    
•    Design & Build data pipelines with an emphasis on scale, performance and reliability.
•    Provide technical expertise in the areas of design and implementation of Data Lake solution powered by Databricks on AWS cloud.
•    Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data
•    Partner with the data teams, enterprise architecture organization to ensure best use of standards for the key data domains and use cases
•    Continuous learner with an eye on emerging trends around data lake architecture and enterprise data solutions.
•    Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards

Experience & Qualifications:
•    BE, MCA or MS degree in Computer Science or Information Technology
•    8+ years of experience building solutions in big data technologies.
•    Strong experience programming with more than one of Java, Scala, Python, Spark.
•    Hands-on experience designing and building streaming data pipelines using Kafka, Confluent etc. 
•    Must have experience building Data Lake & Data warehouse solutions using ETL,ELT pipelines on any of Databricks, Snowflake, Azure Data Lake etc. 
•    Strong understanding of database and analytical technologies in the industry including MPP and NoSQL databases
•    Strong understanding of cloud platforms like AWS, Azure, or GCP, and their services (e.g., EC2, S3, AKS, EKS, etc.).
•    Experience in continuous delivery through CI/CD pipelines, containers and orchestration technologies. 
•    Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib) is an added advantage.
•    Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally.
•    Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management
•    Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners
•    Ability to prioritize and manage work to critical project timelines in a fast-paced environment
•    Financial services industry experience is an added advantage.
•    Databricks experience or certifications is an added advantage.
•    AWS or any public cloud certification is a must.
About S&P Global Ratings
At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.
S&P Global Ratings is a division of S&P Global (NYSE: SPGI).  S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.  
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 45K - 84K *
327,"Senior Data Engineer, Enabling Functions Data Product Enablement",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation. #HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 121K - 186K *
328,Business Intelligence Architect - Career,Eastman,"Hyderabad, IN, 500 008",Senior-level / Expert,"Founded in 1920, Eastman is a global specialty materials company that produces a broad range of products found in items people use every day. With the purpose of enhancing the quality of life in a material way, Eastman works with customers to deliver innovative products and solutions while maintaining a commitment to safety and sustainability. The company’s innovation-driven growth model takes advantage of world-class technology platforms, deep customer engagement, and differentiated application development to grow its leading positions in attractive end-markets such as transportation, building and construction, and consumables. As a globally inclusive and diverse company, Eastman employs approximately 14,500 people around the world and serves customers in more than 100 countries. The company had 2022 revenues of approximately $10.6 billion and is headquartered in Kingsport, Tennessee, USA. For more information, visit www.eastman.com. 
  Responsibilities
Key Skills/Job Responsibilities:
•    Strong technical and functional experience in managing stakeholders and team of BI analysts.
•    Must have proven experience in MSBI stack and delivering end to end BI solutions independently.
•    Strong Communication skills and ability to confidently communicate a point of view.
•    Maintain awareness of new technologies, plan & oversee implementation & adoption of new technologies.
•    Handle project assignments and training opportunities to grow capabilities of each team member.
•    Maintain awareness of work assignments and progress for each team member. Ensure each team member has an appropriate challenging workload.
•    Setting up goals and team commitments.
•    Responsible for team’s adherence to standards and guidelines set by EIM organization. Contribute to standards repositoy when needed.
•    Co-ordinating with scrum master/ project managers to ensure agile practices and scrum ceremonies are followed.
•    Participate in recruit, orientations, trainings, performance reviews and finding personal growth opportunities for employees.
•    Work with the functional managers & U.S. based supervisors to understand future application development and support needs and plan resources accordingly.
•    Supervise daily delivery activity and provide periodic status updates to upper management.
Desired Skills:
•    Strong experience in the areas of Business Intelligence and Reporting.
•    Proven stakeholder management skills.
Qualifications
Qualifications:
Education: B.Tech/B.E. - Any Specialization, M.E/M.Tech - Any Specialization, MBA.
Experience:  10 to 15 years of strong Business Intelligence/Business Analytics experience or equivalency is preferred
Eastman Chemical Company is an equal opportunity employer.  All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other characteristics protected by law.
  Eastman is committed to creating a powerfully diverse workforce and a broadly inclusive workplace, where everyone can contribute to their fullest potential each day.",USD 45K - 84K *
329,Data Scientist,Mastercard,"Gurgaon, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Scientist
Job Description –Data & Analytics Team – Data Visualization Expert/ Data Scientist II
Overview
Data & Analytics build internal analytic partnerships, strengthening their focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market strategies.
The Mastercard Commercial Analytics team is responsible for expansion of business-to-business analytics footprint and for delivering incremental business insights, volume opportunities across commercial products.

• Are you excited about Data Assets and the value they bring to an organization?
• Are you an evangelist for data driven decision making?
• Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across six continents?
• Do you want to be the go-to resource for data analytics in the company?

Role
• Work closely with global & regional teams to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data in order to support analytics and reporting needs across products, markets and services.
• Translate business requirements into tangible solution specifications and high quality, on time deliverables
• Create repeatable processes to support development of modeling and reporting
• Effectively use tools to manipulate large-scale databases, synthesizing data insights.
• Apply quality control, data validation, and cleansing processes to new and existing data sources
• Connect with stakeholders across business and technology and serve as a SPOC for all the requirements and communications.

All About You
• Experience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis

• Experience with Data Visualization libraries/tools like D3.js, three.js, Highcharts, SVG, HTML5, WebGL
• Experience on Platforms/Environments: SQL Server, Microsoft BI Stack
• Experience with data visualization tools such as Tableau, Domo, PowerBI is a must. Industry standard certification credentials are a plus
• Financial Institution or a Payments experience a plus
• Experience presenting data findings in a readable and insight driven format. Experience building support decks.
• Experience in building automation flow using Alteryx/ Tableau prep/ Python/ R
• Experience using big data batch and streaming tools (Spark, AWS tools, Hadoop)
• Experience with function scripting languages: Python, Scala, R
• Advanced SQL coding is a must
• Experience on SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS) and SQL Server Reporting Services (SSRS) will be an added advantage
• Experience in building data models a must
• Understanding of full stack and product management concepts around product strategy, business case, high-level technical use case and ROI measurement
• Excellent problem solving, quantitative and analytical skills
Scripting knowledge with Python and Bash are essentials
• ETL(Logic) using python, SQL, and NoSQL databases, API
• Must be able to interact with management, internal stakeholders and collect requirements
• Must be able to perform in a team, use judgment and operate under ambiguity

Education
• Bachelor’s or master’s degree in a Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred

Additional Competencies
• Excellent English, quantitative, technical, and communication (oral/written) skills
• Analytical/Problem Solving with excellent communication skills
• Strong diligence and quality focused
• Creativity/Innovation with focused on solution
• Initiative-taking, operates with a sense of urgency
• Product Management/Risk Mitigation
• Able to prioritize and perform multiple tasks simultaneously
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 136K - 205K *
330,"Software Engineering Manager (Hadoop, Impala, Spark, C#, .Net)",Mastercard,"Pune, India",Mid-level / Intermediate,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Software Engineering Manager (Hadoop, Impala, Spark, C#, .Net)
Our Purpose



We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.



Title And Summary



Manager, Software Engineering (.NET, C#, Bigdata, Hadoop)



Overview



As a Manager, Software Development Engineer in the Mastercard Data & Services Technologies team, you will play a valuable role within a successful and rapidly growing business unit, working closely with experienced and motivated engineers to solve challenging problems. As a member of the Mastercard D&S Technical Foundations Team, you will bring your technical knowledge and full stack development experience to help build, deploy, and scale our data pipeline to support the needs of many analytical products in our ecosystem. The Technical foundations team builds scalable, easy-to-use services and frameworks that provide the foundation for many of Mastercard's customer-facing applications. We work closely with market-facing product engineering teams to help them take maximum advantage of these capabilities and to evolve our platform to meet their needs and the needs of our customers. We are looking for a Software Engineering Manager who is excited to engage deeply with our core technologies, design and implement a highly scalable data pipeline using modern and big-data focused scale-out technologies (distributed storage, scale-out compute, elastic resources in the cloud).

Our engineers work in small, flexible teams. Every team member contributes to feature design, building, and testing. There are no rigid organizational structures at Mastercard; each team uses processes that work the best for that team's members and projects.



Position Responsibilities



Implement scalable and efficient data architectures using technologies like Hadoop, Impala, Spark on-premises.
Evaluate and recommend new technologies and approaches to improve the performance, scalability, and reliability of our software systems
Build out a data pipeline and compute tier that operates on Hadoop and Impala/Spark
Critically review the code and guide the team with a focus on improving the code quality
Lead large scale projects from inception to release
Provides strategic leadership related to engineering process, specific applications and systems, or software-development methodologies
Manage software engineers and serve as a technical resource for team members and mentor junior engineers and team members
Collaborate with partners teams across broader Mastercard (Software Delivery, Corporate Security, Privacy and Data Protection, Global Product Management) to deliver high-quality solutions that meet business requirements
Ensure that code is well-designed, maintainable, and adheres to best practices and standards
Play a key role in shaping the direction of engineering practices through working on a scrum-size team empowered to organize and run the team as they see fit


Additional Tasks As Required



All About you:



Experience in full stack software development with a focus on data-driven applications
Experience with scale-out technologies like Hadoop, Impala, Spark on-premise
Strong understanding of database technologies, proficiency with SQL
Experience working with .NET and C# technologies
Background in big data with hands-on experience with Impala or Spark development
Strong knowledge of the architecture and internals of technologies in the Hadoop ecosystem is a plus
Experience with data modeling and data architecture design
Proficiency with advanced object-oriented programming
Excellent problem-solving and analytical skills
Excellent written and oral communications skills
Ability to mentor and lead junior team members
Bachelor's degree in Computer Science, Computer Engineering, Software Engineering or a related field


Corporate Security Responsibility



Responsibilities



All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must



Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 30K - 56K *
331,Associate Director – Big Data Architect - Engineering,S&P Global,IN - MUMBAI HIRANANDANI BUSINESS PARK UNIT NO 201,Mid-level / Intermediate,"About the Role:
Grade Level (for internal use):
12
S&P Global Ratings is looking for an Associate Director - Big Data Architect to join the Data Lake team within Data Services group, a team of data and technology professionals who define and execute the strategic data roadmap for S&P Global Ratings. The successful candidate will participate in the design and implementation of S&P Ratings cutting edge data services and analytical solutions.
The Team
The Data Lake team is responsible for data ingestion from internal source systems in batch/real-time modes, curation and governance of the data assets created in the platform. The team also works towards adopting the new features of the Databricks product and optimizing the operational aspects of the platform to enhance the user community experience.  The team has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy.
The Impact: You will work alongside a  high visibility team, architect and provide hands-on support to the Rating Organization’s Data Services Product Engineering Team with a unique opportunity to build and evolve S&P Ratings next gen data and analytics platform.
Our Hiring Manager Says
If you are an individual that brings demonstrated experience of architecting and delivering data lake/lakehouse solutions, this is an excellent opportunity. We are looking for someone who has in-depth technical knowledge around data lake systems, is completely hands-on and worked on transformational initiatives for the business.
Responsibilities:                                       
Design & Build data pipelines with an emphasis on scale, performance and reliability.
Provide technical expertise in the areas of design and implementation of Data Lake solution powered by Databricks on AWS cloud.
Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data
Partner with the data teams, enterprise architecture organization to ensure best use of standards for the key data domains and use cases
Continuous learner with an eye on emerging trends around data lake architecture and enterprise data solutions.
Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards
Design and maintain the overall architecture for the product(s)/platform(s) in alignment with enterprise architecture and platform strategy (including architectural roadmaps).
Experience & Qualifications:
BE, MCA or MS degree in Computer Science or Information Technology
10+ years of experience building solutions in big data technologies.
Strong experience programming with more than one of Java, Scala, Python, Spark.
Hands-on experience designing and building streaming data pipelines using Kafka, Confluent etc.
Strong understanding of cloud platforms like AWS, Azure, or GCP, and their services (e.g., EC2, S3, AKS, EKS, etc.).
Must have experience building and leading teams delivering cloud based Data Lake & Data warehouse solutions on Databricks with sound understanding of Delta Lake, DeltaLiveTables, Structured Streaming, Change Data Feed features.
Strong understanding of database and analytical technologies in the industry including MPP and NoSQL databases
Should have a keen eye towards cloud and data storage cost optimizations. 
Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib) is an added advantage.
Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally.
Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management
Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners
Ability to prioritize and manage work to critical project timelines in a fast-paced environment
Financial services industry experience is an added advantage.
Databricks experience or certifications is an added advantage.
AWS or any public cloud certification is a must.
About S&P Global Ratings
At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.
S&P Global Ratings is a division of S&P Global (NYSE: SPGI).  S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.  
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
10 - Officials or Managers (EEO-2 Job Categories-United States of America), IFTECH103.2 - Middle Management Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 30K - 56K *
332,Data Analyst,ANZ Banking Group Limited,"Bengaluru, IN",Entry-level / Junior,"About the role
•        To deeply understand the power of data to generate quality customer insights, manage information, identify trends and make decisions.
•        This critical role represents the engine of our team and enables quality outcomes. Without it we will not be successful.
•        Implement a fact-based culture throughout the bank.
•        Demonstrates in-depth customer insights and acts as an advocate,  enhancing the customer experience by challenging and encouraging others to put the customer first.
•        Maintains commitment to change; engages with others to gain buy-in and act as an advocate for continuous improvement. Proactively identifies, support and drive opportunities for change
•        Continuous generation, monitoring, presenting and conducting of 'fact-based' analysis of relevant customer insights to use at any time for the development and improvement of relevant and innovative propositions.
•        Continuous measurement and analysis of various data risk & customer journeys.
•        Perform data analysis within the team in order to support team goals.
•        Generate, monitor, present and analyse relevant insights and risks for stakeholders of Data Risk.
•        Sourcing data from a variety of sources to combine, synthesise and analyse to generate insights.
•        Support key data platforms and/or data scheduling jobs to support insights delivery to key audiences
•        Lead, Optimise, Design and execute enterprise data & advisory services and capabilities increase adotion of the Data Management, the Data Risk Theme & relevant frameworks to ultimately uplift critical data in ANZ.
What will your day look like
The ‘must have’ knowledge, skill and experience (KSE) the role requires are:
•        A teamplayer –I know we only win if we all win.  I recognise and value the different perspectives and skills my team mates bring. It is not about being a hero but jumping in and contributing to the successful delivery of our mission
•        The customer’s biggest fan –I demonstrate a thirst for better understanding the customer and define the problem and develop solutions through their eyes
•        A collaboration champion–I work closely with my colleagues & stakeholders to ensure alignment and champion the sharing of learning across teams
•        Comfortable being uncomfortable–I am comfortable with uncertainty and have the ability to effectively manage myself through ambiguity by making meaning, building relationships and creating clarity with my peers
•        Continuous improvement junkie –I constructively challenge the status quo, I look for better ways of doing things and passionately advocate continuous improvement
•        Committed to my own and other’s growth –I strive to stretch and grow myself and others by identifying my own development areas, seeking feedback and providing feedback to others to help them learn and grow everyday
•        A problem solver –I am energised by tackling complex problems.  I use my critical thinking, network, skills, knowledge, and available data to drive better outcomes for our customers and the bank
•        Commercially and Tech curious –I have a wide-angled lens.  I am curious about what’s happening in the external market and in emerging trends and innovations (technological and otherwise) and how we use this information to better inform our decisions andactions. 
•        Risk savvy –I build sustainable solutions that protect stakeholders and customers and proactively address risks by role-modelling improvements in the bank’s overall risk and control environment.
What will you bring?
  The ‘good to have’ knowledge, skill and experience (KSE) the role requires are:
  •        Hands-on knowledge and experience with tools and techniques for analysis (eg data warehouses, databases (e.g., SAS, SQL, Cognos, etc.), and data processing tools, analysis, presentation and application
•        Strong ability to translate data insights into practical business recommendations
•        Depending on the team allocation and assignment, a mix of:
•        Dashboarding experience (Qlik, Tableau)
•        Data Platform Engineering and/or Data Operations management
•        Ability to effectively communicate to all stakeholders (technical and non technical)
So, why join us?
It is expected that all our employees behave in way that aligns to our Purpose, Code of Conduct and Values. 
  Our Purpose is to shape a world where people and communities thrive.
  Our Code of Conduct helps each of us to make fair, balanced and ethical decisions in our day-to-day work, building our reputation as a bank we can all be proud of.
  Our Values are what we call our “ticket to play, that means our people have integrity and do the right thing by our customers, community, colleagues and partners. We work collaboratively, take accountability, are always respectful, and aspire to excellence as we shape a world where people and communities thrive.
Job Posting End Date",USD 54K - 94K *
333,Data Scientist II,Mastercard,"Gurgaon, India",Entry-level / Junior,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Scientist II
Job Description – Data and Analytics Team – Data Scientist II
Overview
Data and Analytics has pioneered a transaction based revenue methodology to inform and guide Mastercard’s Strategy, Product Design and Innovation within the Products & Innovation business. We
build internal analytic partnerships, strengthening their focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market
strategies.
• Are you excited about Data Assets and the value they brings to an organization?
• Are you an evangelist for data driven decision making?
• Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across 6 continents?
• Do you want to be the go-to resource for data analytics in the company?
Role
• Work closely with Global Send team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data in order to support team analytics and reporting needs across products, markets and services.
• Translate business requirements into tangible solution specifications and high quality, on time deliverables
• Create repeatable processes to support development of modeling and reporting
• Effectively use tools to manipulate large-scale databases, synthesizing data insights. Provide 1st level insights/conclusions/assessments and present findings via Excel and PowerPoint.
• Apply quality control, data validation, and cleansing processes to new and existing data sources

All About You
• Experience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis
• Financial Institution or a Payments experience a plus
• Experience presenting data findings in a readable and insight driven format. Experience building support decks.
• Advanced SQL coding
• Experience on Platforms/Environments: SQL Server, Microsoft BI Stack
• Experience on SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS) and SQL Server Reporting Services (SSRS) will be an added advantage
• Experience in building data models a plus
• Experience with data visualization tools such as Tableau, Domo, PowerBI a plus
• Experience with Hadoop environments, Python, R, WPS, a plus
• Excellent problem solving, quantitative and analytical skills
• In depth technical knowledge, drive and ability to learn new technologies
• Strong attention to detail and quality
• Team player, excellent communication skills
• Must be able to interact with management, internal stakeholders and collect requirements
• Must be able to perform in a team, use judgment and operate under ambiguity

Education
•Bachelor’s or Master’s Degree in a Computer Science, Information Technology, Engineering,Mathematics, Statistics, M.S./M.B.A. preferred

Additional Competencies
•Excellent English, quantitative, technical, and communication (oral/written) skills
•Analytical/Problem Solving
•Strong attention to detail and quality
•Creativity/Innovation
•Self-motivated, operates with a sense of urgency
•Project Management/Risk Mitigation
•Able to prioritize and perform multiple tasks simultaneously
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 126K - 198K *
334,Data Engineer,Zscaler,"Mohali, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Job Description
Responsibilities/What You’ll Do
Collaborate with Data & Technical architects, integration and engineering teams to capture inbound/outbound data pipeline requirements, conceptualize and develop solutions.
Support the evaluation and implementation of the current and future data applications/technologies to support the evolving Zscaler business needs.
Collaborate with IT business engagement & applications engineer teams, enterprise data engineering and business data partner teams to identify data source requirements.
Profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating into Zscaler’s data warehouse in Snowflake.
Continuously optimize existing data integrations, data models and views while developing new features and capabilities to meet our business partners needs.
Work with Data Platform Lead to design and implement data management standards and best practices.
Continue to learn and develop next generation technology/ data capabilities that enhance our data engineering solutions.
Develop large scale and mission-critical data pipelines using modern cloud and big data architectures.
Qualifications
3 - 5 years of experience in data warehouse design & development.
Proficiency in building data pipelines to integrate business applications (salesforce, Netsuite, Google Analytics etc) with Snowflake
Must have proficiency in SQL and data modeling techniques (Dimensional) – able to write structured and efficient queries on large data sets
Must have hands-on experience in Python to extract data from APIs, build data pipelines.
Strong hands-on experience in ELT Tools like Matillion, Fivetran, Talend, IDMC (Matillion preferred) , data transformational tool – DBT and in using AWS services like EC2, s3, lambda, glue.
Solid understanding of CI/CD process, git versioning, & advanced snowflake concepts like warehouse optimizations, SQL tuning/pruning
Experience in using data orchestration workflows using open-source tools like Apache Airflow, Prefect
Knowledge of data visualization tools such as Tableau, and/or Power BI
Must demonstrate good analytical skills, should be detail-oriented, team-player and must have ability to manage multiple projects simultaneously.
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 121K - 186K *
335,Data Scientist - Machine Learning Operations (MLOps) Job,Yash Technologies,"Hyderabad, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Machine Learning Operations (MLOps) Professionals in the following areas :
  Experience
5-8 Years
Job Description
Design and implement cloud solutions, build MLOps on cloud (Azure, AWS)
Build CI/CD pipelines orchestration by GitLab CI, GitHub Actions, Circle CI, Airflow or similar tools
Data science model review, run the code refactoring and optimization, containerization, deployment, versioning, and monitoring of its quality
Data science models testing, validation and tests automation
Communicate with a team of data scientists, data engineers and architect, document the processes
Experience with large dataset processing, querying and creating descriptive and diagnostic Dashboards and Reports
Experience in leading and implementing complex data science projects
Developed a state-of-the-art Data Science and ML runtime stack in a multi-cloud environment
Convert proof of concepts to production-grade solutions that is scalable
Devise and strategies to ensure ML heavy systems operate with high accuracy in Production and adapt to discovered needs
Research and implement best practices to improve existing Machine Learning infrastructure
Perform research and rapid iterations of development to refine posed problems and identify potential solutions
Experience with various classifications of data including Personally Identifiable Information (PII) and access, audit, and compliance/governance of same.
Primary Skills
Python, R, DataIku, Azure DataBricks, Azure data factory, Azure ML services
ML flow, Model monitoring platforms like Fiddler
Azure DevOps, Azure Web App, Data Robot, Azure Event Hub
Key Scanners
Python, R, DataIku, Azure DataBricks, Azure data factory, Azure ML services
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 136K - 205K *
336,Associate Data Engineer,Novo Nordisk,"Bengaluru, Karnataka, IN",Mid-level / Intermediate,"      Department – Digital Supply Chain
    Does your motivation come from challenges and working in a dynamic environment? Do you thrive in a working environment where close collaboration with key stakeholders and strategic alignment is essential? Do you have a can-do attitude with continuous improvement as one of your career objectives? Then we might have the right position for you. Apply now and join a growing team, working in an international environment. Apply Now!
  The Position 
As Data Engineer, your responsibility is to enable movement of existing data-lake (SQL server) to a cloud-based environment and transforming existing ETL using latest AWS technologies. You will be entrusted with below major responsibilities:
Work with transactional data extracted from different ERP systems and develop and maintain ETL pipelines delivering data for reporting and advanced analytics.
Further, develop, maintain, test, and evaluate data solutions within organizations what the data scientists and the data stewards have defined.
Create documentation & guiding material.
 
  Qualifications
You hold a Masters/Bachelors with have 2-6 years of experience in Data and Analytics and overseen end-to-end implementation of data pipelines on cloud-based data platforms.
Strong programming skills in Python, PySpark, SQL and Spark SQL. Included object-oriented programming and concepts.
Experience in AWS and API Integration/Integration in General with Knowledge of data warehousing concepts.
You have project experience writing SQL queries transforming and structuring data, and data storage practices.
Project experience working on Amazon Web Services (in particular, using EMR, Kinesis, RDS, S3, SQS, Lambda, Glue, Databricks, Redshift, Athena and similar).
Support use of data engineering toolsets (e.g., Python (especially PySpark), SQL, Notebooks).
Knowledge of business intelligence tool packs such (Alteryx, Tableau, SAP BI) is preferred.
Experience with SAP Master Data Management (MDM) is preferred.


  About the department

Supply Chain was established in March 2017 as part of Product Supply Devices & Supply Chain Management business plan towards 2020. The Business plan has three parts; Robust, Ready, Effective and Supply Chain Global Business Services (GBS) is part of the last one focusing business through offshoring. The unit is anchored under Supply Chain Planning (SCP) in Head Quarter and is the agreed place to consolidate Supply Chain activities across Novo Nordisk. The Supply Chain offshoring journey has started in D&S, Service Delivery Catalogue is taking form and other areas within Product Supply can soon join or add to the Catalogue to optimise costs and reduce complexity by operating an effective supply chain.
  Working at Novo Nordisk
We are a proud life-science company, and life is our reason to exist. We’re inspired by life in all its forms and shapes, ups and downs, opportunities, and challenges. For employees at Novo Nordisk, life means many things – from the building blocks of life that form the basis of ground-breaking scientific research, to our rich personal lives that motivate and energise us to perform our best at work. Ultimately, life is why we’re all here - to ensure that people can lead a life independent of chronic disease.
  Contact
To submit your application, please upload your CV online (click on Apply and follow the instructions).
Apply Now!
  Deadline
15th January 2024.
    We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 90K - 152K *
337,"Senior Software Engineer - Java, BigData, Distributed",Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Qualifications
What you will do:
Development of our large-scale distributed platform by leveraging Java technology stack, Streaming, event-driven architecture, and NoSQL databases.
Develop and implement best engineering practices to optimize team productivity and delivery timelines.
Manage and mentor a team of highly skilled engineers to deliver high-quality software.
You will be responsible for product features related to data transformations, enrichment, and analytics
You will discuss with product managers, UX designers, and other backend teams to understand requirements and translate the same into functional specifications 
You will seize every opportunity to refactor code in the interests of maintainability and reusability
Lead and provide technical direction and mentorship to junior engineers and bring out the best in them
The ideal candidate has a proven track record of building large scale enterprise products, and is a creative thinker, problem solver, learner, and a fantastic manager of people, and is motivated with engineering excellence.
Requirements:
Education: BS Computer Science or Equivalent
Minimum 14+ years of software development experience
Experience in Core Java, Concurrency, Distributed Computing and Scalable web services
Experience in building and managing high performing engineering teams.
Excellent communication skills with the ability to collaborate effectively with cross-functional teams.
Responsible for all stakeholder management including but not limited to business, product, and operations.
Hiring, mentoring, and retaining a best-of-class engineering team
Experience using batch and stream processing frameworks like Spark/Kafka Streaming, Spring batch or equivalent
Proficiency with Tomcat installation and configuration.
Proficiency with Maven (preferred) or Gradle builds and dependency management systems.
Experience with CI & CD systems such as Jenkins or Bamboo
Metrics-driven development experience and experience using metrics systems like Grafana, Prometheus, etc
Desired skills:
Ability to write code that can perform efficiently in a big data setup
Experience with big-data technologies like Spark, Redshift, etc.
Strong knowledge of various DBMS systems including NoSQL architectures and design principles
Experience tuning JVM for optimal application performance
Successfully delivered software products from ideation through to implementation and support
Experience with any Graph Database like AWS Neptune, Neo4j, Spark Graphx, etc.
Understanding of statistics and machine learning
#LI-YK1
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 31K - 58K *
338,Sr. BI Analyst,AkzoNobel,"Pune, IN",Senior-level / Expert,"We supply the sustainable and innovative paints and coatings that our customers, communities – and the environment – are increasingly relying on. Our world class portfolio of brands – including Dulux, International, Sikkens and Interpon – is trusted by customers around the globe. We’re active in more than 150 countries and have set our sights on becoming the global industry leader. It’s what you’d expect from a pioneering paints company that’s committed to science-based targets and is taking genuine action to address globally relevant challenges and protect future generations.
For more information please visit www.akzonobel.com.
© 2023 Akzo Nobel N.V. All rights reserved.
Job Purpose
The Senior BI Analyst is responsible for developing, maintaining, and leading the execution of the analytics solutions to improve performance and achieve the future vision of stakeholders. Senior BI Analyst reports into the Analytics Manager of GBS - Business Insights team
  You will be partnering with various business teams to understand the analytics needs, collaborate with the IT organization to build data driven – Analytics solutions.  You will also be responsible for the end-to-end delivery of descriptive, diagnostic, predictive & prescriptive analytics solutions for stakeholders.
Key Accountabilities
Business partnering with all the key senior leaders in the organization to determine opportunities / requirements for Data analytics solutions that can drive revenue growth, operational efficiencies, customer value etc.
Project Management: Should be able to independently manage several projects, track actions and reach out to stakeholders when needed.
Solution design & development:
Develop new solution using BI Tools (Power BI, SAP analytics Cloud)
Build wireframes, proof-of-concepts
Translate business logic to technical calculations that will help the technical team to build the metrics
Fetch and embed data from SAP HANA, BW, Azure SQL, Excel, flat files, Sharepoint list etc.
Perform data transformation, engineering, [joint, exclusion, enrichment, pivoting, etc.]  using SQL, Databricks Pyspark,
Automate process using Power Automate, Sharepoint list
Integrate & prepare multi sourced - complex data efficiently
Experience
Academic and professional background:
Bachelors or master’s degree in analytics, Business, or finance from a premier institute
Minimum 6+ years work experience in Data analytics & visualization roles in a global or multinational environment
  Skillset and professional experience:
Highly skilled in communication and collaboration, with experience in working with cross-functional teams and presenting data insights to executive stakeholders.
Capable of working independently to identify business problems and opportunities that can be addressed through data analysis.
Highly skilled in data analysis and modeling, with the ability to work with large datasets and complex data structures.
Exceptional in creating visualizations in PowerBI (+DAX) that effectively communicate complex data insights to non-technical audience.
Proficient in using SQL, and other data analysis tools.
Skilled in programming languages such as PySpark for Databricks, Python or R, with experience in data wrangling, data cleaning, and statistical analysis. Has a deep understanding of data modeling and can work with complex data structures.
Education
Please add the content for the advert here
Competencies
Accepting Direction
Accepting Responsibility
Acquiring Information
At AkzoNobel we are highly committed to ensuring an inclusive and respectful workplace where all employees can be their best self. We strive to embrace diversity in a context of tolerance. Our talent acquisition process plays an integral part in this journey, as setting the foundations for a diverse environment. For this reason we train and educate on the implications of our Unconscious Bias in order for our TA and hiring managers to be mindful of them and take corrective actions when applicable. In our organization, all qualified applicants receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age or disability.
Requisition ID: 36473 ",USD 110K - 150K *
339,"Senior Data Visualization Engineer, Clinical Operations and Real World Data",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Position: Senior Data Visualization Engineer, Clinical Operations and Real World Data
Location: Hyderabad, India
At Bristol Myers Squibb, we are inspired by a single vision – transforming patients’ lives through science. In oncology, hematology, immunology, and cardiovascular disease – and one of the most diverse and promising pipelines in the industry – each of our passionate colleagues contribute to innovations that drive meaningful change. We bring a human touch to every treatment we pioneer. Join us and make a difference.     
Position Summary
At BMS, digital innovation and Information Technology are central to our vision of transforming patients’ lives through science. To accelerate our ability to serve patients around the world, we must unleash the power of technology.  We are committed to being at the forefront of transforming the way medicine is made and delivered by harnessing the power of computer and data science, artificial intelligence, and other technologies to promote scientific discovery, faster decision making, and enhanced patient care.   
If you want an exciting and rewarding career that is meaningful, consider joining our diverse team!
As a Senior Data Visualization Engineer based out of our BMS Hyderabad Office, you are part of the (DD) Drug Development data team that delivers data and analytics capabilities for Clinical Operations and Real World Data functions. The ideal candidate will have a strong background in designing and improving the user experience of data products and services. The role involves a combination of creative and analytical skills, as well as an understanding of user behavior, and technology.
Key Responsibilities
The Senior Data Visualization Engineer will be responsible for analyzing, designing, and developing data products that meet the needs of stakeholders.
Develop project and portfolio user interfaces like report visualizations and dashboards as a key capability and value driver.
User research: Conducting user research to understand user needs, behaviors, and pain points. This may involve surveys, interviews, and usability testing.
Designing user interfaces: Designing user interfaces that are intuitive, user-friendly, and visually appealing. This may involve wireframing, prototyping, and creating high-fidelity designs to enhance user experience.
Information architecture: Creating information architecture that organizes information and content in a way that is easy to access and navigate.
Usability testing: Conducting usability testing to evaluate the effectiveness of user interfaces and make improvements.
Collaboration with stakeholders: Collaborating with product managers, developers, and other stakeholders to ensure that the user experience aligns with business objectives and technical requirements.
Accessibility: Ensuring that digital products and services are accessible to users with disabilities and comply with accessibility guidelines.
Help analyze data multiple sources of spectrum-related information, recommend, and develop reports, and coach stakeholders on visualization enhancements for our products
Staying up to date with industry trends: Keeping up to date with the latest trends and advancements in UX design and technology, and applying this knowledge to enhance the organization's UX design capabilities.
Responsible for the development of KPIs to assess health of the portfolio including time, financial & quality at the study, program, and portfolio level.
Serves as the Subject Matter Expert on GDD Data & Analytics Solutions and build domain knowledge of the DD specific area
Comfortable working in a fast-paced environment with minimal oversight
Mentors other team members effectively to unlock full potential.
Prior experience working in an Agile/Product based environment.
Provides strategic feedback to vendors on service delivery and balances workload with vendor teams.
Qualifications & Experience
Degree in Computer Science, Design & Engineering, Biotechnology, or a related field.
4-6 years proven working experience as a product Data Visualization Engineer and/or Visualization developer.
4-6 years Hands on experience and high proficiency in Data Visualization / BI Tools like Tableau, SpotFire and/or R-Shinny etc.
Experience with rapid wireframing, prototyping and storyboarding tools like Miro boards, and Figma tool set
Fluent in Front-end products (React, Angular) on modern JS and web technologies including various delivery modalities, iOS/Android/Web, Speech, Chatbot etc., like technologies.
Experience designing for both responsive and fixed size applications.
Ability to wireframe, prototype, apply Design thinking principles and validate data products.
At least 3 years technical expertise in product design and development, data visualization techniques
Knowledge of statistics, data sciences and experience using statistical packages for analyzing datasets (SAS, R, R-Shiny etc.) is a plus.
Familiarity with database and ETL processes from Information management and consumption standpoint is needed. 
Experience with cloud-based data technologies such as Tableau Cloud, AWS, Azure, or Google Cloud Platform
Strong analytical and problem-solving skills
Excellent communication and collaboration skills Functional knowledge or prior experience in Lifesciences Research and Development domain is a plus.
Experience and expertise in establishing agile and product-oriented teams that work effectively with teams in the US and other global BMS sites.  
Initiates challenging opportunities that build strong capabilities for self and team.
Demonstrates a focus on improving processes, structures, and knowledge within the team. Leads in analyzing current states, deliver strong recommendations in understanding complexity in the environment, and the ability to execute to bring complex solutions to completion.
Why You Should Apply
Around the world, we are passionate about making an impact on the lives of patients with serious diseases. Empowered to apply our individual talents and diverse perspectives in an inclusive culture, our shared values of passion, innovation, urgency, accountability, inclusion, and integrity bring out the highest potential of each of our colleagues.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives.
Our company is committed to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace adjustments and ongoing support in their roles. Applicants can request an accommodation prior to accepting a job offer. If you require reasonable accommodation in completing this application, or any part of the recruitment process direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement. 
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
340,EY - GDS Consulting - Data Analytics - Data Modelliing - Senior,EY,"Pune, MH, IN, 411014",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        EY-Consulting - Data and Analytics – Senior - Data Modeller
  EY's Consulting Services is a unique, industry-focused business unit that provides a broad range of integrated services that leverage deep industry experience with strong functional and technical capabilities and product knowledge. EY’s financial services practice provides integrated Consulting services to financial institutions and other capital markets participants, including commercial banks, retail banks, investment banks, broker-dealers & asset management firms, and insurance firms from leading Fortune 500 Companies. Within EY’s Consulting Practice, Data and Analytics team solves big, complex issues and capitalize on opportunities to deliver better working outcomes that help expand and safeguard the businesses, now and in the future. This way we help create a compelling business case for embedding the right analytical practice at the heart of client’s decision-making.
  The opportunity
  We’re looking for a candidate with 3-8 years of expertise in data science, data analysis and visualization skills.Act as Technical Lead to a larger team in EY GDS DnA team to work on various Data and Analytics projects
  Your key responsibilities
  Work as a Senior team member to contribute in various technical streams EY DnA implementation project.
Client focused with good presentation, communication and relationship building skills.
Completion of assigned tasks on time and regular status reporting to the lead
Collaborate with technology team and support the development of analytical models with the effective use of data and analytic techniques and validate the model results and articulate the insights to the business team
Interface and communicate with the onsite teams directly to understand the requirement and determine the optimum solutions
Create technical solutions as per business needs by translating their requirements and finding innovative solution options
Provide product and design level functional and technical expertise along with best practices
Get involved in business development activities like creating proof of concepts (POCs), point of views (POVs), assist in proposal writing and service offering development, and capable of developing creative power point content for presentations
Participate in organization-level initiatives and operational activities
Ensure continual knowledge management and contribute to internal L&D teams
Building a quality work culture and Foster teamwork and lead by example
  Skills and attributes for success
  Use an issue-based approach to deliver growth, market and portfolio strategy engagements for corporates
Strong communication, presentation and team building skills and experience in producing high quality reports, papers, and presentations.
Experience in executing and managing research and analysis of companies and markets, preferably from a commercial due diligence standpoint
  To qualify for the role, you must have
  BE/BTech/MCA/MBA with 3 - 7 years of industry experience with machine learning, visualization, data science and related offerings.
At least around 3-8 years of experience in BI and Analytics.
To be have ability to do end to end data solutions from analysis, mapping, profiling, ETL architecture and data modelling.
Knowledge and experience of at least 1 Insurance domain engagement life or Property n Causality.
Understanding of Business Intelligence, Data Warehousing and Data Modelling.
Good experience using CA Erwin or other similar modelling tool is absolute must.
Experience of working in Guidewire DataHub & InfoCenter skills.
Strong knowledge of relational and dimensional data modelling concepts
Develop logical and physical data flow models for ETL applications.
Translate data access, transformation and movement requirements into functional requirements and mapping designs.
Strong knowledge of data architecture, database structure , data analysis  and SQL skills
Experience in data management analysis. Analyse business objectives and evaluate data solutions to meet customer needs.
Establishing scalable, efficient, automated processes for large scale data analyses and management
Prepare and analyse historical data and identify patterns
To collaborate with technology team and support the development of analytical models with the effective use of data and analytic techniques.
To validate the model results and articulate the insights to the business team.
Drive the Business requirements gathering for analytics projects
Intellectual curiosity - eagerness to learn new things
Experience with unstructured data is added advantage
Ability to effectively visualize and communicate analysis results
Experience with big data and cloud preferred
Experience, interest and adaptability to working in an Agile delivery environment.
Ability to work in a fast-paced environment where change is a constant and ability to handle ambiguous requirements
Exceptional interpersonal and communication skills (written and verbal)
Ideally, you’ll also have
  Good exposure to any ETL tools.
Good to have knowledge about P&C insurance.
Understanding of Business Intelligence, Data Warehousing and Data Modelling.
Must have led a team size of at least 4 members.
Experience in Insurance and Banking domain
Prior Client facing skills, Self-motivated and collaborative
  What we look for
  A Team of people with commercial acumen, technical experience and enthusiasm to learn new things in this fast-moving environment
An opportunity to be a part of market-leading, multi-disciplinary team of 1400 + professionals, in the only integrated global transaction business worldwide.
Opportunities to work with EY Consulting practices globally with leading businesses across a range of industries
  What working at EY offers
  At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
  Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you
  About EY
  As a global leader in assurance, tax, transaction and Consulting services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.
  If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.
  Join us in building a better working world. 
  Apply now
  EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 45K - 84K *
341,DET AI Lead GDSN,EY,"Kolkata, WB, IN, 700091",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        EY-IoT Senior – Consulting
  As part of our GDS Consulting team, you will be part of Digital & Emerging team delivering to clients across regions.
The client base spans across various sectors and includes collaboration with other teams within Consulting services.
  The opportunity
  Technical Lead in Technology Consulting to work closely with IoT team responsible for delivering a best-in-class on-premises and cloud capability for the products and platforms for our customers across the globe on IoT (Internet of Things) space. This is a fantastic opportunity to be part of a leading firm whilst being instrumental in the growth of our service offering.
  Your key responsibilities
  Be with a forward-thinking organisation at the forefront of AI and machine learning innovation.
Build and optimize distributed systems that can scale for large volumes of data.
 Architect, design and develop scalable, fault-tolerant services on prem or cloud
You should know how to clean and prepare data for analysis. This includes removing errors, identifying outliers, and transforming data into a format that can be analysed.
 Design broad distributed system interactions and optimize any part of the stack including low level systems
 Leverage and contribute to relevant open-source cloud native projects
  Skills and attributes for success
  Strong coding experience in one or more languages: Go, Python etc.
Candidate must have experience around Data Analysis, Algorithm Design, Machine Learning Models, Statistical Analysis, Data Visualization, Deep Learning
 Good understanding of data structure and algorithms.
Working experiences on visual analytics and on-prem edge analytics
Knowledge of database systems like MySQL, PostgreSQL, Oracle, or MS SQL.
 Strong experience in docker, kubernetes and cloud native technologies
 Strong understanding of datacenter design including compute, storage, and networking
 Familiarity with on prem, cloud and hybrid software deployment architectures
 Strong understanding of distributed compute and storage architectures
 Strong understanding of OS internals, virtualization, application performance monitoring, compute storage, networking management.
 Familiarity with machine learning concepts and popular frameworks (like Tensorflow, PyTorch etc) is a strong plus
 Experience with hardware accelerators like GPU is a strong plus.
 Experience in working with large codebases or contribution to open source is a strong plus.
 Experience in building full stack multi-tenant services on a virtualized infrastructure is a very strong plus.
  To qualify for the role, you must have
BE/BTech/MTech with a sound industry experience of 3 to 6 Years
Proven experience as a technical lead in AI and NLP projects.
Strong expertise in genAI frameworks and tools.
Relevant professional certifications: Cloud: Microsoft DP-100, AI-900
Excellent communication skills with consulting experience preferred
  Ideally, you’ll also have
  Experience in domains like Manufacturing, P&U, Healthcare, Supply Chain, Automotive
Have a service-oriented attitude with strong interpersonal skills
Strong interpersonal and communication skills; ability to work in a team environment
Ability to work independently with minimal direction; self-starter/self-motivated
Quick learner, adaptability in a highly moving and fast-growing environment
Able to guide / influence the work of others
Resourceful & proactive: take initiative & act
    What working at EY offers
  At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
  Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you
        EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 45K - 84K *
342,Senior Data Scientist,Mastercard,"Gurgaon, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Scientist
Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.

Job Title
Senior Data Scientist

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Our Team:
As consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Solutions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.
• Are you excited about Data Assets and the value they bring to an organization?
• Are you an evangelist for data-driven decision-making?
• Are you motivated to be part of a team that builds large-scale Analytical Capabilities supporting end users across 6 continents?
• Do you want to be the go-to resource for data science & analytics in the company?


The Role:
• Work closely with global optimization solutions team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support data insights and analytical needs across products, markets, and services
• Develop and implement a test-and-learn strategy to improve the performance of marketing campaigns
• Design and run experiments to test different marketing strategies and tactics
• Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.
• Drive the evolution of products with an impact focused on data science and engineering.
• Perform data ingestion, aggregation, and processing on high volume and high dimensionality data to drive and enable data unification and produce relevant insights.
• Continuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations.
• Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.

All about You
• A superior academic record at a leading university in Computer Science, Data Science, Technology, mathematics, statistics, or a related field or equivalent work experience
• Prior experience working in a product development role and campaign analytics.
• High proficiency in using Python/Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), and SQL to build Big Data products & platforms
• Demonstrated success interacting with stakeholders to understand technical needs and ensuring analyses and solutions meet their needs effectively.
• Ability to build a strong narrative on the business value of products and actively participate in sales enablement efforts.
• Able to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor.
• Ability to easily move between business, analytical, and technical teams and articulate solution requirements for each group.
• Experience with Enterprise Business Intelligence Platform/Data platform i.e. Tableau, PowerBI is a plus.
• Prior experience as a machine learning resource and with open-source tools is a plus
• Knowledge of ML frameworks, libraries, data structures, data modeling, and software architecture is a plus.
• Experience on Cloud Data Platforms Azure/AWS will be a plus.

Education
• Bachelor’s or Master’s Degree in a Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred

Additional Competencies
• Excellent English, quantitative, technical, and communication (oral/written) skills
• Analytical/Problem Solving
• Strong attention to detail and quality
• Creativity/Innovation
• Self-motivated, operates with a sense of urgency
• Project Management/Risk Mitigation
• Able to prioritize and perform multiple tasks simultaneously
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 136K - 205K *
343,Senior Software Engineer - Big Data,S&P Global,IN - MUMBAI HIRANANDANI BUSINESS PARK UNIT NO 201,Senior-level / Expert,"About the Role:
Grade Level (for internal use):
09
S&P Global Ratings is looking for a Senior Big Data Engineer to join the Data Lake team within Data Services group, a team of data and technology professionals who define and execute the strategic data roadmap for S&P Global Ratings. The successful candidate will participate in the design and build of S&P Ratings cutting edge data services and analytical solutions.
The Team
The Data Lake team is responsible for data ingestion from internal source systems in batch/real-time modes, curation and governance of the data assets created in the platform. The team also works towards adopting the new features of the Databricks product and optimizing the operational aspects of the platform to enhance the user community experience.  The team has a broad and expert knowledge on Ratings organization’s critical data domains, technology stacks and architectural patterns, fosters knowledge sharing and collaboration that results in a unified strategy. 
The Impact
You will be an expert contributor and part of the Rating Organization’s Data Services Product Engineering Team with a unique opportunity to build and evolve S&P Ratings next gen data and analytics platform.
Our Hiring Manager Says
If you are an individual that brings demonstrated experience of delivering big data projects as a data engineer, this is an excellent opportunity. We are looking for someone who is passionate about data wrangling and analysis and is a polyglot in data analysis related programming languages. 
Responsibilities:    
•    Design & Build data pipelines with an emphasis on scale, performance and reliability.
•    Provide technical expertise in the areas of design and implementation of Data Lake solution powered by Databricks on AWS cloud.
•    Ensure data governance principles adopted, data quality checks and data lineage implemented in each hop of the data
•    Partner with the data teams, enterprise architecture organization to ensure best use of standards for the key data domains and use cases
•    Continuous learner with an eye on emerging trends around data lake architecture and enterprise data solutions.
•    Ensure compliance through the adoption of enterprise standards and promotion of best practice / guiding principles aligned with organization standards

Experience & Qualifications:
•    BE, MCA or MS degree in Computer Science or Information Technology
•    4+ years of experience building solutions in big data technologies.
•    3+ years of experience in data transformation and analysis with one or more of Scala, Python, Spark and related libraries.
•    Strong foundational understanding on data models and query languages.
•    Experience in continuous delivery through CI/CD pipelines, containers and orchestration technologies. 
•    Experience building streaming data pipelines using Kafka, Confluent etc is an added advantage. 
•    Experience With Machine Learning Libraries and Frameworks (TensorFlow, MLlib) is an added advantage.
•    Expert knowledge of Agile approaches to software development and able to put key Agile principles into practice to deliver solutions incrementally.
•    Monitors industry trends and directions; develops and presents substantive technical recommendations to senior management
•    Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners
•    Financial services industry experience is an added advantage.
•    Databricks experience or certifications is an added advantage.
•    AWS or any public cloud certification is an added advantage.
About S&P Global Ratings
At S&P Global Ratings, our analyst-driven credit ratings, research, and sustainable finance opinions provide critical insights that are essential to translating complexity into clarity so market participants can uncover opportunities and make decisions with conviction. By bringing transparency to the market through high-quality independent opinions on creditworthiness, we enable growth across a wide variety of organizations, including businesses, governments, and institutions.
S&P Global Ratings is a division of S&P Global (NYSE: SPGI).  S&P Global is the world’s foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the world’s leading organizations navigate the economic landscape so they can plan for tomorrow, today.

For more information, visit www.spglobal.com/ratings
What’s In It For You?
Our Purpose:
Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology–the right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence®, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People:
We're more than 35,000 strong worldwide—so we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We’re committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We’re constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.
Our Values:
 Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits:
We take care of you, so you can take care of business. We care about our people. That’s why we provide everything you—and your career—need to thrive at S&P Global.

Our benefits include: 
Health & Wellness: Health care coverage designed for the mind and body.
Flexible Downtime: Generous time off helps keep you energized for your time on.
Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.
Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.
Family Friendly Perks: It’s not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.
Beyond the Basics: From retail discounts to referral incentive awards—small perks can make a big difference.
For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/
Diversity, Equity, and Inclusion at S&P Global:
At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation – Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn’t stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.  
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 45K - 84K *
344,"Associate Director, Data Science",Alcon,Bengaluru - AGS,Mid-level / Intermediate,"Summary of Position:
A career at Alcon is like no other.  We are innovative.  We are impactful.  We are the largest eye care medical device company helping restore sight and allowing millions of people worldwide to see brilliantly. We have a long history of industry firsts and a diverse highly talented team that keeps us on the cutting edge.
We are currently hiring an Associate Director, Data Science at our AGS Bangalore. This strategic and inquisitive person will develop and run with data-centered projects. In keeping with this overarching aim, the Sr. Manager will be required to outline work requirements, provide guidance to the team on active projects, and harness their mastery of Data Science to consult on high value, high visibility use cases.
Key Responsibilities:
Formulating, suggesting, and managing data-driven projects which are geared at furthering the business's interests.
Collaborate with Data Strategy team to collate and clean data from various entities for later use
Selecting and employing advanced statistical procedures to obtain actionable insights.
Cross-validating models to ensure their generalizability.
Delegating tasks to Data Scientists and Analysts in order to realize the successful completion of projects.
Producing and disseminating non-technical reports that detail the successes and limitations of each project – Analytics Translation.
Suggesting ways in which insights obtained might be used to inform business strategies.
Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant.
Mentoring a data science team and delivering on key use cases across Sales/Marketing, Supply Chain and Finance
Key Requirements/Minimum Requirements:
Bachelor’s Degree or Equivalent years of directly related experience (or high school+15 yrs; Assoc.+11 yrs; M.S.+5 yrs; PhD+3 yrs)
The ability to fluently read, write, understand and communicate in English
7 Years of Relevant Experience
Experience as a leader and mentor on a data science team
Experience with statistical models e.g. ARIMA, multinomial logistic regression, Neural Nets, etc.
Experience managing data pipelines and/or model maintenance and registry.
Masters degree in Data science, Business Administration or related degree
Strong analytical skills and technical problem solving
Solid experience in building code and models
Project Management experience
Experience with tools such as: Python, SQL, AWS, Sagemaker, Domino, etc
Work hours: 1 PM to 10 PM IST
Relocation assistance: Yes
Employment Scams: Alcon is aware of employment scams which make false use of our company name or leader’s names to defraud job seekers. Alcon does not offer any positions without interview and never asks candidates for money. All our current job openings are displayed here on the Careers section of our website, where you can search for open positions and apply directly.
If you have encountered a job posting or been approached with a job offer that you suspect may be fraudulent, we strongly recommend you do not respond, send money or personal information, and check our website for current job openings.
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 110K - 223K *
345,Principal Data Engineer,GSK,Bengaluru,Senior-level / Expert,"At GSK we are building a best-in-class data and prediction powered team that is ambitious for patients.
Scientific Digital and Tech’s goal is to power the discovery, development and supply of medicines and vaccines to patients. This means new tools to discover new medicines and vaccines, predictive capability for pre-clinical research, accelerated CMC and supply chain and an improved day-to-day laboratory experience for our scientists. Our Digital & Tech solutions will automate workflows and speed up decisions; freeing hands and releasing minds to focus on science. 
As R&D enters a new era of data driven science, we are building a data engineering capability to ensure we have high quality data captured with context and aligned data models, so that the data is useable and reusable for a variety of use cases. 
GSK R&D and Digital and Tech’s collective goal is to deliver business impact, including the acceleration of the discovery and development of medicines and vaccines to patients.  The R&D Digital and Tech remit has expanded over the past 2 years, and to position GSK for the future, The change will strengthen R&D Tech, to provide more strategic impact, focus, accountability, and improved decision making in the use of Digital, Data and Analytics (DDA) to strengthen the pipeline.
Job Purpose
This role contributes to the construction of the development data fabric and data strategy. This role will interact with architects, engineers, data modelers, product owners as well as other team members in Clinical Solutions and R&D. This role will actively participate in creating technical solutions, designs, implementations & participate in the relentless improvement of R&D Tech systems in alignment with agile and DevOps principles.
The Data Engineer demonstrates both depth and breadth across key data engineering competencies e.g. Software Development, Testing, DevOps, Data Science/Analytics, and cloud. Can collaborate with experts from other subject domains. Primary responsibilities include using Azure cloud services and GSK data platform tools to ingest, egress, and transform data from multiple sources.
In addition, the role will demonstrate core engineering knowledge/experience of industry technologies, practices, and frameworks such as data fabric and scaling data platforms, containerization, cloud-based platforms, data analytics, machine learning, and data streaming.  Examples of technologies include Java/C#/Python, Denodo, GIT, Azure Devops, Data Bricks, Presto, Spark, Azure Data Factory, ADLS V2, Kafka, Selenium, JUnit/NUnit, SAFe, Kanban, Docker, AI/ML, Azure/GCP Cloud Architecture including networking principles and scaling applications. 
The Data Engineer, Clinical Solutions role is a senior technical role and will provide you the opportunity to lead key activities to progress your career.  These responsibilities include the following:
Working with other teams that are defining devops and data platform practices to meet the requirements of clinical solutions.
Supporting engineering teams in the adoption and creation of data fabric best practices.
Conducting PoCs of new technologies and helping to embed them in product teams
Being part of a cutting-edge team creating the Development Data Fabric
Ensures that technical delivery is fully compliant with GSK Security, Quality and Regulatory standards
Ensures use of relevant R&D Tech / central services and collaborating with service partners in identification and delivery of service improvements
Maintains best practices for engineering and architecture on our Confluence site. This requires hands on experience with cutting edge technology.
Pro-actively engages in experimentation and innovation to drive relentless improvement
Provides leadership, technical direction and GSK expertise to architecture and engineering teams composed of GSK FTEs, strategic partners and software vendors.
Why you?
Basic Qualifications:
Are you ready to work in an environment where you are continuously expected to work on projects with new technology and expected to use this technology to deliver real business value?
We are looking for professionals with these required skills to achieve our goals:
Total 10+ years of experience and proficient with at least 3 of the below skills and can demonstrate knowledge and value with relevant experience in all the following competencies:
Must have experience in Spark, Python and Databricks
Software development, architecture design & technology platforms/frameworks
Data Platforms and Domain-driven design
Agile, DevOps & Automation [of testing, build, deployment, CI/CD, etc.]
Data science (e.g. AI/ML), data analytics & data quality/integrity
Testing strategies & frameworks
Role requires:
Demonstrated skill in delivering high-quality engineered data products
Knowledge of industry standards and technology platforms aligned to GSK and R&D roadmaps
Excellent communication, negotiation, influencing and stakeholder management skills
Customer focus and excellent problem-solving skills
Computer Science or related bachelor’s degree – MS in Computer Science is preferred
Familiarity and use of various open-source ecosystems including JavaScript, Bigdata, java, python etc.
Good understanding of various software paradigms: domain-driven, procedural, data-driven, object-oriented, functional
Familiar with .Net Core (C#), Java, Python
Demonstrable knowledge depth in more than one area of software engineering and technology
Preferred Qualifications:
If you have the following characteristics, it would be a plus:
Experience in agile software development and DevOps, relevant technology platforms [e.g., Kubernetes] and frameworks [e.g. Docker] including cloud technologies & data structures (i.e. information management), data models or relational database design
Subject matter expertise in clinical development
R&D Tech requires Engineers with understanding of the relevant technical and scientific domains. Able to deliver continuous change to meet rapidly evolving R&D strategy and ambition.
Experience with agile development methods, with security strategies and best practices, data integration mechanisms, architectural design tools, delivering and integrating COTS applications, areas of Service Oriented Architecture (SOA), Application Integration, Business Process Management and Data Quality.
Experience in applying AI/ML, data curation, virtualization, predictive modelling, workflow, and advanced visualization techniques to enable decision support across multiple products and assets to drive results across R&D business operations.
At GSK we value diversity (Gender, LGBTQ +, PwD etc.) and treat all candidates equally. We aim to create an inclusive workplace where all employees feel engaged, supportive of one another, and know their work makes an important contribution.
#LI-GSK
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
 ",USD 45K - 84K *
346,Power Bi - Data-warehouse Administrator,Xplor,"Pune, India",Senior-level / Expert,"Company Description
Take a seat on the Xplor Rocketship and join us as a Data Engineer to help people succeed across the world.
We’re a global team of builders, listeners and problem-solvers who are relentlessly focused on making life simple, so our customers can get back to growing their business, engaging consumers and doing what they love.
Job Description
Overview
As a member of the global data engineering team, reporting to the Data and Analytics Manager, this role has a primary focus on administering our enterprise data warehousing environments. Primarily Power Bi, Data warehouse and Snowflake assets
Responsibilities include administering and maintaining business intelligence assets, user access, roles, workspaces and integrations to other systems.
This position will be working in our global team across our largest business units and experience with large enterprise scale environments is essential.
Key Responsibilities
The primary tasks, duties, and responsibilities are:
Maintaining and enhancing reporting and Power BI solutions.
Administering access controls via SSO integrations, MFA etc.
Administering and automating workspace compute configuration Workspace  
Assisting with producing or trouble shooting reporting stored procedures via T-SQL scripting and DAX where required.
Deployment of Power Bi reports through approved changes and automating the process.
Managing snowflake assets, deploying approved changes as required.
Contribute to cloud migration and ensure system uptime for data warehouse products.
Participate in Agile work planning, testing, and quality assurance.
Qualifications
Technical Skills
Experienced level knowledge - Business Intelligence/reporting tools including Microsoft SQL, SSAS, Power BI, DAX.
Particular experience with the administration of Power BI for gateways, RLS.
Powershell scripting for automating tasks and applying changes via sripted methods.
Experience with Snowflake for administraion and permissions of all core structures such as users, roles, databases, warehouses  
Competency with source control and change management practices to follow change approval and implement change in a safe and controlled manner.
Understanding of data governance practices, data lineage, and data quality management to ensure accurate, consistent, and reliable data.
Familiarity with cloud base tooling – Snowflake, DBT or Coalesce, Fivetran.
Education/Qualifications
BA/BS degree in Computer Science, Computer Engineering, or related field, or equivalent practical experience.
Preferred Qualifications include:
Microsoft and Snowflake accreditations.
 Additional Information
Joining Xplor’s Central Technology (CT) team
There are over 600 Xplorers in our CT team that work as one team across the world. You'll get the chance to engage through Communities of Interest in Technologies (CIT), our Architectural Advisory Board or work on DOOR (Develop Only Once and Reuse).
Being a technology company selling SaaS-based software solutions, you can see your work clearly in the success of the business. You'll be a strategic enabler via world-class capabilities fostering product development and innovation.
Some of the other perks and benefits:  
o 12 weeks Gender Neutral Paid Parental Leave for both primary and secondary carer
o #GiveBackDays/Commitment to social impact – 3 extra days off to volunteer and give back
to your local community
o Ongoing dedication to Diversity & Inclusion initiatives such as D&I Council, Global
Mentorship Program
o Access to free mental health support
o Flexible working arrangements
 We understand that diverse candidates have diverse needs. We welcome you to inform us of any additional needs related to completing your job application or participating in the interview process, via talent@xplortechnologies.com. 
We kindly ask you to apply through our careers portal or external job boards (LinkedIn, Naukri, Indeed, etc) only. Please don't send your application via email. They will not be forwarded. 
More about us 
Xplor Technologies is a global platform integrating SaaS solutions, embedded payments, and Commerce Accelerating Technologies to help businesses succeed. Xplor provides enterprise-grade SaaS solutions for businesses in “everyday life” verticals: Childcare & Education; Fitness & Wellbeing, Field Services and Personal Services – and a global cloud-based payment processing platform.
Xplor Technologies serves over 78,000 customers that processed over $36 billion in payments, operating across 20 markets in 2022. 
Good to know
To learn more about us and our products, please visit www.xplortechnologies.com/us/careers. 
We also invite you to check out our Candidate FAQs for more information about our recruitment process www.xplortechnologies.com/us/recruitment-faqs.
Xplor is committed to providing equal opportunities in employment and creating an inclusive work environment. We provide equal opportunities to all our employees and to all eligible applicants for employment in our company. We do not unfairly discriminate on any ground, including race, caste, religion, color, ancestry, marital status, gender, sexual orientation, age, nationality, ethnic origin, disability or any other category protected by applicable law.
We are a 2024 Circle Back Initiative Employer – we commit to respond to every applicant.",USD 45K - 84K *
347,Principal AI/ML Engineer,GSK,Bengaluru,Senior-level / Expert,"Job Description
At GSK we are building a best-in-class data and prediction powered team that is ambitious for patients. We have already delivered unprecedented change over the past four years, improving R&D, becoming a leader in Consumer Healthcare, strengthening our leadership, and transforming our commercial execution. Now, we’re making the most significant changes we’ve made to our business in over 20 years. We’re on track to separate and create two new companies in 2022: New GSK with a leading portfolio of vaccines and specialty medicines as well as R&D based on immune system and genetics science; and a new world-leading consumer healthcare company of loved and trusted brands.

With new ambition comes new purpose. For New GSK, this is to unite science, talent, and technology to get ahead of disease together – all with the clear ambition of delivering human health impact; stronger and more sustainable shareholder returns; and as a new GSK where outstanding people thrive.
Getting ahead means preventing disease as well as treating it. How we do all this is through our people and our culture. A culture that is ambitious for patients – so we deliver what matters better and faster; accountable for impact – with clear ownership of goals and support to succeed; and where we do the right thing. So, if you’re ready to improve the lives of billions, join us at this exciting moment in our journey. Join our challenge to get Ahead Together.
As R&D enters a new era of data driven science, we are building a data engineering capability to ensure we have high quality data captured with context and aligned data models, so that the data is useable and reusable for a variety of use cases. 
GSK R&D Digital and Tech’s collective goal is to deliver business impact, including the acceleration of the discovery and development of medicines and vaccines to patients.  The R&D Digital and Tech remit has expanded over the past 2 years, and to position GSK for the future, The change will strengthen R&D Tech, to provide more strategic impact, focus, accountability, and improved decision making in the use of Digital, Data and Analytics (DDA) to strengthen the pipeline.
Job Purpose
This role contributes to the construction of the development data fabric and data strategy. This role will interact with architects, engineers, data modelers, product owners as well as other team members in Clinical Solutions and R&D. This role will actively participate in creating technical solutions, designs, implementations & participate in the relentless improvement of R&D Tech systems in alignment with agile and DevOps principles.
The Data Engineer – AI/ML demonstrates both depth and breadth across key data engineering competencies e.g. Software Development, Testing, DevOps, Data Science/Analytics, and cloud. Can collaborate with experts from other subject domains. Primary responsibilities include using Azure cloud services and GSK data platform tools to ingest, egress, and transform data from multiple sources.
In addition, the role will demonstrate core engineering knowledge/experience of industry technologies, practices, and frameworks such as data fabric and scaling data platforms, containerization, cloud-based platforms, data analytics, machine learning, and data streaming.  Examples of technologies include Java/Python, Denodo, GIT, Azure Devops, Databricks, Presto, Snowflake, Spark, Azure Data Factory, ADLS V2, Kafka, Selenium, JUnit/PyTest, SAFe, Kanban, Docker, AI/ML, Azure Cloud Architecture including networking principles and scaling applications. 
The Data Engineer – AI/ML, Clinical Solutions role is a senior technical role and will provide you the opportunity to lead key activities to progress your career.  These responsibilities include the following:
Working with other teams that are defining devops and data platform practices to meet the requirements of clinical solutions.
Supporting engineering teams in the adoption and creation of data mesh best practices.
Conducting PoCs of new technologies and helping to embed them in product teams.
Ensures that technical delivery is fully compliant with GSK Security, Quality and Regulatory standards.
Ensure engineered solutions address scale, reuse, and high availability requirements by using platforms and established standard methodologies.
Work on Generative AI technologies.
Collaborate with cross-functional teams including data scientists, product managers, and software engineers to solve complex problems.
Ability to gain knowledge in ML Engineering with Large Language Models and run them efficiently (Managed LLMs and self-hosted LLMs)
Maintains best practices for engineering and architecture on our Confluence site. This requires hands on experience with cutting edge technology.
Pro-actively engages in experimentation and innovation to drive relentless improvement.
Provides leadership, technical direction and GSK expertise to architecture and engineering teams composed of GSK FTEs, strategic partners, and software vendors.
Why you?
Basic Qualifications:
Are you ready to work in an environment where you are continuously expected to work on projects with new technology and expected to use this technology to deliver real business value?
We are looking for professionals with these required skills to achieve our goals:
Total 10+ years of experience and proficient with some of the below skills and can demonstrate knowledge and value with relevant experience in all the following competencies:
8+ years of work experience in large-scale, sophisticated systems development initiatives focused on Data & Analytics, Machine Learning, and similar areas with hands-on experience.
3+ years of experience in building the applications, data pipelines, ML Ops Pipelines.
Experience in Programming Languages like Python, and exposure to some of Python’s ML ecosystem (numpy, pandas, scikit-learn, tensorflow, etc.)
Experience building highly scalable analytical applications using Messaging/Streaming Technologies (Kafka, Azure Eventhub), Relational and NoSQL database, Datawarehouse (Snowflake), RESTful APIs, and ETL/ELT technologies.
Keen understanding of event-driven, microservices architecture, modern software integration patterns and software engineering principles.
Must have experience in Azure, Spark, Python and Databricks.
Software development, architecture design & technology platforms/frameworks.
Data Platforms and Domain-driven design.
Agile, DevOps & Automation [of testing, build, deployment, CI/CD, etc.]
Data science (e.g. AI/ML), data analytics & data quality/integrity.
Testing strategies & frameworks
Role requires:
 Demonstrated skill in delivering high-quality engineered data products.
 Familiarity with statistical and machine learning techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning.
 Knowledge of industry standards and technology platforms aligned to GSK and R&D roadmaps.
 Excellent communication, negotiation, influencing and stakeholder management skills.
 Customer focus and excellent problem-solving skills.
 Computer Science or related bachelor’s degree – MS in Computer Science is preferred.
 Good understanding of various software paradigms: domain-driven, procedural, data-driven, object-oriented, functional.
 Familiar with Java and/or Python.
 Demonstrable knowledge depth in more than one area of software engineering and technology.
Preferred Qualifications:
If you have the following characteristics, it would be a plus:
Experience in agile software development and DevOps relevant technology platforms [e.g., Kubernetes] and frameworks [e.g. Docker] including cloud technologies & data structures (i.e. information management), data models or relational database design.
Subject matter expertise in clinical development
R&D Tech requires Engineers with understanding of the relevant technical and scientific domains. Able to deliver continuous change to meet rapidly evolving R&D strategy and ambition.
Experience with agile development methods, with security strategies and best practices, data integration mechanisms, architectural design tools, delivering and integrating COTS applications, areas of Service Oriented Architecture (SOA), Application Integration, Business Process Management and Data Quality.
Experience in applying AI/ML, data curation, virtualization, predictive modelling, workflow, and advanced visualization techniques to enable decision support across multiple products and assets to drive results across R&D business operations.
At GSK we value diversity (Gender, LGBTQ +, PwD etc.) and treat all candidates equally. We aim to create an inclusive workplace where all employees feel engaged, supportive of one another, and know their work makes an important contribution.
#LI-GSK
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
 ",USD 174K - 275K *
348,"Data Engineer I, Enabling Functions Data Product Enablement",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation. #HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 110K - 180K *
349,Principal Master Data Management (MDM) Engineer,OneTrust,Bengaluru,Senior-level / Expert,"Strength in Trust 
OneTrust is the trust intelligence cloud platform organizations use to transform trust from an abstract concept into a measurable competitive advantage. Organizations globally use OneTrust to enable the responsible use of data while protecting the privacy rights of individuals, implement and report on their cyber security program, make their social impact goals a reality, and create a speak up culture of trust. Over 14,000 customers use OneTrust's technology, including half of the Global 2,000. OneTrust currently ranks #24 on the Forbes Cloud 100 list of top private cloud companies in the world and employs over 2,000 people in regions across North America, South America, Asia, Europe, and Australia.
The Challenge 
Principal Data Engineers will be part of an innovative data team that enables Marketing, Product, Sales, and Finance to explore data and take actions that differentiate us from our competition.  You will work closely with other team members like data architects and business analysts to understand what the business is trying to achieve, move data from source to target, and design optimal data models.  
Your Mission 
You will work closely with other team members like data architects and business analysts to understand what the business is trying to achieve, move data from source to target, and design optimal data models.  
Design and build facts, dimensions, snapshots, SCDs in Snowflake using DBT/Airflow/ELT tools 
Design Enterprise Data Models for ease of data access, accuracy, and scale 
Develop ELT and implement development best practices applicable for very large and wide data sets 
Work effectively using scrum with multiple team members to deliver analytical solutions. 
Solve immediate production issues with an eye to solve things for long-term 
Drive technical conversations with stakeholders to explore all facets of problem and solution 
You Are
This hands-on technical role demands excellent knowledge and can demonstrate best practices in the industry.   
Your Experience Includes 
Bachelor’s Degree or Master’s Degree in Computer Science, Engineering or related field 
8+ years of experience with very large-scale data warehouse projects 
Experience working in high-growth, fast-paced environment  
BS in Computer Science or equivalent is required 
Experience working in high-growth, fast-paced environment  
Prior experience working with Snowflake/Redshift, AWS, S3 
Experience in building ETL pipelines using DBT 
Prior experience in designing data models with Salesforce, Workday, Marketo, and Product Usage logs 
Experience in designing Data Warehouse: Product Usage, Deferred Revenue, Revenue Metrics 
Very comfortable in designing facts, dimensions, snapshots, SCDs 
Strong Datawarehouse architecture knowledge and ability to write complex SQL for processing raw data, data validation and QA 
Strong Experience with Python and manipulation of various data formats for extraction and transformation 
Experience working with data orchestration tool Apache Airflow  
Experience with Python and manipulation of various data formats for extraction and transformation 
Extra Awesome 
Experience in designing Data Warehouse solutions for Marketing and Sales domains. 
Cross-team collaboration: Data Engineers are part of a team, working with database administrators, data analysts and management and need to be effective communicators. 
Attention to Detail: Databases are complex, and a minute error can cause huge problems. 
Problem-Solving Skills: Data Engineers look at an issue that needs to be solved and come up with solutions quickly. 
Growth Learner: Desire to continue to learn about the future architecture of data technologies. 
Benefits
As an employee at OneTrust, you will be part of the OneTeam. That means you’ll receive support physically, mentally, and emotionally so that you can do your best work both in and out of the office. This includes comprehensive healthcare coverage, remote or hybrid workplace flexibility, flexible PTO, equity stock options, annual performance bonus opportunities, retirement account support, 14+ weeks of paid parental leave, career development opportunities, company-paid privacy certification exam fees, and much more. Specific benefits differ by country. For more information, talk to your recruiter or visit onetrust.com/careers.
Resources  
Check out the following to learn more about OneTrust and its people: 
OneTrust Careers on YouTube
@LifeatOneTrust on Instagram
Your Data
You have the right to have your personal data updated or removed. You also have the right to have a copy of the information OneTrust holds about you. Further details about these rights are available on the website in our Privacy Overview. You can change your mind at any time and have your personal data removed from our database. In order to do this you must contact us and let us know you wish to be removed. The request should be made on the Data Subject Request Form.
Our Commitment to You 
When you join OneTrust you are stepping onto a launching pad — the countdown has begun. The destination? A career without boundaries working alongside a diverse and inclusive crew who is passionate about doing meaningful work. As a pioneer, your voice and expertise will help chart the direction of an entirely new industry — Trust. Our commitment to putting people first starts with you. Your growth is part of the mission. Our goal is to give you the power to embark on the next phase of your uniquely, unique career 
OneTrust provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by local laws.",USD 45K - 84K *
350,Manager - Data Engineering,Mastercard,"Gurgaon, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Manager - Data Engineering
Data & Analytics team builds internal analytic partnerships, strengthening focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market strategies.
• Are you excited about Data Assets and the value they bring to an organization?
• Are you an evangelist for data driven decision making?
• Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across 6 continents?
• Do you want to be the go-to resource for data analytics in the company?
The ideal candidate has a knack for seeing solutions in sprawling data sets and the business mindset to convert insights into strategic opportunities for our company.

Role & Responsibilities
• Lead cross-functional projects using advanced data modeling and analysis techniques to discover insights that will guide strategic decisions and uncover optimization opportunities
• Proactively drive the vision for BI and Data Warehousing across global products group, and define and execute on a plan to achieve that vision
• Define the processes needed to achieve operational excellence in all areas, include project and process management and system reliability
• Build, develop and maintain data models, data pipelines, reporting systems, data automation systems, dashboards and performance metrics that support key business decisions.
• Translate business requirements into tangible technical solution specifications and high quality, on time deliverables.
• Create reusable processes to support development of modeling and reporting
• Effectively use tools to manipulate large-scale databases, synthesizing data insights.
• Apply quality control, data validation, and cleansing processes to new and existing data sources.
• Recruit, train, develop and supervise analyst-level employees.
• Communicate results and business impacts of insight initiatives to stakeholders in leadership, technology, sales, marketing and product teams.

All About You
• 8+ years of experience in BI and data warehousing
• Data architecture experience and experience in building data models
• Experience scaling and managing 3+ person teams
• Communication and leadership experience, with experience initiating and driving projects
• Experience presenting data findings in a readable and insight driven format. Experience building support decks.
• Advanced SQL skills, ability to write optimized queries for large data sets (Big data)
• Experience on Platforms/Environments: Cloudera Hadoop, Big data technology stack, SQL Server, Microsoft BI Stack
• Experience with data visualization tools such as Looker, Tableau, PowerBI.
• Project management experience
• Experience with Python, R, a plus
• Experience on SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS) and SQL Server Reporting Services (SSRS) will be an added advantage
• Financial Institution or a Payments experience a plus
• Excellent problem solving, quantitative and analytical skills
• In depth technical knowledge, drive and ability to learn new technologies
• Strong attention to detail and quality
• Team player, excellent communication skills
• Must be able to interact with management, internal stakeholders and collect requirements
• Must be able to perform in a team, use judgment and operate under ambiguity

Education
• Bachelor’s or Master’s Degree in Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred

Additional Competencies
• Excellent English, quantitative, technical, and communication (oral/written) skills
• Analytical/Problem Solving
• Strong attention to detail and quality
• Creativity/Innovation
• Self-motivated, operates with a sense of urgency
• Project Management/Risk Mitigation
• Able to prioritize and perform multiple tasks simultaneously
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 121K - 186K *
351,Bigdata Developer- Assistant Vice President,State Street,"Hyderabad, India",Executive-level / Director,"Job Title
Delivery Lead, Counterparty & Market Risk Systems
Role Summary
&
Role Description
This role is responsible for leading the Engineering team that would design & implement inhouse applications/solutions and integrate the vendor products into the complex landscape of the Bank’s Risk Infrastructure which include Datalake and Hadoop ecosystem
Responsible for implementation, delivery & support locally. This also involves integration, reporting & analytics, CDCI, test automation and application support.
Core/Must have skills
Minimum of 4 years of experience in design or architecting the solution with minimum requirements by effectively coordinating activities between business analysts, developers, managers and the end-users
Minimum of 10 Years of experience in coding, debugging and analytical skills:  Core problem solving skills, ability to analyze available data and potential solutions, eliminate possible solutions and select an optimal solution.
Minimum of 8 Years of hands on programming experience in core & Advanced Java
Strong knowledge of: Spring, Multithreading, memory management, Spring batch, Spring Boot, Spring MVC, SQL.
Minimum of 5 Years of Experience in Bigdata ecosystem like Hadoop, hive, impala, spark, scala
Strong knowledge of Databases – Oracle, Datalake etc.
Hands-on experience in CICD.
Technology frameworks like Java Spring, Integration frameworks like Kafka/MQ/JMS.
Use advanced technical expertise in analyzing, designing, estimating, and developing software applications to project schedule
Hands-on Technology Experience (Desirable): Should have good understanding of DevOps, Cloud computing and the emerging technologies.
Good to have skills
Experience working in a geographically spread out team
Strong Leadership & Client Facing Skills
Excellent communication skills both verbal and written
Results-oriented: Tenacious, gets things done, should know how to approach the problem statement and identify solutions
Self-starter & able to work with minimal guidance, and ability to establish oneself within the team
Work Schedule
On-Premise or Hybrid
Keywords (If any)
Engineering degree in Computer Science or equivalent field from top schools.
Individual contributor with 14 to18 years of related software development experience.",USD 85K - 120K *
352,"Data Specialist, Center of Excellence – Sourcing",GlobalFoundries,IND - Karnataka - BANGALORE,Mid-level / Intermediate,"We are searching for a Data Specialist to join the Center of Excellence for Sourcing within the Global Supply Chain (GSC). This individual will be a responsible for the development and maintenance of procurement data.
About GlobalFoundries:
GlobalFoundries is a leading full-service semiconductor foundry providing a unique combination of design, development, and fabrication services to some of the world’s most inspired technology companies. With a global manufacturing footprint spanning three continents, GlobalFoundries makes possible the technologies and systems that transform industries and give customers the power to shape their markets. For more information, visit www.gf.com.
Summary of Role:
We are searching for a Data Specialist to join the Center of Excellence for Sourcing within the Global Supply Chain (GSC). This individual will be a responsible for the development and maintenance of procurement data.
Essential Responsibilities:
Create Data Visualizations, Analytics, and KPIs within PowerBI
Ability to explore and understand commercial, financial, and procurement data
Create new PowerBI data models using existing PowerBI Dataflows
Engage with stakeholders to gather reporting requirements
Provide maintenance and updates to organization master data
Provide training and documentation on data analytic solutions to stakeholders
Troubleshoot reporting issues and identify corrective actions
Required Qualifications:
Bachelor's degree in data science, data analytics, computer science, or other related engineering
Excellent data skills – familiarity with SAP / Oracle, Power BI, Microsoft Office, SQL
Ability to interpret commercial and procurement arrangements and translate to data
Fluency in English Language – written & verbal
Preferred Qualifications:
Related Professional Certifications
GlobalFoundries is an equal opportunity employer, cultivating a diverse and inclusive workforce. We believe having a multicultural workplace enhances productivity, efficiency and innovation whilst our employees feel truly respected, valued and heard.
As an affirmative employer, all qualified applicants are considered for employment regardless of age, ethnicity, marital status, citizenship, race, religion, political affiliation, gender, sexual orientation and medical and/or physical abilities.
All offers of employment with GlobalFoundries are conditioned upon the successful completion of background checks, medical screenings as applicable and subject to the respective local laws and regulations.
To ensure that we maintain a safe and healthy workplace for our GlobalFoundries employees, please note that offered candidates who have applied for jobs in India will have to be fully vaccinated prior to their targeted start date. For new hires, the appointment is contingent upon the provision of a copy of their COVID-19
vaccination document, subject to any written request for medical or religious accommodation.
Information about our benefits you can find here: https://gf.com/about-us/careers/opportunities-asia
 ",USD 70K - 109K *
353,Intelligent Automation - Conversational AI Platform Architect,Alcon,Bengaluru - AGS,Senior-level / Expert,"Provide governance and ensure that designs, prototypes, and solutions meet technical standards, framework and guidelines
Deliver solutions in alignment with standard while meeting quality, performance, security, compliance requirements
Work with Conversational AI / Bot technical teams and business partners to design, develop and maintain Bots. Includes software architecting and development outside of Bot platforms.
Vendor/Partner Management - Manage relationships with Automation tool vendors, partners including licensing, updates, and support.
Create accurate development effort estimates in collaboration platform provider
Work with Product owner, Scrum master to drive user story creation and epics for bots.
Present and demonstrate proposed solutions as required.
User Access, Change, Incident and Release management
Audit & Reporting of platform
Support setup, integrations and continuous improvement on the platforms involved.
Act as a backup for RPA AutomationAnywhere platform admin.
Standard Minimimum Requirements
Education: Bachelor’s degree or equivalent years of applicable experience
Experience: 5+ years of applicable experience in Conversational AI with awareness of Generative AI/Chat GPT
Refer to “Specific Job posting content” section for additional experience details.
Language
The ability to fluently read, write, understand, and communicate in English.
 Specific Job Posting Content
5+ years of experience developing or leading or managing Conversational AI platforms.
Experience with RPA AutomationAnywhere platform a plus
Strong knowledge of infrastructure architecture including VDIs, security, network, storage, database, etc.,
Strong collaboration skills for effective communication across multiple teams and stakeholders, both internal and external
Exceptional presentation, written and verbal communication skills (English)
Must be self-motivated with an excellent attitude; Able to prioritize work, complete multiple tasks and work under deadlines.
Exposure to Pharma Medical Device Industry domain is preferred
Exposure to GxP or GDPR or ISRM compliance is preferred
Ability to understand and apply practices and patterns related to data access, integrations, security, and privacy/GDPR
Ability to work independently and as part of a team with strong collaboration skills; Data savvy, problem solver
High learning agility
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 45K - 84K *
354,Sr. Data Scientist - Machine Learning (ML) Job,Yash Technologies,"Hyderabad, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Machine Learning (ML) Professionals in the following areas :
  Experience
5-8 Years
Job Description
Role: Machine Learning Developer

Total Experience: 5-8 years
As a Developer for machine learning, you will work in a team of  experienced researchers, data scientists and application 
developers taking on challenges posed by the Yash customers and product units.
You will work together with a team of dedicated experts including researchers, developers, DevOps engineers, and architects with a single goal of building best machine learning pipelines for a variety of use cases spanning commerce, agriculture, Insurance, financial markets, and procurement. You will have the chance to work with the richest data sets available in the world addressing real-world problems. Your primary goal will be to implement state-of-the-art algorithms and to develop new approaches and technologies for deriving value from our customers’ data.
You will have a chance to select and implement the best technologies and approaches based on your own experience, judgment, and experimentation results. This role combines:
Experience with Machine Learning, NLP, Deep Learning Practical knowledge of working with scalable platforms for processing of huge data sets, 
Ability to understand the data, associated processes and business implications, 
Scaling from minimum viable product up to shippable production code, 
Build and maintaining innovative new products from the ground-up.
  Key Responsibilities
Push the frontiers of what is possible in the area of  machine learning to create new Incubation
 Explore, understand, and implement most recent algorithms and approaches for supervised and unsupervised machine learning and deep learning 
Comfortably handle multi-terabyte data sets in scale-up and scale-out environments 
Understand business processes which create and consume data to be able to select best approaches, evaluate their performance, and assess business relevance 
Create excellence both in terms of results quality and system scalability through continuous evaluation, analysis, and refinement of the system implementation 
Communicate the relevance of implemented systems and achieved results in a visual and consistent way
Work closely with the team (product owner, designers, and other developers) and customers to holistically understand business and user requirements, and derive adequate application development concepts 
Performing quality assurance tasks 
Working together with partners and customers 
Solve complex integration issues 
Ability to work in global teams with different time zones 
Immerse yourself quickly in new topics, terminology and development tasks
  Job Role and Skills required
Quick List
Role Total Exp Must to have Good to have
Data Scientist (AI) 5-8 Years
Min 3+ years of relevant experience in data analytics
 Experience in developing minimum viable product related to data analytics
Qualification in statistics or mathematics
 Any data science certifications
 Good understanding on ML & DL algorithms and frameworks (Scikit-learn, Tensorflow/Keras/ PyTorch/ H2O etc.)
Should have worked on diverse projects related to NLP and computer vision
Well versed with data science methodologies and frameworks (NLTK, RASA, Spacy, OpenCV, Scikit-learn, Tensorflow)
Good proficiency on Python/ R/ Tableau/Power BI etc.
Understanding of RDBMS concepts - SQL, Oracle
Willing to work in a challenging environment
Strong communication skills
Experience on prescriptive analytics
Experience on web frameworks like R-Shiny, Flask or Django
Experience in developing Machine Learning models on the cloud (Azure, GCP or AWS)
Domain experience in manufacturing industry
Understanding of No-SQL databases - MongoDB, Cassandra, Neo4j
  Minimum Qualifications, Skills
Degree in Computer Science, Information Technology, 
Data Science, Mathematics, Statistics, Operations Research or related field 
Track record of developing novel learning algorithms and/or systems 
Proficiency in handling of multi-terabyte datasets in big data frameworks 
Experience with Machine and Deep Learning software packages & libraries such as Keras, TensorFlow, Scikitlearn, Spacy, NLTK, RASA, Spacy, DeepLearning4j, Caffe, Torch, Theano, etc; programming languages such as Python is must. 
Ability to visualize data and present core insights in a clear and compelling way 
Ability to understand business processes and drive to solve business problems
Experience in Cloud like Azure, AWS and GCP is plus. 
Excellent with written and verbal communication and attitude to thrive in a fun, fast-paced startup-like environment.
An attention to detail with self-discipline and a drive for results
Demonstrated ability to work in ambiguous situations
Good at conceptualization and execution of projects
Strong business acumen to connect technology and business
Good Time Management skills – ability to prioritize tasks and projects
Proactive approach to problem resolution, suggesting alternate solutions
Be able to work under tight deadlines & pressure without compromising on quality
Good communication and Strong Interpersonal Skills
Worked in distributed/cross-functional teams
Positive attitude and a team player
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 136K - 205K *
355,Solution Architect Power BI Job,Yash Technologies,"Bengaluru, KA, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Power BI Professionals in the following areas :
  Job Description:
  The Solution Architect, D&T, Power BI possesses good  knowledge and experience to assist in  overall design, development, and implementation of BI Applications. The role is involves working in areas of solution design, development, performance tuning and troubleshooting. 
This role must have hands-on experience in Power BI, M, DAX functions, data warehouse design, SQL databases and SQL statements. 
  Essential Duties and Responsibilities:
Assist in  designs, implements, and supports the enterprise BI dashboards and reports.
Develops reports, dashboards & KPI scorecards and aggregate data from various sources.
Balance functionality look/feel and performance to ensure an excellent user experience which is a strong focus of the role.
Work with other teams to gather and document reporting requirements and to use the underlying data sources/data warehouses to meet business requirements.
Liaise with the SAP Data Warehouse team to design the data model.
Support to conduct training programs and knowledge transfer sessions for junior developers as needed
Other duties as assigned.
  Basic Qualification and Experience:
Bachelor’s degree or equivalent experience 
3-5 years of relevant experience in the areas specified under Essential Duties and Responsibilities.
  Preferred Knowledge, Skills and Abilities:
Good experience with and in-depth knowledge of Power BI, M and DAX functions
Experience as a Power BI Developer or Data Scientist.
Knowledge and experience in development of reports, dashboards, KPI scorecards, aggregating data from multiple sources
Experience in designing dashboards on phones and tablets. 
Background in data warehouse design (e.g. dimensional modeling) and SQL databases and SQL statements.
Good experience in ADF using Linked Services/Datasets/Pipeline/ to Extract, Transform, and load data from different sources like Azure SQL, Blob storage, Azure SQL Data warehouse
Understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework.
Proven abilities to take initiative and be innovative
Analytical mind with a problem-solving aptitude
Ability to work autonomously in a fast-paced & complex environment with a self-motivated work ethic; utilize sound judgment with an ability to manage multiple priorities with a sense of urgency
Ability to work in a virtual environment in a global organization
Able to comply with the company’s safety and quality policies at all times.
  Travel Requirements
Office environment 
10% of travel requirement
  Physical and Mental Requirements:
Occasional on-call work required
Ability to work in a global and virtual environment and to effectively prioritize and execute tasks in a high-pressure environment.
Ability to work autonomously in a fast-paced & complex environment with a self-motivated work ethic; utilize sound judgment with an ability to manage multiple priorities with a sense of urgency.
Prefer 12pm – 9pm India time. Willingness to work outside of these hours as needed.
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
356,Data Engineer,FairMoney,"Bengaluru, Karnataka, India - Remote",Mid-level / Intermediate,"FairMoney is a pioneering mobile banking institution specializing in extending credit to emerging markets. Established in 2017, the company currently operates primarily within Nigeria, and it has secured nearly €50 million in funding from renowned global investors, including Tiger Global, DST, and Flourish Ventures. FairMoney maintains a strong international presence, with offices in several countries, including France, Nigeria, Germany, Latvia, the UK, Türkiye, and India.
In alignment with its vision, FairMoney is actively constructing the foremost mobile banking platform and point-of-sale (POS) solution tailored for emerging markets. The journey began with the introduction of a digital microcredit application exclusively available on Android and iOS devices. Today, FairMoney has significantly expanded its range of services, encompassing a comprehensive suite of financial products, such as current accounts, savings accounts, debit cards, and state-of-the-art POS solutions designed to meet the needs of both merchants and agents.

We are building Engineering centres of excellence across multiple regions and are looking for smart, talented, driven engineers. This is a unique opportunity to be part of the core engineering team of a fast-growing fintech poised for more rapid growth in the coming years.
To gain deeper insights into FairMoney's pivotal role in reshaping Africa's financial landscape, we invite you to watch this informative video. 
Role and responsibilities
At FairMoney, we are making a lot of data-driven decisions in real-time: risk scoring, and fraud detection as examples.
Our data is mainly produced by our backend services, and is being used by the data science team, BI team, and management team. We are building more and more real-time data-driven decision-making processes, as well as a self-serve data analytics layer.
As a senior data engineer at FairMoney, you will help build our Data Platform:
Ensure data quality and availability for all data consumers, mainly data science and BI teams. ingest raw data into our BigQuery DataWarehouse
Make sure data is processed and stored efficiently: work with backend teams to offload data from backend storage
Work with data scientists to build real-time machine learning feature computation pipelines
Spread best practices in terms of data architecture across all tech teams
Effectively form relationships with the business in order to help with the adoption of data-driven decision-making.
You will be part of the Datatech team, sitting right between data producers and data consumers. You will help build the central nervous system of our real-time data processing layer by building an ecosystem around data contracts between producers and consumers.
Our current stack is made of:
Batch processing jobs (Apache Spark in Python or Scala)
Streaming jobs (Apache Flink deployed on Kinesis Data Analytics)
REST apis (Python FastApi)
AWS Kinesis / Apache Kafka as message bus
AWS Lambda as lightweight processors
Apache Iceberg as an analytics table format
BigQuery as a data warehouse
Skills
You will work on a daily basis with the below tools, so you need working experience on:
Languages: Python and Scala
Big data processing frameworks:
Streaming: Apache Flink
Batch: all or one of Apache Spark - Apache Flink - Apache Beam
Streaming services: Apache Kafka / AWS Kinesis
Managed cloud services: one of AWS EMR / AWS Kinesis Data Analytics
Docker
Building REST APIs
Requirements
Ideally, you should have at least 3 years of experience with:
Deployment/ management of stateful streaming jobs
The Kafka ecosystem: Kafka connects mainly
Infrastructure as code frameworks (Terraform)
Architecture around data contracts: Avro Schemas management, schema registries (Confluent Kafka / AWS Glue)
Kubernetes
Data quality frameworks (Great Expectations / Aws Deequ)
Benefits
Training & Development
Family Leave (Maternity, Paternity)
Paid Time Off (Vacation, Sick & Public Holidays)
Remote Work
Recruitment Process
A screening interview with one of the members of the Talent Acquisition team ~30 minutes.
Interview with the hiring manager - Head of Data Platform team
Assignment to be done at home
Technical interview: code review/ presentation of the assignment at home",USD 90K - 152K *
357,Data Engineering Lead,Cargill,"Bengaluru, Karnataka, India, 560087",Senior-level / Expert,"Job Purpose and Impact
The Application Development Analyst III will build, maintain, integrate and implement software applications within the organization. In this role, you will conduct software application development, quality assurance, configuration, installation and support to ensure smooth, stable and timely implementation of new software and updates to installed applications.
Key Accountabilities
Conduct complex technical software development, debug systems and software applications and leverage existing programs to provide solutions as needed.
Compile and prioritize enhancements and defect resolutions to applications, implementing changes.
Performs advanced and complex programming, coding and documentation of systems and applications software.
Prepare detailed technical specifications to write applications and programs based on business requirements.
Develop systems or application technology in accordance with internal and external software compliance standards for multiple projects.
You will work under minimal supervision and independently handle complex issues while referring only the most complex issues to higher-level staff. 
Other duties as assigned
Qualifications
MINIMUM QUALIFICATIONS
Bachelor’s degree in a related field or equivalent experience
Minimum of four years of related work experience
Other minimum qualifications may apply
PREFERRED QUALIFICATIONS
Ability to program with proficiency in SCALA programming language
Experience with Big Data technologies and framework such as Hadoop, Spark, Impala, Scheduling tools such as Oozie.
Advanced SQL skills
Experience in designing and building applications
Good to have – Experience on the Snowflake platform.
Demonstrated understanding of software design and programming principles",USD 121K - 186K *
358,Data Analyst 1,Publicis Groupe,"Bengaluru, India",Entry-level / Junior,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
About BU
At the heart of everything we do is data and this team. Our premium data assets empower the team to drive desirable outcomes for leading brands across industries. Armed with high volumes of transactional data, digital expertise and unmatched data quality, the team plays a key role in improving all our product offerings. Our data artisans are keen on embracing the latest in technology and trends, so there’s always room to grow and something new to learn here.
Why we are looking for you
Understanding of basic file formats.
Ability to create and modify file layouts.
Ability to generate and interpret data field reports and quantify data variations.
Database deliverables include file manipulations and report building.
Follow a data loading plan and support data maintenance policy.
Determine how tables relate to each other and how fields interact within the tables for a relational model.
Ability to interpret specific requirements for data processing, apply standard data mappings and transformations, and create coding instructions for the Client Programming team as required.
Ability to evaluate and confirm accuracy of all coding conditions through review of reports and sample records.  Escalate and work with appropriate teams to identify and fix any issues.
Understanding of basic conditional logic and file segmentation.
Experience working in a Linux command line environment.
Experience with transactional marketing data is highly desirable.
What you will enjoy in this role
The Data Analyst 1 is responsible for review, standardization, and application of consumer and business transactional data to the Abacus Cooperative Database.
Primary responsibility for this role is to review client files and ensure consistent and accurate standardization of these files for loading.
This role will work closely with Data Acquisition Leads and Client Programming (C-Prog) to ensure that the converted data structure meets outlined requirements.
This role supports a productionized modelling/list fulfilment environment and requires a high degree of accuracy as well as ability to keep projects moving at a fast pace.
What you will do
Customer Service
Keep data managers updated on file status and any issues.
Collaborate with Data Acquisition Leads and Client Programming on data file structure and processing standards.
Accuracy
Meet and maintain departmental quality metrics.
Document project requirements and changes for future reference.
Productivity
Timely execution of deliverables meeting / exceeding client expectations / deadlines
Ability to multi-task and stay organized while working multiple projects simultaneously.
Knowledge and Skill Development
Applies and maintains privacy and data security standards appropriately.
Assist teammates to ensure obligations to internal/external customers are met.
Takes responsibility/ownership for day-to-day assignments/activities.
Qualifications
Bachelors in Computer Science (or equivalent) with 1 years of experience with data analysis and processing skills.
Required Skills
Data processing skills.
Excellent communication, interpersonal, organization, and customer service skills. 
Position demands computer literacy, adaptability, attention to detail and the ability to coordinate and prioritize multiple tasks. 
Individual is required to be self-motivated and at the same time be able to also work effectively and cooperatively in a team environment.
Demonstrated comfort and proficiency working in Windows, GUI, and Command Line interfaces such as Linux.
Proven ability to work independently and as part of a team.
Ability to learn and apply knowledge quickly.
Flexible and adaptable in managing priorities in a fast-paced environment.
Work Timings: 1pm – 10 pm ( Fixed Shift with cab facility)
Strong analytical and decision making skills
Additional Skills that are a plus
Self-starter as well as a team player
Experience working with remote team
Good at documentation
Detail oriented with excellent communication skills
Working knowledge of MS Products
Experience working with Linux
Knowledge of task management tools is a must, knowledge of JIRA desired
Scripting experience.",USD 54K - 94K *
359,"Sr Associate, Data Science",Kyndryl,IN152015 NOIDA (IN152015) ARTHA INFRATE,Senior-level / Expert,"Who We Are
At Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.

The Role
Roles and responsibilities - technical lead of the account, responsible for the design, development, and deployment of data solutions to the elevance health account. Solutions include Bigfix, Sciencelogic, Cockpit, Tableau, SQL, TOC Portal, AI POCs. Application Development Role Overview: Understand the progress of the current Ruby -> Python Django migration. Complete Ruby -> Python Django migration where prior dev has left off. Have application architecture understanding to understand infrastructure + application and make recommendations for future improvements. Receive break/fix issues, triage issues, mitigate issues. Understand and mitigate server, db vulnerabilities. Possible future MySQL migration (to oracle or MS SQL, TBD) -- Primary Skills: Ruby, Python Django. Application Infrastructure, Maintenance

Who You Are
Roles and responsibilities - technical lead of the account, responsible for the design, development, and deployment of data solutions to the elevance health account. Solutions include Bigfix, Sciencelogic, Cockpit, Tableau, SQL, TOC Portal, AI POCs. Application Development Role Overview: Understand the progress of the current Ruby -> Python Django migration. Complete Ruby -> Python Django migration where prior dev has left off. Have application architecture understanding to understand infrastructure + application and make recommendations for future improvements. Receive break/fix issues, triage issues, mitigate issues. Understand and mitigate server, db vulnerabilities. Possible future MySQL migration (to oracle or MS SQL, TBD) -- Primary Skills: Ruby, Python Django. Application Infrastructure, Maintenance

Being You
Diversity is a whole lot more than what we look like or where we come from, it’s how we think and who we are. We welcome people of all cultures, backgrounds, and experiences. But we’re not doing it single-handily: Our Kyndryl Inclusion Networks are only one of many ways we create a workplace where all Kyndryls can find and provide support and advice. This dedication to welcoming everyone into our company means that Kyndryl gives you – and everyone next to you – the ability to bring your whole self to work, individually and collectively, and support the activation of our equitable culture. That’s the Kyndryl Way.

What You Can Expect
With state-of-the-art resources and Fortune 100 clients, every day is an opportunity to innovate, build new capabilities, new relationships, new processes, and new value. Kyndryl cares about your well-being and prides itself on offering benefits that give you choice, reflect the diversity of our employees and support you and your family through the moments that matter – wherever you are in your life journey. Our employee learning programs give you access to the best learning in the industry to receive certifications, including Microsoft, Google, Amazon, Skillsoft, and many more. Through our company-wide volunteering and giving platform, you can donate, start fundraisers, volunteer, and search over 2 million non-profit organizations.  At Kyndryl, we invest heavily in you, we want you to succeed so that together, we will all succeed.
Get Referred!
If you know someone that works at Kyndryl, when asked ‘How Did You Hear About Us’ during the application process, select ‘Employee Referral’ and enter your contact's Kyndryl email address.",USD 95K - 160K *
360,Senior Data Engineer,JLL,IND-CORP Bengaluru-TDIM - PTT,Senior-level / Expert,"Senior Data Engineer
JLL Technologies COE
About JLL and JLL Technologies
JLL is a leading professional services firm that specializes in real estate and investment management. Our vision is to reimagine the world of real estate, creating rewarding opportunities and amazing spaces where people can achieve their ambitions. In doing so, we will build a better tomorrow for our clients, our people and our communities.
JLL Technologies is a specialized group within JLL. At JLL Technologies, our mission is to bring technology innovation to commercial real estate. We deliver unparalleled digital advisory, implementation, and services solutions to organizations globally. Our goal is to leverage technology to increase the value and liquidity of the world's buildings, while enhancing the productivity and the happiness of those that occupy them.
What this job involves
JLL Technologies Enterprise Data team is a newly established central organization that oversees JLL’s data strategy. We are seeking data professionals to work with our colleagues at JLL around the globe in providing solutions, developing new products, building enterprise reporting & analytics capability to reshape the business of Commercial Real Estate using the power of data and we are just getting started on that journey!
We are looking for a Senior Data Engineer who is self-starter to work in a diverse and fast-paced environment that can join our Enterprise Data team. This is an individual contributor role that is responsible for designing and developing of data solutions that are strategic for the business and built on the latest technologies and patterns. This a global role that requires partnering with the broader JLLT team at the country, regional and global level by utilizing in-depth knowledge of data, infrastructure, technologies and data engineering experience.
As a Senior Data Engineer at JLL Technologies, you will:
Contributes to the design of information infrastructure, and data management processes to move the organization to a more sophisticated, agile and robust target state data architecture
Develop systems that ingest, cleanse and normalize diverse datasets, develop data pipelines from various internal and external sources and build structure for previously unstructured data
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Develop good understanding of how data will flow & stored through an organization across multiple applications such as CRM, Broker & Sales tools, Finance, HR etc
Design & develop data management and data persistence solutions for application use cases leveraging relational, non-relational databases and enhancing our data processing capabilities
Develop POCs to influence platform architects, product managers and software engineers to validate solution proposals and migrate
Functionally lead team of data engineers to deliver data solutions in Agile manner while mentoring junior-level data engineers
Sounds like you? What we are looking for:
Bachelor’s degree in Information Science, Computer Science, Mathematics, Statistics or a quantitative discipline in science, business, or social science.
Minimum of 6 years of experience as a data developer using Python, Kafka, Spark Streaming, Azure SQL Server, Cosmos DB/Mongo DB, Azure Event Hubs, Azure Data Lake Storage, Azure Search etc.
Excellent technical, analytical and organizational skills.
Hands-on engineering lead who is curious about technology, should be able to quickly adopt to change and one who understands the technologies supporting areas such as Cloud Computing (AWS, Azure(preferred), etc.), Micro Services, Streaming Technologies, Network, Security etc
Hands-on Experience for building Data Pipelines in Cloud.
Design & develop data management and data persistence solutions for application use cases leveraging relational, non-relational databases and enhancing our data processing capabilities.
Experience handling un-structured data, working in a data lake environment, leveraging data streaming and developing data pipelines driven by events/queues
Team player, Reliable, self-motivated, and self-disciplined individual capable of executing on multiple projects simultaneously within a fast-paced environment working with cross functional teams
Someone who is genuinely excited about data infrastructure and operations with a familiarity working in cloud environments and Working with data excites you: you have created data architecture, you can build and operate data pipelines, and maintain data storage, all within distributed systems
What you can expect from us:
You’ll join an entrepreneurial, inclusive culture. One where we succeed together – across the desk and around the globe. Where like-minded people work naturally together to achieve great things.
Our Total Rewards program reflects our commitment to helping you achieve your ambitions in career, recognition, well-being, benefits and pay.
Join us to develop your strengths and enjoy a fulfilling career full of varied experiences. Keep those ambitions in sights and imagine where JLL can take you...
Apply Today!
Location:
Hybrid (inactive) –Bengaluru, KA
Job Tags:
If this job description resonates with you, we encourage you to apply, even if you don’t meet all the requirements.  We’re interested in getting to know you and what you bring to the table!
About JLL –
For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500® company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com.
JLL Privacy Notice
Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.
For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.
For additional details please see our career site pages for each country.
For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here.
Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities.  If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process –  you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",USD 121K - 186K *
361,Senior Data Engineer,Commonwealth Bank,Bengaluru - Manyata Tech Park Road,Senior-level / Expert,"Job Description:
You are an experienced Senior Data Engineer who is passionate about data and the technologies
We are high performing engineers pushing the boundaries of data engineering
Together we will build state-of-the-art data platforms, using world-leading technology and innovation
Do work that matters
Markets Operational Datastore(MODS) is a data platform that ingests data(structured and unstructured) from various internal and external systems and conformed to a data model that underpin Regulatory Reporting, Market Risk, Credit Risk, Quants and Trader Surveillance.
In your role as Senior Data Engineer, you will be required to work with Markets Data Platform, Data Office and other platform stakeholders.
What will set you up for success?
You’re passionate about building industry leading group data products
You’re ready to execute state-of-the-art coding practices, driving high quality outcomes to solve core business objectives and minimise risks
You’re capable of creating both technology blueprints and engineering roadmaps
You feel at home and can lead and drive a culture where quality, excellence and openness are championed
You’re constantly thinking outside the box and breaking boundaries to solve complex data problems
Roles and Responsibilities
Problem solving – advanced analytical and problem-solving skills to analyse complex information for key insights and present as meaningful information to senior management
Communication – excellent verbal and written communication skills with ability to lead discussions with a varied stakeholder across levels
Risk Mindset – All CommBank employees are expected to proactively identify and understand, openly discuss and act on current and future risks.
Experience
Good understanding of Data Engineering principles including Data Modelling methodologies.
8+ years of experience in building Data Warehouse, Data Lake and Data Lakehouse using Ab Initio including Express>It, Control Centre, Metadata Hub, Query>It and other products.
Experience with Batch and Streaming based integrations.
Experience with CI/CD tools (e.g. TeamCity, Artifactory, Octopus, Jenkins, SonarQube etc.)
Experience in designing and building Docker images and manage containers (Kubernetes/EKS). 
AWS Cloud Experience and Certifications highly desirable.
Sound understanding of relational as well as NoSQL databases.
Practical knowledge on any programming language like Java/Python/Go and advanced SQL skills.
Proven experience implementing data acquisition and distribution through RESTful API services.
Experience with Apache Kafka highly desirable.
Be able communicate your idea clearly and effectively.
Working with us:
Whether you’re passionate about customer service, driven by data, or called by creativity, a career with CommBank is for you.  
Our people bring their diverse backgrounds and unique perspectives to build a respectful, inclusive, and flexible workplace with flexible work locations. One where we’re driven by our values, and supported to share ideas, initiatives, and energy. One where making a positive impact for customers, communities and each other is part of our every day. 
Here, you’ll thrive. You’ll be supported when faced with challenges and empowered to tackle new opportunities. We’re hiring engineers from across all of Australia, you’ll be empowered to do your best work and be given the choice on when and where that work happens. We really love working here, and we think you will too. 
If you're already part of the Commonwealth Bank Group (including Bankwest, x15ventures), you'll need to apply through Sidekick to submit a valid application. We’re keen to support you with the next step in your career.
We're aware of some accessibility issues on this site, particularly for screen reader users. We want to make finding your dream job as easy as possible, so if you require additional support please contact HR Direct on 1800 989 696.
Advertising End Date: 30/01/2024",USD 121K - 186K *
362,Azure Big Data Specialist,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Overall 8+ years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks,Synapse, ADF.Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processesMust Have skills : Azure Data factory (ADF), Azure Databricks (ADB), Azure Synapse Analytics (SQL DW), Azure Analysis Services (AAS), Azure Data Lake Storage (ADLS),
Azure SQL Database (SQL DB), SQLExperience with NoSQL databases such as cosmosdb, Cassandra, CosmosDB, MongoDB.Experience in Real-Time Data Processing using Eventhub,IoT Hub,Apache Kafka ,Structured Streaming and Stream analytics.Experience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, CosmosDB, Kafka, Azure Data Factory (ADF), Blob, ADLS, EventHub.Sound Knowledge on Azure DevOps and CI/CD tools like Jira, Confluence, Bamboo, Bitbucket.Hands on experience in RDBMS like MSSQL,Oracle,Mysql ,Teradata
Qualifications
BE, MS, M.Tech or MCA
Additional Information
Overall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks,Synapse, ADF.Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processes",USD 71K - 111K *
363,BI Developer,Roland Berger,"Mumbai, India",Mid-level / Intermediate,"Company Description
We are the world's leading strategy consultancy with European roots.  We work together with leading international industrial and service companies, as well as public institutions, to develop and implement innovative solutions.
Job Description
As a BI Developer, you will be responsible for transforming data into actionable insights by designing and developing business intelligence solutions. You will work closely with data analysts and stakeholders to understand reporting and analysis needs and create data visualizations, reports, and dashboards that enable informed decision-making.
 Main activities:
Creating interactive reports and dashboards using BI tools like Tableau, Power BI, QlikView, or custom-built solutions
Translating business requirements into visually appealing and informative data visualizations
Writing and optimizing SQL queries to retrieve and manipulate data for reporting and analysis
Performance-tuning queries for faster data retrieval
Using visualization best practices to create meaningful and actionable data visualizations easy to interpret
Qualifications
You have a M.Sc. or Bachelors in a quantitative field (Information Systems, Computer Science, Physics, Mathematics, etc.) and demonstrated industry experience as BI developer for 3-4 years.
 Technical Requirements:
 BI Technologies – Proficiency in one or more BI tools such as Power BI (must have), Tableau, QlikView, MicroStrategy etc.
Database Technologies – Knowledge of querying data from databases (including relational and document-based and key-value stores; e.g., Postgres, SQL Server, Cassandra, Redis)
Data Modeling – Understanding data modeling concepts, such as entity-relationship diagrams, dimensional modeling, and star schemas etc.
Data Querying Technologies – Experience in working data querying using SQL
Other skills – Strong knowledge of Excel and reporting
Knowledge of visualization and reporting best practices
Exposure to data warehousing concepts and tools
Certification in relevant BI tools or data technologies
Additional Information
An exciting international environment of projects, customers and consultants
Extensive training opportunities in data analytics and data engineering.
Competitive salary",USD 76K - 128K *
364,Data Engineer,Roland Berger,"Mumbai, India",Mid-level / Intermediate,"Company Description
We are the world's leading strategy consultancy with European roots.  We work together with leading international industrial and service companies, as well as public institutions, to develop and implement innovative solutions.
Job Description
As a Data Engineer you are responsible for handling data pipelines and supporting data architecture. You will be joining a fast-growing team of consultants and data specialists to bring cutting edge technology solutions to our clients. You will design architectures for data integration and processing to provide high quality datasets and utilize Big Data processing tools to build data pipelines on modern technology stack like Azure / AWS or GCP. You will also be required to setup and implement data management frameworks across client organizations.

In this role you will take the responsibility for project scoping, data collection, data extraction, data processing, data cleaning and enrichment to support the team in the conceptual development and implementation of data platforms. Your area of expertise covers the creation of a complete, end-to-end data pipeline: from the import of structured and unstructured raw data, its processing and transformation, metadata management to the implementation of scalable analytics platforms. 

Further, you will apply your understanding of analytical methodologies and the related infrastructure requirements to continuously collaborate with our team of Data Analytics Consultants and Data Scientists to develop state of the art data-based solutions for our clients. On a day to day basis you will work with state-of-the-art technology and always apply a solution- and goal-oriented approach
Qualifications
You have a M.Sc. or Bachelors in a quantitative field (Information Systems, Computer Science, Physics, Mathematics, etc.) and demonstrated industry experience in data engineering (junior data engineer – 2 to 3 years, mid-level data engineer – 4 to 5 years)
Core Technical Requirements:
Database Technologies – Knowledge of working with data models and databases (including relational and document-based and key-value stores; e.g., Postgres, SQL Server, Cassandra, Redis)
Data Quality Technologies – Knowledge of working with data quality check automation using tools like great expectations, DBT etc. 
Visualization Technologies – Knowledge of developing, maintaining and publishing dashboards on  visualization tools like Power BI and Tableau
ETL Technologies – Experience in data extraction/ingestion, processing and loading (including Informatica, Talend, Matillion etc.)
Cloud Technologies – Experience in working on cloud infrastructures and cloud-based analytics systems (e.g., AWS, Azure, Google Cloud Platform etc.)
Big Data Technologies – Experience in handling Big data and (e.g., Apache Hadoop Ecosystem (Hive, HBase, Impala, Oozie etc.), Apache Spark)
SAP Technologies – Experience working with various SAP Technologies (SAP S4/HANA, SAP BW, SAP Fiori etc.)
Streaming Technologies - Understanding of event-driven and log-structured architectures (Kafka, Flink, Kinesis), streaming and batch processing methods and data transfer protocols
Programming Languages - Strong coding knowledge in common programming and query languages (Java, Scala, SQL, Python)
Data Management – Experience in defining and implementing data management frameworks (including data governance, metadata management, data lifecycle etc.)
Version Control Technologies – Experience working with version control (e.g., Git, SVN etc.)
SDLC Model – Knowledge of SDLC models (e.g., Waterfall, Agile, CI/CD)
Containerization - Experience with container-based infrastructures (Docker/Kubernetes)
Experience in the development of API services (REST, e.g. with Flask)
Basic knowledge of common libraries and frameworks (NumPy, pandas, scikit-learn etc.). 
Demonstrable knowledge of applying Data Engineering best practices (coding practices, testing (unit, system, acceptance, black box etc.), code review)
Additional Information
An exciting international environment of projects, customers and consultants
Extensive training opportunities in data analytics and data engineering.
Competitive salary",USD 90K - 152K *
365,Technical Specialist Data Management,Kyndryl,IN152015 NOIDA (IN152015) ARTHA INFRATE,Senior-level / Expert,"Who We Are
At Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.

The Role
Job description
We are seeking a skilled and experienced ELK Stack Engineer to join our team. The ideal candidate will have a deep understanding of the ELK stack—Elasticsearch, Logstash, and Kibana—and will play a key role in designing, implementing, and maintaining our log and data analytics infrastructure.
Responsibilities:
ELK Stack Implementation:
Maintain & Monitor ELK stack infrastructure for log and data analysis.
Ensure the scalability, performance, and reliability of the ELK stack.
Monitoring and Alerting:
Set up monitoring solutions using ELK for real-time analysis and alerting.
Identify and address performance bottlenecks and issues.
Collaboration and Documentation:
Collaborate with cross-functional teams to understand log and data requirements.
Document ELK stack configurations, processes, and best practices.
Qualifications:
Technical Skills:
Strong expertise in Elasticsearch, Logstash, and Kibana.
Proficient in writing and optimizing Elasticsearch queries.
Experience with log file formats, parsing, and log enrichment.
Scripting and Automation:
Proficiency in any scripting languages such as Python, Ruby, or Shell scripting.
Automation skills for deploying and managing ELK stack components.
System Administration:
Familiarity with Linux/Unix system administration and performance tuning.
Troubleshooting:
Strong troubleshooting skills for identifying and resolving issues in ELK stack.
Collaboration and Communication:
Excellent teamwork and communication skills.
Ability to work collaboratively with developers, system administrators, and other stakeholders.
Education and Experience:
Bachelor's degree in Computer Science, Information Technology, or a related field.
Proven experience as an ELK Stack Engineer or similar role.
Preferred Additional Skills:
Experience with other data analytics tools and platforms.
Knowledge of distributed systems and cloud environments.

Who You Are
Education and Experience:
Bachelor's degree in Computer Science, Information Technology, or a related field.

Being You
Diversity is a whole lot more than what we look like or where we come from, it’s how we think and who we are. We welcome people of all cultures, backgrounds, and experiences. But we’re not doing it single-handily: Our Kyndryl Inclusion Networks are only one of many ways we create a workplace where all Kyndryls can find and provide support and advice. This dedication to welcoming everyone into our company means that Kyndryl gives you – and everyone next to you – the ability to bring your whole self to work, individually and collectively, and support the activation of our equitable culture. That’s the Kyndryl Way.

What You Can Expect
With state-of-the-art resources and Fortune 100 clients, every day is an opportunity to innovate, build new capabilities, new relationships, new processes, and new value. Kyndryl cares about your well-being and prides itself on offering benefits that give you choice, reflect the diversity of our employees and support you and your family through the moments that matter – wherever you are in your life journey. Our employee learning programs give you access to the best learning in the industry to receive certifications, including Microsoft, Google, Amazon, Skillsoft, and many more. Through our company-wide volunteering and giving platform, you can donate, start fundraisers, volunteer, and search over 2 million non-profit organizations.  At Kyndryl, we invest heavily in you, we want you to succeed so that together, we will all succeed.
Get Referred!
If you know someone that works at Kyndryl, when asked ‘How Did You Hear About Us’ during the application process, select ‘Employee Referral’ and enter your contact's Kyndryl email address.",USD 45K - 84K *
366,Senior Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
Job Summary:
Support data driven decision making for business functions across Tesco and TBS by developing analytics solutions using math; tech and business knowledge

In this job; I am accountable for:
- Follow Tesco's Business Code of Conduct and always act with integrity and due diligence
- Engage with market leaders to understand problems to be solved; translate the business problems to analytics problems; taking ownership of specified analytical modules and translate the answers back to decision makers in business terms
- Think beyond the ask and develop solutions that will contribute to existing solutions
- Accountable for high quality and timely completion of specified work deliverables
- Write codes that are well detailed; structured; and compute efficient
- Drive value delivery through efficiency gain by automating repeatable tasks; report creation or dashboard refresh
- Collaborate with colleagues to craft; implement and measure analytical solution
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Understands business needs and in depth understanding of Tesco processes
- Builds on Tesco processes and knowledge by applying CI tools and techniques
- Responsible for completing tasks and transactions within agreed metrics
- Solves problems by analyzing solution alternatives

Key people and teams I work within and outside of Tesco:
Enterprise Analytics Senior Management
Tesco UK / ROI / Central Europe / APAC market stakeholders
Qualifications
2-4 years of experience in analytics delivery in any one of domains suck as retail; CPG; telecom or hospitality and for one of the following functional areas - marketing; supply chain; customer; merchandising; operations; finance or digital preferred

Operational skills relevant for this job:
- Logical Reasoning; Problem Solving; Storyboarding
- Basic Statistical Concepts - Central Measures of data; Hypothesis testing
- ML Concepts - Regression; Classification; Clustering; Timeseries; NLP etc.
- Tools/Languages - Adv. Excel; Adv. SQL; Hive; python; dash; Tableau
- GenAI - LLMs; RAG framework etc.
Additional Information
Last Date of Application-22nd Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
367,REF17619U-Python(ML+AI+chatbot) Assistant Manager - WTS,WNS Global Services,"Pune, India",Senior-level / Expert,"Company Description
WNS (Holdings) Limited (NYSE: WNS), is a leading Business Process Management (BPM) company. We combine our deep industry knowledge with technology and analytics expertise to co-create innovative, digital-led transformational solutions with clients across 10 industries. We enable businesses in Travel, Insurance, Banking and Financial Services, Manufacturing, Retail and Consumer Packaged Goods, Shipping and Logistics, Healthcare, and Utilities to re-imagine their digital future and transform their outcomes with operational excellence.We deliver an entire spectrum of BPM services in finance and accounting, procurement, customer interaction services and human resources leveraging collaborative models that are tailored to address the unique business challenges of each client. We co-create and execute the future vision of 400+ clients with the help of our 44,000+ employees. Our global footprint spans 16 countries with 61 delivery centers worldwide including in China, Costa Rica, India, the Philippines, Poland, Romania, South Africa, Spain, Sri Lanka, Turkey, United Kingdom and the United States.
Job Description
6 - 10 years of experience as a Python Developer with a strong understanding of Python programming concepts and best practicesBachelor’s Degree/B.Tech/B.E in Computer Science or a related disciplineDesign, develop, and maintain robust and scalable Python-based applications, tools, and frameworks that integrate machine learning models and algorithmsProven experience Demonstrated expertise in developing machine learning solutions, including feature selection, model training, and evaluationProficiency in data manipulation libraries (e.g., Pandas, NumPy) and machine learning frameworks (e.g., Scikit-learn, TensorFlow, PyTorch, Keras)Experience with web frameworks like Django or FlaskContribute to the architecture and design of data-driven solutions, ensuring they meet both functional and non-functional requirementsExperience with databases such as MS-SQL Server, PostgreSQL or MySQL. Solid knowledge of OLTP and OLAP conceptsExperience with CI/CD tooling (at least Git and Jenkins)Experience with the Agile/Scrum/Kanban way of workingSelf-motivated and hard-workingKnowledge of performance testing frameworks including Mocha and Jest.Knowledge of RESTful APIs.Understanding of AWS and Azure Cloud services
Qualifications
Bachelor’s Degree/B.Tech/B.E in Computer Science or a related discipline",USD 45K - 84K *
368,EY - GDS Consulting - D&A - Data Scientist - Senior,EY,"Pune, MH, IN, 411014",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        Job Description: Senior Data Scientist
  Role Overview: We are seeking a highly skilled and experienced Senior Data Scientist with a minimum of 4 years of experience in Data Science and Machine Learning, preferably with experience in NLP, Generative AI, LLMs, MLOps, Optimization techniques, and AI solution Architecture. In this role, you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise. The ideal candidate should have a deep understanding of AI technologies and experience in designing and implementing cutting-edge AI models and systems. Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role.
  Responsibilities:
Your technical responsibilities:
Contribute to the design and implementation of state-of-the-art AI solutions.
Assist in the development and implementation of AI models and systems, leveraging techniques such as Language Models (LLMs) and generative AI.
Collaborate with stakeholders to identify business opportunities and define AI project goals.
Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges.
Utilize generative AI techniques, such as LLMs, to develop innovative solutions for enterprise industry use cases.
Integrate with relevant APIs and libraries, such as Azure Open AI GPT models and Hugging Face Transformers, to leverage pre-trained models and enhance generative AI capabilities.
Implement and optimize end-to-end pipelines for generative AI projects, ensuring seamless data processing and model deployment.
Utilize vector databases, such as Redis, and NoSQL databases to efficiently handle large-scale generative AI datasets and outputs.
Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs.
Collaborate with domain experts, stakeholders, and clients to understand specific business requirements and tailor generative AI solutions accordingly.
Conduct research and evaluation of advanced AI techniques, including transfer learning, domain adaptation, and model compression, to enhance performance and efficiency.
Establish evaluation metrics and methodologies to assess the quality, coherence, and relevance of generative AI outputs for enterprise industry use cases.
Ensure compliance with data privacy, security, and ethical considerations in AI applications.
Leverage data engineering skills to curate, clean, and preprocess large-scale datasets for generative AI applications.
  Requirements:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field. A Ph.D. is a plus.
Minimum 4 years of experience in Data Science and Machine Learning.
In-depth knowledge of machine learning, deep learning, and generative AI techniques.
Proficiency in programming languages such as Python, R, and frameworks like TensorFlow or PyTorch.
Strong understanding of NLP techniques and frameworks such as BERT, GPT, or Transformer models.
Familiarity with computer vision techniques for image recognition, object detection, or image generation.
Experience with cloud platforms such as Azure, AWS, or GCP and deploying AI solutions in a cloud environment.
Expertise in data engineering, including data curation, cleaning, and preprocessing.
Knowledge of trusted AI practices, ensuring fairness, transparency, and accountability in AI models and systems.
Strong collaboration with software engineering and operations teams to ensure seamless integration and deployment of AI models.
Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions.
Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at various levels.
Understanding of data privacy, security, and ethical considerations in AI applications.
Track record of driving innovation and staying updated with the latest AI research and advancements.
  Good to Have Skills:
Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems.
Utilize optimization tools and techniques, including MIP (Mixed Integer Programming).
Drive DevOps and MLOps practices, covering continuous integration, deployment, and monitoring of AI models.
Implement CI/CD pipelines for streamlined model deployment and scaling processes.
Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelines.
Apply infrastructure as code (IaC) principles, employing tools like Terraform or CloudFormation.
Implement monitoring and logging tools to ensure AI model performance and reliability.
Collaborate seamlessly with software engineering and operations teams for efficient AI model integration and deployment.
Familiarity with DevOps and MLOps practices, including continuous integration, deployment, and monitoring of AI models.
    EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 135K - 205K *
369,"Analyst 4, Data Analytics",Western Digital,"Bengaluru, India",Senior-level / Expert,"Company Description
Company Description
At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.
At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that. Our technology helped people put a man on the moon.
We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world’s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.
Binge-watch any shows, use social media or shop online lately? You’ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That’s us, too.
We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital®, G-Technology™, SanDisk® and WD® brands.
Today’s exceptional challenges require your unique skills. It’s You & Western Digital. Together, we’re the next BIG thing in data.
Job Description
Job Description
Partner with HR team members, leaders, and stakeholders across Western Digital to develop a deep understanding of current and emerging HR use cases and challenges, identify priorities for research and execute impactful research projects
Design, build and deploy the analytical/ BI reports like People Insights & Collaboration using enterprise-level tools and technologies.
Connect and analyze multiple sources of organizational data to provide actionable insights on HR strategies
Responsible for analyzing and visualizing the various domain-specific data.
Provide subject matter expertise and advice on People analytics topics and data collection
Communicate research findings to HR groups and senior leaders relating findings to technical and non-technical audiences
Present research insights both internally and outside the organization to become a thought leader in this space
Collaborate with People Analytics and IT team members to access data and explain data requirements
Producing the weekly, monthly, and quarterly scheduled reports, including Executive Management Information and Workforce Metrics in an accurate and timely manner
 Supporting the effort of data integrity and data governance
Demonstrate ethics and judgement when dealing with confidential data and research with underrepresented communities
Stay current on research and best practices, summarizing findings and recommendations for enhancing current processes and practices
Qualifications
Qualifications
6-8 years of professional-level work experience with an emphasis on HR and People Analytics
Deep subject-matter expertise in HR domain, and/or closely related areas.
Excellent communication skills with demonstrated ability to build strong relationships within an organization
Comfortable presenting information and ideas to HR and Business Leaders
Advanced SQL Knowledge ( Oracle, Teradata )
Working experience and/or familiarity with Tableau, Python, R or related tools
Experience with Tableau, OBIEE, Alteryx, or related tools
Exceptional interpersonal skills with people across geographies, functions, and levels of the organization
Strong Project Management skills, ability to prioritize and meet deadlines and measure progress and success and manage multiple projects with competing deadlines
Ability to handle highly confidential data
Thrives in a fast-paced, complex environment
Highly motivated self-starter who takes initiative
Goal-oriented, proactive, accountable, and passionate about driving results
Maintains a positive attitude and forward-thinking approach despite challenges
Shows personal commitment and acts to continuously learn and improve
Actively seeks out information about a wide variety of cultures and viewpoints
Strong organizational skills with exceptional attention to detail and a strong design instinct
Preferred:
 Bachelor’s/Master’s degree, PhD a plus, with a focus or specialization in HR and/or in a field emphasizing people research in organizations (e.g., Industrial/Organizational Psychology, Organizational Behavior, Management, Organizational Development)
Experience conducting research in organizations, including research design, data collection, statistical analysis, interpretation of results, and making actionable recommendations
Ability to select and apply appropriate statistical methods to people research problems in organizations
Additional Information
All your information will be kept confidential according to EEO guidelines.",USD 45K - 84K *
370,Data Scientist II,G2,Bengaluru,Mid-level / Intermediate,"About G2 - The Company
G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.
G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here!
About G2 - Our People 
G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.  
As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community  strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs). 
We support our employees by offering generous benefits, such as flexible work, ample parental leave. Click here to learn more about our benefits. 
This is a hybrid position, with the team meeting in person two days a week at our Bengaluru office. 
About the Role
G2 is looking for a Data Scientist II, this role encompasses leading model development and contributing to machine learning product development. You'll own end-to-end data science workflows, experiment with advanced algorithms, mentor junior team members, and drive innovation within the data science domain. You will work on Improving G2’s  intent scoring, content moderation, and other AI-driven features through the use of machine learning.
In this role, you will:- 
Modeling and Statistical Analysis (50%):
Independently lead the development of machine learning models, owning feature engineering, extraction, model selection, and optimization Design experiments by formulating statistical hypotheses, defining data requirements, pre-processing and cleaning the data, and performing the hypothesis testing.Operationalise models at scale applying AI and engineering best practices by working with the ML engineers.
Experiment with various algorithms and techniques to advance model performance.
Define feedback and evaluation methods for the business problems.
Demonstrate excellent coding and debugging skills.
Business, Data Understanding, and Impact (30%):
Make impactful contributions by leveraging AI and Machine Learning expertise to address pressing business challenges.Collaborate with cross functional teams to understand the business requirements and data architecture.
Translate business requirements into technical solutions by working with the business and senior data scientists.
Identify and document the data requirements and manage data collection and preparation for projects.
Design and document training and testing strategy.
Document methodologies, findings, and outcomes of model experiments and present it to the team and key stakeholders.
Mentorship and Guidance (20%):
Mentor junior team members, providing technical support, guidance on model development, and best practices implementation.
Coach junior team members, helping them understand complex datasets, models, and business requirements by giving clear and actionable feedback.
Encourage the development of best practices and innovative approaches in data analysis and modeling.
Requirements:- 
4+ years experience as a data scientist involved in data extraction, analysis and modeling.
4+ years of experience in Python and SQL or related tools for machine learning.
Strong understanding of statistics and linear algebra.
Proficiency in machine learning algorithms and all stages of machine learning.
Familiarity with neural networks and deep learning.
Familiarity with AWS services and Snowflake.
Proficiency in handling structured and unstructured data.
Successful end-to-end delivery of data science products.
Exposure to MLOps tools like MLFlow, KubeFlow, DVC,AWS Sagemaker, Seldon etc
Experience deploying models in a AWS cloud environment - with specific experience with AWS tools such as Sagemaker and Step Functions.
Expertise with Natural Language Processing and Understanding.
Experience with libraries and frameworks for training ML and DL models (PySpark, Tensorflow).
Experience and expertise in ML Operations best practices.
  Our Commitment to Inclusivity and Diversity
At G2, we are committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, or marital, veteran, or physical or mental disability status. 
Learn more about our commitments here Commitments",USD 86K - 160K *
371,Data Scientist,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About the role
The goal of the Pod Member in PADS is to help deliver model-building projects to the business using their technical skills as well as their inquisitive nature. This is a complex role Machine Learning, Data Extraction, Data Exploration, Statistics skills. A combination of these skillsets will allow the applicant to help the team deliver accurate and ethical results on time. The Pod Member will be asked to justify their design decisions and participate in challenging model purposes as well as efficacy.
What you’ll do
Work with an HR Data Science Pod to help deliver key predictive and inferential models to the business.
Create and execute against a project plan that includes building models or other data-driven products that help address those business needs.
Maintain and deploy developed models interrogate data sources and modeling approaches with ethics and bias in mind.
Quickly understanding new data sources and finding quick ways to extract information from them for modeling and inference purposes.
Working with technical teams to bring developed models from exploration to deployment.
Application of Machine Learning and Statistical methods which will be the most useful for HR processes.
Testing models for fairness and bias and being conscious of the many ways in which bias can affect processes.
Using an MLOps infrastructure to help build, deploy, and monitor created models.
Understand business problems and translate them into models that drive result
What you’ll need
Undergraduate or master’s degree in CS/Engineering, Statistics, STEM or Mathematical degree.
Minimum of 2-4 yrs. work experience in Data Science.
Experience in Python, NLP, statistical knowledge, ML & Azure ML or any cloud machine learning.
Machine Learning (scikit-learn, PyTorch, Keras, etc.)
Data Analysis (pandas)
Data Extraction
Programming proficiency in Python and R
Comfort working in command lines.
Good to have skills:
Power BI
MySQL
Responsible AI
Confluence
Good Scripting Knowledge
SpaCy
What you’ll get
Competitive salary, generous paid time off policy, charity match program, Group Medical Insurance, Parental Leave, Employee Assistance Program (EAP)
Collaborative, team-oriented culture that embraces diversity.
Professional development and unlimited growth opportunities.
#LI-AS13
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:82523
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 126K - 198K *
372,Data Analyst,Experian,"Hyderabad, India",Entry-level / Junior,"Company Description
Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.
We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.
Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group
 Job Description
Experian Consumer Information Service (CIS) is looking for a Delivery Analyst, based in Hyderabad, India to work alongside our UK colleagues to deliver business outcomes for the UK&I region.  
  Background: 
This is an incredibly exciting time for the Experian UKI Region, as we look to build our presence out in Hyderabad and embark on a technology transformation programme to meet our global ambition to significantly scale our business over the next five years. This is an opportunity to join us on this journey and be part of a collaborative team that uses Agile DevSecOps principles to deliver business value.   
  By way of background, the business unit currently comprises of 27 engineering teams who deliver over 70 products achieving $250m revenue per annum.  
  Our unique culture and agile ways of working offer a great opportunity to those seeking to join a talented set of diverse problem solvers to design, build and maintain our products. We pride ourselves in excellence, adopting best practices and holding ourselves to the highest standards. 
  The Role: 
The CIS team is at the forefront of change to digitise customer journeys, helping consumers fulfil their dreams more quickly and easily than ever. You will be working with lenders, fintechs and digital marketplaces to create industry disrupting solutions in one of the biggest financial services markets. 
  The delivery analyst will work from requirements from the client and interpret these and implement the changes in our own solution. They will be responsible for delivery, as well as feeding into design choices for new deliveries and ensuring work is carried out according to business standards. They will work closely with the Client Manager, Data and Analytics teams, and the Go To Market Team to support on executing the pipeline. 
  Key Responsibilities:  
  Line manage a small team of other analysts and guide them in delivering results for clients 
Understand the end to end process for customer delivery, and manage a backlog and pipeline of work for junior analysts 
Maintaining existing solutions and delivering solutions for new clients 
Configuration of products via database tables, using SQL queries 
Configuration of the product to deliver excellent client outcomes 
Using an in-house tool to build scorecards using decision trees and arithmetic logic calculations 
Working according to all regulatory requirements as well as existing change processes and security standards 
Advocate for a culture that achieves business goals, delights customers and acts in a manner conducive to the fair and reasonable treatment of all consumers, irrespective of whether these are Experian UK clients and consumers or not 
Oversee the maintenance and upkeep of documentation for operational processes 
Develop product knowledge 
Accurately Configure product following client requirements 
Develop a constructive working relationship with the client management teams  
Ensure that your delivery Analysis activities are delivered to time, quality and schedule. 
Ensure your delivery meets all the functional requirements provided by product consultants 
Create and maintain any other relevant documentation as required for successful delivery e.g. User Guides, Implementation Guides, Training Guides etc., providing that it is within scope of the role 
Identify any changes needed to product functional documentation in line with any changes made to the product 
Qualifications
Qualifications   
Degree level and / or equivalent level of professional experience, preferably with some element of mathematics, statistics, or computer science. 
Technical knowledge coupled with reasonable understanding of business operating principles 
Communication - Communicate progress of work (progress reports & future plans) to the team and recommend effective corrective actions where necessary, this will be done through retrospectives. 
Customer Service - Pro-actively manage UK internal stakeholder expectations. 
Continuous process improvement - Identify measures to improve delivery and customer satisfaction. 
Networking - use effective working relationships within Experian and third-party suppliers to ensure developments add value and meet business expectations. 
Experience  
Working collaboratively, leads by example and inspires trust of others 
Coordinating with stakeholders, sales teams and leadership teams around feasible achievements and upcoming opportunities 
E - Directing junior analysts  
Required Technical Skills/Knowledge  
Experience using Excel for data manipulation and presentation 
Basic knowledge of SQL to INSERT/UPDATE/DELETE operations 
Statistical & Mathematical Ability
Beneficial Skills/Knowledge  
Experience in the credit industry 
Additional Information
Who are Experian?
We unlock the power of data to create opportunities for consumers, businesses and society. At life’s big moments – from buying a home or car, to sending a child to university, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage their data with confidence so they can maximize every opportunity.
For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done. Our 17,000 people in 37 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.
Could this be the role for you? Apply now to start your journey with Experian.
To learn more about our culture and what it’s really like to work here, check out our LinkedIn and social media channels using the hashtags #ExperianLife and #ExperianWay.
Why choose us?

Our colleagues’ health and wellbeing are a top priority for us, that’s why our reward, benefits and wellbeing programmes are designed so you can come to work feeling your very best self. Our benefits focus on health, money and lifestyle so you can tailor your benefits to your own personal needs. Whether it’s your physical and mental wellness, getting to work or planning for the future, we have a range of flexible options to have you covered!

We are committed to building an inclusive culture and to creating an environment where people can balance successful careers with their commitments and interests outside of work. Our flexible working practices support our belief that this balance brings long-lasting benefits for our business as well as our people. Some roles lend themselves to flexible options more than others, and if this is important to you, we are open to discussing agile working opportunities during the hiring process
Experian Careers - Creating a better tomorrow together
Find out what its like to work for Experian by clicking here",USD 56K - 94K *
373,MLOps Engineer,Clarifai Inc.,Remote (India),Mid-level / Intermediate,"About the Company
Clarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States, Canada, Estonia, Argentina & India.
We have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage.
Clarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.
Your Impact
As one of Clarifai's MLOps Engineers, you will have impact within the developer community, machine learning field, and on Clarifai's business by using state-of-the-art machine learning tools, assisting with our innovation engine, and transferring your deep learning knowledge to others at Clarifai and our end users. Your work will help drive our scalable SDK development, which will play a pivotal role in shaping the future of our software ecosystem.
The Opportunity
You will have the chance to work with a world class team of researchers, ML engineers, software developers, product managers and marketers. In a highly collaborative environment, you will help Clarifai deliver the cutting edge features developed via the SDK which will position you as a leader in the machine learning and AI space. Your innovative contributions will be paramount to:
Extermal:  Driving growth and AI adoption within the developer community, while expanding Clarifai’s user base and footprint in the ever growing AI market.
Internal:  Shape the direction of our products and open up new opportunities for expansion while keeping Clarifai on the cutting edge of Machine Learning technology
Requirements
2+ years of python experience
2+ years hands on experience developing ML software and pipelines
2+ years of cloud exposure: AWS, Google Cloud, Azure (at least one of them)
2+ experience with large scale software development: testing, automation, system-design, performance optimization, concurrent development
ML Theory Foundations: 3+ years of experience with machine learning user journey (data handling, training frameworks, eval frameworks)
Up to date with ML-infra tools and technology: PyTorch, TensorFlow, Docker, Kubernetes, CI/CD
Great to Have
masters/PhD 
ML publications
open source contributions 
SDK Development experience 
Onnx, Nvidia Triton 
Kubeflow
mlflow 
pandas 
Golang, relational databases",USD 73K - 134K *
374,Senior Data Science Consultant,TE Connectivity,"Bengaluru, KA, IN, 560076",Senior-level / Expert,"At TE, you will unleash your potential working with people from diverse backgrounds and industries to create a safer, sustainable and more connected world. 
Job Overview
The Digital Manufacturing EMEA team is part of the Continuous Improvement EMEA Team, focusing on waste elimination and efficiency improvements in all its aspects, with a significant contribution on the overall financial performance of Automotive EMEA.
The Continuous Improvement EMEA team reports to Operations Automotive EMEA.
By providing new generation digital solutions to our Operational teams across EMEA, our team creates full transparency and speed in the ongoing digital & lean transformation(s), which will enable all involved functions to leverage data to develop business insights and roadmap updates based upon clearly arranged and understandable data.
Due to the extended scope, focusing also on the connecting processes from Supplier(s) to Manufacturing ending at the Customer(s) (internal and external) we will function as ‘the’ differentiator for our Company.
This ‘Data Scientist Automotive EMEA’ will report to the Sr. Mng. Digital Manufacturing EMEA. 
  Responsibilities:
Lead projects and work together with our Automotive EMEA Operations plants, internal (IT, TEIS, Corporate Technology, CoE, SC, ..) and external partners in the area of Digital Factory (Applications, ML, AI, DL), aligned with Operations Automotive EMEA Strategy.
Lead Digital Factory improvement projects (Enhancements) of existing applications together with internal / external supplier and customers (project management) until the level of RTD (Ready To Deploy)
Use a combined knowledge of computer science and applications, modelling, statistics, analytics and math to solve problems
Identify and interpret data sources, manage large amounts of data, merge data sources together, ensure consistency of data-sets, create visualizations to aid in understanding data
Develop, Validate and Deploy (including Training and Coaching of the users) until the level of RTD (Ready To Deploy), Digital Factory Applications, ML models, contributing to waste elimination and efficiency improvements within all Operations functions (Manufacturing, Quality, SC, LOG, ….), this together with our internal and external partners.
Desired Candidate Profile:
Good understanding of a technology driven manufacturing company.
Knowledge of the core manufacturing technologies: Stamping, Plating, Assembly, Molding.
Experienced with data visualization tools like PowerBi, Tableau, ThingWorx,..
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Development experience in programming languages R, Python,..
Knowledge, experience in JAVA scripting
Excellent pattern recognition and predictive modelling skills.
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, neural networks and deep learning etc.
Experience in technologies like, Jupyter Notebooks, Numpy, Pandas, Seaborn, Scikit-learn, PyTorch and TensorFlow.
Exposure to recent developments in Deep Learning domain.
Database skills, on-premises and cloud based.
Experience in AWS is an advantage, functional knowledge of AWS platforms such as Sagemaker, S3, and RedShift.
Excellent presentation skills in both spoken en written English.
The ability to translate, explain and bring, complex data science topics to an easy understandable level, speeding up acceptance level in general.
Bachelor or master in data science
Team player with a solution focused problem-solving mentality.
Change agent with high Execution level, including training and coaching talents.
Passioned about the combination Technology, Data, Analytics and Statistics with link to Quality, Product and Process Engineering
Inspired by and searching actively for new technologies and methods.
Driving TE Values : Integrity, Accountability, Teamwork, Innovation
Working knowledge of connectivity to databases (using various packages like sqlite3,pyodbc, postgresSQL,AWS Redshift)  and working with Big Data on languages like Python/R
Working knowledge of Image classification which may include
Algorithms like CNN, SVM, k-Nearest neighbor, MLPs and SGD (Stochiastic gradient Descent) would be a welcome addition etc.
Data Preprocessing - Image resizing, Gaussian Blur
Data normalization - PCA (Principal Component Analysis) etc
Working experience in AWS and/or MS Azure for model building and deployment using pre-defined services
End-to-end implementation experience of ML models - using server-based callbacks
Real-time computer vision algorithms
Exposure to vision systems
Deep learning techniques
Auto ML tools
Transfer learning to utilize model accuracy and feedback loop implementation

  Competencies
Values: Integrity, Accountability, Teamwork, Innovation
ABOUT TE CONNECTIVITY
TE Connectivity is a global technology leader enabling a secure, sustainable, productive, and connected future. Our broad range of connectivity and sensor solutions have been proven in the most demanding environments, enabling advancements in transportation, industrial applications, medical technology, energy technology, data communications, and for the home. With more than 85,000 employees, including more than 7,500 engineers, we work with customers in nearly 140 countries. TE ensures that EVERY CONNECTION COUNTS. Learn more at www.te.com and on LinkedIn, Facebook, WeChat and Twitter.
  WHAT TE CONNECTIVITY OFFERS:
We are pleased to offer you an exciting total package that can also be flexibly adapted to changing life situations - the well-being of our employees is our top priority!
•    Competitive Salary Package
•    Performance-Based Bonus Plans
•    Health and Wellness Incentives
•    Employee Stock Purchase Program
•    Community Outreach Programs / Charity Events
•    Employee Resource Group
Across our global sites and business units, we put together packages of benefits that are either supported by TE itself or provided by external service providers. In principle, the benefits offered can vary from site to site.",USD 95K - 158K *
375,Data engineer - Azure,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About Gartner IT :
Join a world-class team of skilled engineers who build creative digital solutions to support our colleagues and clients.  We make a broad organizational impact by delivering cutting-edge technology solutions that power Gartner.  Gartner IT values its culture of nonstop innovation, an outcome-driven approach to success, and the notion that great ideas can come from anyone on the team. 
About this role:
The Master Data Management Engineer will be responsible for designing and building Master Data Management functionality that would help enable better Master Data across Gartner. She would maintain the highest data quality standards demanded by Gartner utilizing multiple state of the art technologies in data engineering, data operations and data mastering in a cloud-based environment.
What you’ll do:
Analyze business requirements, design solutions and implement functionality related to MDM
Build and maintain Data Pipelines using SQL and AWS technologies like Glue and Python
Build and configure web services, pub-sub queues, Event Driven Architecture components
Follow best practices and industry standards while implementing Data Engineering and Mastering functions.
Utilize Master Data Management tools like Ataccama and inhouse tools to ensure filtering, mastering and data quality rules are properly enabled and adequately tested.
Engage in data to day data operations involving troubleshooting of data pipelines, monitor and maintain job schedules.
What you’ll need:
Strong IT professional with 2+ years of experience in cloud-based data engineering preferably in AWS. The candidate should have strong analytical and problem-solving skills.
       Must have:
1 to 2 years of experience in cloud based (Azure preferred) data engineering.
Expert level coding skills in Python or Java
Very good SQL and data analytics skills – ability to look at complex stored procedures, troubleshoot performance issues.
Attitude and aptitude to learn, collaborate and work towards common goals of the MDM team. Must be a team player.
Who you are:
Graduate/Postgraduate.  BE/Btech, ME/MTech or MCA is preferred. 
Excellent communication skills.
Able to work independently within but interact with a team collaboratively in a fast-paced AGILE environment.
Feels strongly about the importance of Master Data and will do your best to improve it’s quality and trust across the organization
Strong desire to improve upon their skills in tools and technologies.
Don’t meet every single requirement? We encourage you to apply anyway. You might just be the right candidate for this, or other roles.
#LI-AJ4
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84096
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 90K - 150K *
376,Intelligent Automation (RPA/AI/ML) Service Delivery Lead,Alcon,Bengaluru - AGS,Senior-level / Expert,"Responsible for leading large scale automation team that includes SLA alignment, incident/problem management, design, development, testing, root cause analysis, bugfixes, improvements, financial cost management.
Seek and build stakeholder relationships to enhance delivery and better understand, identify and work through issues.
Lead governance process to ensure automation quality by adhering to methodology, SDLC, Design & Code standards, security and compliance policies.
Vendor/Partner Management - Manage relationships with Automation tool vendors, partners including licensing, updates, and support.
Coordinate and manage the overall automation pipeline, ensuring that projects are on track and resources are allocated appropriately.
Manage customer issues, and provide effective remediation in a timely manner, communicating out status, performance metrics to stakeholders at all levels of the organization.
Responsible for operational support & architecture optimizations through automation.
Drive continuous improvement across platform and products through automation, measurements, and standard processes,
Provide technical direction on design considerations, including performance, scalability, maintainability, and traceability.
Works with Automation Technical Team members to facilitate the planning and execution of RPA and other Automation projects.
Coordinate with the business and the Automation team to identify and provide support for solution designs for production issues and enhancements.
Identify scope, benefits, constraints, and risks for Automation initiatives; capture and document current state manual processes including data flows.
Consider change management implications for implementation of new processes for Automation.
Deliver key business analysis artifacts, using best practices and tools, for the design, solution and execution of medium and large projects.
Help design, document and maintain system processes.
Essential Job Functions (state in 5-7 bullets the core accountabilities, from job catalog)
Experience managing delivery of automation use cases by working with the business and technical teams
Strong effective working relationships with team members, stakeholders and management.  Demonstrate strong collaboration across all levels of the organization.
Effective Persuasive Communication including the ability to influence SMEs and business stakeholders toward change, automation and continuous improvement
Knowledge of RPA, AI/ML technologies and spectrum of best practices with process automation and operational excellence.
Strong analytical skills, coupled with a logical, disciplined, and structured approach to documentation and procedures.
Excellent spoken and written communication. Assertive and confident raising action points with senior individuals
A team player that is willing to learn and adapt in a high pace delivery environment.
Maintain up to date knowledge of industry trends and developments in areas including generative AI, RPA, process mining, etc.
Standard Minimimum Requirements
Education: A bachelor’s degree in a technical field required (MS Preferred): Computer Science, Information Systems, Mathematics or STEM related fields.
Experience: 10+ Years of IT Experience
8+ years of Experience working with automation software (e.g., Automation Anywhere (preferred), Blue Prism, UI Path, Power Automate), AI/ML and Python.
5+ years of experience in managing large global Automation teams.
Experience in analyzing data to draw business-relevant conclusions.
Certification in ""Intelligent Automation"" technology.
Functional knowledge including SDLC, CI/CD pipelines, test automation, solution architecture, API architecture and design, and systems integration.
Strong communication skills to translate technical design ideas and proposals to both technical and non-technical group of customers.
Refer to “Specific Job posting content” section for additional experience details.
Language
The ability to fluently read, write, understand, and communicate in English.
Specific Job Posting Content
Continuous learning attitude of the emerging technology trends and instituting innovative thinking/approach throughout the organization.
Substantial skills in the platform technologies in their domain, sufficient to drive technical solutioning with the ability to effectively engage with engineers to make decisions on technical trade-offs.
Contributes with ideas that challenge thinking and standardize processes.
Strong problem-solving skills with ability of accurately analyze situations and reach productive decisions based on informed judgment.
Strong collaboration skills for effective communication across multiple teams and stakeholders, both internal and external
Data savvy individual with hands on experience in preparing, analyzing and deriving insights from data
Ability to understand and apply practices and patterns related to data access, integrations, security, and privacy/GDPR
Knowledge of enterprise data management concepts, principles, and practices as related to master data, reference data, and/or metadata as well as data governance.
Experience in working as part of Agile teams and using agile and collaboration tools like Jira, Confluence
Ability to work independently and as part of a team with strong collaboration skills
Data savvy, problem solver
High learning agility
Alcon is an Equal Opportunity Employer and takes pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital status, disability, or any other reason.",USD 45K - 84K *
377,Product Data Analyst,MillerKnoll,Bengaluru - IBU Cunningham Road,Entry-level / Junior,"Why join us? 

Our purpose is to design for the good of humankind. It’s the ideal we strive toward each day in everything we do. Being a part of MillerKnoll means being a part of something larger than your work team, or even your brand. We are redefining modern for the 21st century. And our success allows MillerKnoll to support causes that align with our values, so we can build a more sustainable, equitable, and beautiful future for everyone.
Role: Product Data Analyst  
Location: Bangalore
Job Description
The Product Data Specialist position is responsible for organizing, creating and updating product information in our internal systems.  This position will help build and maintain a wide breadth of data associated with our product assortment including but not limited to pricing, dimensions, care instructions, design history, key features, and compliance details. 
Essential Functions
Ensure the timely and accurate creation of new SKUs to support product launches via CSV upload and/or direct data entry into relevant systems maintaining strict adherence to data integrity standards.
Audit SKU and product level data to ensure adherence to data integrity standards, updating where appropriate.
Update product information including cost, price, or other facets are made in a timely and accurate fashion.
Gather product data from a variety of sources including vendor websites, PDFs, and spreadsheets and organize into CSV files for upload into backend systems. 
Perform additional responsibilities as requested to achieve business objectives of the team.
Ideal candidate
Bachelor’s degree or equivalent experience working with large data sets.
4-6 years’ experience working with ERP systems and/or content management systems.
Superior attention to detail.
Strong excel / CSV skills; comfortable working with and manipulating large data sets.
Ability to work effectively with a variety of internal and external business partners.
Ability to work independently and manage multiple projects, with excellent time management skills.
Excellent written, verbal and interpersonal communication skills.
Ability to take direction, constructive criticism and to work within specified deadlines.
Adhere to process and procedures defined for the role, the team and the organization.
Demonstrates ability to work effectively with a variety of internal and external business partners.
Knowledge of Net Suite or similar ERP or PIM systems a plus.
Who We Hire?

Simply put, we hire everyone. MillerKnoll is comprised of people of all abilities, gender identities and expressions, ages, ethnicities, sexual orientations, veterans from every branch of military service, and more. Here, you can bring your whole self to work. We’re committed to equal opportunity employment, including veterans and people with disabilities.",USD 22K - 42K *
378,Senior Market Research Analyst,Roche,Chennai RSS,Senior-level / Expert,"The Position
Position title: Senior Market Research Analyst
Location: Chennai or Hyderabad
Roche has established Global Analytics and Technology Center of Excellence (GATE) in India to drive analytics & technology driven solutions by collaborating with Roche affiliates across the globe.
As a Senior Market Research Analyst, you will work closely with stakeholders in the business teams across Roche’s global affiliates, conduct research on internal & external data sources, generating qualitative and quantitative insights, and deliver high quality research and analytics solutions to business problems. You will be required to conceptualize unstructured business problems and apply research and analytical skills to address business questions.
In this role, you will:
Be the subject matter expert on healthcare industry trends, primary and secondary research
Competency in conducting/analyzing pharma market research(from various sources including public and proprietary databases), distilling down data into concise summaries focused on the key insights informing business decisions and strategies
Persuasive written and verbal communication skills; comfortable with technical and non-technical audiences
Develop a deep understanding of patients, HCPs and other customers, and market dynamics (healthcare industry)
Proactively mine internal information, reports maintained by vendors and other external sources to spot trends, patterns, areas of opportunities and threats for the business, synthesis insights and build the initial foundational insights and story.
Design and execute primary and secondary market research, synthesizing the results and insights from the research into actionable recommendations for business
Generate qualitative / quantitative reports that communicate the key takeaways with a holistic point of view
Experience in working with unstructured, free text, qualitative interviews and synthesizing this into themes and business action - desirable
Experience in designing and conducting surveys - desirable
Strong attention to detail, ownership with minimal guidance to add value in a dynamic environment
Specific requirements w.r.t. Qualitative Market Research
Understanding of the applications, pros & cons of various qualitative market research techniques
Comfort synthesizing qualitative insights into a meaningful / impactful and motivating story
Desk research to provide background insights on a topic
Social listening - ability to create landscape reports / topical reports utilizing SL
Synthesizing insights from multiple insight channels to a meaningful story
Specific requirements w.r.t. Quantitative Market research
Understanding of the applications, pros & cons of various quantitative market research techniques
Strong understanding of basic statistical concepts and ability to apply them to analyze data from primary and secondary research studies
Ability to work with statistical software packages such as SPSS, R, or SAS to clean, analyze, and interpret data – highly preferred
Utilize and be comfortable working with raw data from quant studies - cleaning data, analyzing data and charting data into a meaningful story (ATUs, Trackers)
Comfort running MaxDiff survey analysis / Conjoint studies/ cluster analysis/ factor analysis and similar studies
Qualifications:
Overall experience of 5-6 years in the market and business research space in the Pharma, Healthcare, Biotechnology domain
Experience of working with US customers
Strong understanding of the drug development process from clinical phases to launch and commercialization
Hands on experience with SQL, MS-Excel & MS-PowerPoint is must and SAS/ Python/ AWS/ R/ SPSS are nice to have
Strong verbal and written communication skills with ability to develop compelling stories, present to the stakeholders and influence decision-making
Self-starter with innovative mindset and passionate about solving complex problems
Highly motivated, learning oriented and quality-focused individuals would be preferred
Education:
B. Sc. / B. Tech/ B.E. – Biotechnology/ Pharma/ Healthcare/ Life sciences (mandatory)
MBA or Certification in area of market research/ analytics (good to have)
Who we are
At Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we’ve become one of the world’s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.
Roche is an Equal Opportunity Employer.",USD 63K - 150K *
379,Data Engineer- AWS,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About Gartner IT :
Join a world-class team of skilled engineers who build creative digital solutions to support our colleagues and clients.  We make a broad organizational impact by delivering cutting-edge technology solutions that power Gartner.  Gartner IT values its culture of nonstop innovation, an outcome-driven approach to success, and the notion that great ideas can come from anyone on the team. 
About this role:
The Master Data Management Engineer will be responsible for designing and building Master Data Management functionality that would help enable better Master Data across Gartner. She would maintain the highest data quality standards demanded by Gartner utilizing multiple state of the art technologies in data engineering, data operations and data mastering in a cloud-based environment.
What you’ll do:
Analyze business requirements, design solutions and implement functionality related to MDM
Build and maintain Data Pipelines using SQL and AWS technologies like Glue and Python
Build and configure web services, pub-sub queues, Event Driven Architecture components
Follow best practices and industry standards while implementing Data Engineering and Mastering functions.
Utilize Master Data Management tools like Ataccama and inhouse tools to ensure filtering, mastering and data quality rules are properly enabled and adequately tested.
Engage in data to day data operations involving troubleshooting of data pipelines, monitor and maintain job schedules.
What you’ll need:
Strong IT professional with 2+ years of experience in cloud-based data engineering preferably in AWS. The candidate should have strong analytical and problem-solving skills.
       Must have:
1 to 2 years of experience in cloud based (AWS preferred) data engineering.
Expert level coding skills in Python or Java
Very good SQL and data analytics skills – ability to look at complex stored procedures, troubleshoot performance issues.
Attitude and aptitude to learn, collaborate and work towards common goals of the MDM team. Must be a team player.
Who you are:
Graduate/Postgraduate.  BE/Btech, ME/MTech or MCA is preferred. 
Excellent communication skills.
Able to work independently within but interact with a team collaboratively in a fast-paced AGILE environment.
Feels strongly about the importance of Master Data and will do your best to improve it’s quality and trust across the organization
Strong desire to improve upon their skills in tools and technologies.
Don’t meet every single requirement? We encourage you to apply anyway. You might just be the right candidate for this, or other roles.
#LI-AJ4
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:84092
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 90K - 150K *
380,"Regional Data Scientist APAC - MD,FT COE",Bayer,"Delhi, Delhi, IN",Senior-level / Expert,"  At Bayer we’re visionaries, driven to solve the world’s toughest challenges and striving for a world where ,Health for all, Hunger for none’ is no longer a dream, but a real possibility. We’re doing it with energy, curiosity and sheer dedication, always learning from unique perspectives of those around us, expanding our thinking, growing our capabilities and redefining ‘impossible’. There are so many reasons to join us. If you’re hungry to build a varied and meaningful career in a community of brilliant and diverse minds to make a real difference, there’s only one choice.
  Regional Data Scientist APAC - MD,FT COE 
  POSITION PURPOSE:
The Regional Data Scientist APAC is responsible to develop and utilize best-in-class data management techniques and modeling methodologies for Regional Market Development (MD) field experiments and drive value to customers through data analytics. This role is also responsible for identifying and establishing best practices and systems to collect and store data, optimize data usability, and analyze data with predictive models. In conjunction with the Global FT COE team, develop data structure for MD data lake, working with internal and public data (including image data) allowing the data to be used for artificial intelligence and meta-analyses. The role will effectively network within the Data Science Community and collaboratively partner with regional and country Market Development teams to drive efficient and effective field trials and provide analytical insights to support product and solution recommendations.
  YOUR TASKS AND RESPONSIBILITIES:
Work on creating the right data structure, data lake and data flow
Provide data in real time in automated flow
Develop and validate data QA/QC procedures
Independently perform statistical and predictive modeling of field trial data (including image data) for rapid analyses that enhance decision quality to support new product launches (including S&T, CP, SGR, Biologics, Digital etc), grow market share, and product maintenance in APAC
Identify technical gaps within the Market Development region and applying data science acumen to unsolved business goals
Provide clear and understandable validated analysis of trial results to internal customers which drive both strategic decisions, knowledge transfer, and marketing/sales support
Provide value added business recommendations and solutions based on innovative predictive analytics to accelerate product development and characterization
Apply data analytical principles which maximize the predictive power of trial results to enable data-based decision making and support APAC business growth
Ensure quality control processes are established for verification and validation of data
Partner with IT teams to ensure data stewardship best practices are followed across data systems and processes from data entry through reporting
Collaborate with interdisciplinary scientists to gather requirement for data pipelines; Optimize algorithms and data workers to scale horizontally and contribute to the development of new algorithms and capabilities that will enable connected pipeline analytics for all pipelines
WHO YOU ARE:
M.S., Ph.D. preferred, in statistics, data science or quantitative discipline
Experience with GPC cloud services (BigQuery), python, github, R, and data modeling methodologies
Technical knowledge in: SQL and NoSQL databases (data warehousing, data modeling, etc.)
Experience with big data tools (Spark, Kafka.)
Experience with tools for authoring workflows and pipelines (Airflow, AWS Step Functions, etc.)
Demonstrated ability to work effectively in teams and collaborate across functions
Demonstrated ability to interpret results effectively and clearly communicate complex concepts and recommendations
Bayer does not charge any fees whatsoever for recruitment process. Please do not entertain such demand for payment by any individuals / entities in connection with recruitment with any Bayer Group entity(ies) worldwide under any pretext. 
Please don’t rely upon any unsolicited email from email addresses not ending with domain name “bayer.com” or job advertisements referring you to an email address that does not end with “bayer.com”. 
    YOUR APPLICATION  
    Bayer is an equal opportunity employer that strongly values fairness and respect at work. We welcome applications from all individuals, regardless of race, religion, gender, age, physical characteristics, disability, sexual orientation etc. We are committed to treating all applicants fairly and avoiding discrimination.
        Location: India : Delhi : Delhi || India : Karnataka : Bangalore || India : Maharashtra : Mumbai || India : Tamil Nadu : Chennai || India : Telangana : Hyderabad     
Division: Crop Science    
Reference Code: 804165     
    Contact Us
  + 022-25311234",USD 135K - 205K *
381,Tech Lead - Azure Databricks Job,Yash Technologies,"Hyderabad, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Azure Databricks Professionals in the following areas :
    Job description
Bachelors degree in Computer Science, Computer Engineering, or related technical discipline.
Mandatory Skills:Azure Data engineering, Pyspark, Python, Azure Data Bricks, Azure Data Factory, SQL.
  5+ years exp as a Data Engineer must have with ADF,Databricks,Pyspark, Python
Must have experience with databricks
-Technical expertise in data modelling
  Azure Data Factory (ADF): Candidate should know how to create data pipelines, schedule activities, and manage data movement and transformation using ADF
  Azure Databricks: Candidate should be adept at using Databricks for data engineering tasks like data ingestion, transformation, and analysis
  Oracle Database- Candidate should be proficient in using it for data storage, retrieval, and basic manipulation.
  Very strong in SQL programming
  Programming in Python / PySpark
  Azure DevOps: Knowledge of Azure DevOps is valuable for implementing Continuous Integration and Continuous Deployment (CI/CD) pipelines for data engineering solutions
  Monitoring and Optimization: Understanding how to monitor the performance of data engineering solutions and optimize them for better efficiency is crucial
  Data Quality and Data Cleaning: Knowing how to ensure data quality and perform data cleaning operations to maintain reliable data is important for data engineers.
  Data Modeling and ETL/ELT: You should be skilled in data modeling techniques and Extract, Transform, Load (ETL) or Extract, Load, Transform (ELT) processes for data integration.
  Good to have Apache Hive: Knowledge of Hive, a data warehousing and SQL-like query language that provides an abstraction over Hadoop MapReduce
  Good to have Apache Spark: Understanding of Spark and its various components.
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
382,"Sr Director, Data Science",Gartner,Gurgaon - Cyber Park,Senior-level / Expert,"About the role:
This is a unique opportunity to join our fast-growing Data Science team. In the role of Sr. Director, Data Science you will be responsible for building & leading a Data Science team who creates and operationalizes Machine Learning models and automated tools that use internal and external data to identify and capture opportunities to improve client retention. We are looking for a great structured thinker & creative problem solver who can design and deliver solutions that meet stakeholder needs while powering through many constraints and dependencies. A senior leader who is aware of the larger data science landscape, who leans in and partners across multiple stakeholders to build alliances and deliver valuable and usable tools and insights.
What you will do: 
Work closely with executive business leaders across Research, Product, and other organizations to influence their priorities while translating data science implications to technical teams
Create a strategy and overall vision for where and how data science can further develop scaled insights that increase client value and retention through improved Research and Products. A few potential projects or domains you may get involved with:
Lead teams in: developing models to identify the highest value assets (including research content, analyst interactions with clients, and product functionality like the client-facing platform, peer, and tools) or applying Natural Language Processing (NLP) to sense client demand based on various data sources including search, readership, recoded interactions with Gartner experts, and associates.
Deliver advanced analytics that surface insights about Gartner Research and Products to increase the impact on retention, improve the client experience, and boost economic productivity
Lead Data Science team operations, engineers and product managers to develop analytics and ML pipelines to support scalable analysis and internal tools
Partner closely with senior leaders in Global Product Management (Customer & Market Research), Primary Research, Secondary Research, and analytics teams to deliver insights about client demand, the impact of Gartner insights, and the consumability of Gartner content
Foster a culture with a platform mindset that builds reusable data sources and globally applicable models using consistent approaches.
Be a champion for quality in all that we do; promote best-in-class quantitative methods and process documentation
Inject the most applicable technology, including Machine Learning, Artificial Intelligence, Generative AI, Natural Language Processing, and Statistical Modelling
Manage data science process efficiency, consistency, and quality. For example, coding standards, code reviews, peer reviews, ensuring code reusability, providing technical feedback, ensuring solutions are documented
Immediately build and lead a team of six new-hire data scientists
What you will need:
Degree (advanced degree preferred) in a quantitative research field (e.g., Math, Operations Research, Physical Science, Computer Science, Economics or Engineering, etc.)
10+ years of relevant experience in data science
Experience hiring, building, and managing a team of data scientists.
Well-versed in a wide range of analytical techniques such as advanced statistics, machine learning, and natural language processing
Practical, intuitive problem-solver with a demonstrated ability to translate business objectives into actionable data science tasks and translate quantitative analysis into actionable business strategies
Connections to the external ML/Data Science community and knowledge in emerging technologies
Experience and proficiency with various programming languages (Python), machine learning models, statistical packages, SQL/relational databases, cloud computing (Azure), and distributed processing (Databricks)
Desire and ability to develop and coach data scientists
Superior verbal and written communication skills
Experience influencing senior executives and working through formal and informal networks to achieve cross-functional outcomes
Demonstrated ability to conceive and propose innovative solutions to complex business problems
Demonstrated ability to develop roadmaps, lead team execution, validate models, and successfully deliver solutions
What you will get:  
Competitive salary, generous paid time off policy, charity match program, Medical, Dental & Vision Plans, Parental Leave, Employee Assistance Program (EAP), 401K matching and more!
Collaborative, team-oriented culture that embraces diversity 
Professional development and unlimited growth opportunities
#LI-PM3
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:80706
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 95K - 158K *
383,"Senior Manager, Data Quality",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
The data quality manager will be responsible for ensuring the quality of data by implementing various data quality checks and measures. This includes establishing data standards and policies, and ensuring adherence to these standards with a focus on improvement of data quality and trust
Champion and mature the data governance and quality processes and programs including metadata management, data lineage & literacy, user access management, data flow diagrams and documentation
Work collaboratively with cross-functional teams, including engineering, operations, and business groups to ensure that all quality initiatives are aligned with Visa's overall business objectives
Update and maintain data catalog and report inventory with contextual information and manage quality control metrics and testing activities, including establishing sampling plans and procedures
Responsible for defining and implementing data quality checks and data reconciliation rules in partnership with Ethics & Compliance's (E&C) business stakeholders, technical data architects and data engineers to ensure data integrity
Engage with stakeholders across the organization to identify data quality needs, draft requirements, assist in the development of data quality checks, track, monitor, and report of the overall health of data in the organization
Ensure that all quality-related documentation is complete and accurate, including specifications, procedures, and process flows
Establish success metrics and assist with preparation of material for regular team, leadership, and governance forums to review progress and initiatives with key stakeholders
Leverage AI to establish strong preventive action systems to continually improve operational performance and performance in meeting regulatory standards
Work closely with our solution vendors on roadmap items for implementation and provide feedback for additional improvements that would benefit the organization
Analyze and extract data from various sources to build user-friendly analytic solutions for business use
Partner with data owners and data stewards to develop workflows, dashboards, and automation of data governance activities within our data governance tools
Follow data management processes and procedures and provide input to the creation of data definitions, business rules and data access methods
Perform functional, regression, usability tests, etc. as applicable for both new and existing datasets, systems, reports, and dashboards
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
• Deep understanding of data quality management, data governance & standards, and associated technologies
• Proven experience in establishing and operationalizing data quality management capabilities in a complex, global organization.
• Practical knowledge of industry frameworks for Data Quality, such as DAMA
• Detailed experience with Informatica Data Quality, knowledge of SAP MDG as a Data Quality tool
• Demonstrable experience in leveraging data catalogues to support Data Quality use case delivery
• Ability to write SQL queries to conduct data validations and probe quality issues with data
• Ability to develop technical expertise and understanding of system interdependencies and their impacts on Test Data
• Strong experience in Project Delivery Methodologies such as SDLC, Iterative, Agile, Scrum, Kanban
• Experience with test automation tools and frameworks
• Ability to abstract technical details and effectively communicate to audiences at different levels
• Excellent listening, communication, leadership, and presentation skills. Strong organizational and documentation skills
• Ability to develop and maintain relationships with internal partners. Proficient at balancing multiple efforts at a time.
• Ability to navigate through ambiguity to clarify objectives and execution plans
• Exemplify flexible thinking, curiosity, self-motivation, dedication to quality, focus on the details, and a positive perspective.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
384,Software Engineer - AI/ML,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
2+ years of experience with Java or a similar OO language
Passion for JavaScript and the Web as a platform, reusability, and componentization
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Experience with any of the modern UI frameworks like Angular, React or Vue
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
knowledge of basic AI/ML techniques and algorithms
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
385,Data Engineer 2,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
Organization Objective/Purpose:
This position in the Engineering team under the Digital Integration Services organization. We drive the first mile of the customer experience through personalization of offers and content. We are currently on the lookout for a smart, highly driven software engineer.
You will be part of a team that is focused on building solutions, pipelines using latest software engineering design principles and tech stacks. You will also be expected to Identify, design, and implement improvements including re-designing infrastructure for greater scalability, optimizing data delivery and automate continuous integration and deployment processes/pipelines.
The incumbent is also expected to partner with various stakeholders, bring scientific rigor to design and develop high quality software.
She / He also must have excellent verbal and written communication skills and be comfortable working in an entrepreneurial, ‘startup’ environment within a larger company.
Brief Description of Role:
Develop solutions for Epsilon that will deliver high quality personalized recommendations across different channels to our customers
Working with Data science team to ensure seamless integration and support of machine learning models.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Develop end-to-end (Data/Dev/MLOps) pipelines based on in-depth understanding of cloud platforms, AI/ML lifecycle, and business problems to ensure solutions are delivered efficiently and sustainably.
Collaborate with other members of the team to ensure high quality deliverables
Learning and implementing the latest design patterns in software engineering
Qualifications
Data Management 
Experience with both structured and unstructured data, and Hadoop, Apache Spark, or similar technologies 
Good understanding of Data Modeling, Data Warehouse, Data Catalog concepts and tools
Experience with Data Lake architectures, and with combining structured and unstructured data into unified representations
Able to identify, join, explore, and examine data from multiple disparate sources and formats 
Ability to reduce large quantities of unstructured or formless data and get it into a form in which it can be analyzed 
Ability to deal with data imperfections such as missing values, outliers, inconsistent formatting, etc.
Ability to manipulate large datasets, (millions of rows, thousands of variables)
Software Development 
Ability to write code in programming languages such as Python, PySpark and shell script on Linux
Familiarity with software development methodology such as Agile/Scrum
Love to learn new technologies, keep abreast of the latest technologies within the cloud architecture, and drive your organization to adapt to emerging best practices
Architecture and Infrastructure
Architectural design experience on AWS.
Experience in delivering software with AWS EC2, S3, EMR/Glue, Lambda, Data Pipeline, CloudFormation, Redshift etc.
Good knowledge of working in UNIX/LINUX systems
Qualifications 
Bachelor’s Degree in Engineering and related field with 2+ years of similar experience
Tech Stack: Python, PySpark, Micro services, Docker, Serverless Frameworks & Databricks.
Hands on experience building ETL workflows/pipelines
Experience in relational and non-relational databases and SQL (NoSQL is a plus).
Experience with Cloud technologies (AWS or Azure)
Experience building Data and CI/CD/MLOps pipelines
Familiarity with Airflow and MLFlow tools
Familiarity with automated unit/integration test frameworks
Experience working on AdTech or MarTech technologies is added advantage
Knowledge of machine learning algorithms and concepts and implementation will be a plus
Good written and spoken communication skills, team player.
Strong analytic thought process and ability to interpret findings 
 In addition, the candidate should have strong business acumen, and interpersonal and communication skills, yet also be able to work independently. He/she should be able to communicate findings and the way techniques work in a manner that all stakeholders, both technical and non-technical, will understand.
 ",USD 121K - 186K *
386,Senior Data Scientist,Toast,Bengaluru,Senior-level / Expert,"Toast is driven by building the restaurant platform that helps restaurants adapt, take control, and get back to what they do best: building the businesses they love.
  Now, more than ever, the Toast team is committed to our customers. We’re taking steps to help restaurants navigate these unprecedented times with technology, resources, and community. Our focus is on building the restaurant platform that helps restaurants adapt, take control, and get back to what they do best: building the businesses they love. And because our technology is purpose-built for restaurants, by restaurant people, restaurants can trust that we’ll deliver on their needs for today while investing in experiences that will power their restaurant of the future. 
  Bready* to make a change?
As the Senior Data Scientist in our Bangalore Data Science team, you will contribute to building machine learning algorithms using our huge reservoir of sales and transaction data. You will work with architects, engineers and product managers to solve business and customer problems and turn machine learning models into business impact across product lines.
About this Roll*:
Partner with product managers, engineers, and senior strategy leaders to improve the product. Make sure the right questions are being asked, solicit feedback, and iterate until you reach meaningful conclusions backed by solid analysis
Design and analyze A/B experiments to evaluate the impact of changes we make to the product
Apply a diverse set of tactics such as statistics, quantitative reasoning, machine learning and Deeplearning  to research and produce insights
Break down larger ML initiatives into smaller problems that enables data science to deliver incremental business value and lead the team to execute on them
Use Spark/PySpark  daily to develop data pipelines, write complex queries, and perform analysis
Communicate analysis and decisions to high-level partners and executives in verbal, visual, and written media
Develop resources to empower data access and self-service so your expertise can be leveraged where it is most impactful
Develop, debug, and improve data models. Our product moves fast and new data doesn’t always fit in existing models/data distributions. Think about ingesting and storing data in the most useful and scalable format.
Define KPIs, build ETLs, construct dashboards and other tools for you and other stakeholders
  Do you have the right ingredients*?
Advanced degree in Data Science, Statistics, Applied Math, Computer Science, Engineering or other equivalent quantitative disciplines
6 + years of industry experience in the field of Data Science and Machine Learning
Strong proficiency in Python and SQL; experience with some of the following languages, tools, and frameworks: R, Spark, Scala, scikit-learn, Tensorflow, PyTorch, etc.
Familiarity with standard software engineering practices and tools including object-oriented programming, test-driven development, CI/CD, git, shell scripting, task orchestration (Airflow, Luigi, etc.) and preferably AWS tooling (Sagemaker, DynamoDB, ECS, etc.)
Strong knowledge of underlying mathematical foundations of statistics and machine learning
Prior success deploying machine learning solutions in large-scale production environments
Deep experience in one or more of the following areas: natural language processing, recommender systems, and deep learning
Experience leading cross-functional projects that depend on the contributions of others in multiple disciplines
Experience applying both statistical and machine-learning techniques to solve practical product problems such as predicting churn, defining frameworks for measuring success, and clustering user archetypes


Nice to have:
Experience working on product & platform initiatives focused on measuring platform success
  Our Spread* of Total Rewards
We strive to provide competitive compensation and benefits programs that help to attract, retain, and motivate the best and brightest people in our industry. Our total rewards package goes beyond great earnings potential and provides the means to a healthy lifestyle with the flexibility to meet Toasters’ changing needs. Learn more about our benefits at https://careers.toasttab.com/toast-benefits.

*Bread puns encouraged but not required


  We are Toasters
Diversity, Equity, and Inclusion is Baked into our Recipe for Success.
At Toast our employees are our secret ingredient. When they are powered to succeed, Toast succeeds.
The restaurant industry is one of the most diverse industries. We embrace and are excited by this diversity, believing that only through authenticity, inclusivity, high standards of respect and trust, and leading with humility will we be able to achieve our goals.
Baking inclusive principles into our company and diversity into our design provides equitable opportunities for all and enhances our ability to be first in class in all aspects of our industry.
Bready* to make a change? Apply today!
Toast is committed to creating an accessible and inclusive hiring process. As part of this commitment, we strive to provide reasonable accommodations for persons with disabilities to enable them to access the hiring process. If you need an accommodation to access the job application or interview process, please contact candidateaccommodations@toasttab.com.",USD 135K - 205K *
387,Data Engineer (Databricks / Scala / Python),SkyPoint Cloud,"Bengaluru, Karnataka",Senior-level / Expert,"Who we are:
 Skypoint’s mission is to unify data integration, analytics, and AI into a cohesive SaaS offering powered by Data Lakehouse architecture. Our Generative AI Platform brings people and data together with a focus on enhancing healthcare, financial services and other regulated industries. We are proud partners of Microsoft, OpenAI, DataStax and Databricks.
 Website: Skypoint.ai
 
Location: Global Technology Park, Bellandur, Bangalore, India.

Here is what you can expect to work on in this critical role:

You will lead the efforts to leverage the data to its maximum value. Our platform processes billions of rows in data every month on behalf of millions of users.

How do our Data Engineers spend their time?

You can expect to spend about 50% building and scaling the Skypoint Lakehouse, data pipelines and about 20% of your time defining and implementing DataOps methodologies. 

Additionally, 20% of your time will be spent writing and optimizing queries and algorithms. Lastly, you’ll spend about 10% of your time supporting and monitoring pipelines.

Our team values collaboration, a passion for learning and a desire to become a master of your craft. We thrive in asynchronous communication. You will have a lot of support from leadership when you communicate proactively with detailed information about any roadblocks you may encounter.

Qualities of Data Engineers Who Thrive in This Role

🔥 You are a driven, self-starter type of person who isn’t afraid to dig for answers, stays up-to-date on industry trends and is always looking for ways to enhance your knowledge (yes, Databricks-related podcasts count! 🎧)

💡Your skill set includes a blend of Databricks-related technologies in Azure or AWS or GCP

🖥️ Experience with Python or Scala is a must! (you’ve got a software engineering hat)

💡 Working with Python, Scala, Spark (Databricks) interacting with Delta Lakehouse, Delta Live Tables and Unity Catalog

Skills & Experience Required:

💡4-6 years of industry experience
🔥 Spark (Scala or Python), Databricks
💡 Strong backend programming skills for data processing, with practical knowledge of availability, scalability, clustering, micro services, multi-threaded development and performance patterns.
-- Experience with the use of a wide array of algorithms and data structures.
-- Experience in workflow orchestration platforms like Databricks DLT/ADF/AWS Glue/Airflow etc.
-- Strong Distributed System fundamentals
-- Strong handle on REST APIs
-- Experience in NoSQL databases
-- Most recent work experience MUST include work on Scala or Python and Spark (Databricks)

Educational Level:

🔥 BS / BE / MS in Computer Science from a Top Tier school (IITs / RECs etc.)


Perks of working with us:

·       Opportunity to work with a US-based fast-growing SaaS start-up (Industry Data & AI).
·       Competitive total compensation package including equity and performance-based bonus plans.
·       Industry-focused certifications and ongoing training opportunities.
·       Company happy hours and fun team-building activities.
·       Meal cards, other incentives, and gift hampers.
·       Awards and recognition programs.


Join Skypoint and Let's Soar Beyond Boundaries Together!

Ready to Surf the AI Revolution and Dive into Innovation? Armed with top-tier education and cutting-edge expertise, come aboard Skypoint, where we're not merely redefining technology – we're crafting the future with our revolutionary Generative AI Platform. If you're all set to embrace the extraordinary, seize this opportunity, and together, we'll conquer new horizons! Don't wait, Apply Now and Supercharge Your Career with Skypoint!


Skypoint is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",USD 121K - 186K *
388,"Senior Analyst, Data Science & Analytics",TransUnion,Pune,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
Impact you’ll make:
This position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.

• You will partner with internal and external cross-functional teams to drive new business initiatives and deliver long term value-added product propositions for TU’s B2B customers globally. This includes but is not limited to developing predictive risk management and business intelligence solutions for credit card issuers, auto & mortgage lenders, collections agencies, and retail banks.
• You will contribute in analytic engagements involving descriptive, predictive, and prescriptive analysis through the consumer lending portfolio lifecycle, leveraging various techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).
• You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, Python, SQL, Hive, and Spark on server and cloud based computing platforms.
• You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.
• You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.
• You will foster a high performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.
What You'll Bring:
What we’ll bring:
A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.
Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.
Our culture encourages our people to hone current skills and build new capabilities while discovering their genius.
We provide a modern computing environment based on best-in-class ""big data"" and cloud computing technologies and the freedom to explore new data sources and statistical and machine learning methodologies.
Our Analytics team is home to some of the most brilliant minds in the market. Here, we will not only understand your stats jokes, we’ll appreciate them.
What you’ll bring:
Bachelors (4 year) degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least four (3) year of professional experience performing analytic work in Financial Services or related industries
Strong analytical, critical thinking, and creative problem-solving skills
Excellent understanding of machine learning techniques and algorithms, such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, Gradient Boosting, etc.
Advanced programming skills; proficiency with a statistical language such as R; experience using other programming and data manipulation languages preferred (SQL, Hive, Pig, Python, C/C++, Java); high level of familiarity with Microsoft Office tools
Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast-paced environment
Strong project management skills with the ability to manage multiple assignments effectively
Ability to travel 10-20%
Impact You'll Make:
What we'd prefer to see:
Master’s (2 years) or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field.  And, at least one (1) year of professional experience performing analytic work in Financial Services or related industries
Familiarity with credit bureau data and business practices
Experienced with Tableau or other visualization tools
Advanced skills using Excel formulas, macros, and pivot tables to provide detailed analytical reports.
Operates under modest supervision in a complex and dynamic, matrixed environment
Experienced working in a company with a global presence
Experience with modern ""big data"" frameworks (Hadoop, Spark, cloud)
TransUnion Job Title
Sr Analyst, Data Science and Analytics",USD 95K - 158K *
389,Senior Machine Learning Engineer (Python and SQL),"Acquia, Inc.",Remote - India,Senior-level / Expert,"Acquia empowers the world’s most ambitious brands to create digital customer experiences that matter. With open source Drupal at its core, the Acquia Digital Experience Platform (DXP) enables marketers, developers, and IT operations teams at thousands of global organizations to rapidly compose and deploy digital products and services that engage customers, enhance conversions, and help businesses stand out.
Headquartered in the U.S., Acquia has been named a top software company by The Software Report and rated a leader by the analyst community. Acquia’s India office is a Great Place to Work certified organization. We are Acquia. We are building for the future and we want you to be a part of it!
Responsibilities
Contribute working code, documentation, and automated tests that deliver on Sprint goals
Participate in experimentation and prototype building in a collaborative environment, iterating on concepts based on feedback
Work closely with the data team to ensure the appropriate data is available and usable and can serve the appropriate machine learning needs
Customize, fine-tune, and deploy AI/LLM models
Build connectors between APIs powered by different tech stacks
Collaborate with Product, Design, and Data teams as needed to ensure the systems and architecture being built support roadmap, consistency, and platform R&D goals
Contribute as needed to the core libraries used by all teams in the interest of the consistency, stability, robustness, cost effectiveness, and performance of consuming applications and services.
Work with your team to understand and implement R&D Standards.
Review code as needed based on risk/scope and provide feedback and guidance to ensure it complies with our technical standards and security requirements.
Mentor and train other team members on important technical topics through team meetings, pair programming, lunch 'n learns, etc. as needed.
Collaborate with the architecture team to ensure the platform we are building is consistent with the overarching architectural goals at Acquia
Ensure software systems comply with contractual RTO and RPO requirements
An ability to drive desired customer outcomes by learning and understanding the problems being solved.
You will be successful if you:
Are a continuous learner who is able learn through online trainings, books and podcasts as the AI landscape is rapidly evolving
Are comfortable with ambiguity and working in a fast-paced environment 
Balance critical thinking with creative problem-solving 
Make informed decisions, balancing quantitative and qualitative reasoning
Requirements
5+ years of experience as a Data Scientist, Machine Learning Engineer, or Data Engineer
Excellent communication and collaboration skills
Strong knowledge of Python and SQL
Experience writing automated tests
Knowledge of ML Ops tooling
Strong mathematical background and knowledge of machine-learning concepts and algorithms
Strong working knowledge of at least one cloud platform and its related technologies
Ability to learn and adapt to new technologies quickly and become productive in their use
What gives you an edge?
Experience working with AWS
Understanding of software architecture and the tradeoffs between different architectural patterns
Understanding of AI application architectural patterns and tradeoffs
Experience fine-tuning LLMs
Experience with implementing an ML Ops stack
Individuals seeking employment at Acquia are considered without regard to race, color, religion, caste, creed, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation. Whatever you answer will not be considered in the hiring process or thereafter.",USD 150K - 230K *
390,Assistant Manager - ESG Data Reporting,GSK,Bengaluru Luxor North Tower,Mid-level / Intermediate,"Are you looking for a highly visible business partnering analytics role that allows you to shape data strategy with a focus on compliance?  If so, this Planning & Control Manager role could be an ideal opportunity to explore.
As a Planning & Control Manager, you will be responsible for delivering cost effective and high-quality reporting and analytics across a complex risk organization while complying with GSK legal and ethical standards.
This role will provide YOU the opportunity to lead key activities to progress YOUR career.  These responsibilities include some of the following:
•             Design and develop analytical solutions to understand risks across key business processes
•             Execute analytics to provide insights to the Global Finance risk & control environment and enable decisions on the adequacy of the business control framework
•             Perform data analytics on data retrieves obtained from the Enterprise Resource Planning (ERP) organisation and build out standard reports that can then be used for handover to Continuous Control Monitoring to operational staff
•             Develop relationships with ERP teams & Global Ethics & Compliance (GEC) Independent Business Monitoring (IBM) & Audit &Assurance to ensure successful data mining and analytics activities are conducted regularly
•             Partner with the Process Operations teams globally as well as Global Process Owners (GPOs) to identify stakeholder needs and report trends in process gaps, process risks with a view to create positive risk management impact
•             Proactively engage Process Operations teams/GPOs to identify opportunities to leverage technology and analytics in connection with driving simplification and efficiency across processes
•             Collaborate on various special projects requiring data analytical and risk assessment skills e.g. Root Cause Analysis (RCA)
•             Participate on cross-functional and matrixed projects to reduce risk and/or implement new or enhanced controls related to key processes or systems
Why you?
Basic Qualifications:
We are looking for professionals with these required skills to achieve our goals:
Bachelor’s degree in Mathematics, Statistics, Engineering, Information Systems or Finance
2+ years of experience in delivering and embedding analytics with a focus on risk in business operations
Experience working with relational database management systems
Experience with large, complex data analytics, or machine learning and Big Data projects
Preferred Qualifications:
If you have the following characteristics, it would be a plus:
Master’s degree in Mathematics, Statistics, Engineering, Information Systems or Finance
Knowledge of audit, controls and risk management processes
Familiarity with data modelling, entity relationship diagrams, and data dictionaries
Demonstrated experience in developing KPI’s and visual controls
Why GSK?
Our values and expectations are at the heart of everything we do and form an important part of our culture.
These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:
Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.
Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Continuously looking for opportunities to learn, build skills and share learning.
Sustaining energy and well-being.
Building strong relationships and collaboration, honest and open conversations.
Budgeting and cost-consciousness.
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
 ",USD 30K - 56K *
391,Senior Analytics Engineer,EarnIn,Bengaluru,Senior-level / Expert,"ABOUT EARNIN:
As one of the first pioneers of earned wage access, our passion at EarnIn is building products that deliver real-time financial flexibility for those with the unique needs of living paycheck to paycheck. Our community members access their earnings as they earn them, with options to spend, save, and grow their money without mandatory fees, interest rates, or credit checks. Since our founding, our app has been downloaded over 13M times and we have provided access to over $15 billion in earnings.
We’re fortunate to have an incredibly experienced leadership team, combined with world-class funding partners like A16Z, Matrix Partners, DST, Ribbit Capital, and a very healthy core business with a tremendous runway. We’re growing fast and are excited to continue bringing world-class talent onboard to help shape the next chapter of our growth journey.
ABOUT THE POSITION:
This is a high-impact role with a lot of excitement. You will work across the team, help drive data-driven decisions, establish new business metrics, and own automated reporting systems. You will develop solutions to complex business problems characterized by imperfect data. You will gather, transform, and present data to enable data-driven decision-making. You will help scale the analytics we are offering to both internal and external stakeholders. This position will be based in Bangalore/Bengaluru and will be hybrid. 
WHAT YOU'LL DO:
Streamline data flows from source and produce high quality data and pipelines (15%)
Develop and maintain data pipelines, ETL processes, and data integration workflows to ensure efficient and accurate data acquisition from various internal & external sources using SQL, Python, or other scripting languages
Work with data infrastructure to triage infra issues and drive to resolution and serve as the key point to bridge between data infrastructure and end customers
Design, build, and optimize data architecture & models to support business reporting and analytics needs. Understand evolving business requirements to optimize/update data pipelines in SQL
Monitor and optimize the performance of data systems, troubleshoot issues, and propose solutions for data-related problems
Design, develop and maintain scaled, automated, user-friendly systems, reports, dashboards, etc. that will support our financial needs (45%)
Build and deliver high quality visualization and reporting solutions to support Finance business needs
Design and create customized reports for all new financial reconciliation needs catering to their specific needs
Automate reporting for Finance using Python, Periscope, Tableau, Amplitude and other Earnin in-house business intelligence tools and platforms
Interface with Finance, Engineering and Analytics to understand data needs and deliver high quality data products (30%)
Get familiar with finance domain at Earnin and identify opportunities for process automation
Take ownership of debt facility analytics and other core finance areas as needed
Build data functional expertise and own data quality for allocated areas of ownership. 
Create quality controls on data feed to ensure high quality data delivered for end product
Design, build and launch new data extraction, transformation and loading processes in production as and when required
Implement data governance practices, including data security, privacy, and compliance measures
Deep analysis to uncover areas of opportunity and present recommendations that will help shape the strategy and operations of business stakeholders
Create project related documentation for requirements, design, processing methodologies and changes planned and other relevant areas
Provide analytical support for financial needs such as annual audits, new product revenue reporting and external lender inquiries.
Be a data and functional expert at Earnin (10%)
Stay up to date with industry trends and emerging technologies in the field of business intelligence and data analytics.
Be a data SME related to finance domain
Identify and recommend BI and data tools that can be used within the company for increased productivity and scalability
WHAT WE'RE LOOKING FOR:
Master degree in Compute Science, Engineering or Analytics related fields
2+ years of relevant work experience in Analytics, Business Intelligence, Data Science etc
3+ years experience in custom ETL design, implementation and maintenance.
2+ years experience with schema design and dimensional data modeling.
2+ years experience in writing complex SQL queries and Python 
2+ years experience working with Snowflake / Databricks or similar distributed compute systems
3+ experience with business intelligence tools such as Tableau, Power BI, or QlikView.
2+ years of working with relational databases (Redshift, PostgreSQL) and big data structures
1+ Experience with any cloud platform (Ex: AWS) and big data technology (Ex: Spark)
2+ years of experience in collaborating with cross-functional teams
Ability to analyze data to identify deliverables, gaps and inconsistencies
Strong problem-solving and analytical skills",USD 127K - 190K *
392,Sr Staff Data Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
 This position reports to: Director, Data Engineering and Data Science
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.  
As a member of the Product Operations Analytics team, you’ll focus on driving operational awareness to our Executive Team while partnering with leaders throughout ServiceNow to fundamentally improve how we run our business. With a combination of exceptional analytical skills, an insatiable curiosity, and an entrepreneurial “get stuff done” mindset, you’ll help us better understand our customers, partners, and products, and drive important changes that will shape the future of ServiceNow.
What you get to do in this role:
We are looking for a Rock Star with a winning track record in Big Data, Data Warehousing, Visualization and Data Web Services.  The Staff Data Engineer will be a core technical contributor to the team with deep expertise in manipulating and structuring large, complex datasets that feed central data warehouses.  S/he will be responsible for helping stand up and maintaining daily data transfer jobs, database structures, identifying data integrity issues, and developing documentation on data assets. The Staff Data Engineer will also work closely with ServiceNow data analysts and data scientists to help prep data for models and dashboards. 
 The ideal candidate should have a background in Engineering, Statistics, Mathematics, Computer Science, equivalent quantitative field or related practical experience with an obsession on data quality. S/he should have an outstanding ability to foster relationships with staff across departments and be motivated to continuously achieve positive results.  Extensive understanding to the needs of data visualization is a must for this role.  S/he should also be able to effectively handle ad hoc requests and multitask with ease and little guidance.
 Examples Of Day-to-Day Responsibilities
 Enforcing company data policies and procedures to ensure data quality and reduce discrepancies
Securing approvals for data access based on business needs
Developing scalable automated ETL jobs and maintain them
Identify any data integrity issues and deep dive to find root cause
Develop and manage Python and API calls to stand up master data sets and merge datasets across disparate systems
Training analysts and data scientists alike on available data sources
Ensuring very large databases and compute clusters operate optimally
Implementing and maintaining database structures and governance
Developing / maintaining documentation on databases and production tables
Collaborating across the company’s multiple data teams to meet analytics deliverables
 Qualifications
In order to be successful in this role, we need someone who has:
Bachelor’s degree in Engineering, Computer Science, Statistics, Mathematics, a related quantitative field, or equivalent practical experience.
14+ years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with advanced experience in SQL and an additional object-oriented programming language (e.g., Python, Java, JavaScript)
Experience with Jenkins & Git a PLUS
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders
Proven track record for developing/maintaining performance optimized data models for production analytics
Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs
Passion for analyzing large and complex data sets and converting them into the information which drive business decisions
Attention to detail, organization and effective verbal/written communication skills
Experience in big data instances: Cloudera, Azure, Snowflake, and the like.
Proven track record in rolling out self-service analytics solutions (e.g. Tableau Server Ask Data, etc)
Solid decision making, negotiation, and persuasion skills, often in ambiguous situations
Must be able to work in fast paced environment and be able to adapt to changing requirements.
Understanding of technology development projects and the full technology development lifecycle
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business. 
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
393,IT Data Analytic Architect - Biopharma Commercial,Merck Group,"Bengaluru, Karnataka, IN, 560100",Senior-level / Expert,"  Work Your Magic with us!  
  Ready to explore, break barriers, and discover more? We know you’ve got big plans – so do we! Our colleagues across the globe love innovating with science and technology to enrich people’s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.  
  Your Role:
As an IT Data Analytic Archtect, you will collaborate with APAC business stakeholders to deliver data analytics-driven technology solutions. You'll assess, prioritize, and plan projects while building strong relationships to drive innovation. With deep expertise in data analytics and business processes, you'll define requirements, manage delivery, and provide direction to the data analytics team. You'll also partner with international business and Global IT teams for successful project execution and budget management.
  Who You Are:
• Bachelor's degree in Data science, Data analytics or a related field.
• At least 5 years of experience in IT project management, business analysis, data analytics, data warehousing, or a related field
• At least 5 years of experience as a business analyst designing reporting solutions and business analytics architecture using cloud data warehouse technologies, analytic solution, SQL, Python and data visualization tools (Specially QlikSense)
• Understanding of data governance, data management, and data security.
• Strong analytical and problem-solving skills with the ability to translate business requirements into technical specifications.
• Excellent stakeholder engagement and communication skills.
• Experience working in global, cross-functional teams.
• Experience with Pharmaceutical Sales and Marketing is a plus
• Excellent English communication skills
  What We Offer:
We offer a dynamic and collaborative work environment where you can make a significant impact. Joining our team provides the opportunity to work with cutting-edge technology and enhance your expertise in data analytics. You will have exposure to global projects, work closely with diverse teams, and contribute to driving innovation. We provide competitive compensation and benefits packages, along with continuous learning and professional development opportunities.

What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
 
Apply now and become a part of our diverse team!
 ",USD 45K - 84K *
394,Manager / Senior Manager - Talent Acquisition (Work Location- Mumbai),Liminal,"Mumbai, Maharashtra, India - Remote",Senior-level / Expert,"We are seeking an experienced and strategic Senior Manager of Talent Acquisition to lead our recruitment department and contribute to the overall success of our organisation. Your job as a recruiter would involve sourcing, screening, and hiring the right talent for an organisation.
Responsibilities
Sourcing Candidates: You will actively seek out potential candidates through various channels like job boards, social media, networking, and referrals.
Screening and Assessing: They review resumes, conduct initial interviews, and assess candidates' skills, experience, and qualifications to determine their fit for specific roles.
Managing Recruitment Processes: You will coordinate the entire hiring process, from initial contact with candidates to scheduling interviews, conducting assessments, and managing follow-ups.
Building Relationships: You will develop and maintain relationships with candidates, acting as a point of contact throughout the hiring process and ensuring a positive candidate experience.
Collaborating with Hiring Managers: you will work closely with hiring managers to understand job requirements, discuss candidate profiles, and align on the best hiring strategies.
Maintaining Recruitment Metrics:You will be Tracking and analyzing recruitment data, such as time-to-hire, cost-per-hire, and candidate sources, to improve recruitment strategies.
Staying Updated: You will need to stay abreast of industry trends, market conditions, and changes in hiring practices to adapt and improve recruitment strategies.
Ensuring Compliance: You will ensure that the recruitment process complies with legal and organizational policies, including equal employment opportunity (EEO) regulations.
Employer Branding: You will be contributing to the development of the company's employer brand by showcasing its culture, values, and opportunities to potential candidates.
Ultimately, you will play a crucial role in identifying and securing top talent that aligns with the organization's goals and values. Your efforts contribute significantly to shaping a company's success by building strong, capable teams.
Requirements
Minimum 8+ years of core experience as a core recruiter and driven things independently
Exposure to start up environment and fast paced workplace will be great
Should have worked on leadership, tech roles and fintech based hirings.
Should have worked on various recruitment tools or ATS like Lever,Workable etc for hirings
Reporting Manager
The resource will directly report to the Vice President - HR.
Benefits
Best in Class Salary
At Liminal, we appreciate the good talent, and ensure that our employees are compensated with the salary brackets that are best in the industry.
15-Day Salary
No need to wait till the end of the month anymore! Get your salary credited every 15 days.
Flexi-hours
We don’t like to micromanage. We believe it's impolite to ask employees to punch in & out or follow similar activities to track the number of working hours. We trust our employees to get the job done and achieve the identified goals.
‍ESOP
A liberal ESOP policy, ensures that every employee remains motivated toward the success of the organisation and does not take this as any other job task. By adopting an excellent ESOP policy, we want to ensure that our employees benefit immensely from the growth of the organisation.
Self-Managed Paid Leaves
Say bye to leave without pay! Yes, there are no limits to the number of leaves you can take. We want employees to be responsible enough to strike a good work-life balance.
Liminal Book Club
Liminalites believe in the power of reading. Whether fiction or non-fiction, reading habits can fetch maximum ROI on time and money invested. You can raise a request for a book, and it will be delivered to your doorstep. No need to return or share, it’s yours to keep forever.
Health Insurance
We care for our beloved Liminalites. Our health insurance provides comprehensive coverage to our employees and their spouses and dependent children.
Lifetime free access
Liminal employees receive lifetime free access to the Liminal Vaults platform even after they decide to move on. Employees will additionally get Trezors / Ledgers at zero cost as a part of their onboarding. You can enjoy the benefits of the software as well as the hardware for free.
Best in Class Devices and Subscriptions
Get the best devices and tools you need to deliver your work. We provide the best subscriptions to ensure the highest levels of work efficiency.
HealthyMe Program
The challenge consists of completing exercise of any sort (physical/ mental/ walk /run /cycle / any sport/ game) consecutively for 30 days for 30 minutes, 4 times within the 6 months and receive a monetary reward of $30 for each 30-day streak.
1Password Account
1Password is a password manager and digital vault that helps users store, manage and secure their passwords, credit cards, personal information and other sensitive data. The platform will help our employees generate strong and unique passwords, and then store and autofill them across their devices and apps with a single click.
Employee Referral
Under the Referral Bonus Program our employees can earn incentives to introduce new talent to the organisation. The referral bonus will be credited to the employee account once the candidate completes 3 months with Liminal.
Growth Gateway Program
We believe in personal and professional growth, and we want our employees to have the tools they need to succeed. We offer a wallet of USD 400 that can be used to enrol in any learning program or certification that you desire.
Bouquet of Apps
Not just Netflix, let’s enjoy more wonderful applications. We all need a little extra help sometimes, which is why we offer a bouquet of apps covering health, knowledge, entertainment, and finance. Use any of these apps and receive a reimbursement of USD 15 per month.
Culture:
We Are Liminal
At Liminal, we’re building the best home for digital assets. Making them secure and efficient every day!
As a team, we thrive to inspire and push you to live your dream and build a technology that challenges the status quo.
We Enable
Liminal is where crypto-native citizens live. We wish to make digital assets accessible, simple, transparent, and secure.
Ambitious
We are an ambitious team of individuals who are chasing the Big Hairy Audacious Goals (BHAG) and we work with full authority. There are no right or wrong decisions, but only timely or late decisions.
Thus, we execute with great speed. We think, we create, we deliver, and we drive innovation.

Emotionally Intelligent
Successful companies are built on strong and positive emotions, and we aim to drive this internally. Emotional intelligence leads to impactful results.
There may be tough days or even months, but we make sure we pull each other through a great and successful quarter. As a team, we celebrate even the small wins together.

Goal-Oriented
We focus on the goal, and we ensure that the journey is fruitful too. We learn from each other’s experiences, whether success or failure, each chapter adds to a takeaway which is a useful lesson.
We share, express, and aim to achieve the planned outcome together as a team.

Appreciative
As a team, we are thankful to have each other's back. We are kind when we give feedback, and we take feedback positively. Liminal’s motivating culture to showcase one’s work, and share appreciation, sets us apart from others.

Process Driven
Seamless workflow between the team is the secret ingredient. We take ownership of our work, and ensure its delegated with due diligence and automated in time.
“It’s not about 500 people, but 500X people that makes the difference. And, this is what we follow at Liminal.”

We Grow Together
This is the best time to join Liminal. We’re building a team that is shaping the future of secured digital transactions. This learning experience will not just enhance your professional profile, but also add value to your personal growth.

Collaborative Work Environment
We spend most of our time at work, finding answers to problems or building solutions, and hence it becomes imperative to ensure that we enjoy our time at work. We take pride in the lively culture that we have built at Liminal.
#li-remote",USD 31K - 58K *
395,Data Engineer-Teradata,Capco,India - Bengaluru,Mid-level / Intermediate,"Job Title: Data Engineer-Teradata
About Us
“Capco, a Wipro company, is a global technology and management consulting firm. Awarded with Consultancy of the year in the  British Bank Award and has been ranked Top 100 Best Companies for Women in India 2022 by Avtar & Seramount. With our presence across 32 cities across globe, we support 100+ clients across banking, financial and Energy sectors. We are recognized for our deep transformation execution and delivery. 
WHY JOIN CAPCO?
You will work on engaging projects with the largest international and local banks, insurance companies, payment service providers and other key players in the industry. The projects that will transform the financial services industry.
MAKE AN IMPACT
Innovative thinking, delivery excellence and thought leadership to help our clients transform their business. Together with our clients and industry partners, we deliver disruptive work that is changing energy and financial services.
#BEYOURSELFATWORK
Capco has a tolerant, open culture that values diversity, inclusivity, and creativity.
CAREER ADVANCEMENT
With no forced hierarchy at Capco, everyone has the opportunity to grow as we grow, taking their career into their own hands.
DIVERSITY & INCLUSION
We believe that diversity of people and perspective gives us a competitive advantage.
MAKE AN IMPACT
  JOB SUMMARY:
Position: Consultant
Location: Bangalore 
Band: M2
Role Description:
5+ years of overall experience and at least 4 years working as Data Engineer in big data platforms.
4+ years of extensive programming experience in Teradata Tools and Utilities.
Proven hands-on experience in building complex analytical queries in Teradata or similar RDBMS.
Experience in different relational databases (i.e. Teradata, Oracle, PostgreSQL).
Solid experience with CI/CD development and deployment tools (preferably Azure DevOps).
Demonstrated experience of turning business use cases and requirements to technical solutions.
Knowledge in data modelling and database management such as performance tuning of the Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications.
Strong team collaboration and experience working with remote teams.
WHY JOIN CAPCO?
You will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry. We offer: • A work culture focused on innovation and creating lasting value for our clients and employees • Ongoing learning opportunities to help you acquire new skills or deepen existing expertise • A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients • A diverse, inclusive, meritocratic culture
We offer:
A work culture focused on innovation and creating lasting value for our clients and employees
Ongoing learning opportunities to help you acquire new skills or deepen existing expertise
A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients",USD 90K - 150K *
396,Staff Data Engineer,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Payments are a very exciting and fast-developing area with a lot of new and innovative ideas coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation for the next 5 to 10 years. VISA is a strong leader in the payment industry, and is rapidly transitioning into a technology company with significant investments in this area.
If you want to be in the exciting payment space, learn fast and make big impacts, VISA Risk and Authentication group is an ideal place for you!
The Risk development group is responsible for building critical risk and fraud prevention applications and services at VISA. This includes idea generation, architecture, design, development, and testing of products, applications, and services that provide Visa clients with solutions to detect, prevent, and mitigate fraud for Visa and Visa client payment systems.
This position is ideal for an experienced SW engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be one of the member of the RISK development team focusing on design and build of software solutions that leverage data to solve business problems. Sometimes you will be designing brand-new software solutions, and at other times you may be refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our customers.
The role is for a self-motivated individual with expert software engineering skills and extensive knowledge of Go, Database, J2EE and B2B/B2C technologies. The candidate will be extensively involved in leading hands-on software engineering activities including POCs, design, documentation, development and test of new functionality.  Candidate must be flexible and willing to switch tasks based on team’s needs. You will also help and guide junior team members.
Essential Functions
Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions.
Drive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.  Responsibilities span all phases of solution development including:
Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.
Proficient in writing microservices and API’s in GoLang.
Experience and thorough working knowledge in GoLang data structures like map, slices, interfaces, structs, go routines and channels.
Experience in building API’s in GO, protocol buffer, and gPRC for high performance and handling race conditions.
Worked on handling high-concurrency and low-latency applications written in GoLang.
Experience with container-based deployments using Docker and Kubernetes.
Guide junior team members, time to time help others un-blocked
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:

5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.

Preferred Qualifications:

Bachelors degree in Computer Science or related field with 8 years of Software Development Experience or a Masters degree with 4 years of Software Development Experience.
Exposure to leading-edge tech such as Stream Computing, In-Memory Computing.
Expert in at least one of the following: Golang, Java, or C/C++
Experience with web service standards and related patterns (REST, gRPC).
Candidate should have good experience working with GO drivers and worked on gPRC communication using protocol buffer.
Good Experience on container-based deployments using Docker, working with Docker images, Kubernetes and Docker Registries.
Experience in building gPRC API’s to provide backend integration with other open stack and down stream API’s.
Must have experience developing large scale, enterprise class distributed system or subsystems that require high availability, low-latency, & strong data consistency computing
Experience implementing solutions for low-latency, distributed services using open standard technologies.
Experience with Big Data and analytics in general leveraging technologies like Hadoop, Spark, and MapReduce a plus
Experience with No SQL database technologies like Cassandra will be a plus
Experience with Kafka will be a plus
Experience with distributed caching technologies like REDIS a plus
Experience architecting solutions with Continuous Integration and Continuous Delivery in mind
Strong interpersonal and leadership skills with effective communication (both written and verbal) skills and the ability to present complex ideas in a clear & concise way, a team player with a strong work ethic
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
397,Staff Machine Learning Engineer,Conga,"Bengaluru, India",Senior-level / Expert,"Company Description
A career that’s the whole package!
At Conga, we’ve built a community where our colleagues can thrive. Here you’ll find opportunities to innovate, support for growth through individual and team development, and an environment where all voices can be heard.
Conga crushes complexity within an increasingly complex world. With our revenue lifecycle management solution, we transform your unique complexities for order configuration, execution, fulfillment, and contract renewal processes with a single critical insights data model that adapts to ever-changing business requirements and aligns the understanding and efforts of every team.
Our mission: Empower customers to deliver transformational revenue growth by aligning teams, processes, and technology to maximize customer lifetime value.
Our approach is grounded in the Conga Way, a framework for what we stand for and everything we do as an organization — from hiring to decision making and product development. Developed with direct input from our colleagues, the Conga Way is the foundation for our culture.
Job Description
Job Title: Staff Machine Learning Engineer
Locations: Bangalore
Reports to: Director, Machine Learning
A quick snapshot…
A Machine Learning Engineer at Conga will produce a tailor-made solution for each problem. The only way to achieve optimal results is to carefully process the data and select the best algorithm for the given context. You’ll participate in building, designing, and optimizing Artificial Intelligence (AI) systems.
Why it’s a big deal…
The Machine Learning Engineer will play a vital role in the technology stack and will keep the system updated. The key role at Conga, would be to incorporate the customer’s legal contracts, and accomplishments of records by means of implementing, evaluating, and deploying strong commercial solutions. Your judgement to determine appropriate courses of action, within defined practices and procedures will be vital.
Are you the person we’re looking for?  
Related experience. At least 8+ years of experience in commercial text-based machine learning. Ability to understand complex problems, decompose them into a set of testable hypotheses, implement bug-free experiments, analyze the results, and produce insights, solutions, and next steps from the analysis. Your models are then used to automate processes like image classification, speech recognition, and market forecasting.
Algorithm and Data Visualization. You will work independently and collaborate in small teams. You will be excited to write great code, get close to the data, and create great ML models. You would be analyzing the ML algorithms that could be used to solve a given problem and ranking them by their probability of success. Exploring and visualizing data to understand it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
Skills & Experience. Proficiency with Python and basic libraries for machine learning:
Python 3.x, jupyter notebook or PyCharm or VS Code
· Deep Learning Frameworks: PyTorch, spaCy, Keras
· Deep Learning Architectures: LSTM, CNN, Self-Attention and Transformers
· Hypothesis generation; Evaluation and sampling methodologies
· Named Entity Recognition, Classification, Information Extraction, Co-Reference Resolution
· Feature extraction and ad-hoc analytic & modeling approaches
Education: A bachelor’s degree in Engineering or equivalent
Here’s what will give you an edge…
Innovative Thinking. At Conga we are working on latest technologies, along with the rules of how we use data to target. You should want to take initiative to research new tactics and find new ways to improve campaign effectiveness.    
Developing professional. As a developing professional your expertise will be visible to all levels. You regularly rely on policies and procedures to resolve a variety of issues. You’ve worked on problems that required you to review a variety of factors to analyze a situation. You’ve built productive internal and external working relationships.
Did we pique your interest?   
If this sounds like the kind of job you would love in the kind of environment where you would thrive, please click apply. We'd love to hear from you! 
Don’t meet every requirement for the role?  
Studies have shown that women and members of ethnic minorities are less likely to apply to jobs unless they meet every single qualification. At Conga we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You just might be the right candidate for this or other roles.
 #LI-SR1
Qualifications
Education: A bachelor’s degree in Engineering or equivalent
Additional Information
Conga is proud to be an Equal Opportunity Employer and provides equal employment opportunities to all employees and applicants regardless of race, color, religion, gender, gender identity, age, national origin, disability, parental or pregnancy status, marriage and civil partnership, sexual orientation, veteran status, or any other characteristic protected by law. Reasonable accommodations will be made to meet the requirements of the Americans with Disabilities Act and will be provided as requested by candidates taking part in all aspects of the selection process. All your information will be kept confidential according to EEO guidelines. Conga is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.",USD 45K - 84K *
398,Software Engineer - Azure Databricks Job,Yash Technologies,"Bengaluru, KA, IN",Mid-level / Intermediate,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Azure Databricks Professionals in the following areas :
  Requirements and skills
Mandatory Skills:Azure Data engineering, Pyspark, Python, Azure Data Bricks, Azure Data Factory, SQL.
-3+ years exp as a Data Engineer must have with ADF,Databricks,Pyspark, Python
Must have experience with databricks
-Technical expertise in data modelling

Responsibilities
Design and develop business-critical backend systems using stream processors and high-quality data pipelines.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and
Azure big data technologies.
Build a data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Perform root cause analysis on external and internal processes and data to identify opportunities for improvement
Build processes that support data transformation, workload management, data structures, dependency, and metadata
Work with all stakeholders to design and code large-scale batch and real-time data pipelines on Azure.
Perform code reviews, and lead by example on code refactoring for readability, extensibility, and testability
Requirements
A bachelor''s degree in computer science or equivalent
3+ years of experience in Data Engineering, or related field in Architecting and developing end to end scalable data applications and data pipelines
Experience with Azure big data tools:ADF, Azure Databricks, ADLS,good to have Azure Synapse
Experience with relational SQL and NoSQL databases.
Excellent problem solving and analytic skills associated with working on structured and unstructured datasets using Azure bigdata tools
Experience with data pipeline and workflow management tools: ADF and Logic Apps
Experience with Azure cloud services: VM, ADF,Azure Databricks, Azure SQL DB, Azure Synapse
Experience with scripting languages Python. and have strong knowledge in developing Python notebooks
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, 
source management, build processes and testing
Lead design, data strategy and road map exercises, and implementation
Demonstrated strength and experience in data modeling, ETL development and data warehousing concepts
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 30K - 56K *
399,Wells Analytics Engineer,ExxonMobil,"Bengaluru, KA, IN",Mid-level / Intermediate,"  About us
  At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.
  The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies. 
  We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.
What role you will play in our team
  We are looking for experienced engineers with an emphasis on data engineering and data visualization to provide wells engineering support across ExxonMobil’s global portfolio. 
ExxonMobil is a long-term career orientated company where you will have opportunities to develop your skills across data engineering and visualization, while working across different projects and business functions on a global scale.
What you will do
  Provide day to day operations support for applications by performing troubleshooting and technical analysis to identify root causes and develop problem resolutions
Partner with global customer to provide application break-fix and enhancement to meet maintenance process requirement
Participate in application enhancement, upgrade or application enablement in new sites
Experience in supporting applications with interfaces to SQL database and API Integrations
Design, configuration and unit testing experience in the product lifecycle methodology
Master IT operation processes and their related tools, like Security & Control, Problem Management, Change Management etc.
Frame business problems, identify alternatives, and collaborate on solutions with other analysts, architects, and stakeholders
Gather business requirements, workflows, and associated data models
About You
  Skills and Qualifications
  Bachelor’s degree in Petroleum Engineering or related field from a recognized university with minimum GPA of 6.0 and above.
Minimum 3 years of experience in the Oil and Gas Industry specializing in either Drilling, Completions, or workovers.
Minimum 3 years of experience in related fields like Applications Support & Business Analysis
Excellent communication skills, including an ability to communicate technical concepts to non-technical staff
Good in coordination skills
Demonstrated ability to troubleshoot issues, identify root cause, and recommend solutions
Demonstrated ability to quickly learn / understand new technologies / applications 
Preferred Qualifications / Experience
  Prior work experience in the oil and gas industry is an advantage
Prior work experience in Cloud Technology is preferred
Prior work experience with the below mentioned areas will be an advantage:    
WellView and other Peloton suite of apps
Interface with other systems (WebServices, ETL or File exchange)
Azure cloud configuration
Advanced Excel 
SQL Queries / SQL Server
Packaging Scripting (e.g. Powershell or VB Macros)
  Your benefits
  An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you: 
  Competitive compensation 
Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits 
Retirement benefits 
Global networking & cross-functional opportunities
Annual vacations & holidays
Day care assistance program
Training and development program
Tuition assistance program
Workplace flexibility policy
Relocation program
Transportation facility
  Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company’s eligibility guidelines.
Stay connected with us
  Learn more about ExxonMobil in India, visit ExxonMobil India  and Energy Factor India.
Follow us on LinkedIn and ExxonMobil (@exxonmobil) • Instagram photos and videos
Like us on Facebook
Subscribe our channel at YouTube
  EEO Statement
  ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.
  Business solicitation and recruiting scams
  ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.
 
  Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship. 
  Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",USD 90K - 172K *
400,"Senior Data Operations Engineer, EF Data",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Desired Candidate Characteristics: 
Ability to understand the needs of the business and commitment to deliver the best user experience and adoption 
Accountable for Operations and enhancements for Enabling Functions Data pipelines-lead incident and problem management, plan, and coordinate upgrades, and ensure solutions are reliable and meeting SLAs
Accountable for assessing capacity and prioritization along with onshore and partner teams for operations, support, enhancements
Monitor, Restart, Repair the Ingestion, Refinement, and/or Transformation Jobs as needed and collaborate with partners and/or other team members.
Develop knowledge articles, run books or templates and processes to prevent typical job failures and self-heal Ingestion, Refinement, and/or Transformation jobs across Enabling Functions
Have a continuous improvement and learning mindset and open to bring innovation and automation best practices
Ensure data quality and integrity through data validation and testing  
Implement and maintain security protocols to protect sensitive data  
Stay up to date with emerging trends and technologies in data engineering and analytics  
Collaborate with the Enterprise Data and Analytics Platform team, other functional data pods and Data Community lead to shape and adopt data and technology strategy
Prior experience working in an Agile/Product based environment is a plus
Provides strategic feedback to vendors on service delivery and balances workload with vendor teams  
.  
 Qualifications & Experience
Requires thorough knowledge of the principles and concepts of a discipline and developed knowledge of other related disciplines, typically gained through a university degree and 4-6 years of experience.
Hands-on experience with configuration and maintenance of Data engineering pipelines using (Cloudera Data Platform, AWS Data Ecosystem), AWS Glue Studio, Python, etc.),
Experience with Data Science Platforms (Domino Data Lab) and Tableau is a plus
Thorough understanding of and working experience in Cloud eco-system, in particular AWS 
Experience with CFT/Terraform, Infrastructure as Code (IaC) and configuration languages. 
Agile software development. 
Works predominately within established procedures. Actively participates in troubleshooting of routine problems. Acts as a functional mentor to more junior team members. Experience with implementing improvements in areas such as maintainability, scalability, availability, extensibility, and security 
Experience implementing, maintaining, and troubleshooting continuous integration/continuous delivery (CI/CD) 
Working knowledge of ITSM best practices and tools (e.g., ServiceNow) 
Working knowledge of information security best practices 
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 125K - 238K *
401,Data Engineer-Tableau,Capco,India - Bengaluru,Mid-level / Intermediate,"Job Title: Data Engineer-Tableau
About Us
“Capco, a Wipro company, is a global technology and management consulting firm. Awarded with Consultancy of the year in the British Bank Award and has been ranked Top 100 Best Companies for Women in India 2022 by Avtar & Seramount. With our presence across 32 cities across globe, we support 100+ clients across banking, financial and Energy sectors. We are recognized for our deep transformation execution and delivery. 
WHY JOIN CAPCO?
You will work on engaging projects with the largest international and local banks, insurance companies, payment service providers and other key players in the industry. The projects that will transform the financial services industry.
MAKE AN IMPACT
Innovative thinking, delivery excellence and thought leadership to help our clients transform their business. Together with our clients and industry partners, we deliver disruptive work that is changing energy and financial services.
#BEYOURSELFATWORK
Capco has a tolerant, open culture that values diversity, inclusivity, and creativity.
CAREER ADVANCEMENT
With no forced hierarchy at Capco, everyone has the opportunity to grow as we grow, taking their career into their own hands.
DIVERSITY & INCLUSION
We believe that diversity of people and perspective gives us a competitive advantage.
MAKE AN IMPACT
  JOB SUMMARY:
Position: Consultant
Location: Bangalore 
Band: M2
Role Description:
5+ years of hands-on experience in Data visualizations, BI analytics, and reporting tools
Experience in Business Intelligence and Data Analysis technologies with strong data management skills 
Experience in one or more BI tools like Tableau, Power BI, Qlik
Demonstrated experience of turning business use cases and requirements to technical solutions.
Knowledge in data modelling and database management such as performance tuning of the Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications.
Experience in establishing connectivity and extraction of data from RDBMS, Big Data, cloud platforms
Expert knowledge in SQL – Teradata, Oracle, PostgreSQL
Exposure to ETL tools like Talend, Informatica, DataStage, SSIS
FS/ Banking domain expertise
Self-starter with strong self-management skills, Team player, Strong oral and written communications skills.
Able to creatively apply analytical solutions to business problems and adapt to changes per requirement/standards.
Ability to work under constant pressure to tight deadlines and deliver high quality output.
Strong team collaboration and experience working with remote teams
WHY JOIN CAPCO?
You will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry. We offer: • A work culture focused on innovation and creating lasting value for our clients and employees • Ongoing learning opportunities to help you acquire new skills or deepen existing expertise • A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients • A diverse, inclusive, meritocratic culture
We offer:
A work culture focused on innovation and creating lasting value for our clients and employees
Ongoing learning opportunities to help you acquire new skills or deepen existing expertise
A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients",USD 90K - 150K *
402,Sr Data Engineer,Aryng,"Delhi, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a Senior Data Engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 186K *
403,"Business Intelligence Analyst, LBA Data Service",Wolters Kluwer,"IND - Pune, Kalyani Nagar",Entry-level / Junior,"Basic Function
The Data Business Intelligence Analyst-I (“Business Intelligence Analyst-I ”) for Wolters Kluwer, Fulfillment Center of Excellence will be responsible for performing the quality assurance testing for the Legal Bill Analysis Center of Excellence (LBACOE).  The Legal Bill Analysis (“LBA”) process involves the prompt, accurate and efficient auditing of electronically submitted legal fee and expense invoices submitted by law firms and vendors of our clients. 
The Business Intelligence Analyst-I provides guidance and expert feedback to business unit and other internal partners, especially the CIOx Data Science Team, on a variety of bill review scenarios. Specifically, they will be considered a subject matter expert in various practice areas and legal billing best practices. The ultimate goal of Business Intelligence Analyst-I is to fully leverage their robust legal knowledge base to assist in building accurate, high-quality artificial intelligence models that aid the legal bill review. 
The Business Intelligence Analyst-I extracts core legal concepts at the heart of the invoice, analyzing the full legal context of the invoice in line with our clients’ billing guidelines and communicating this analysis with recommendations to internal partners. As such, this role may also be required to provide traditional LBA invoice review and/or quality assurance tasks by making initial or additional adjustments to previously adjusted invoice line-item entries, as well as corrections to adjusted and non-adjusted invoice lines.   
The Business Intelligence Analyst-I is responsible for AI module review and analysis, along with strong working knowledge of client requirements for the applicable AI solution.  They oversee and manage at least one LBA Data Service AI module in conjunction with being responsible for file review of self and others, along with refinements to enhance AI performance, as needed.  This role may also support sales and guideline benchmarking as necessary.
  Essential Responsibilities
Core Legal Bill Review Responsibilities
Drive the results of the LBACOE quality assurance process, as follows:
Conduct review invoice lines, applying specialized legal subject matter expert knowledge to context of legal invoice line items.
Verify the compliance to legal billing guidelines by law firms and vendor submitting invoices.
Verify the accuracy of the UTBMS task codes (Fee, Activity and Expense codes) applied to invoice line items.
Independently make adjustments to invoice line items as necessary based on his or her assessment of the legal context of the invoice while utilizing specialized his or her legal subject matter expert knowledge to extract core critical legal terminology and concepts.  Document reasons for any additional adjustments made to invoice line items, identifying the billing guideline violated and the rationale for the amount adjusted.
Forward the audited and peer-reviewed legal invoice through the review chain as required
Promptly and professionally resolve law firm appeals, as follows:
Address law firm requests for reconsideration of adjusted amounts while utilizing careful judgment, legal knowledge and utmost professionalism while upholding integrity of the legal billing process.
Work with law firms in a professional manner via legal expert-to-expert written communications to carefully resolve disputed adjusted invoice line items using sound independent discretion and vast legal knowledge base.
Efficiently and accurately review appealed legal invoice entries.
Data Service Responsibilities
Perform the invoice review analysis, specifically, but not limited to the Data Service initiative within the Legal Bill Analysis Center of Excellence (LBACOE).
Provide expert assessment of the legal context and terminology in invoices and data files and assigned Data Service AI output. 
Analysis and deconstruction of client billing guidelines and legal services agreements into code-based formats to be leveraged by Data Service and AI experts.
Validate and certify accuracy of Data Service AI generated file outputs through multiple levels of iteration per client and per project until desired results are achieved
Heavy team collaboration and solutioning in team review and analysis through strong understanding of LBA Data Service AI.
Create logic and develop AI pattern-based rules through deep existing domain expertise.
Mentor & Coach LBA Data Service team members in general and by way of query resolution, training, etc.
Manage development, refinement, and performance of at least one AI module of Data Service
Coordinate module creation and release schedule for same with Data service AI team
Assist with AI logic enhancements and technical issues related to current AI modules and rules
Assist with customer escalation/ internal AI team or Review team escalation log for designated module
Other responsibilities and tasks as needed or required
Additional Responsibilities and Skills:
Support internal management in documenting performance metrics for internal use and use with clients and law firms.
Strong understanding of legal terminology and claims legal situations, multijurisdictional exposure preferred.
Using sound discretion and legal expertise, analyze and condense legal service agreements to produce effective operational outputs meeting and, in some cases, exceeding customer expectations.
Excellent computer skills with the ability to learn the electronic legal bill submission and auditing software
Sound command of the English language-- grammar, syntax and style -- including an understanding of the conventions of punctuation and capitalization
Strong Microsoft Excel and data analysis skills
Effective communication skills - ability to obtain information from others and deliver information to others orally and in written form
Ability to carry out detailed written or verbal instructions; ability to respond to requests effectively and efficiently
Job qualifications
Education, Experience, Knowledge and Tools
Minimum Experience: Relevant Bachelors or higher, JD, and 1-3 years industry (bill review/legal) experience:
Experience with legal billing processes is an advantage, but not necessary
Familiarity of the federal and/or state rules of civil procedure.
Strong understanding of legal terminologies.
Experience with law firm is also preferred.   
Preferred Experience: 
Prior US and International legal invoice review and analysis experience in a legal invoice analyst role. 
Prior experience in auditing claims litigation.
Experience in handling appeals of legal invoice claims adjustments.
Prior experience with direct communication with law firms in a legal invoice review context.
Experience with handling conflict with law firms, in writing and telephonically.
Ability to effectively communicate legal analysis to those with varying levels of legal expertise.  
Highly developed communication skills, including both excellent written and verbal skills.
Required Competencies:
Communications:   Strong arbitration and organizational skills are critical to being successful in this role.  Strong communications skills and the ability to organize and motivate team members in a matrix environment are essential.
Team Work:  Must work collaboratively with people within LBACOE and throughout the entire WK organization, while providing constructive feedback to LBACOE from the BUs.
Problem Solving:  Capable of independent thinking and rendering sound decisions.  Astute at identifying and engaging the necessary resources to help in decision making.  Takes quick actions to identify and resolve the cause of any problem.  Proactive in nature.
Leadership:  Exhibits individual control over day to day responsibilities as well as the ability to work collaboratively with other BUs to produce results. 
Planning and Organizing:  Must be able to implement plans with the purpose of achieving short and long term goals.  Must be able to prioritize in order to accomplish these goals in a given time period.
Technology:  Has the ability to partner with experts in the technology field to identify technology gaps and requirements necessary to develop position and impactful solutions.
Learning:  Ability to acquire new or modify existing knowledge to support a changing market place and workforce.  Can demonstrate a capability to learn by study, experience, or instruction.
Initiative and Enterprise:  Is self-directed and has the ability to translate ideas into action and get things done.
Tools:
Knowledge Microsoft Office Suite ( Word, Excel, PowerPoint, Outlook).",USD 49K - 96K *
404,"Senior Associate II, Data Engineering",Kyndryl,INMANBP Bengaluru (INMANBP) Manyatha,Mid-level / Intermediate,"Who We Are
At Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.

The Role
You are a great fit if you can:
Dissect business problems and devise analytical solutions 
Collaborate with experts in a business area, getting an understanding of the underlying business process, strategy and execution 
Identify approaches to improve model accuracy and effectiveness of analytics 
Address business needs by prioritizing critical pain points that, once solved, will drive the most value 
Extract, transform, and combine all incoming data with the goal of discovering a previously hidden insight, which in turn can provide a competitive advantage or address a pressing business problem
Not just simply collect and report on data, but also build statistical models, determine what they mean, then recommend ways to apply the data 
Design, deploy, and tune analytics models integrated with structured / unstructured data sources 
Select a suitable tool for the analytics solution or working with data 
Create visual presentations of analytics results and translates quantitative insights for a non-technical audience 

Who You Are
You’re good at what you do and possess the required experience to prove it. However, equally as important – you have a growth mindset; keen to drive your own personal and professional development. You are customer-focused – someone who prioritizes customer success in their work. And finally, you’re open and borderless – naturally inclusive in how you work with others.

Required Technical and Professional Expertise
2+ years of experience of relevant work experience in Data Engineering.
Strong knowledge in data modeling, database design and data management best practice
Ability to architect, design and implement infrastructure and platforms from a data and storage perspective.
Manage ETL processes for your data, including legacy data, real-time data streams, and APIs.
Strong Experience in SQL Query Design and Implementation.
Experience in working in an agile development team.
Broad and deep data and analytics skills such classification, communication, creativity, diagnostics, metrics / measurement, organizing, prioritization, qualitative and quantitative analysis and research.
Experience with programming languages, such as Python, C, C++, and Java
Participate in multi-functional teams or conduct special projects. 
Preferred Technical and Professional Experience
Bachelor's or master’s degree in computer science, Information Systems, Security, or a related Engineering field
Experience working with cloud-based data platforms, data integration and governance framework with one of the three cloud technologies (Azure, AWS, or GCP)
Experience with containerization packaging, tooling, and DevOps methodologies
Data engineering certification is a plus

 
Being You
Diversity is a whole lot more than what we look like or where we come from, it’s how we think and who we are. We welcome people of all cultures, backgrounds, and experiences. But we’re not doing it single-handily: Our Kyndryl Inclusion Networks are only one of many ways we create a workplace where all Kyndryls can find and provide support and advice. This dedication to welcoming everyone into our company means that Kyndryl gives you – and everyone next to you – the ability to bring your whole self to work, individually and collectively, and support the activation of our equitable culture. That’s the Kyndryl Way.

What You Can Expect
With state-of-the-art resources and Fortune 100 clients, every day is an opportunity to innovate, build new capabilities, new relationships, new processes, and new value. Kyndryl cares about your well-being and prides itself on offering benefits that give you choice, reflect the diversity of our employees and support you and your family through the moments that matter – wherever you are in your life journey. Our employee learning programs give you access to the best learning in the industry to receive certifications, including Microsoft, Google, Amazon, Skillsoft, and many more. Through our company-wide volunteering and giving platform, you can donate, start fundraisers, volunteer, and search over 2 million non-profit organizations.  At Kyndryl, we invest heavily in you, we want you to succeed so that together, we will all succeed.
Get Referred!
If you know someone that works at Kyndryl, when asked ‘How Did You Hear About Us’ during the application process, select ‘Employee Referral’ and enter your contact's Kyndryl email address.",USD 90K - 150K *
405,Senior AI/ML Engineer,ValGenesis,"Chennai, Tamil Nadu, India",Senior-level / Expert,"ValGenesis is seeking a talented Senior AI/ML Engineer to join our team. As a Senior AI/ML Engineer, you will be responsible for developing and implementing cutting-edge AI/ML algorithms and models to drive innovation in our cloud-based platform. You will work closely with cross-functional teams to design and develop scalable AI/ML solutions that deliver actionable insights and improve user experience.
Responsibilities
Collaborate with product managers, data scientists, and software engineers to identify AI/ML opportunities and develop innovative solutions.
Implement and deploy AI/ML algorithms and models into production environments.
Optimize and fine-tune AI/ML models to improve accuracy and efficiency.
Conduct experiments, perform data analysis, and present findings to stakeholders.
Develop and maintain documentation for AI/ML algorithms, models, and solutions.
Stay up-to-date with the latest AI/ML research and technologies and apply them to improve our platform.
Mentor and provide technical guidance to junior AI/ML engineers or team members.
Requirements
Minimum of 5 years of experience as an AI/ML Engineer or related role.
Strong knowledge of AI/ML techniques, algorithms, and frameworks.
Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn.
Proficient in Python and relevant libraries for data manipulation and model development.
Experience with cloud platforms such as AWS, Azure, or Google Cloud.
Working knowledge of data processing and storage technologies.
Solid understanding of software engineering principles and best practices.
Ability to work collaboratively in a fast-paced, agile environment.
Excellent problem-solving and analytical skills.
Good communication and interpersonal skills.
How We Work
Our Chennai and Bangalore offices are onsite, 5 days per week. We believe that in-person interaction and collaboration fosters creativity, and a sense of community, and is critical to our future success as a company. 
ValGenesis is an equal-opportunity employer that makes employment decisions on the basis of merit. Our goal is to have the best-qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristics protected by local law.",USD 174K - 275K *
406,Sr Data Scientist,Target,"Tower 02, Manyata Embassy Business Park, Racenahali & Nagawara Villages. Outer Ring Rd, Bengaluru 540065",Senior-level / Expert,"JOIN TARGET AS Senior Data Scientist - Digital Fulfillment
Description:
Target is an iconic brand, a Fortune 50 company and one of America’s leading retailers.
Global Supply Chain and Logistics at Target is evolving at an incredible pace. We are constantly reimagining how we get the right product to the guests better, faster and more cost effectively than before across 1900 locations
A role with the Data Science team means building scalable data science products in support of the ever-changing supply chain landscape. This will mean being more intelligent, automated and algorithmic in our decision-making. Evaluating product flow from vendor to distribution center, and to the stores across the first mile, middle mile and last mile, with focus on inventory modeling and replenishment, to improve operating efficiencies both within 4 walls of distribution center and across the network.
So, we’re looking for exceptional people who are proactive, creative, independent, innovative and comfortable working in varying degrees of ambiguity. Are you a creative problem-solver who seeks root cause, simplifies problems, quickly identifies solutions, commits to a plan and then positively influences others to execute it? If so, you will have success on this dynamic team.
About the role: 
Our Supply Chain Data Science team oversees the development of state-of-the-art mathematical techniques to help solve important problems for Target’s Supply Chain e.g. identifying the optimal quantities and positioning of inventory across multiple channels and locations, planning for the right mix of inventory investments vs guest experience, Digital order Fulfillment planning, transportation resource planning, etc.  As a Senior Data Scientist in Digital fulfillment Planning space, you will have the opportunity to work with Product, Tech, and business partners to solve retail challenges at scale for our fulfillment network.
As a Senior Data Scientist at Target you will get an opportunity design, develop, deploy and maintain data science models and tools.  You’ll work closely with applied data scientists, data analysts and business partners to continuously learn and understand evolving business needs.  You’ll also collaborate with engineers and data scientists on peer teams to build and productionize fulfillment solutions for our supply chain/logistics needs. 
In this role as a Senior Data Scientist, you will:
Develop a strong understanding of business and operational processes within Target’s Supply chain.
Develop an in-depth understanding of the various systems and processes that influence Digital order fulfillment speed & costs.
Analyze large datasets for insights leading to business process improvements or solution development.
Develop optimization-based solutions, approximate mathematical models (probabilistic/deterministic models) of real-world phenomena, predictive models and implement the same in real production systems with measurable impact.
Work with the team to build and maintain complex software systems and tools.
Add new capabilities and features to the simulation framework to reflect the complexities of an evolving digital fulfillment network.
Develop and deploy modules to run simulations for testing and validating multiple scenarios to evaluate the impact of various fulfillment strategies.
Adopt modular architecture and good software development/engineering practices to enhance the overall product performance and guide other team members.
Produce clean, efficient code based on specifications.
Enhance and maintain simulation environment to enable testing/deploying new features for running custom, user defined scenarios through the simulator.
Coordinate the analysis, troubleshooting and resolution of issues in the models and software.
Requirements:
Bachelor’s/MS/PhD in Mathematics, Statistics, Operations Research, Industrial Engineering, Physics, Computer Science, or other related fields
3-4+ years of relevant experience
Strong analytical thinking and data visualization skills. Ability to creatively solve business  problems, innovating new approaches where required.
Ability to clean, transform, manipulate, and analyze large datasets for insights leading to business process improvements or solution development. Background in handling supply chain data will be preferable but not mandatory.
Experience developing, testing, and maintaining large codebases in a collaborative environment while meeting industry best practices.
Highly proficient in programming skills in Python, SQL, Hadoop/Hive, Spark.
Excellent working knowledge of Mathematical and statistical concepts, optimization, data structures and algorithms, data analysis, simulations, visualizations, and applications of same in a variety of business problems.
Good working knowledge of machine learning, probability estimation methods, linear programming (integer, real and mixed integer) stochastic processes, and their applications in industry settings.
Experience deploying solutions with large-scale business impact in commercial setting.
Self-driven and results oriented. Willing to stretch to meet tight timelines.
Strong team player with ability to collaborate effectively across geographies/ time zones.
Excellent written and verbal communication skills
Why work with us at Target?  
You will work directly on the Data Science problems that have the most impact on Target's entire supply chain, forecasting and merchandising teams.
We love open source! Many of our team members contribute to open-source communities and get to do it during work time. We try to contribute back to our communities where we can and are grateful to be able to open source some of our own projects!  
We value diversity. We believe that diversity and inclusion is of core importance when try to create positive in-store experiences for our guests, and we think it is also critically important when building our teams. Read more about our commitment to diversity and inclusion  
We value our team members for who they are, not just what they can get done. We are parents, hobbyists, enthusiasts, family members, and community members, and can offer flexibility to our team members' schedules and work arrangements so that they can flourish both inside and outside of work.",USD 135K - 205K *
407,Manager Business Process Analyst-ETL / Datastage Senior Admin,Teva Pharmaceuticals,"Bengaluru, India, 560052",Senior-level / Expert,"Who we are
Together, we’re on a mission to make good health more affordable and accessible, to help millions around the world enjoy healthier lives. It’s a mission that bonds our people across nearly 60 countries and a rich, diverse variety of nationalities and backgrounds. Working here means working with the world’s leading manufacturer of generic medicines, and the proud producer of many of the products on the World Health Organization’s Essential Medicines List. Today, at least 200 million people around the world take one of our medicines every single day. An amazing number, but we’re always looking for new ways to continue making a difference, and new people to make a difference with.
The opportunity

This position is for a ETL / Datastage administrator, within TEVA Application Infrastructure team in the Global Infrastructure unit. 
He/ She will be ultimately working on all Teva ETL / Datastage activities across the globe and his focus is to ensure platform reliability, availability, and serviceability; to provide technical expertise and guidance for both infrastructure and application teams, and design, evaluate, install, upgrade, diagnose, and performance tune Datastage platforms, supporting production interfaces, working with IBM vendor for support.
How you’ll spend your day
•    Datastage Senior Admin responsibilities include but not limited to the following:
•    Apply proven communication, analytical and problem-solving skills to identify, communicate and resolve issues, problems in order to maximize the returns on IT and Business investments.
•    Deploy, Administer, Support and maintain datastage applications to enable communication between applications with varying interfaces.
•    Installs, maintains, and administers datastage server environments primarily in Linux environments.
•    Installs, configures, and fine tunes datastage components such as Business Works, MFT, Plugins and Adapters.
•    Develops, improves, and documents the processes for maintaining and administrating the datastage environment.
•    Enforces best practices for security and reliability across IT
•    Work closely with Integration teams, IT Infrastructure, SAP and boundary system development teams 
•    Occasionally provide after-hours support
Your experience and qualifications
•    Minimum 7 years of proven System Administration experience with datastage application
•    Strong Linux and Windows administration skills is mandatory 
•    Strong knowledge of high-availability, load-balancing and failover configurations across application, infrastructure, and platform components
•    General familiarity with networking, security and automated deployments
•    Understanding of security design for enterprise software systems 
•    Able to work independently as an expert, or under the guidance of Architect/Lead
•    Experience on additional Middleware platforms a plus
•    CI/CD tools (JIRA, GitHub, Jenkins etc.) knowledge a plus
•    Bachelor’s degree in Computer Science 
Make a difference with Teva Pharmaceuticals
Reports To
Associate Director IT Business Application
Already Working @TEVA?
If you are a current Teva employee, please apply using the internal career site available on ""Employee Central"". By doing so, your application will be treated with priority. You will also be able to see opportunities that are open exclusively to Teva employees. Use the following link to search and apply: Internal Career Site
The internal career site is available from your home network as well. If you have trouble accessing your EC account, please contact your local HR/IT partner.
Teva’s Equal Employment Opportunity Commitment
Teva Pharmaceuticals is committed to equal opportunity in employment. It is Teva's global policy that equal employment opportunity be provided without regard to age, race, creed, color, religion, sex, disability, pregnancy, medical condition, sexual orientation, gender identity or expression, ancestry, veteran status, national or ethnic origin or any other legally recognized status entitled to protection under applicable laws. We are committed to a diverse and inclusive workplace for all. If you are contacted for a job opportunity, please advise us of any accommodations needed to support you throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.",USD 45K - 84K *
408,ETL + abinitio | 4 to 12 Years | Pune,Capgemini,"Pune, MH, IN",Mid-level / Intermediate,"Job description
Validating data source Extracting data applications of transformation logic 
Uploading data in target tables 
Responsible for data storage system before it goes live Create multiple test for data validation 
Will be helpful if having knowledge in tools like Informatica or Abinitio or oracle or sas or etc 
Write test data scripts based on ETL mapping artifacts 
Create strategies and test cases for application that use ETL components 
Define and track quality assurance metrics such as defects defect count test results and test status 
Create sqlscripts based on etl mapping 
Data warehouse testing experience will help 
Design and develop UNIX commands as part of ETL process 
Test data creation Test cases creation Test execution E2e Test Env ownership 
Jira knowledge is helpful Unix data handling and awk sed air and m commands
Primary skills
Validating data source Extracting data applications of transformation logic 
Uploading data in target tables 
Responsible for data storage system before it goes live Create multiple test for data validation 
Will be helpful if having knowledge in tools like Informatica or Abinitio or oracle or sas or etc 
Write test data scripts based on ETL mapping artifacts 
Create strategies and test cases for application that use ETL components 
Define and track quality assurance metrics such as defects defect count test results and test status 
Create sqlscripts based on etl mapping
Secondary skills
Data warehouse testing experience will help
Design and develop UNIX commands as part of ETL process 
Test data creation Test cases creation Test execution E2e Test Env ownership 
Jira knowledge is helpful Unix data handling and awk sed air and m commands 
SQLs analytical queries creation execution 
Good soft skills 
Interpersonal skills 
Team player and positive attitude 
Ownership towards delivery is must have",USD 30K - 56K *
409,"Director, Analytics Engineering",Crunchyroll Inc.,"Hyderabad, Telangana, India",Executive-level / Director,"About Crunchyroll
WE HELP EVERYONE BELONG. IT’S OUR PURPOSE.
Founded by fans, Crunchyroll delivers the art and culture of anime to a passionate community. We super-serve over 100 million anime and manga fans across 200+ countries and territories, and help them connect with the stories and characters they crave. Whether that experience is online or in-person, streaming video, theatrical, games, merchandise, events and more, it’s powered by the anime content we all love.
Join our team, and help us shape the future of anime!
About Crunchyroll
WE HELP EVERYONE BELONG. IT’S OUR PURPOSE.
Founded by fans, Crunchyroll delivers the art and culture of anime to a passionate community. We super-serve over 100 million anime and manga fans across 200+ countries and territories, and help them connect with the stories and characters they crave. Whether that experience is online or in-person, streaming video, theatrical, games, merchandise, events and more, it’s powered by the anime content we all love.
Join our team, and help us shape the future of anime!
About the role
We are looking for someone in India to assume the role of Director for Analytics Engineering. As part of our India Operations, you will hold paramount importance in our pursuit of building a global top-tier business intelligence team within the Center for Data and Insights (CDI). This pivotal role will directly report to the Head of Data Engineering, underscoring its significance in upholding and enhancing our BI capabilities. Operating within the dynamic realms of AWS and GCP ecosystems, the Director will guide our BI engineers, collaborating with data and analytics leaders to standardize technologies and workflows across several aspects such as storytelling, dashboard creation, reporting, and data modeling. By ensuring the uniformity and dependability of data and insights, you will contribute to our broader goal of empowering informed decision-making.
You will embody an empathetic and service-oriented approach to address the organization's flourishing data and insights culture while simultaneously fortifying and future-proofing our technological framework. You will lead the consolidation and revitalization of global support operations for our BI platforms. In the initial half-year period, we envision the Director, Analytics Engineering, orchestrating the formation of a dedicated team that will oversee worldwide operations, provide comprehensive support, and also facilitate the seamless transition from AWS to GCP.
If you are an experienced professional with a passion for orchestrating high-performance business intelligence endeavors and an eagerness to steer transformative changes, we encourage you to consider this role as an avenue to shape our CDI's trajectory and make an indelible impact. Your journey as the Director, Analytics Engineering, promises to be both fulfilling and instrumental in propelling our data-driven ambitions to new heights.
About You
We get excited about candidates, like you, because...
8+ years of expertise in Business Intelligence development and/or Analytics Engineering.
Managed engineering and analytics teams for more than 5 years.
Proficient in using event data collection tools like Snowplow, Segment, Google Tag Manager, Tealium, mParticle, and others.
Hands-on experience throughout the complete lifecycle of implementing compute and orchestration tools, including Databricks, Airflow, Talend, etc.
Familiarity with streaming OLAP engines like Druid, ClickHouse, Spark, and others.
Experience with AWS services such as EMR, Redshift, Lambda, Glue, Athena, and more.
Working knowledge of BI tools like Tableau, Looker, Google Analytics, Superset, and Amplitude.
Previous involvement in constructing multi-touch attribution platforms through integrations with walled gardens and digital platforms.
Familiarity with Customer Data Platforms (CDPs) and Data Management Platforms (DMPs).
Experience in high-security environments like HIPAA, PCI, or similar contexts.
Proficiency in handling substantial datasets (Terabytes of data/billions of records) within databases like Redshift, BigQuery, Hive, and Spark, using scripting languages like Scala, SQL, Python, etc.
You excel in interpersonal interactions, are attentive to others' viewpoints, and prioritize our success over individual ideas.
Navigate within a matrixed organization and communicate effectively with peers and senior executives across local and global settings.
You holds a Bachelor's degree in Computer Science, Information Systems, or a related field.
About the Team
Center for Data and Insights (CDI) is a service oriented horizontal organisation that is uniquely positioned within the company to be the trusted and unbiased source of timely data-based insights for Crunchyroll. Our vision is to inspire, support and guide our stakeholders to be data-aware and build the systems of intelligence to discover insights and act on them. We have built a highly functional organization that truly believes in being a responsive partner, with the utmost curiosity, unwavering accountability and the courage to lead with actions.
Why you will love working at Crunchyroll
In addition to getting to work with fun, passionate and inspired colleagues, you will also enjoy the following benefits and perks:
Receive a great compensation package including salary plus performance bonus earning potential, paid annually.
Flexible time off policies allowing you to take the time you need to be your whole self.
Generous medical, dental, vision, STD, LTD, and life insurance
Health Saving Account HSA program
Health care and dependent care FSA
401(k) plan, with employer match
Employer paid commuter benefit
Support program for new parents
Pet insurance and some of our offices are pet friendly!
#LifeAtCrunchyroll #LI-Hybrid
About our Values
We want to be everything for someone rather than something for everyone and we do this by living and modeling our values in all that we do. We value
Courage. We believe that when we overcome fear, we enable our best selves.
Curiosity. We are curious, which is the gateway to empathy, inclusion, and understanding.
Service. We serve our community with humility, enabling joy and belonging for others.
Kaizen. We have a growth mindset committed to constant forward progress.
Our commitment to diversity and inclusion
Our mission of helping people belong reflects our commitment to diversity & inclusion. It's just the way we do business.
We are an equal opportunity employer and value diversity at Crunchyroll. Pursuant to applicable law, we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Crunchyroll, LLC is an independently operated joint venture between US-based Sony Pictures Entertainment, and Japan's Aniplex, a subsidiary of Sony Music Entertainment (Japan) Inc., both subsidiaries of Tokyo-based Sony Group Corporation.
Questions about Crunchyroll's hiring process? Please check out our Hiring FAQs: https://help.crunchyroll.com/hc/en-us/articles/360040471712-Crunchyroll-Hiring-FAQs
Please beware of recent scams to online job seekers. Those applying to our job openings will only be contacted directly from @crunchyroll.com email account.",USD 170K - 221K *
410,Senior Manager Big Data Administration,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
About BU
At the heart of everything we do is data and this team. Our premium data assets empower the team to drive desirable outcomes for leading brands across industries. Armed with high volumes of transactional data, digital expertise and unmatched data quality, the team plays a key role in improving all our product offerings. Our data artisans are keen on embracing the latest in technology and trends, so there’s always room to grow and something new to learn here.
Why we are looking for you?
Epsilon is a leading provider of multi-channel marketing services, technologies and database solutions. Epsilon is seeking a Sr Manager of Big Data Administration  with a balance of managerial and technical skills to work out of our Bengaluru, India location and oversee a team of Big Data Administrators and Data Warehouse and implementing and supporting solutions running on premise or cloud for Database Marketing clients.
What will you enjoy in this role?
Seeking a highly motivated and well-rounded Manager for Big Data Administration with combination of Tech skills and people management. Someone who is strong on Leadership and developing good professional relationships

What will you do? 
Manage, mentor and coach a team of up to 10 Database and Big Data and Administrators
Working exposure handling sizeable volume (in Gb’s) of data
Perform hands-on Big Data Administration on several client engagements.
Participate in gathering requirements and contribute to the architecture design of Big Data client solutions for Marketing and Analytics
Be proficient in cluster administration tasks including patching, upgrades, backup and recovery, troubleshooting, performance diagnostics and tuning, and SQL optimization.
Hands-on experience monitoring and reporting on Hadoop resource utilization and troubleshooting.
Hands-on experience supporting code deployments (Spark, Hive, Kafka etc.) into the Hadoop cluster.
Experience in administration of Hadoop Big Data tools --experience working on batch processing and tools in the Hadoop technical stack (e.g., MapReduce, Yarn, Hive, presto, HDFS, Oozie)
Knowledge on MPP/DW appliance database like Greenplum, Teradata etc
Possess knowledge in replication to Disaster Recovery site, data encryption, backup storage and archiving procedures.
Work with client teams in the support of development and deployment of Big Data and database jobs
Work closely with IT, developers and competency teams to ensure that applications availability and performance are within agreed on service levels.
Contribute to structures design, capacity and cluster expansion planning.
Research and recommend automated approaches to Big Data and DW solution administration.
Enforce standards and best practices for availability, security, backup and recovery.
Contribute to developing and documenting Big Data and DW standards, guidelines and operational procedures.
Evaluate Big Data and DW technologies and Cloud Services and recommend to technical management.
Perform a variety of tasks relying on experience and judgment to manage time, plan and accomplish goals on several projects.
Manage on-call rotation for 24 x 7 x 365 support.
 Qualifications
10+ years of general technology experience (preferably database administration)
B.S. in Computer Science or related discipline or equivalent work experience required. Hadoop and/or AWS certification is a plus.
At least 3+ years of experience managing Data Warehousing solutions on Netezza, Teradata, Greenplum, Vertica or similar.
4+ experience managing technical teams.
Cloud Data Warehouse database technologies AWS Redshift is must and Snowflake is a plus
Knowledge of Hadoop and or Big Data cloud services such AWS EMR or Cloudera
Ability to diagnose problems and resolve issues across various tiers (application, database, network)
Strong UNIX/Linux knowledge and understanding of DW MPP architecture, technologies and concepts.
Adherence to SDLC, Change Management, troubleshooting and development methodologies.
Strong leadership and inter-personal skills to manage and mentor direct reports.
Superb analytical and problem-solving skills
Excellent written and verbal communication skills
 ",USD 45K - 84K *
411,Assistant Manager - Data Quality,TransUnion,Mumbai - One World Center,Mid-level / Intermediate,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
We are one of India’s leading credit information company with one of the largest collections of consumer information. We aim to be more than just a credit reporting agency. We are a sophisticated, global risk information provider striving to use information for good.
We take immense pride in playing a pivotal role in catalyzing the BFSI industry in the country. We got here by tapping into our excitement and passion of wanting to make a difference in the lives of our clients and consumers.
We at TransUnion CIBIL are an equal opportunity employer and are committed to a policy of treating all our associates and job applicants equally. Applicants are evaluated on the basis of job qualification - not race, color, sex / gender, religion, caste, national origin, age, disability, marital status, citizenship status, sexual orientation, gender identity or any other status, whether or not protected. We are committed to taking affirmative action to employ and advance minorities, women, and qualified disabled individuals. We ensure a safe, productive, and harassment-free workplace for all.
Culture and Values
Our culture is welcoming, energetic, and innovative. There’s an overall synergy that flows throughout the company, creating a sense of connect, belonging and unity in knowing that we’re all working to achieve the same overall goal. Our core values which we live by every day are integrity, People, Customer, and Innovation.
https://www.transunion.com/privacy/global-job-applicant
What is excitement and passion for us?
We define it as a blend of curiosity, ability to unlearn and yet continuously learn, able to connect with meaning and finally the drive to execute ideas till the last mile is achieved. This passion helps us focus on continuous improvement, creative problem solving and collaboration which ensures delivery excellence.

Dynamics of the Role
This is an exciting time in TransUnion CIBIL. With investments in our people, technology and new business markets, we are redefining the role and purpose of a credit bureau.
The role will be responsible for assisting in formulating and managing the development and implementation of goals, objectives, policies and procedures for data quality and performance. S/he will be responsible for ensuring proper implementation of quality assurance objectives and meeting the set target for Commercial Data in lending Industry.
What You'll Bring:
Roles & Responsibilities
Responsibility 1): Build & Manage Business intelligence process
Understand the core process of Data reporting by Credit Bureaus by Financial institution
Develop mechanism to analyze Daily data flow into the repository.
Share insights , trends and monitor key business metrics around Personal/ consumer and Rural lending
Create custom dashboards and MIS for top management
Conduct RCA and review mechanism for critical data fields.
Responsibility 2): Big Data Analysis
Apply Big data tools Spark/ HiveSQL / Pyspark/ SQL to prepare meaningful stories related to Quality and Risk parameters
Build automation jobs on Hadoop / Mapr platform for BAU ( day to day ) activities
Create Analytical dashboard on powerBI / Tableau for sharing insights and decision making
Responsibility 3): Engagement with members/ financial institution
Conduct detail analysis of new/existing members who are submitting data.
Develop & monitor variables for deep dive into data as per regulatory /compliance.
Identify and share analysis with member institution for continuous improvement.
Lias with cross functional teams to improve the quality of data in Fintech space
Engage with external financial institutions to drive the improvement in data quality.
Impact You'll Make:
Experience and Skills
3+ year work experience in BFSI Domain Business Intelligence
Atleast 3+ year of strong database experience (RDBMS etc.) using SQL / Spark / HiveSQL
Hands on experience in SQL / Pyspark and ability to write complex queries is mandatory
3+ years’ experience in working with large database and datamarts (in GB’s and TB’s of data) with focus on efficiency of data access to run analytics engagement
3+ years of working exposure to BI and visualization platforms for developing Business dashboard solutions
2+ years of experience in Tableau / PowerBI
Exposure to data warehousing concepts and practices would be preferred
Exposure to BIG data technologies will be a plus
Exposure to digital and advance analytics would be a Plus
Tableau/PowerBI certified or any other technical certification will be plus
Self-starter, ability to work independently, handle ambiguous situations and exercise judgement in variety of situations.
** Strong communication, organizational, verbal & written skills. (Important Skill)
High degree of responsibility and ownership, strong multitasking, coordination and tenaciously looking for ways to get results.
TransUnion Job Title
Specialist I, Data Design and Analysis",USD 30K - 56K *
412,"Manager, Statistical Programming",Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Please see attached JD
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 30K - 56K *
413,Sr Software Engineer - AI/ML,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
5+ years of experience with Java programming language
Experience with JavaScript, Database and the Web as a platform, reusability, and componentization
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
Knolwledge of basic AI/ML techniques and algorithms
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 45K - 84K *
414,AI/ML Engineer,Avantor,IND-Pune(GBC),Senior-level / Expert,"Job Summary
We are seeking an experienced Machine Learning Engineer to join our dynamic team. The ideal candidate will have a firm understanding of machine learning techniques, algorithms, and the ability to apply them to large-scale, complex datasets to develop predictive models. A strong background in SAP data is advantageous. This is a mid to senior-level position, perfect for someone ready to put their technical skills to use in a growing, innovative organization.
MAJOR JOB DUTIES AND RESPONSIBILITIES (List in order of importance)
NLP Application Development: Design, develop, and deploy an intelligent chatbot/virtual assistant using state-of-the-art language models and NLP techniques. Ensure the application responds accurately to user queries and maintains context throughout the interaction.
Working across client teams to develop and architect Generative AI solutions using ML and GenAI
Developing and promoting standards across the community
Evaluating and selecting appropriate AI tools and machine learning models for tasks, as well as building and training working versions of those models using Python and other open-source technologies
Help democratize the AI building process while advancing the capabilities of autonomous and human-controlled agents.
Setup and train large language models (BERT, GPT-3, etc.) and other state-of-the-art neural networks
Data Preprocessing: Clean, structure, and preprocess raw data to make it suitable for use with NLP models. This includes text normalization, tokenization, and other data transformation techniques.
Model Training and Validation: Train and fine-tune NLP models using appropriate datasets. Validate model performance using suitable metrics and techniques, adjusting model parameters as necessary to optimize performance.
Integration: Work on integrating the NLP capabilities with various platforms including SAP, Salesforce, SharePoint, and ServiceNow. Ensure smooth and efficient data exchange between systems.
Performance Optimization: Regularly monitor and evaluate the performance of the chatbot/virtual assistant. Use analytics to identify areas for improvement and optimize the system for better user experience and accuracy.
Collaboration: Collaborate with other engineers, data scientists, and business analysts to understand requirements, refine models, and implement NLP solutions.
Keeping Current with Industry Trends: Stay up-to-date with the latest advancements in NLP, machine learning, and AI. Evaluate and adopt new technologies, tools, and methodologies as appropriate to improve our capabilities.
QUALIFICATIONS (Education/Training, Experience and Certifications)
Bachelor's or Master's degree in Mathematics, Statistics, Computer Science, Data Science, AI, Machine Learning, or a related field.
3+ years of professional experience in NLP/LLM solutions, with a focus on developing chatbots/virtual assistants or similar applications
3 Years of experience in programming Python/R
Proficiency in industry-leading NLP tools, libraries, and frameworks
KNOWLEDGE SKILLS AND ABILITIES (Those necessary to perform the job competently)
Experience in deep learning and training LLMs.
Expertise in programming languages commonly used in NLP, such as Python.
Hands on experience with forecasting, predictive modelling, and classification.
Hands on experience with AWS services, such as S3, EC2, SageMaker
Exposure to Generative AI/OpenAI ChatGPT/LangChain
Hands-on experience integrating with platforms like SAP, Salesforce, SharePoint, and ServiceNow is a strong advantage.
Strong understanding of NLP concepts and techniques, such as tokenization, entity recognition, sentiment analysis, and language modelling.
Strong understanding in building and maintaining API solutions.
Excellent problem-solving skills, with the ability to troubleshoot technical challenges and develop effective solutions.
Strong communication skills, with the ability to explain complex NLP concepts to non-technical stakeholders.
A collaborative team player who can work effectively in cross-functional teams.
DISCLAIMER:
The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position.
Avantor is proud to be an equal opportunity employer.
EEO Statement:
We recognize the value of diverse workforce and aim to create employment opportunities such that all employees achieve their full potential and work in an environment free of discrimination and harassment. We are an Equal Employment/Affirmative Action employer. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, caste, color, religious creed, ethnicity, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by central, national, provincial or local laws.
3rd party non-solicitation policy
By submitting candidates without having been formally assigned on and contracted for a specific job requisition by Avantor, or by failing to comply with the Avantor recruitment process, you forfeit any fee on the submitted candidates, regardless of your usual terms and conditions. Avantor works with a preferred supplier list and will take the initiative to engage with recruitment agencies based on its needs and will not be accepting any form of solicitation",USD 174K - 275K *
415,Artificial Intelligence Department Manager,Valeo,CHENNAI - CHE7-3,Senior-level / Expert,"Valeo is a tech global company, designing breakthrough solutions to reinvent the mobility. We are an automotive supplier partner to automakers and new mobility actors worldwide. Our vision? Invent a greener and more secured mobility, thanks to solutions focusing on intuitive driving and reducing CO2 emissions. We are leader on our businesses, and recognized as one of the largest global innovative companies.
Technical Leadership and Team Management:
➔ Develop and communicate a strategic vision for the Computer Vision Deep Learning
department in alignment with the company's overall goals.
➔ Provide technical leadership for the team, overseeing people management, task
tracking, and reporting of activities.
➔ Lead the research and development efforts for the next generation of complex
products.
➔ Lead the team in setting clear objectives, milestones, and key results.
Strategic Planning and Collaboration:
➔ Collaborate with project managers to determine resource requirements for projects.
➔ Conduct state-of-the-art research into deep learning and computer vision approaches
and methodologies.
➔ Create high-level module and sub-module architectures during project kick-off and
pre-development phases.
Technical Guidance and Approval:
➔ Offer expertise to algorithms and embedded leads in designing computer vision/deep
learning functions.
➔ Approve and sign off on all computer vision/deep learning designs in collaboration
with relevant leads.
Research and Development:
➔ Conduct research, development, benchmarking, testing, and documentation of
state-of-the-art computer vision and image processing algorithms, specifically for
autonomous parking and driving applications within the assigned project team.
➔ Explore and contribute to next-generation algorithms and identify new business
opportunities.
Industry Representation and Networking:
➔ Represent the Valeo at various Industry Working Groups and Conferences as directed.
➔ Develop and maintain relationships with university counterparts to stay abreast of the
latest advancements.
Intellectual Property and Innovation:
➔ Support Intellectual Property activities and generate Invention Disclosure Memos to
facilitate patent applications.
Cross-Team Collaboration:
➔ Contribute to design reviews across algorithm teams to ensure consistency and
efficiency.
➔ Collaborate on the design and implementation of in-company training sessions in your
area of expertise.
Deep Learning Manager-Specific Responsibilities:
➔ Oversee the strategic implementation of deep learning initiatives within the team.
➔ Drive the development of deep learning models and algorithms for cutting-edge
applications.
➔ Mentor and guide team members in the application of deep learning techniques.
➔ Ensure the alignment of deep learning strategies with overall project goals.
➔ Stay updated on the latest advancements in deep learning and implement best
practices within the team.
➔ Collaborate with stakeholders to define the vision and roadmap for deep learning
projects.
➔ Provide technical insights into the integration of deep learning solutions with
embedded DSP platforms.
➔ Foster a culture of continuous learning and skill development within the deep learning
team.
➔ Identify and address challenges in the implementation of deep learning algorithms.
➔ Champion process improvements and efficiency enhancements in the context of deep
learning projects.
Candidate Profile
Required Skills/Experience
Educational Qualifications:
➔ Bachelor's (B.E./B.Tech.) degree with 15+ years of work experience or
➔ Master's (M.E./M.S.) degree with 13+ years of work experience or
➔ Ph.D. in Computer Science with 12+ years of work experience
➔ Computer science, Physics, Electronic Engineering, Software Engineering.
Programming and Deep Learning Skills:
➔ Strong proficiency in C and C++ programming.
➔ Alternatively, strong rapid prototyping skills using Python, Matlab, Octave.
➔ Extensive experience in implementing and optimizing deep learning solutions.
Deep Learning Frameworks:
➔ Proficiency in popular deep learning frameworks such as TensorFlow, PyTorch, or
similar.
➔ Hands-on experience in developing and deploying deep learning models for
real-world applications.
Computer Vision Expertise:
➔ In-depth understanding of fundamental computer vision algorithms and approaches.
➔ Proven experience in integrating deep learning techniques with computer vision
applications.
Communication Skills:
➔ Excellent English language communication skills, both written and verbal.
➔ Ability to communicate complex deep learning concepts to technical and
non-technical stakeholders.
Team Management:
➔ Demonstrated experience in managing deep learning and computer vision teams.
➔ Proven ability to lead high-competency teams effectively.
Innovation and Motivation:
➔ High level of innovation and motivation to drive advancements in deep learning
technologies.
➔ Track record of successfully introducing innovative deep learning solutions.
Research Experience:
➔ Strong research background with a focus on deep learning methodologies.
➔ Published research papers or patents in deep learning and related fields.
Problem-Solving Skills:
➔ Excellent problem-solving skills, particularly in addressing complex challenges in
deep learning projects.
Adaptability:
➔ Ability to adapt to evolving technologies and stay updated with the latest
developments in deep learning and computer vision.
Collaboration and Interpersonal Skills:
➔ Proven ability to work collaboratively in cross-functional teams.
➔ Effective interpersonal skills to foster a positive and collaborative team environment.
Project Management:
➔ Strong project management skills with the ability to plan, execute, and deliver deep
learning projects on time and within budget.
Desired Attributes
Specialization:
➔ Computer Vision, Image Processing, Signal Processing and Machine Learning.
Deep Learning and AI:
➔ Experience with Deep Learning and AI frameworks.
OpenCV Proficiency:
➔ Skilled in OpenCV programming.
Academic Contributions:
➔ Published academic work in the relevant field.
Algorithm Development:
➔ Proven experience in algorithm development for LIDAR, camera systems, sensor
fusion, computer vision, ultrasonics, RADAR,.
Simulation Tools:
➔ Familiarity with PC-based simulation tools.
Embedded Software Development:
➔ Experience in developing software for embedded platforms.
➔ Proficient in CUDA or OpenCL for parallel programming.
➔ Experience in developing algorithms for autonomous and/or real-time systems.
Version Control:
➔ Proficient in version control software.
Automotive Industry Experience:
➔ Previous involvement in the automotive industry.
Job:
R&D Department/Product Manager
Organization:
Engineering Software
Schedule:
Full time
Employee Status:
Regular
Job Type:
Permanent contract
Job Posting Date:
2023-04-20
Join Us !
Being part of our team, you will join:
- one of the largest global innovative companies, with more than 20,000 engineers working in Research & Development
- a multi-cultural environment that values diversity and international collaboration
- more than 100,000 colleagues in 31 countries... which make a lot of opportunity for career growth
- a business highly committed to limiting the environmental impact if its activities and ranked by Corporate Knights as the number one company in the automotive sector in terms of sustainable development

More information on Valeo: https://www.valeo.com",USD 45K - 84K *
416,Data Analyst - Price hub,Cargill,"Gurgaon, Haryana, India, 122002",Entry-level / Junior,"Want to build a stronger, more sustainable future and cultivate your career? Join Cargill's global team of 155,000 employees who are committed to safe, responsible and sustainable ways to nourish the world. This position is in Cargill’s food ingredients and bio-industrial business, where we anticipate trends around taste, nutrition and safety to innovate and provide solutions to manufacturers, retailers and foodservice companies.
Job Purpose and Impact
The Data Analyst - Price hub is responsible for delivering robust data support along with analytic inputs in business requirements and data management activities to support different business units within Cargill. In this role, you will contribute to the continuous process improvement on price data management, standardization and harmonization and you will be actively involved in developing and implementing action plans on business performance optimization.
Key Accountabilities
Deploy a basic understanding of the trading questions that data can help to solve.
Mapping upstream data source fields to Price Hub attributes; along with formulating transformation rules for new/derived columns in mapping
Work with data engineers to give them the requirement for them to create the data output flow.
Test the output data within Price Hub to validate if it is as per the said rules and check for anomalies and relay them back to data engineers for corrections.
Create documentation for the newly mapped data source for consumers for easy understanding and create adhoc SQL queries for consumers based on their requirements.
Handle basic issues and problems under direct supervision, while escalating more complex issues to appropriate staff.
Other duties as assigned
Qualifications
Minimum Qualifications
Bachelor's degree in a related field or equivalent experience
Minimum of two years of experience in a related field
Experience in MS office suite (Outlook, Excel, Word, Power Point) and entry level SQL
Preferred Qualifications
Experience in managing and planning pricing metadata such as data mining and analysis of price types such as exchange futures prices, options, cash, bids and offer price etc.
Ability to make case across and help people learn the basic of data connection to web-based portal to power excel via Oracle Database Connectivity (ODBC)",USD 56K - 94K *
417,BI Developer II (Power BI & SQL),Verisk,"Hyderabad, India",Mid-level / Intermediate,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
The Business Intelligence Developer II will develop and implement Business Intelligence (BI) solutions to support increasing the efficiency of Verisk processes, enhancing Verisk’s current products, and developing new products. This position works with an existing team of Business Intelligence Developers within the Verisk Claims Solutions group that services both internal and external customers. Following existing patterns, the successful candidate will develop and deliver timely business intelligence solutions that meet specific technical requirements.
Duties and Responsibilities
Work with Product Owners and customers to understand requirements, validate solutions and troubleshoot issues
Work closely with QA ,Data Engineering team to develop BI solutions and have the desire and ability to make connections across different disciplines to support the entire project team
Analyze and understand user behavior, and log and resolve software bugs in a timely manner
Develop high quality reporting worksheets/data source field lists and data visualizations for dashboards on various Business Intelligence tools such as ThoughtSpot and Power BI
Write SQL scripts for reports and row level security creation
Maintain, support and enhance our data analytics as a service platform capabilities
Work with BI Platform Developers for upgrades and onboarding new features 
Work with vendor support teams to resolve technical issues
Proactively research and understand the latest BI trends
Qualifications
BS degree in Information Technology or related discipline with 2+ years of relevant experience
Strong programming, visualization, and analytical skills
Ability to solve problems analytically and creatively 
Ability to unit test solutions to ensure high quality and accuracy
Strong communication (written and oral) skills
Experience creating reports and dashboards, in BI Tools (e.g. Power BI, ThoughtSpot, Tableau) for internal and external use
Experience with generating reports and analysis using SQL and databases (e.g. Snowflake, MS SQL Server, PostGres, BigQuery, Hive)
Understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework
Familiar with scripting languages (e.g. Python, JavaScript, Scala) to connect and work with APIs, not required but nice to have
Familiar with cloud services (e.g. AWS/GCP/Azure) not required but nice to have
Familiar with version control (GIT) not required but nice to have
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 76K - 128K *
418,Data Engineer with Python /Pyspark,Unison Consulting Pte Ltd,India - Remote,Senior-level / Expert,"Develop and implement data pipelines for ingesting and collecting data from various sources into a centralized data platform.
Develop and maintain ETL jobs using AWS Glue services to process and transform data at scale.
Optimize and troubleshoot AWS Glue jobs for performance and reliability.
Utilize Python and PySpark to efficiently handle large volumes of data during the ingestion process.
Design and implement scalable data processing solutions using PySpark to transform raw data into a structured and usable format.
Apply data cleansing, enrichment, and validation techniques to ensure data quality and accuracy.
Create and maintain ETL processes using Python and PySpark to move and transform data between different systems.
Optimize ETL workflows for performance and efficiency.
Collaborate with data architects to design and implement data models that support business requirements.
Ensure data structures are optimized for analytics and reporting.
Work with distributed computing frameworks, such as Apache Spark, to process and analyze large-scale datasets.
Manage and optimize databases, both SQL and NoSQL, to support data storage and retrieval needs.
Implement indexing, partitioning, and other database optimization techniques.
Collaborate with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver effective solutions.
Work closely with software engineers to integrate data solutions into larger applications.
Implement monitoring solutions to track data pipeline performance and proactively identify and address issues
Ensure compliance with data privacy regulations and company policies.
Stay abreast of industry trends and advancements in data engineering, Python, and PySpark.
Requirements
Proficiency in Python and PySpark.
Strong knowledge of data engineering concepts and best practices.
Hands-on experience with AWS Glue and other AWS services.
Experience with big data technologies and distributed computing.
Familiarity with database management systems (SQL and NoSQL).
Understanding of ETL processes and data modeling.
Excellent problem-solving and analytical skills.
Strong communication and collaboration skills.
Bachelor's degree in Computer Science, Information Technology, or a related field.",USD 121K - 186K *
419,Enterprise Data Analyst,ACA Group,"Pune, MH, IN, 411057",Entry-level / Junior,"Enterprise Data Analyst :
  Responsibilities:
Administrative Tasks:
Manage Power BI workspaces, datasets, and reports.
Set up and maintain data sources for seamless data connectivity.
Monitor and optimize report performance.
Collaborate with IT teams to ensure data security and compliance.
Data Transformation:
Understand existing Extract, transform, and load data process from various sources into Power BI.
Understand and troubleshoot existing data models using DAX language.
Implement and document effective data cleansing and enrichment processes.
Troubleshooting and Issue Resolution:
Investigate and resolve data-related issues in Power BI reports and data sets.
Investigate and resolve data-related security issues in Power BI data sets.
Debug performance bottlenecks and optimize queries.
Provide technical support to end-users.
Report Development:
Design and develop visually appealing dashboards and reports.
Implement interactive visualizations using Power BI features.
Collaborate with business stakeholders to gather requirements.
Strong experience to connect to and work with data sources such as SSAS, Synapse.
Documentation:
Document data models, report specifications, and best practices.
Create user guides and training materials for Power BI users.
Create technical documentation for internal teams.
Qualifications:
Bachelor’s degree in Computer Science, Information Systems, or related field.
Minimum of 5 years of experience as a Power BI Developer and administrator.
Proficiency in Power BI Desktop, DAX, and data modeling.
Proficiency in Power BI administration and security
Strong analytical and problem-solving skills.
Excellent communication and teamwork abilities.
Excellent troubleshooting skills.
Excellent documentation skills.
Preferred Skills:
Certification in Power BI and Azure administration (e.g., Microsoft Certified: Data Analyst Associate, Azure Administrator Associate).
    What working at ACA offers:
We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. Our Total Rewards package includes medical coverage fully funded by ACA for employees and their family as well as access to Maternity & Fertility and Wellness programs. ACA also provides Personal Accident Insurance, Group Term Life Insurance, Employee Discount programs and Employee Resource Groups. You’ll be granted time off for designated ACA Paid Holidays, Privilege Leave, Casual/Sick Leave, and other leaves of absence to support your physical, financial and emotional well-being.
About ACA:
  ACA Group is the leading governance, risk, and compliance (GRC) advisor in financial services. We empower our clients to reimagine GRC and protect and grow their business. Our innovative approach integrates consulting, managed services, and our ComplianceAlpha® technology platform with the specialized expertise of former regulators and practitioners and our deep understanding of the global regulatory landscape.
What we commit to:
  ACA is firmly committed to a policy of nondiscrimination, which applies to recruiting, hiring, placement, promotions, training, discipline, terminations, layoffs, transfers, leaves of absence, compensation and all other terms and conditions of employment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected status",USD 56K - 94K *
420,Data Specialist,Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"What makes Gartner Consulting a GREAT fit for you?
A career at Gartner Consulting will be unlike any other you have experienced. Not only are we passionate about technology and its applications, but we are also committed to attracting the most creative, talented, and self-driven people to take our well-regarded Consulting function to a whole new level. When you join Gartner, you will be a part of some of the most innovative business and technology efforts in the marketplace today. We are technology thought leaders for the 21st century. You can expect to connect technology innovations to strategic requirements of an organization and to the commercial needs of a business, all within the context of a changing digital economy. Consulting associates enjoy a collaborative work environment, exceptional training, and career development opportunities. If you thrive on solving complex business challenges with technology, Gartner Consulting is the place for you.
About this role:
The Data Specialist is responsible for developing and maintaining reports, data analytics and requests for market and internal data using various technologies.  Focus will be both strategic and tactical reports that assist in growth of the business. 
What you’ll do:
Supporting and working alongside the Systems and Operations Director you will be responsible for fulfilling the reporting, data analytics and dashboard needs of the business
Retrieval and manipulation of data from spreadsheets, a data warehouse or database environment.
Become proficient in using CRM tools and systems to be able to design, develop and test enhancements to existing or new reports and dashboards.
Upload, manage and maintain accurate system information e.g. territory alignments and leads
Provide reports used for weekly, monthly or annual analysis to business leaders
Collaborate with multiple stakeholders to define and execute on reporting needs
Respond to data requests from leadership in a timely and efficient manner
What you’ll need:
Bachelor’s degree essential, preferably a Business or Finance Discipline
1-3 years of business experience with 1+ years of experience in the BI space
Experience with Salesforce CRM and Power BI data visualization is desirable
Detail-orientated with an unwavering commitment to pursue relevant and accurate data.  Delivering accurate data is key.
Ability to take notes and follow instructions.
Ability to handle multiple, time-sensitive projects while focusing on the quality of work delivered and meeting deadlines
Strong verbal and written communication skills
Strong work ethos both independently and in a team environment
Natural aptitude for critical and analytical thinking with problem solving skills
Strong organizational skills within a fast-paced deadline driven environment
Fluent in English language
Who you are:
Self-starter and a quick learner, demonstrates no-limits mindset
Strong consultative skill and problem-solving ability and strong desire to win
Passionate about technology and helping clients in the time of industry disruption led by technology evolution
Leadership to drive great result through a team of talented but junior consultants, motivate and help them grow
High performing team player with strong intercultural communication and collaboration
What Gartner Consulting will offer you?
A world-class consulting environment
The opportunity to work on cutting edge IT strategy engagements with a tier one client portfolio
A competitive salary
Structured bonus based on individual and corporate performance
Opportunities for promotion with a clear defined career development structure
Opportunity to participate actively in the development and future of Gartner Consulting
A dynamic but relaxed and supportive working environment that encourages personal development
#LI-AS12
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:83826
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 70K - 110K *
421,Modelling / Data Science - Sr Analyst - Analytics,dentsu international,"Bengaluru, India",Senior-level / Expert,"Company Description
About Merkle
Merkle, a dentsu company, is a leading data-driven customer experience management (CXM) company that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The company’s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive hyper-personalized marketing strategies. Its combined strengths in consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions drive improved marketing results and competitive advantage. With more than 14,000 employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the Americas, EMEA, and APAC. For more information, contact Merkle at
1-877-9-Merkle or visit www.merkle.com.
Job Description
Job Description
Roles & Responsibilities
3 + years in Analytics
Strong SQL background ( Must Have, To be evaluated using a written SQL Test)
Strong communication ( Must have)
Analytics Problem solving skills
People with Marketing Analytics/CRM Analytics background ( Nice to Have)
BFSI Background ( Nice to have)
Ideally we are looking for folks who can translate business problems to analytics problem, extract the required data from various databases, do the analysis and be able to present it to the client
We don’t necessarily need folks with Advanced Modeling experience
Qualifications
Qualifications/Certifications:
- BE/ B.Tech, ME/MTech (Computer Science)
- Advanced degree in a quantitative discipline, preferably Mathematics/Statistics or similar will be an added advantage",USD 95K - 158K *
422,Teaching Assistant Intern - Data Science,Testbook,"Noida, Uttar Pradesh, India",Entry-level / Junior,"Location: Noida,Uttar Pradesh,India
  About Testbook
Testbook is the fastest growing & leading EdTech platform established 8 years ago. We focus on Government & Private Job Exams with an eye to capture Banking, SSC, Railways, GATE, UPSC, Teaching and many more categories. Testbook is poised to revolutionize the industry with a registered user base of over 4.2 Crore students, 700+ crore questions solved on the WebApp, and a knockout Android App. Testbook has raced to the front and is placed to capture bigger markets. Testbook is the perfect incubator for talent, “you come, you learn, you conquer”. You will train under the best mentors and become an expert in your field. That being said, the flexibility in the projects you choose, how and when you work on them, what you want to add to them is respected in this startup. You will be sole master of your work. The IIT pedigree of the co-founders has attracted the brightest minds in the country to Testbook. A team rapidly swelling in ranks, it now stands at 800+ in-house employees and hundreds of remote interns and freelancers. These number are rocketing weekly. Now is the time to join the force.
 Role and responsibilities 
1. Organize mentor sessions which would be in the one-to-one or one-to-many format to address any common doubt, have practice problems or cover a topic in extra depth from the live sessions.
2. Be available for at least 4 hours everyday for one-to-one doubt solving sessions and solve individual doubts of learners.
4. Auditing assignments and connecting with students with detailed feedback.
 Must have.
A passion to impact and shape-up Education in India
Strong communication skills and good command over written English.
Past experience of appearing for competitive exams is a plus.
Experience in teaching would be plus.
knowledge of Excel, SQL, Python, Advance Python Libraries (Numpy, Pandas, Matplotlib, Seaborn), Statistics (using Excel & Python). Machine Learning.
Apply to this job",None
423,Data Engineer,Nestlé,"Bengaluru, IN, 560103",Entry-level / Junior,"About IT in Nestlé
We are a team of IT professionals from diverse cultures, genders and age groups in the world’s largest food and beverage company. We innovate every day through forward-looking technologies to create opportunities for Nestlé’s digital challenges with our consumers, customers and employees.
We have exciting positions in our new Nestlé global services operations based in Bangalore, which works alongside our Regional IT Hub in Sydney and Global IT hubs to provide technology services. This set up will design, implement and maintain IT solutions and sharpen Nestlé’s focus in the growing areas of digital, analytics and innovation to support changing customer, consumer and shopper focus.
When you join our IT team, you’ll have the opportunity to collaborate across local and global Nestlé teams and external partners to deliver innovative technologies that create tangible business value and contribute proactively to our sustainability goals. Our diversity brings fresh and innovative thinking to how we approach new and existing challenges while embracing different cultures, genders, sexual orientation, abilities and flexible ways of working.
Watch our videos on women in IT and flexibility in IT and visit IT Jobs and Vacancies in India | Nestlé (nestle.in) to learn more.
  Position Summary
  Joining Nestlé means you are joining the largest food and beverage company in the world.  At our very core, we are a human environment – passionate people driven by the purpose of enhancing the quality of life and contributing to a healthier future. 
  To strengthen our Global IT Hub in Bangalore, we are looking for an IT Data Architect/Engineer within our Data Analytics Products and Services (DAPS) product group for Supply Chain.  In this position, you will engage closely with IT, portfolio management and the Supply Chain functions.  You will work with internal & external development teams and the business to design and develop high-performing analytics products at scale, enabling our business stakeholders and receivers to create solutions that enhance our data-driven capabilities. 
  A day in the life of IT DAPS Snr Data Architect/Engineer
Reporting to Global  IT Product Manager  Data and Analytics Supply Chain
Engage with Product Managers, Product Owners, Business Analysts , Data Engineers and Architects of IT and ADI Streams for understanding the data and analytics needs.
Partner with IT Supply Chain Stream and Corporate Function, Zone and markets to understand, analyse, and translate pain points or opportunities.
Work with external partners, to design and develop data and analytics products that deliver business value as efficiently as possible. Ensure data products delivered for the organization comply with Industry standards and are scalable and performant, using a range of On-premises and Cloud toolsets, including SAPBW with HANA and the  new generation analytics platforms such as Azure, Snowflake and Power BI.
You will design and develop data and analytics products to support both standard reporting and more advanced analytics and machine learning use cases.
You may work as the lead solution architect, collaborating with Data Engineers and Data Scientists. 
Define data requirements, data flows, and data integration strategies to ensure seamless data access and usage across systems.
Experience using waterfall and agile development methodologies.
continuously improving data flows, queries and processes for optimal performance and data quality
Design and implement data security measures to safeguard sensitive information within Data Products.
Ensure data products comply with data governance policies, data privacy regulations, and industry best practices.
Maintain comprehensive documentation of Data Product designs, data models and architecture patterns.
Communicate technical concepts and solutions to both technical and non-technical stakeholders effectively.
Stay updated with latest data technologies, tools, trends and identify opportunities for innovation and improvement in Data Product development processes.
Provide technical leadership and mentorship to internal and external Data Engineering teams, fostering a culture of excellence and continuous improvement.
Support Product Owners, Product Managers and Product Group Managers through the full product lifecycle from new product initiation through to product retirement.
  What will make you successful
Bachelors or master’s degree in computer science, engineering, math’s, finance, statistics, or related discipline. 
Most likely you will come from a data engineering  background, with 10+ years’ experience spanning between building data assets and pipelines and as a Data architect or similar role to serve analytics use cases. 
Whilst capable of performing hands-on development, you are keen to progress to leading and coaching others.   You are keen to drive the work of development teams to be able to create solutions at scale.
You have a track record of delivering analytics products at scale using SAP-BW and newer-generation data warehousing platforms specifically Snowflake and Azure Services.  Ideally you have experience of using modern front-end analytics tools such as Power BI and SAP SAC.
Strong expertise in data modelling techniques, data integration and data architecture patterns.
Strong expertise in database technologies, data warehousing and ETL processes.
In-depth knowledge of data management best practices, data governance and data security.
Excellent analytical and problem-solving skills.
Ability to work in a fast-paced, dynamic environment managing multiple projects simultaneously.
Strong experience with effective communication at different levels in the organization and in English.
An appreciation for data democratization and the F.A.I.R data principles.
Be autonomous and proactive in proposing action plans, establishing relationships, and engaging with different areas of the IT organization and the business.
Demonstrated experience in establishing standard processes and managing performance to achieve key metrics
Experience explaining technical concepts and technologies
Experience working in a global environment and with virtual teams
Effective communication and presentation skills are vital as you develop working partnerships with internal and external stakeholders, such as service integrators, service provides and vendors across the globe (face-to-face and remote)
With stakeholders based in various time zones, flexibility is essential as you participate in teleconferences and activities outside of standard business hours.
  About Nestlé
Nestlé enjoys a reputation as the world’s largest food and beverage company driven by our purpose - enhancing quality of life everyone, today and for generations to come. At Nestlé, we constantly explore and push the boundaries of what is possible with foods, beverages, and nutritional health solutions to enhance quality of life and contribute to a healthier future to better support individuals, families, communities and the planet. We have more than 2000 brands ranging from global icons to local favourites and are present in 190 countries worldwide.    
   ",USD 110K - 181K *
424,Graduate Engineer Trainee- B.Tech/ B.E - Data Science/ IT/ CS,ZF Friedrichshafen AG,"Chennai, TN, IN, 631604",Entry-level / Junior," Req ID 62789 Chennai, India
      Main accountabilities, responsibilities and deliverables of a Data Science Analyst:
Responsible for building analytical systems and predictive models as well as experimenting with new models and techniques.
Continuously improve the business's data analysis model, creating industry-leading performance through the leveraging of new and creative data-sources & analytical solutions.
Work with stakeholders to identify analytics technology requirements. Lead teams to develop, adapt, combine, and choose data science methodology.
Evaluate business analytics strategies and determine analysis goals. Determine data requirements and performance metrics to support analysis.
Interpret and analyze data problems and guarantee data quality and integrity.
Ensure that data projects align with organizational goals.
Utilize data visualization tools to deliver insights to stakeholders.
Responsible for the conception, planning, and prioritizing of data projects.
Drives practical use and knowledge increase of Data Science techniques within the whole QA Function.
  Be part of our ZF team as Graduate Engineer Trainee- B.Tech/ B.E - Data Science/ IT/ CS and apply now!
Contact
Madhumitha Rajan
 ",USD 110K - 168K *
425,AWS Data Dev Engineer,NTT DATA,"Bengaluru, Whitefield, KA, IN",Mid-level / Intermediate,"As an AWS Data Engineer, you will contribute to our client and will have the below responsibilities:
Work with technical development team and team lead to understand desired application capabilities.
Candidate would need to do development using application development by lifecycles, & continuous integration/deployment practices.
Working to integrate open-source components into data-analytic solutions
Willingness to continuously learn & share learnings with others
Required:
5+ years of direct applicable experience with key focus:
Glue and Python; AWS; Data Pipeline creation
Develop code using Python, such as o Developing data pipelines from various external data sources to internal data.
Use of Glue for extracting data from the design data base. Developing Python APIs as needed
Minimum 3 years of hands-on experience in Amazon Web Services including EC2, VPC, S3, EBS, ELB, Cloud-Front, IAM, RDS, Cloud Watch.
Able to interpret business requirements, analyzing, designing and developing application on AWS Cloud and ETL technologies
Able to design and architect server less application using AWS Lambda, EMR, and DynamoDB
Ability to leverage AWS data migration tools and technologies including Storage Gateway, Database Migration and Import Export services.
Understands relational database design, stored procedures, triggers, user-defined functions, SQL jobs.
Familiar with CI/CD tools e.g., Jenkins, UCD for Automated application deployments
Understanding of OLAP, OLTP, Star Schema, Snow Flake Schema, Logical/Physical/Dimensional Data Modeling.
Ability to extract data from multiple operational sources and load into staging, Data warehouse, Data Marts etc. using SCDs (Type 1/Type 2/ Type 3/Hybrid) loads.
Familiar with Software Development Life Cycle (SDLC) stages in a Waterfall and Agile environment.
Nice to have:
Familiar with the use of source control management tools for Branching, Merging, Labeling/Tagging and Integration, such as GIT and SVN.
Experience working with UNIX/LINUX environments
Hand-on experience with IDEs such as Jupiter Notebook
Education & Certification University degree or diploma and applicable years of experience",USD 24K - 44K *
426,"Tech Prof-Data Science, Assoc",Halliburton,"Bengaluru, KA, IN, 560103",Entry-level / Junior,"We are looking for the right people — people who want to innovate, achieve, grow and lead. We attract and retain the best talent by investing in our employees and empowering them to develop themselves and their careers. Experience the challenges, rewards and opportunity of working for one of the world’s largest providers of products and services to the global energy industry.
  Under general supervision, a Data Scientist will perform data engineering, data modeling or model deployment. A Data Scientist will collaborate to obtain data from sources, complete data clean up and build a data dictionary under guidance. This role is able to build models under guidance and understand how to deploy the model and assist in the deployment process. An undergraduate degree in STEM and 1+ years of related experience is required, master's degree in STEM preferred.
  Halliburton is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation.
  Location
6th Floor, Hibiscus Tower 2 Bu, Bangalore, Karnataka, 560103, India
  Job Details
Requisition Number: 181418  
Experience Level: Experienced Hire 
Job Family: Engineering/Science/Technology 
Product Service Line: Global R&D  
Full Time / Part Time: Full Time
Additional Locations for this position: 
  Compensation Information
Compensation is competitive and commensurate with experience.",USD 110K - 168K *
427,"Mgr, Data Engineer Mgmt",ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
As a Lead Data Engineer, you will play a crucial role in designing, implementing, and improving the quality of our data infrastructure (e.g. processes, data storage, data pipelines). You will lead a team of data engineers and collaborate with other teams of data scientists, engineers, designers, product teams, and business stakeholders to ensure the efficient and reliable flow of data to support our workforce intelligence products. The ideal candidate will have a strong background in data engineering, excellent leadership skills, and a passion for leveraging data to answer business questions. This position reports to the Director, Employee Workflows Data Science.  
What you get to do in this role:
Lead and mentor a team of data engineers, providing guidance and support to ensure successful project deliveries. 
Foster a collaborative and innovative team culture, encouraging continuous learning and professional development. 
Collaborate with data scientists, analysts, and product development to understand data requirements and ensure data solutions meet business needs. 
Work closely with Advanced Technology Group (ATG) teams to accelerate production and deployment times for ML services. 
Oversee the integration of data from various sources, ensuring data consistency, accuracy, and reliability. 
Implement ETL processes to transform raw data into a usable format for analysis and reporting. 
Establish and enforce data governance best practices, including data quality, metadata management, and data lineage. 
Recommend and implement data quality testing and data pipeline tests for infrastructure and code. 
Experience working with PII data and identifying security risks in data pipelines. 
Lead the deployment and documentation of Java and Python APIs, and the design of DAG-based workflow frameworks for deploying and running APIs. 
Lead the design of AB rollouts, logging, and developing best practices for deployment, and syncing data between applications, databases, logs, etc. 
Experience with building data pipelines in an Infrastructure-as-Code environment (e.g. Terraform). 
Continuously monitor and optimize data processing and storage systems for performance and efficiency. 
Troubleshoot and resolve data-related issues in a timely manner. 
Communicate effectively with technical and non-technical stakeholders to ensure alignment on data strategies and solutions. 
Implementing ETL and preprocessing data pipelines with a preference for automation. 
Stay informed about emerging technologies in the data engineering space and assess their potential for adoption within the organization. 
Evaluate and recommend tools, frameworks, and architectures to enhance the data engineering capabilities of the team. 
Remotely collaborate with a geographically distributed team and be willing to pitch in to perform other tasks when you see such opportunities. 
Qualifications
To be successful in this role you have:
Bachelor's or Master's degree in computer science, engineering, or a related field.
5+ years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in PL/SQL and an additional object-oriented programming language (e.g., Python, Java, JavaScript)
Proven experience as a Data Engineer, with a track record of designing and implementing complex data solutions.
Strong proficiency in data modeling, ETL processes, and data integration techniques.
Experience with big data technologies such as Hadoop, Spark, and related ecosystems.
Proficient in programming languages such as Python, Java, or Scala.
Excellent leadership and team management skills.
Strong problem-solving and analytical abilities.
Familiarity with cloud platforms, such as AWS, Azure, or Google Cloud.
Knowledge of data governance and security best practices.
Very familiar with putting Python and Java scripts into data pipeline cloud deployments. Additional experience with machine learning frameworks and applications preferred.
Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.
Passion for analyzing large and complex data sets and converting them into the information which drive business decisions.
Attention to detail, organization and effective verbal/written communication skills
Experience in big data instances: Cloudera, Azure, Snowflake, and the like.
Proven track record in rolling out self-service analytics solutions (e.g. Tableau Server Ask Data, etc).
SQL, data warehousing, and ETL pipeline tool experience.
Familiar with devops, CI/CD and using gitlab to collaborate in an Agile environment.
Cloud computing and cloud database experience, preferably with AWS (Redshift, S3, ECS, Sagemaker, Lambda, Pipeline, etc).
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.
Understanding of technology development projects and the full technology. development lifecycle, and experience working with agile development teams.
Communication. Excellent oral and written communication skills.
Solid decision making, negotiation, and persuasion skills, often in ambiguous situations.
Must be able to work in fast paced environment and be able to adapt to changing requirements.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
428,Manager Data Science,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
Who we are looking for?
At Epsilon, our people use real human insights to find solutions that empower some of the biggest brands in the world. Our team is now growing, and we are on the lookout for talented individuals who use descriptive, predictive and prescriptive analytics to impact consumer behaviour every day.
So, are you someone who enjoys leading conversations with influential stakeholders to help clients understand the value of their investments? Then you could be exactly who we are looking for.
Apply today and be part of a creative, innovative and talented team who constantly share insights, solve problems and create the remarkable.
What you’ll do?
The Digital Analytics team in the Client Analytics Group works on client engagements and related delivery for People Cloud Prospect & Discovery environments. The team also partners with client consulting team and platform team and data providers, leveraging analytics and data science to drive strategic thought and effective decision making. The Manager, Data Science is responsible for delivery from multiple client accounts by working with Data Scientists and managing analytic initiatives from conception to completion, providing clients and key stakeholders actionable results and insights that help them achieve their business objectives
Roles & Responsibilities:
Operational
Serve as project lead on most types of analyses performed by the group – develop project plans and manage work efforts of supporting team members
Assess client business and marketing challenges, as well as data assets, and recommend the most appropriate analytic methodology to meet client goals
Manage multiple projects and client accounts simultaneously, while serving as the primary point of contact with the Epsilon account team and clients
Monitor project resources and track progress against task plans to ensure on-time and on-budget project delivery
Document communication with clients to manage expectations and negotiate deadlines
Present analytic findings and statistical results to account teams and clients
Participate in project design, planning and execution, and provide pre-sales support and run proof of concept (POC) for account / sales teams
Ability to perform hands-on analysis on large volumes of customer’s first-party data and third-party data to provide statistically valid analysis and related outputs
Design and Implement Machine learning models using Spark ML and Python/Pyspark
Own end to end implementations of Marketing machine learning models such as Customer Segmentation, Propensity models, CLTV etc.
Create engaging and meaningful data visualizations / power point presentations of findings linked to clear client business impact.
Functional
Lead, manage, mentor and train a team of 10+ Data Scientists to implement the organizations vision and the roadmap with the help of the team members
Provide thought leadership to improve existing processes and incorporate new processes to help team deliver exceptional analytical solutions
Ensure that your team is engaged and motivated to excel in their roles and are being productively utilized on billable projects
Guide your team to follow all policies and procedures for programming, project documentation and other processes as defined by the organisation
Become proficient with Epsilon data assets
Be an active learner - learn new and state of the art tools, technologies, algorithms and methodologies to be at the edge of data science learnings
Collaborate well with cross-functional internal teams as needed to drive results
Qualifications
Bachelor’s degree, or higher, in a quantitative discipline (e.g., Engineering, Statistics, Economics, Mathematics, Marketing Analytics) or significant relevant coursework
Minimum 10+ years of experience in analytics and data science; marketing analytics experience preferred
Must have experience managing a team of people including their goal / outcome setting, performance management and feedback communication
Strong experience with Python, SQL and Microsoft office packages
Must have hands-on experience with machine learning and statistical techniques like Logistic regression, Decision trees, Random Forest, K-means clustering etc.
Experience in distributed computing using PySpark, comfort with DataBricks and experience in machine learning with Spark / MLlib
Strong analytic thought process and ability to interpret findings
Acute attention to detail (QA/QC)
Excellent verbal and written communication skills and good at developing relationships across cross-functional teams
Highly motivated and collaborative team player with strong interpersonal skills
Effective organization and time management skills
Solid planning, priority setting, and project management skills with experience managing multiple projects and resources concurrently
Passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences
Proven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results
Ability to display data visually, creating powerful presentations which effectively demonstrate the value of analytic deliverables",USD 95K - 158K *
429,Machine Learning Engineer,Coinbase,Remote - India,Mid-level / Intermediate,"At Coinbase, our mission is to increase economic freedom around the world, and we couldn’t do this without hiring the best people. We’re a group of hard-working overachievers who are deeply focused on building the future of finance and Web3 for our users across the globe, whether they’re trading, storing, staking or using crypto. Know those people who always lead the group project? That’s us.
There are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we look for candidates who will thrive in a culture like ours, where we default to trust, embrace feedback, and disrupt ourselves. Second, we expect all employees to commit to our mission-focused approach to our work. Finally, we seek people who are excited to learn about and live crypto, because those are the folks who enjoy the intense moments in our sprint and recharge work culture. We’re a remote-first company looking to hire the absolute best talent all over the world.
Ready to #LiveCrypto? Who you are:
You’ve got positive energy. You’re optimistic about the future and determined to get there. 
You’re never tired of learning. You want to be a pro in bleeding edge tech like DeFi, NFTs, DAOs, and Web 3.0. 
You appreciate direct communication. You’re both an active communicator and an eager listener - because let’s face it, you can’t have one without the other. You’re cool with candid feedback and see every setback as an opportunity to grow.
You can pivot on the fly. Crypto is constantly evolving, so our priorities do, too. What you worked on last month may not be what you work on today, and that excites you. You’re not looking for a boring job.
You have a “can do” attitude. Our teams create high-quality work on quick timelines. Owning a problem doesn’t scare you, but rather empowers you to take 100% responsibility for achieving our mission.
You want to be part of a winning team. We’re stronger together, and you’re a person who embraces being pushed out of your comfort zone.
The mission of the Platform Product Group engineers is to build a trusted, scalable and compliant platform to operate with speed, efficiency and quality. Our teams build and maintain the platforms critical to the existence of Coinbase. There are many teams that make up this group which include Product Foundations (i.e. Identity, Payment, Risk, Proofing & Regulatory, Finhub), Machine Learning, Customer Experience, and Infrastructure.
As a machine learning engineer, you will play a pivotal role in constructing essential infrastructure for the open financial system. This involves harnessing diverse and extensive data sources, including the blockchain, to grant millions of individuals access to cryptocurrency while simultaneously identifying and thwarting malicious entities. Your impact extends beyond safeguarding Coinbase, as you'll have the opportunity to employ machine learning to enhance the overall user experience. This includes imbuing intelligence into recommendations, risk assessment, chatbots, and various other aspects, making our product not only secure but also exceptionally user-friendly.
What you’ll be doing (ie. job duties):
Investigate and harness cutting-edge machine learning methodologies, including deep learning, large language models (LLMs), and graph neural networks, to address diverse challenges throughout the company. These challenges encompass areas such as fraud detection, feed ranking, recommendation systems, targeting, chatbots, and blockchain mining.
Develop and deploy robust, low-maintenance applied machine learning solutions in a production environment.
Create onboarding codelabs, tools, and infrastructure to democratize access to machine learning resources across Coinbase, fostering a culture of widespread ML utilization.
What we look for in you (ie. job requirements):
2+yrs of industry experience as a machine learning and software engineer
Experience building backend systems at scale with a focus on data processing/machine learning/analytics.
Experience with at least one ML model: LLMs, GNN, Deep Learning, Logistic Regression, Gradient Boosting trees, etc. 
Working knowledge in one or more of the following: data mining, information retrieval, advanced statistics or natural language processing, computer vision.
Exhibit our core cultural values: add positive energy, communicate clearly, be curious, and be a builder.
Nice to haves:
BS, MS, PhD degree in Computer Science, Machine Learning, Data Mining, Statistics, or related technical field.
Knowledge of Apache Airflow, Spark, Flink, Kafka/Kinesis, Snowflake, Hadoop, Hive.
Experience with Python.
Experience with model interpretability, responsible AI.
Experience with data analysis and visualization.
P54320
Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law.  For US applicants, you may view Pay Transparency, Employee Rights and Know Your Rights notices by clicking on their corresponding links.  Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. 
Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please complete this intake form to let us know the nature of your request and your contact information.  For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).
Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.    
 ",USD 106K - 204K *
430,Sr Machine Learning Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
As a Sr. ML Engineer, you will contribute to features and products by improving the quality of our data processes, data storage, and data pipelines. You will be collaborating with other teams of data scientists, engineers, designers, product teams, and business stakeholders. The ideal candidate will have a desire to learn with a collaborative mindset. This position reports to the Lead Data Engineer, Employee Workflows Data Science.
What you get to do in this role:
Working with Data Science and the Advanced Technology Group (ATG) teams to accelerate production and deployment times for ML services.
Deployment and documentation of Java and Python APIs.
ETL of data structures on MySQL.
Designing DAG-based workflow frameworks for deploying and running APIs.
Responsible for designing AB rollouts, logging, and encouraging best practices for deploying.
Creating and maintaining data pipelines from various sources.
Syncing data between applications, databases, logs, and other places.
Implementing ETL and preprocessing data pipelines with a preference for automation.
Remotely collaborate with a geographically distributed team and be willing to pitch in to perform other tasks when you see such opportunities.
Qualifications
To be successful in this role you have:
5+ years of experience as an ML Engineer.
Very familiar with putting Python and Java scripts into cloud deployments. Additional experience with machine learning frameworks and applications preferred.
SQL, data warehousing, and ETL pipeline tool experience.
Hands on experience with building a modern data stack with AWS. (Step functions, Containers, ECS, Fargate, Redshift, Lambda, Glue, Batch, etc)
Familiar with devops, CI/CD and using gitlab to collaborate in an Agile environment. Terraform experience a plus.
Cloud computing and cloud database experience, preferably with AWS (Redshift, S3, ECS, Sagemaker, Lambda, Pipeline, etc).
Experience working with agile development teams.
Communication. Excellent oral and written communication skills.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 150K - 230K *
431,Sr. Enterprise Data Analyst,ACA Group,"Pune, MH, IN, 411057",Senior-level / Expert,"Senior Enterprise Data Analyst :
Responsibilities:
Data Modeling and Development:
Design, develop, and maintain Analysis Services tabular models (SSAS).
Create efficient data structures to support complex reporting and analysis.
Implement calculated measures, hierarchies, and KPIs.
Understand existing power BI datasets and logic and provide ways to improve and simplify the data modelling via Analysis Services.
Excellent understanding and proven experience with Analysis services roles and implementation of complex data security scenarios.
Data Integration and ETL:
Extract, transform, and load data from various sources into SSAS.
Collaborate with ETL developers to ensure seamless data flow.
Optimize data processing for performance and scalability.
Report Development:
Build interactive dashboards and reports using SSAS cubes.
Customize report layouts and visualizations.
Collaborate with business users to gather requirements and refine reports.
Proven experience of effectively using SSAS cubes with Power BI implementation along with Excel implementation.
Performance Tuning and Troubleshooting:
Monitor SSAS performance and identify bottlenecks.
Optimize query performance and cube processing times.
Investigate and resolve data-related issues.
Investigate data access related issues.
Documentation and Training:
Document SSAS models, data lineage, and best practices.
Provide training to end-users on SSAS usage and self-service reporting.
To qualify for the role you must have:
Bachelor’s degree in Computer Science, Information Systems, or related field.
Minimum of 6 years of experience as an SSAS Developer role.
Proficiency in SSAS tabular models.
Strong SQL skills for data extraction and transformation.
Excellent problem-solving and analytical abilities.
Knowledge of data warehouse concepts and data governance.
  Preferred Skills:
Certification in Power BI and Azure administration (e.g., Microsoft Certified: Data Analyst Associate, Azure Administrator Associate).
What working at ACA offers:
We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. Our Total Rewards package includes medical coverage fully funded by ACA for employees and their family as well as access to Maternity & Fertility and Wellness programs. ACA also provides Personal Accident Insurance, Group Term Life Insurance, Employee Discount programs and Employee Resource Groups. You’ll be granted time off for designated ACA Paid Holidays, Privilege Leave, Casual/Sick Leave, and other leaves of absence to support your physical, financial and emotional well-being.
 About ACA:
ACA Group is the leading governance, risk, and compliance (GRC) advisor in financial services. We empower our clients to reimagine GRC and protect and grow their business. Our innovative approach integrates consulting, managed services, and our ComplianceAlpha® technology platform with the specialized expertise of former regulators and practitioners and our deep understanding of the global regulatory landscape.
What we commit to:
ACA is firmly committed to a policy of nondiscrimination, which applies to recruiting, hiring, placement, promotions, training, discipline, terminations, layoffs, transfers, leaves of absence, compensation and all other terms and conditions of employment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected status.
 ",USD 92K - 144K *
432,Business Intelligence Engineer II,SIXT,"Bengaluru, India",Mid-level / Intermediate,"Job Description
Responsibilities:
Should be self-sufficient to complete e2e ETL task.
Should be self-sufficient in Technical Documentation and version controlling.
Should be self-sufficient in completing Complicated BI reporting requirement.
Take ownership of different BI requirements coming from certain Line of Business.
Grow in-depth Data Knowledge very quickly.
Produce Business In-sights and produce value added suggestions.
Understand Data Gaps and take initiative to full fill the same.
Work closely with Business and should be able to complete Ad-hoc business analysis.
Should be self-sufficient to complete User story decomposition and logical grouping of task.
Should be self-sufficient in Bug Fixing and subsequent stakeholder communication.
Should be self-sufficient in multiple stakeholder handling.
Qualifications
Must have :- 
Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.
Good knowledge on AWS, or any other cloud platform.
Excellent SQL knowledge
Knowledge on Visualization/Dashboarding tools like- Quicksight,Tableau,Google Lookup etc
Good to have knowledge about python
Good knowledge about:
AWS GLUE
Athena
Redshift
AWS IAM
S3
EC2 
Hands on experience with Version controlling (Git)
Good Understanding about BI work flow and reporting. (some idea about how reporting tools works)
Additional Information
Why Choose Sixt?
SIXT is the company with legacy of more than a century offering healthy work environment, friendly work culture and continuous learning. The leadership here believes in team empowerment and challenging opportunities are offered to solve real world problems.
#LI-India
About the department:
Engineers take note: cutting edge technology is waiting for you! We don't buy, we primarily do it all ourselves: all core systems, whether in the area of car sharing, car rental, ride hailing and much more, are developed and operated by SIXT itself. Our technical scope ranges from cloud and on-site operations through agile software development. We rely on state-of-the-art frameworks and architectures and strive for a long-term technical approach. Exciting? Then apply now!
About us:
We are a leading global mobility service provider with sales of €3.07 billion and around 7,500 employees worldwide. Our mobility platform ONE combines our products SIXT rent (car rental), SIXT share (car sharing), SIXT ride (cab, driver and chauffeur services), SIXT+ (car subscription) and gives our customers access to our fleet of 270,894 vehicles, the services of 1,500 cooperation partners and around 1.5 million drivers worldwide. Together with our franchise partners, we are present in more than 110 countries at 2,098 rental stations. At SIXT, a first-class customer experience and outstanding customer service are our top priorities. We focus on true entrepreneurship and long-term stability and align our corporate strategy with foresight. Want to take off with us and revolutionize the world of mobility? Apply now!",USD 47K - 165K *
433,"Staff Data Scientist (7Yrs to 9Yrs, TensorFlow , Python , Bigdata)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Payments are a very exciting and fast-developing area with a lot of new and innovative ideas coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation. VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area. 
If you want to be in the exciting payment space, learn fast and make big impacts, Ecosystem & Operation Risk technology which is part of Visa’s Value-Added Services business unit is an ideal place for you! 
In Ecosystem & Operation Risk group, Payment Fraud Disruption team is responsible for building critical risk and fraud detection and prevention applications and services at Visa. This includes idea generation, architecture, design, development, and testing of products, applications, and services that provide Visa clients with solutions to detect, prevent, and mitigate fraud for Visa and Visa client payment systems. 
This position is ideal for an experienced data scientist who is passionate about collaborating with business and technology partners in solving challenging fraud prevention problems. You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa’s payment systems.  
The right candidate will possess strong ML and Data Science background, with demonstrated experience in building, training, implementing and optimized advanced AI models for payments, risk or fraud prevention products that created business value and delivered impact within the payments or payments risk domain or have experience building AI/ML solutions for similar industries.  
A successful candidate is a technical leader with the ability to engage in high bandwidth conversations with business and technology partners and be able to think broadly about Visa’s business and drive solutions that will enhance the safety and integrity of Visa’s payment ecosystem. The candidate will help deliver innovative insights to Visa's strategic products and business. This role represents an exciting opportunity to make key contributions to strategic offering for Visa. This candidate needs to have strong academic track record and be able to demonstrate excellent software engineering skills. The candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and excellent collaboration skills. 
The ideal candidate will bring the excitement and passion to leverage Generative AI to advance existing fraud detection mechanisms and to innovate and solve new fraud use cases. This engineer will use code generation capabilities like GitHub copilot to drive efficiencies in software development. 
 Essential Functions 
As a Data Scientist you will help design, enhance, and build next generation fraud detection solutions in an agile development environment. 
Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product stakeholders.  
Work with software engineers to ensure feasibility of solutions. Deliver prototypes and production code based on need. 
Experiment with in-house and third-party data sets to test hypotheses on relevance and value of data to business problems. 
Build needed data transformations on structured and un-structured data. 
Build and experiment with modeling and scoring algorithms. This includes development of custom algorithms as well as use of packaged tools based on machine learning, data mining and statistical techniques. 
Devise and implement methods for adaptive learning with controls on effectiveness, methods for explaining model decisions where necessary, model validation, A/B testing of models. 
Devise and implement methods for efficiently monitoring model effectiveness and performance in production. 
Devise and implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production. 
Contribute to development and adoption of shared predictive analytics infrastructure.  
Mentor and train other data scientists on the team on key solutions 
Able to work on multiple projects and initiatives with different/competing timelines and demands. 
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner 
Collaborate across engineering teams and leaders in Ecosystem& Operational Risk, Visa Research, AI Platform, Operations, and Infrastructure (O&I), security and platform teams. 
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Relevant coursework in modeling techniques such as logistic regression, Naïve Bayes, SVM, decision trees, or neural networks
Expert in leading-edge areas such as Machine Learning, Deep Learning, Stream Computing and MLOps
Ability to program in one or more scripting languages such as Perl or Python and programming languages such as Java or Scala
Excellent understanding of algorithms and data structures.
Excellent analytic and problem-solving capability combined with ambition to solve real-world problems
Excellent interpersonal, facilitation, and effective communication skills (both written and verbal) and the ability to present complex ideas in a clear, concise way
Have great work ethics, and be a team player striving to bring the best results as a team
High level of competence in Python, Scala, and Unix/Linux scripts
Extensive experience with SAS/SQL/Hive for extracting and aggregating data
Experience working with large datasets using tools like Pig or Hive is a plus
Experience with Big Data and analytics leveraging technologies like Hadoop, Spark, Scala, and MapReduce
Deep learning experience working with TensorFlow is necessary
Experience with Natural Language Processing is necessary
Passionate about delivering zero defect code that meet or exceed the proposed defect SLA and have high sense of accountability for quality and timeliness of one’s own deliverables and team deliverables
Be systematic and be able to do deep research wanting to uncover the details
Have good work ethics, and be a team player to bring the best results as a team
You have the passion to understand people and always strive to improve our products
Highly driven, resourceful and results oriented
Demonstrated ability to lead and navigate through ambiguity
While you'll have the skill to see and understand the big picture, you're able to stay focused on the task at hand to achieve immediate goals

Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science, Operations Research, Statistics, or highly quantitative field (or equivalent experience) with strength in Deep Learning, Machine Learning, Data Mining, Statistical or other mathematical analysis
Real world experience using Hadoop and the related query engines (Hive / Impala)
Experience with one or more common statistical tools such SAS, R, KNIME, Matlab
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences is a plus
Experience with data visualization and business intelligence tools like Tableau
Modeling experience in card industry or financial service company using for fraud, credit risk, payments is plus
Proficiency in designing & solving classification/prediction problems using open-source libraries such as Scikit learn
Experience in developing large scale, enterprise class distributed systems of high availability, low latency, & strong data consistency
Experience developing instrumentation for software components, to help facilitate real-time and remote troubleshooting/performance monitoring
Experience in architecting solutions with Continuous Integration and Continuous Delivery in mind
Familiarity with in distributed in-memory computing technologies
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 135K - 205K *
434,Data Engineer,3Pillar Global,India,Senior-level / Expert,"We are Chenoa, a 3PILLAR GLOBAL company.

We build breakthrough software products that power digital businesses. We are an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders in Software and SaaS, Media and Publishing, Information Services, and Retail.
 Our key differentiator is our Product Mindset. Our development teams focus on building for outcomes and all of our team members around the globe are trained on the Product Mindset’s core values – Minimize Time to Value, Solve For Need, and Excel at Change. Our teams apply this mindset to build digital products that are customer-facing and revenue-generating. Our business-minded approach to agile development ensures that we align to client goals from the earliest conceptual stages through market launch and beyond.

In 2023, 3Pillar Global India was named as a “Great Place to Work” for the sixth year in a row based on how our employees feel about our company, collaborative culture, and work/life balance - come join our growing team.

Job Description:
 We are looking for a Data Engineer to be part of the product engineering team with one of our esteemed client based out of Mumbai.
The candidate should have 4-6 years of experience in PySpark, Scala and SQL.
Technical Requirement
Good experience in writing data extraction logic in Pyspark / Scala / SQL
Good experience in cleaning of data in Pyspark / Scala and SQL.
Experience in Data ingestion, transformation and performance tuning.
Running queries for transformations.
Handling large and complex dataset like CSV/parquet files from various sources.
Fixing of bugs in ETL pipeline.
Testing and data validation of different modules of projects.
Experience in applying multiple performance tuning technique to get Faster results in Pyspark  / Scala.
Good understanding of Snowflake, Azure services ADF, Azure Blob Storage etc.

Desired Skill Set
Strong decision-making skills, and the ability to drive a plan to completion.
Ability to work flexible hours as required by business priorities.
Strong verbal and written communication skills, and customer service.
Advanced analytical and creative skills demonstrate resourcefulness in problem solving and optimization of design.
Ability to communicate information and issues clearly and succinctly with both technical and non-technical personnel.
Willing to learn new technologies and adapt.
Benefits
A competitive annual salary based on experience and market demands
Flexi-timings
Medical insurance with the option to purchase a premium plan or HSA option for your entire family
Recreational activities
 Business casual atmosphere
#LI-Remote
#LI-PRACHISHARMA",USD 121K - 186K *
435,Senior Gen-AI Data Scientist,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
The ideal candidate will have a strong background in artificial intelligence, machine learning, natural language processing, deep learning, image recognition, and computer vision, with the ability to apply all these skills, in service of creating Innovative and Immersive Experiences, that leverage AI and Gen-AI, to revolutionize how brands engage with consumers.
• You should have deep hands-on experience with large language models (LLMs) and other generative AI techniques.
• You will be responsible for fine-tuning existing Foundation Models, and adapting existing base ML models.
• More importantly, you will also be responsible for coding, training, evaluating, and deploying net-new custom ML models using large datasets, helping create custom AI models for specific use cases, for different dentsu clients and brands.
• You must have deep experience of developing and implementing cutting-edge generative AI models and algorithms using state-of-the-art techniques such as GPT, VAE, and GANs.
• You must have deep technical experience working with technologies related to multimodal AI, covering text, media, image, video, audio and speech.
• Your role will also involve optimizing existing models for improved performance, scalability, and efficiency.
• You will be responsible for hands-on development in Python and PyTorch, across a variety of AI / ML frameworks, AI Cloud Services, and Gen-AI platforms, including enterprise Gen-AI tech, open-source Gen-AI tech and SaaS Gen-AI tech.
Responsibilities:
•Collaborate with client teams and stakeholders to understand their requirements and devise Gen AI models to meet these needs.
•Design, develop, and deploy custom ML models for Gen-AI solutions
•Implement MLOps to automate the deployment, monitoring, and maintenance of ML models.
•Hands-on coding to develop AI / ML solutions from scratch
•Build end-to-end data pipelines to manage data collection, extraction, pre-processing, cleansing, transformation, processing, and use inside custom built Gen-AI models
•Stay informed about the latest advancements in Gen AI, machine learning, and AI technologies to optimize our technical stack.
•Have solid knowledge and exposure across Enterprise Gen-AI Platforms and Solutions, as well as Third-party SaaS and Open Source tech leaders / providers in the Gen-AI space
•Work through the complete lifecycle of Gen AI model development, from training and testing to deployment and performance monitoring.
•Lead R&D initiatives involving Gen-AI Platforms and Services, Large Language Models and existing generative AI systems
Qualifications
Key Requirements
•8+ years of overall experience in technology.
•Minimum 5+ years of overall experience in AL and ML solutions development.
•Bachelors degree in computer science, AI, Machine Learning, or related field.
•Solid understanding of Generative AI, Machine Learning, and Deep Learning algorithms, Software engineering principles
•Super hands-on with ML programming languages such as Python
•Experience with related machine learning platforms, libraries and frameworks like PyTorch, PySpark, TensorFlow, Keras, or similar with CUDA
•Experience with natural language processing (NLP) patterns such as Text representation, Embeddings, Language Modelling, and Semantic understanding
•Experience with libraries such as SpaCy, NLTK, or Stanford CoreNLP
•Experience with large language models such as GPT-4, Google PalM-2, and nVidia NeMO.
•Experience with Vector Databases for custom data and retrieval
•Strong Proficiency in AI Orchestration frameworks such as Langchain and/or Microsoft Semantic Kernel
•Prompt Engineering for implementing large language models
•Strong Proficiency in at least 1 major Cloud AI Platform / Service, and all of their primary AI services and solutions, across Azure, AWS, and Google Cloud.
•Strong Proficiency in working with an AI Cloud Service such as Azure Machine Learning, AWS Sagemaker, or Google Vertex-AI
•Strong Proficiency in being able to code and deploy custom AI / ML models on top of AI Cloud platforms such as Azure OpenAI, AWS Sagemaker/Bedrock
•Experience with and exposure to nVidia AI Cloud Foundation Service, nVidia NeMo LLM frameworks, nVidia Picasso, and other nVidia services / solutions, highly desirable
•Exceptional problem-solving skills and an innovative mindset.",USD 135K - 205K *
436,Data Analyst,JLL,Home Office - India,Entry-level / Junior,"Data Analyst
JLL Technology COE
What this job involves:
About the role
#JLLTechAmbitions
LaSalle Investment Management is a wholly-owned subsidiary of JLL
Technology, Data & Information Management Centre of Expertise (TDIM CoE) (Bangalore)
If you live and breathe digital, we want to offer you a super challenging and exciting role in LaSalle’s Digital Transformation Team. Imagine using digital technologies to disrupt the real estate investment industry.
Our job in LaSalle’s Digital Transformation Team is to be brave and accelerate the impact of digital transformation by partnering closely with our business units, we prototype ideas, test them in the real business scenarios, and quickly adapt the solution. Combining data science, human-centered design, and the latest rapid development techniques—such as agile, microservices and DevOps—we help deliver breakthrough products, experiences, and businesses. 
For our Digital Transformation, we are building a LaSalle’s Digital Experience (LDX) Platform on Azure. The LDX platform will be powered by multiple COTS/Custom Build applications and unified data and content platforms. We are setting up Digital Engineering Hub in Bangalore to support the global implementation of LaSalle’s Digital Transformation Program.   
Responsibilities
Seeking expertise in reading, speaking, and writing simplified Chinese ( Mandarin language )
Proficient in handling Rent Roll Reports, AR Reports, and Trial Balance preparations.
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets. Filter and “clean” data by reviewing reports and performance indicators to locate and correct data source problems
Identify opportunities for data improvement: whether there's a data point missing, queries that are running slowly, or metrics that don't look quite right, and share new ideas/suggestions
Support the design, implement and support data warehousing projects, implements business rules via stored procedures, middleware or other technologies and defines user interfaces
Verify the accuracy of data and maintain and support the data warehouse activities
Support, plan and conduct data warehouse unit system tests, monitors and takes corrective action as needed
Support the build and maintain data warehouse databases, designs, codes, tests and implements complex programs, and scripts
Build key data sets to empower operational and exploratory analysis. Monitoring key metrics, understanding root causes of changes in metrics
Identify and analyze potential data sources which will improve the consistency, timeliness and/or completeness of our data sets
Sounds like you? To apply you need to be:
Experience & Education
At least 2 years of experience in Operational/IT/Finance Data Management Function
Experience working in Investment Banking / Finance / Insurance / Services Industry / Real Estate Industry Preferred
Strong expertise in assisting in delivering well-organized reports, dashboards, data analysis, and statistical models - Devise key metrics with clients and leverage knowledge of data preparation activities such as extraction, cleansing, aggregation, and data analysis to deliver on internal/client requirements
Superb written and verbal skills, ability to communicate technical and non-technical aspects
Bachelor’s degree in an Engineering / Science / Commerce discipline. Advanced degree preferred.
Technical Skills & Competencies
Proficiency working with Microsoft Office, including Excel
Preferred with ability to read and understand at least one programming language (i.e. Python, .net, Java, VBA, etc.)
Preferred with experience with SQL or other relational databases
Fluency in reading, speaking, and writing simplified Chinese (Mandarin language).
Strong expertise with a quantitative aptitude and ability to perform market analysis
What we can do for you:
At JLL, we make sure that you become the best version of yourself by helping you realize your full potential in a fully entrepreneurial and inclusive work environment. If you harbour a passion for learning and adapting new technologies, JLL will continuously provide you with platforms to enrich your technical domains.  We will empower your ambitions through our dedicated Total Rewards Program, competitive pay, and benefits package. It’s no surprise that JLL has been recognized by the Ethisphere Institute as one of the 2019 World’s Most Ethical Companies for the 12th consecutive year.
LaSalle Investment Management (“LaSalle”) is a global real estate investment manager with $66 billion of private and public real estate assets under management and over 750 people in 17 countries and 24 offices worldwide.  Our diverse investor base includes public and private pension funds, insurance companies, governments, endowments and high net worth investors from across the globe.  LaSalle sponsors private separate accounts, private open and closed-end commingled funds, and public real estate securities programs.  As a wholly-owned member of the Jones Lang LaSalle group, LaSalle's investment teams also draw on the intelligence and resources of our parent company, giving us unique access to market opportunities and key industry leaders.
Apply today!
Location:
Hybrid (inactive) –Bengaluru, KA
Job Tags:
If this job description resonates with you, we encourage you to apply, even if you don’t meet all the requirements.  We’re interested in getting to know you and what you bring to the table!
About JLL –
For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500® company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com.
JLL Privacy Notice
Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.
For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.
For additional details please see our career site pages for each country.
For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here.
Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities.  If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process –  you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",USD 56K - 94K *
437,Data Engineer - Glide,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:   
ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.
We’re disruptive. We work hard but try not to take ourselves too seriously. We are highly adaptable and constantly evolving. We are passionate about our product, and we live for our customers. We have high expectations and a career at ServiceNow means challenging yourself to always be better.
What you get to do in this role:
We are building a modern Data Platform for AI at ServiceNow. This platform will evolve to address various data needs from AI practitioners, both from teams inside of ServiceNow and from end customers of ServiceNow. We are in the early phase of defining and developing this platform and the vision is to grow into a comprehensive platform that addresses 
AI development (by the Advanced Technology Group and the various Business Units within ServiceNow)
Production solutions - to build/tune AI solutions based on customer specific data.
End customers - to enable customers to effectively build their own AI solutions.
This is a strategic initiative at ServiceNow and it will have a significant impact in accelerating AI solution development on the ServiceNow platform.
We are in the early stages of this journey and are looking for Technical leadership to drive various aspects of the Data Platform. Significant areas of responsibility are listed below. The expectation is to independently pursue these open-ended areas, investigate, propose, design and implement ideal solutions for ServiceNow. We are looking for strong technical leads who can conceive and develop new systems and lead the evolution of the Solution Architecture with a strong business focus.
Core Data Platform  & Interfaces for data – 
Explore Open Table formats (delta-lake, Apache Iceberg, Apache Hudi) & execution engines (spark SQL / trino),  
Expose suitable Data models and APIs for Data.
Data Pipelines – Data Extraction improvements. Optimized data pipelines. Orchestration of pipelines. 
Governance/Security/Auditing – Establish data governance and security policies as per requirements. End to end security, governance, access control, audit etc.
Drive large features all the way from design to implementation.
Due diligence with respect to functional and test coverage is a given.
Data Catalog/Data Discovery & Lineage
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.
 Qualifications
To be successful in this role you have:
Significant exposure to Data engineering.
Bachelor's degrees in Computer Science or Computer Engineering
2+ Years of experience typically.
Strong experience in Data Engineering & Big Data technologies. Building robust and resilient data pipelines, Data modeling (Dimensional etc.) for Analytic workloads.
Ability to learn and work with multiple technologies in a fast paced environment, to effectively build large scale end-end Analytics solutions.
Expertise in Glide, SQL, PLSQL, Java, Python, Performance tuning to build effective large scale systems is a must. Versatility in using various programming languages, tools and frameworks with effective judgement and focus on the eventual end-end solution is required.
Good understanding of Cloud architecture, security, networking, monitoring and deployments
Hands on experience on any one cloud – AWS, Azure, Google or Oracle is desired. Experience building scalable, highly available and secure distributed multi-tiered systems experience with relational databases
Good knowledge in Rest API development and usage is desirable.
Strong communication and interpersonal skills
Knowledge/experience with data-science techniques is desirable.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 121K - 186K *
438,Data Engineer,Verisk,"Delhi, India",Senior-level / Expert,"Company Description
Wood Mackenzie are the global research, analytics, and consultancy business powering the natural resources industry. For 50 years, we have been providing the quality data, analytics, and insights our customers rely on to inspire their decision making.
Our dedicated oil, gas & LNG, power & renewables, chemicals, metals & mining sector teams are located around the world and deliver a variety of projects based on our assessment and valuation of thousands of individual assets, companies, and economic indicators such as market supply, demand, and price trends.
We have over 1,900 employees in 30 locations, serving customers in nearly 80 countries. Together, we inspire and innovate the markets we serve – providing invaluable intelligence to help our customers overcome the toughest challenges, and make strategic decisions that will, ultimately, accelerate the world’s transition to a more sustainable future.
WoodMac.com
Wood Mackenzie brand video
Job Description
We are seeking a Data Engineer to contribute to our technology strategy in order to deliver the best possible software for our customers. The successful candidate will have informed opinions on technologies, frameworks and approaches to delivery. They must be able to articulate their ideas effectively and strive to constantly improve deliverables. They will have worked in a data centric environment previously and understand the challenges of managing multiple streams of data and ensuring data integrity at all stages. An advocate of cloud technologies and approaches, they will work within an engineering scrum team, tasked with building a data platform to ingest, process and publish our data, both internally and externally. The ultimate objective of this team is to move from manual processes to fully automated data pipelines. 
The successful candidate will be adept at quickly forming strong working relationships with colleagues within the technology and research functions, ensuring a high level of team morale.
Main Responsibilities
Working as part of a team on one or more projects within the Wood Mackenzie portfolio to ensure adherence to best practices
Build and contribute to the data architecture for new systems based on architectural blueprints with performance, scalability and maintenance in mind
Contribute to technology best practices and standards within the data space
Contribute to the resolution of any technical issues blocking progress
Promote a culture of shared code ownership, and actively participate in code reviews
Partner with different business stakeholders within Research, Product Management and Operations, working towards the delivery of strategic goals
Qualifications
About You
Proven experience in at least one major language (Java, Python, JavaScript, .NET)
Experience of automating data ingestion, cleansing and publishing
Proven experience of working with Relational and NoSQL Database systems
Proven experience of building scalable APIs to deliver both data and content
Understanding of continuous delivery and approaches to continuous integration
Strong knowledge of security and performance concerns
Expectations
Excellent problem solving, and analysis skills coupled with great communication skills
Strong organization and planning skills, with the ability to manage multiple priorities simultaneously
A strong attention to detail
Commitment to excellence and meeting high quality standards expected by our clients
Experience in working in different delivery methodologies and an understanding of their benefits/constraints
We are a hybrid working company and the successful applicant will be expected to be physically present in the office at least 2 days per week to foster and contribute to a collaborative environment, but this may be subject to change in the future.
Due to the global nature of the team, a degree of flexible working will be required to accommodate different time zones.
Additional Information
WoodMackenzie is an equal opportunities employer.
We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran’s status, age or disability.
https://www.woodmac.com/careers/jobs/
Unsolicited resumes sent to WoodMackenzie, including unsolicited resumes sent to a WoodMackenzie business mailing address, fax machine or email address, or directly to WoodMackenzie employees, will be considered WoodMackenzie property. WoodMackenzie will not pay a fee for any placement resulting from the receipt of unsolicited resume.
Consumer Privacy Notice
#LI-DA1",USD 110K - 181K *
439,"Data Architect, Data Pole",Renault Group,IN REN RNTBCI CHENNAI,Senior-level / Expert,"Company
RNTBCI PL
Job Description
JOB DESCRIPTION
Responsibility for project content
Design and implement the organization's data architecture, including the data models, data flow diagrams, and data dictionaries.
Develop and maintain the organization's data strategy, including data governance, data quality, and data security policies and procedures.
Collaborate with business analysts, developers, and other stakeholders to understand the organization's data needs and requirements.
Develop and maintain data-related standards and best practices, including data modelling, data integration, and data warehousing.
Develop and implement data migration strategies to ensure the smooth transition of data between systems.
Ensure the quality and integrity of the data, including the implementation of data validation and quality control processes.
Provide guidance and support to developers and other stakeholders on data-related issues.
Ensure compliance with data privacy regulations, such as GDPR and other regional definitions
Skill
Experience with cloud-based data management solutions, such as AWS/ GCP.
Experience with Data Transformation tool such as Talend/Snowflake.
Experience with data science and machine learning tools and techniques.
Experience with data analytics and business intelligence tools.
Job Family
Information Technologies & Systems
Renault Group is committed to creating an inclusive working environment and the conditions for each of us to bring their passion, perform to the full and grow, whilst being themselves.  
We find strength in our diversity and we are engaged to ensure equal employment opportunities regardless of race, colour, ancestry, religion, gender, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, etc. If you have a disability or special need requiring layout of the workstation or work schedule, please let us know by completing this form.
In order to follow in real time the evolution of your applications and to stay in touch with us, we invite you to create a candidate account. This will take you no more than a minute and will also make it easier for you to apply in the future.
By submitting your CV or application, you authorise Renault Group to use and store information about you for the purposes of following up your application or future employment. This information will only be used by Renault Group companies as described in the Group Privacy Policy.",USD 117K - 193K *
440,Senior Data Scientist,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
As part of the EWF Data Science team, you will contribute to features and products by improving the quality of our algorithms and data processes. You will be collaborating with other teams of engineers, designers, product teams, and business stakeholders. The ideal candidate will have a desire to learn with a collaborative mindset. In addition to supporting the expansion of our intelligence solutions, this role will support specific projects related to Generative AI, and reports to the Sr. Manager, Data Science, Employee Workflows.
What you get to do in this role:
 Exploring data and providing reports, metrics, and summaries for projects and teammates.
Developing new algorithms (and working on existing algorithms) for product and feature needs.
Building tools and documentation for ETL, with a preference for automation.
Creating models for NLP algorithms such as named entity extraction, classification, segmentation, and parsing.
Searching and processing large datasets for actionable and usable information.
Create and maintain data structures to facilitate ease of use and accessibility.
Provide guidance and mentoring for more junior data scientists on the team.
Develop data engineering components to enhance product features and data pipelines.
Support and advise product teams on best practices regarding LLM usage and GenAI technologies. Specifically geared towards NLP use cases.
Develop ML models for prediction and/or classification using available data.
Use LLM technologies for projects and provide technical assistance for others regarding LLM and GenAI usage.
Develop intelligent processing pipelines to help with alerting/anomaly detection.
Lead complex and technically challenging projects from concept to completion, including specific projects to advance the Employee Workflows product roadmap.
Take initiative to identify project stakeholders, reach out for requirement clarifications, and communicate changes/objectives/results across teams in a comprehensible way.
Remotely collaborate with a geographically distributed team and be willing to pitch in to perform other tasks when you see such opportunities.
Qualifications
To be successful in this role you have:
6+ years of relevant experience.
Experience functioning as a technical mentor and subject matter expert among team.
Proficient programming and scripting skills in Python/SQL/git/Regex.
Extensive experience with machine learning and text processing libraries, such as TensorFlow, PyTorch, Gensim, Scikit-Learn, Numpy, Scipy, Pandas, etc.
Motivated to work in cutting edge NLP and GenAI algorithms.
Experience with development on a cloud platform (AWS experience preferred).
Highly analytical and data driven mindset.
Experience in using GPUs to train deep learning models with project experience with LLMs.
Strong understanding of large language models (LLM) and prompting approaches.
Experience working with technical and statistical problems and communicating the results to a non-technical audience.
Outcomes-driven, smart, hard-working, and a great team player.
Creative and apply your vision to problem solving.
Strong organizational judgment and problem-solving.
Developed collaborative interpersonal communication skills, including verbal, written and listening communications.
Strong educational background (Masters, but PhD-preferred) in a quantitative discipline.
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 135K - 205K *
441,Staff Machine Learning Engineer,Coinbase,Remote - India,Senior-level / Expert,"At Coinbase, our mission is to increase economic freedom around the world, and we couldn’t do this without hiring the best people. We’re a group of hard-working overachievers who are deeply focused on building the future of finance and Web3 for our users across the globe, whether they’re trading, storing, staking or using crypto. Know those people who always lead the group project? That’s us.
There are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we look for candidates who will thrive in a culture like ours, where we default to trust, embrace feedback, and disrupt ourselves. Second, we expect all employees to commit to our mission-focused approach to our work. Finally, we seek people who are excited to learn about and live crypto, because those are the folks who enjoy the intense moments in our sprint and recharge work culture. We’re a remote-first company looking to hire the absolute best talent all over the world.
Ready to #LiveCrypto? Who you are:
You’ve got positive energy. You’re optimistic about the future and determined to get there. 
You’re never tired of learning. You want to be a pro in bleeding edge tech like DeFi, NFTs, DAOs, and Web 3.0. 
You appreciate direct communication. You’re both an active communicator and an eager listener - because let’s face it, you can’t have one without the other. You’re cool with candid feedback and see every setback as an opportunity to grow.
You can pivot on the fly. Crypto is constantly evolving, so our priorities do, too. What you worked on last month may not be what you work on today, and that excites you. You’re not looking for a boring job.
You have a “can do” attitude. Our teams create high-quality work on quick timelines. Owning a problem doesn’t scare you, but rather empowers you to take 100% responsibility for achieving our mission.
You want to be part of a winning team. We’re stronger together, and you’re a person who embraces being pushed out of your comfort zone.
The mission of the Platform Product Group engineers is to build a trusted, scalable and compliant platform to operate with speed, efficiency and quality. Our teams build and maintain the platforms critical to the existence of Coinbase. There are many teams that make up this group which include Product Foundations (i.e. Identity, Payment, Risk, Proofing & Regulatory, Finhub), Machine Learning, Customer Experience, and Infrastructure.
As a Staff Machine Learning Engineer, you will play a pivotal role in constructing essential infrastructure for the open financial system. This involves harnessing diverse and extensive data sources, including the blockchain, to grant millions of individuals access to cryptocurrency while simultaneously identifying and thwarting malicious entities. Your impact extends beyond safeguarding Coinbase, as you'll have the opportunity to employ machine learning to enhance the overall user experience. This includes imbuing intelligence into recommendations, risk assessment, chatbots, and various other aspects, making our product not only secure but also exceptionally user-friendly.
  What you’ll be doing (ie. job duties): 
Investigate and harness cutting-edge machine learning methodologies, including deep learning, large language models (LLMs), and graph neural networks, to address diverse challenges throughout the company. These challenges encompass areas such as fraud detection, feed ranking, recommendation systems, targeting, chatbots, and blockchain mining.
Develop and deploy robust, low-maintenance applied machine learning solutions in a production environment.
Create onboarding codelabs, tools, and infrastructure to democratize access to machine learning resources across Coinbase, fostering a culture of widespread ML utilization.
What we look for in you (ie. job requirements): 
8+yrs of industry experience as a machine learning and software engineer
Experience building backend systems at scale with a focus on data processing/machine learning/analytics.
Experience with at least one ML model: LLMs, GNN, Deep Learning, Logistic Regression, Gradient Boosting trees, etc. 
Exhibit our core cultural values: add positive energy, communicate clearly, be curious, and be a builder.
Nice to haves:
BS, MS, PhD degree in Computer Science, Machine Learning, Data Mining, Statistics, or related technical field.
Knowledge of Apache Airflow, Spark, Flink, Kafka/Kinesis, Snowflake, Hadoop, Hive.
Experience with Python.
Experience with model interpretability, responsible AI.
Experience with data analysis and visualization.
  PID - P54318
Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law.  For US applicants, you may view Pay Transparency, Employee Rights and Know Your Rights notices by clicking on their corresponding links.  Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. 
Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please complete this intake form to let us know the nature of your request and your contact information.  For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).
Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.    
 ",USD 31K - 58K *
442,Principal Machine Learning Engineer,Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
At Zscaler, our AI and Data Science teams focus on various cybersecurity business-centric use cases including threat detection, policy recommendation, malware detection, content classification, anomaly detection, and AIOps (advanced networking diagnosis). As a Principal Engineer, you will have the opportunity to work on multiple fundamental machine learning problems addressing cloud security, cloud operations, and cloud intelligence.

You will be responsible for leading the development and implementation of advanced machine learning models, mentoring junior team members, and driving strategic AI and data science initiatives. You will have a deep understanding of various stages of an end-to-end Machine Learning project and will be capable of translating business problems into data-driven solutions.

Required Skills
8+ years of experience as a Machine Learning Engineer or Data Scientist, with a proven track record of leading and delivering successful projects
Expertise in Python (e.g., pandas, sklearn, pytorch) and SQL
Extensive experience in feature engineering, model evaluation, and error analysis
In-depth knowledge of Large Language Models (LLMs) and their applications
Master's or Ph.D. in Computer Science/Engineering or other technical field; data science concentration is a plus
Strong passion for leveraging ML/AI to solve real-world business problems at scale 
Exceptional interpersonal, technical, and communication skills
Proven ability to learn, evaluate, and adopt new technologies quickly
Solid computer science foundation
Preferred Skills
Experience in prompt engineering and fine-tuning Large Language Models (LLMs)
Expertise in Graph Neural Networks/Knowledge Graphs
Proficiency in unsupervised learning (clustering) and evaluation
Research experience/publications/patents in relevant areas
Familiarity with public cloud services (such as AWS, Google, Azure) and ML automation platforms (such as Kubeflow)
Proficiency in various programming languages such as (Py)Spark
Deep understanding of operating systems and distributed systems
Knowledge of networking and networking security concepts
Responsibilities
Lead the development of advanced machine learning models to address complex business problems
Mentor and guide team members on projects and professional growth
Collaborate with cross-functional teams to define project objectives and deliverables
Design, implement, and evaluate innovative machine learning solutions, ensuring alignment with business objectives
Drive strategic initiatives, identifying opportunities for improvement and innovation
Applied research: Stay up-to-date and apply the latest advancements in machine learning and data science 
Communicate complex data science concepts to non-technical stakeholders and drive data-driven decision-making across the organization
  #LI-AN4
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 45K - 84K *
443,"Associate Director, Data Science",Kyndryl,INDLFCHE CHENNAI - DLF IT PARK,Mid-level / Intermediate,"Who We Are
At Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.

The Role
Years of experience: 10+ years
Roles and responsibilities -  
technical lead of the account, 
responsible for the design, development, and deployment of data solutions to the elevance health account. 
Solutions include Bigfix, Sciencelogic, Cockpit, Tableau, SQL, TOC Portal, AI POCs.
 Application Development: , High priority
Role Overview: Understand the progress of the current Ruby -> Python Django migration. Complete Ruby -> Python Django migration where prior dev has left off. Have application architecture understanding to understand infrastructure + application and make recommendations for future improvements. Receive break/fix issues, triage issues, mitigate issues. Understand and mitigate server, db vulnerabilities. Possible future MySQL migration (to oracle or MS SQL, TBD)
--
Primary Skills: Ruby, Python Django. Application Infrastructure, Maintenance

Who You Are
Years of experience: 10+ years
Roles and responsibilities -  
technical lead of the account, 
responsible for the design, development, and deployment of data solutions to the elevance health account. 
Solutions include Bigfix, Sciencelogic, Cockpit, Tableau, SQL, TOC Portal, AI POCs.
 Application Development: High priority
Role Overview: Understand the progress of the current Ruby -> Python Django migration. Complete Ruby -> Python Django migration where prior dev has left off. Have application architecture understanding to understand infrastructure + application and make recommendations for future improvements. Receive break/fix issues, triage issues, mitigate issues. Understand and mitigate server, db vulnerabilities. Possible future MySQL migration (to oracle or MS SQL, TBD)
--
Primary Skills: Ruby, Python Django. Application Infrastructure, Maintenance

Being You
Diversity is a whole lot more than what we look like or where we come from, it’s how we think and who we are. We welcome people of all cultures, backgrounds, and experiences. But we’re not doing it single-handily: Our Kyndryl Inclusion Networks are only one of many ways we create a workplace where all Kyndryls can find and provide support and advice. This dedication to welcoming everyone into our company means that Kyndryl gives you – and everyone next to you – the ability to bring your whole self to work, individually and collectively, and support the activation of our equitable culture. That’s the Kyndryl Way.

What You Can Expect
With state-of-the-art resources and Fortune 100 clients, every day is an opportunity to innovate, build new capabilities, new relationships, new processes, and new value. Kyndryl cares about your well-being and prides itself on offering benefits that give you choice, reflect the diversity of our employees and support you and your family through the moments that matter – wherever you are in your life journey. Our employee learning programs give you access to the best learning in the industry to receive certifications, including Microsoft, Google, Amazon, Skillsoft, and many more. Through our company-wide volunteering and giving platform, you can donate, start fundraisers, volunteer, and search over 2 million non-profit organizations.  At Kyndryl, we invest heavily in you, we want you to succeed so that together, we will all succeed.
Get Referred!
If you know someone that works at Kyndryl, when asked ‘How Did You Hear About Us’ during the application process, select ‘Employee Referral’ and enter your contact's Kyndryl email address.",USD 110K - 168K *
444,Business Development Manager (Contract/Telcom Services/Mumbai),PCCW,"Mumbai, MH, IN",Senior-level / Expert,"PCCW Global is a leading telecommunications provider, offering the latest voice and data solutions to multi-national enterprises and communication service providers. Our truly global coverage combined with local, on the ground knowledge has helped us build best in class connections across the globe linking Asia-Pacific, Europe, the Americas, the Middle East and Africa.
Connecting networks, clouds and businesses, Console Connect by PCCW Global is dedicated to helping organisations overcome the barriers and complexity of connecting to the cloud. Our goal is to provide businesses with on-demand, dedicated connectivity into cloud service providers and partners around the globe, making access to business-critical applications simple, predictable and ultra-secure.
Console Connect by PCCW Global is the world’s first global software-defined interconnection platform, born out of the belief that business connectivity should be simpler and more accessible for all. Console Connect enables users to efficiently manage their private connections via a user-friendly interface, regardless of their level of technical expertise.
Backed by PCCW Global, one of the world’s leading telecommunications groups with a tier 1 global IP network, Console Connect is completely scalable and offers maximum resilience and reliability, leaving you confident and secure in your cloud connections.
  Role Overview
We are looking for an energetic Business Development Manager (BDM) to share & present our end-to-end global connectivity and cloud solutions with Telecom Service Providers & customers. You are responsible for managing the existing key Telco accounts & new accounts acquisition in the SAARC region.
  Key Responsibilities 
Achieve the sales target with KPI for your assigned territory annually
Manage existing wholesale businesses and create new accounts targeting MNCs and ICT partners for the cloud transformation businesses
Develop new business and work with strategic partners to expand our global services to meet the customers needed globally
Work diligently with all related parties (eg. Presales, Regional Engagement, trusted partners) to support customer requirements, ensure customer satisfaction and on-time delivery
Maintain good customer relationships with customers/partners from operational level to C level
Work with key customers and decision-makers to create new businesses' cooperation, and enhance global relationships to provide long-standing win-win solutions.
  Requirements 
A minimum of 5-7 years of sales experience in the telecommunication industry
Data center industry, SI & Telco account experience preferred
Relationship management skills and strong solution selling skills, including experience selling to the C-suite
Project management skills (eg. planning, organizing, and coordinating with Project management term to ensure smooth and successful delivery
Computer proficiency with knowledge of Microsoft office (eg, Word, Excel, Outlook, PowerPoint), maintaining records in CRM 
Ability to create new projects and leverage networks & partners for order closing and delivery 
Positive attitude, teamwork and hunter mentality 
Bachelor’s degree in Business or Engineering preferred.
  Experience
Understand Global Data networks (L1 to L3: Internet/IP, IPVPN, and managed CPE), security, and cloud solutions
5-7 years’ sales experience in telecommunication, plus 1-2 years of Cloud Solution Selling experience is preferred.",USD 45K - 84K *
445,"Senior Manager, Clinical Data Management",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.
Functional Area Description
CDM is responsible for integrity, reliability, completeness and quality of clinical trial data and provides end to end clinical data management leadership for trials across the BMS R&D portfolio.
Responsibilities will include, but are not limited to:
Project Management and Leadership
Provides clinical data management leadership within the study team to align on and drive data collection requirements for one or more complex clinical development projects.
Efficiently plans, coordinates, and delivers complete, high quality and reliable clinical trial data in a timely manner for assigned projects.
Responsible for end-to-end clinical data management activities and serves as a primary point of contact for internal and external study team members.
 Provides strong quality and project oversight over third party vendor responsible for data management deliverables.
Takes a leadership role to gather content and integration requirements for EDC and close collaboration with partners supporting other data collection systems (eCOA, External Data, Safety Gateway). Enforces data standard conventions and quality expectations for clinical data per defined processes.
Authors, reviews/revises DM related study plans including Data Quality Management Plan, Data Validation Plans, Data Review Plan, eCRF Completion Guidelines and other study documents to ensure quality and standardization.
Chairs Data Quality Review meetings with cross functional study team members to ensure on-going review of trial data currency, quality, and completeness.
Represents DM on cross-functional project teams & submission Teams.
Lead or support the Health Authority inspections and audits.
Provides coaching and quality oversight of junior Data Management Leads
FSP/CRO/Vendor Oversight
May act as core member of the study team and provides FSP/CRO/Vendor oversight for end-to-end Data Management activities, manages data currency throughout the trial, and overall monitoring DM deliverables according to the Service Level Agreement (SLA).
Continuous improvement initiatives
Provides the relevant support and input to continuous improvement activities within clinical data management.
Provides support for CAPA implementation as required.
#HYDDD
#LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
446,Senior Data Engineer,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
1. Design, build, test, and maintain highly scalable data platforms, ensuring that these systems meet business requirements and industry best practices.
2. Incorporate new data engineering technologies into existing systems, to help move data across systems.
3. Create custom data pipelines and solution components that extract, cleanse, transform, move, and aggregate data across various enterprise systems
4. Identify potential opportunities for data acquisition and explore new uses for existing data.
5. Develop processes and standards for common data models, and data mapping across systems.
6. Use a range of ETL tools, Data integration platforms, and underlying languages and tools to integrate disparate data systems effectively.
7. Leverage data virtualization technologies for data aggregation and unification from multiple, disparate data sources, without the use of any ETL.
8. Recommend ways to improve data reliability, efficiency, and quality.
9. Foster collaboration with data architects, modelers, and IT team members on project goals.
10. Provide technical leadership and consultation on complex projects involving data management, data virtualization, and unification. Qualifications:
11. Bachelor’s/Master’s degree in Computer Science, Data Science, Information Systems, or a related field.
12. Minimum of 5 years of experience in a data engineering role, with a focus on data management and data pipeline construction.
13. Demonstrable experience with data engineering solutions, including data aggregation, data transformation, data movement, and data unification strategies.
14. Proficiency with Data Lakes built on Cloud Services such as Azure and AWS – e.g., ADLS (Azure Data Lake Storage Gen2),
15. Proficiency with cloud platforms, and cloud services, on at least 1 major enterprise cloud (Azure or AWS Cloud)
16. Solid exposure to and experience with data virtualization technologies and platforms, particularly the Denodo platform, is highly preferred.
17. Proficiency with data orchestration services and data workflow platforms – e.g., Apache Airflow, highly preferred.
18. Proficiency in scripting and data intensive languages like SQL, Python, etc.
19. Experience with big data frameworks and associated languages / toolsets is nice-to-have",USD 121K - 186K *
447,Senior Machine Learning Engineer,Coinbase,Remote - India,Senior-level / Expert,"At Coinbase, our mission is to increase economic freedom around the world, and we couldn’t do this without hiring the best people. We’re a group of hard-working overachievers who are deeply focused on building the future of finance and Web3 for our users across the globe, whether they’re trading, storing, staking or using crypto. Know those people who always lead the group project? That’s us.
There are a few things we look for across all hires we make at Coinbase, regardless of role or team. First, we look for candidates who will thrive in a culture like ours, where we default to trust, embrace feedback, and disrupt ourselves. Second, we expect all employees to commit to our mission-focused approach to our work. Finally, we seek people who are excited to learn about and live crypto, because those are the folks who enjoy the intense moments in our sprint and recharge work culture. We’re a remote-first company looking to hire the absolute best talent all over the world.
Ready to #LiveCrypto? Who you are:
You’ve got positive energy. You’re optimistic about the future and determined to get there. 
You’re never tired of learning. You want to be a pro in bleeding edge tech like DeFi, NFTs, DAOs, and Web 3.0. 
You appreciate direct communication. You’re both an active communicator and an eager listener - because let’s face it, you can’t have one without the other. You’re cool with candid feedback and see every setback as an opportunity to grow.
You can pivot on the fly. Crypto is constantly evolving, so our priorities do, too. What you worked on last month may not be what you work on today, and that excites you. You’re not looking for a boring job.
You have a “can do” attitude. Our teams create high-quality work on quick timelines. Owning a problem doesn’t scare you, but rather empowers you to take 100% responsibility for achieving our mission.
You want to be part of a winning team. We’re stronger together, and you’re a person who embraces being pushed out of your comfort zone.
The mission of the Platform Product Group engineers is to build a trusted, scalable and compliant platform to operate with speed, efficiency and quality. Our teams build and maintain the platforms critical to the existence of Coinbase. There are many teams that make up this group which include Product Foundations (i.e. Identity, Payment, Risk, Proofing & Regulatory, Finhub), Machine Learning, Customer Experience, and Infrastructure.
As a machine learning engineer, you will play a pivotal role in constructing essential infrastructure for the open financial system. This involves harnessing diverse and extensive data sources, including the blockchain, to grant millions of individuals access to cryptocurrency while simultaneously identifying and thwarting malicious entities. Your impact extends beyond safeguarding Coinbase, as you'll have the opportunity to employ machine learning to enhance the overall user experience. This includes imbuing intelligence into recommendations, risk assessment, chatbots, and various other aspects, making our product not only secure but also exceptionally user-friendly.
What you’ll be doing (ie. job duties):
Investigate and harness cutting-edge machine learning methodologies, including deep learning, large language models (LLMs), and graph neural networks, to address diverse challenges throughout the company. These challenges encompass areas such as fraud detection, feed ranking, recommendation systems, targeting, chatbots, and blockchain mining.
Develop and deploy robust, low-maintenance applied machine learning solutions in a production environment.
Create onboarding codelabs, tools, and infrastructure to democratize access to machine learning resources across Coinbase, fostering a culture of widespread ML utilization.
What we look for in you (ie. job requirements):
5+yrs of industry experience as a machine learning and software engineer
Experience building backend systems at scale with a focus on data processing/machine learning/analytics.
Experience with at least one ML model: LLMs, GNN, Deep Learning, Logistic Regression, Gradient Boosting trees, etc. 
Working knowledge in one or more of the following: data mining, information retrieval, advanced statistics or natural language processing, computer vision.
Exhibit our core cultural values: add positive energy, communicate clearly, be curious, and be a builder.
Nice to haves:
BS, MS, PhD degree in Computer Science, Machine Learning, Data Mining, Statistics, or related technical field.
Knowledge of Apache Airflow, Spark, Flink, Kafka/Kinesis, Snowflake, Hadoop, Hive.
Experience with Python.
Experience with model interpretability, responsible AI.
Experience with data analysis and visualization.
P54319
Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law.  For US applicants, you may view Pay Transparency, Employee Rights and Know Your Rights notices by clicking on their corresponding links.  Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. 
Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please complete this intake form to let us know the nature of your request and your contact information.  For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).
Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.    
 ",USD 150K - 230K *
448,Team Lead- Field Operations (Chennai),IDEMIA,"Chennai, IN, 600107",Senior-level / Expert,"  You may not know our name, but you have surely used our innovations and solutions.
  Our mission is to unlock the world and make it safer through cutting-edge identity technologies. Every day, around the globe, we are enabling citizens and consumers alike to perform their daily critical activities (such as pay, connect and travel), in the physical as well as digital space. We are transforming their lives by making the world more secure and yet also more streamlined.
  We have brought together complementary know-how and technologies that have never been combined before for both the physical and digital era: secured connectivity, secured payments and secured identity management. Cybersecurity, biometrics, large scale distributed systems and Cloud computing, analytics and smart devices are at the core of both our physical products and our software and systems.
  We serve our clients in 180 countries thanks to our 15,000 employees worldwide. 
  We are looking for Team Lead- Field Operations at Chennai location. 
  Experience Required 5-10 Years
Roles and Responsibilities
  The position as a Field sales operation Manager, The person will be responsible for business delivery through a channel network of agents and Distributors/Direct Sales Agencies across multiple states for Digital Field Services and Financial Inclusion businesses.
  To Deveople and execute a Business plan for establishing sales channel network of agents, BC agents, and Distributors/Direct sales agency for multiple projects.
Establishing and Managing relationships with Banks.
Responsible for the growth of Business and Ensuring the targets on revenue are met.
Ensuring quality of business delivery by maintaining a constant vigil on the input and output from Distributors/Direct sales agencies and agents.
Onboarding, training/development/motivation/guidance of channel partners and field agents to accomplish set goals and targets.
Explore new avenues of growth and new business by maintaining and effective communication on market knowledge and feedback with the management.
Maintaining excellent relationships with channel partners and field forces to help in business delivery and its growth.
Planning and promotions of Business campaigns.
Act as an ambassador and representative of the organization to promote positive relationships and strong partnerships in the region.
  By choosing to work at IDEMIA, you can join the journey of a unique tech company. You can seize all the opportunities of our fast-paced environment. You can add your distinctive qualities to our global community. You can contribute to a safer world.
  We deliver cutting edge, future proof innovation that reach the highest technological standards. We’re well established, and yet still agile. We aren’t too big, and we aren’t too small. And we’re transforming, fast, to stay a leader in a world that’s changing fast, too.
  At IDEMIA, people can develop their expertise and feel a sense of ownership and empowerment, in a global environment, as part of a company with the ambition and the ability to change the world.
  Our teams are close and collaborative; maintaining a dialogue and developing human connections matter to us. We are truly international and we know that diversity is a key driver of innovation and performance. We welcome people from all walks of life, regardless of how they look, where they come from, who they love, or what they think.
  Each of our locations has its own advantages to offer a collaborative and friendly work environment.
  IDEMIA. Expect the unexpected. Join the journey of a unique tech company.",USD 45K - 84K *
449,Data Quality Analysis,NTT DATA,"Hyderabad, TG, IN",Mid-level / Intermediate,"NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Data Quality Analysis to join our team in Hyderabad, Telangana, India.
Required Skills
•    3 - 5 years of IT experience
•    Experience using Atacamma, Data Catalog, Data Quality, 
•    Experience with Vendor Tool Management 
•    Good to have Unix Shellscripting Knowledge, AWS
•    Strong data quality background that includes use of common enterprise data quality tools
•    Deep understanding of technology environments that data quality tools and processes
About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",USD 30K - 56K *
450,Data Management Services - Team Leader,State Street,Mumbai,Senior-level / Expert,"Job Summary: 
The Data Management Services Team Leader will be responsible for overseeing a team of data management professionals and ensuring the effective execution of data-related projects. This role involves leading and coordinating data management activities, implementing best practices, and ensuring the quality and integrity of data. The ideal candidate should possess strong leadership skills, a deep understanding of data management principles, and the ability to drive successful project delivery.
Responsibilities:
Team Leadership:
Provide leadership and guidance to a team of data management professionals.
Foster a collaborative and high-performance team culture.
Conduct regular performance evaluations and provide constructive feedback to team members.
Project Oversight:
Lead and coordinate data management projects from initiation to completion.
Ensure adherence to project timelines, budgets, and quality standards.
Collaborate with cross-functional teams to integrate data management processes into broader initiatives.
Data Quality Assurance:
Establish and enforce data quality standards and procedures.
Conduct regular audits to ensure the accuracy, completeness, and consistency of data.
Implement measures to address data quality issues promptly.
Process Improvement:
Identify opportunities for process improvement within the data management function.
Implement and oversee the adoption of best practices and industry standards.
Streamline data workflows for efficiency and effectiveness.
Training and Development:
Provide training to team members on data management tools, techniques, and best practices.
Support the professional development of team members through mentorship and ongoing training opportunities.
Client Communication:
Collaborate with clients to understand data requirements and expectations.
Communicate project progress, challenges, and solutions to clients in a clear and concise manner.
Qualifications:
Bachelor’s degree in a relevant field (Data Management, Information Technology, etc.).
Proven experience in data management, with at least [X] years in a leadership or supervisory role.
Strong knowledge of data governance, data quality, and data integration principles.
Proficiency in data management tools and technologies.
Excellent communication and interpersonal skills.
Disclaimer: This job description is intended to provide a general overview of the responsibilities and qualifications for the position of Data Management Services Team Leader. The specific duties and qualifications may be subject to change based on business needs. Any modifications will be communicated to the candidate during the hiring process.",USD 45K - 84K *
451,"Lead, Decision Scientist",Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Data
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
As a Decision Scientist, you will deliver key insights and analyses that help Salesforce leaders and teams make key decisions that shape strategy, operations, the way we develop products, sell and interact with customers. You will acquire deep knowledge and understanding of Salesforce products and business goals, build and manage cross-functional relationships, and communicate through digestible, relevant, and actionable storytelling. You will manage data and insights as a product, partnering with data product managers, data engineers, data scientists, ML engineers, visualization engineers, and many other DNA teammates to deliver data products, such as dashboards, ML apps, automation, and much more. You will use business thinking, engineering skills, statistical techniques, and data science practices - such as experimentation, forecasting, clustering, etc. - to wrangle data and deliver relevant and trustworthy insights.
Success in the Role: What would it look like?
A hands-on analyst - You will generate insights (e.g., performance drivers, retention analysis, behavioral personas and much more) to accelerate business growth. This requires acquiring and cleaning data from multiple sources, structuring and building data models, analyzing to generate insights, and distributing those insights to business leaders.
You have an experimentation demeanour. You are passionate about understanding the business problem and your internal users, focusing on outcome not output, and iterating to achieve the business outcome through an experimental approach.
A strategic problem solver - You understand the “big picture” context of your business and analyze data with business a mentality
You translate business challenges into an analytical plan; you think practically and creatively to craft quick, effective solutions to problems
A relationship builder - You will develop relationships and collaborate with teams to understand business problems and build and implement an analytical plan
You are comfortable delivering insights to an executive audience
A cross-functional partner - You will partner with data engineers and product managers to instrument, acquire, develop, and structure data assets that are essential to measuring the success of our products
Identify internal and external collaborators to curate data assets and produce actionable data insights and products
A data champion/A data-lover at heart/data evangelist - You will support the expansion of Salesforce data culture by growing new relationships, hosting learning sessions, integrating or crafting new tools, and improving team processes
Your Experiences
2-10 years of experience in data analytics or data science or a master’s degree in data science, statistics, applied mathematics, analytics or a related field, or equivalent alternative education, skills, and/or practical equivalent experience
You are proficient in common analytical programming languages (e.g. Python or R) and SQL
Experience with Spark and Airflow preferred
You have a strong understanding of statistical and machine learning methods such as A/B testing, experiment design, causal inference, quasi-experimental methods, common ML models, recommendation systems etc.
You are familiar with end-to-end data development, including data model design, quality review, deployment, and maintenance
You are proficient in telling data stories in a wide range of formats, including slides, charts, and dashboards (e.g. Tableau), and can coherently articulate the business impact of your insights product
You are able to plan projects in detail, set schedules, coordinate supplies across product, data, and engineering teams, complete projects end-to-end, and make sure timelines and quality expectations are met
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 129K - 204K *
452,Data Management Services - Manager,State Street,Mumbai,Mid-level / Intermediate,"Job Summary: 
The Data Management Services Manager is a pivotal role responsible for leading and managing a team of data professionals. The primary focus is on overseeing data management activities, ensuring seamless process transitions, and playing a crucial role in client communication. The ideal candidate should demonstrate strong leadership skills, extensive experience in data management, and the ability to effectively communicate with clients while driving process improvements.
Responsibilities:
Team Leadership:
Provide leadership, guidance, and mentorship to a team of data management professionals.
Foster a collaborative and results-driven team culture.
Conduct performance evaluations, set goals, and provide continuous feedback.
Process Transition:
Lead the planning and execution of smooth process transitions within the data management function.
Collaborate with cross-functional teams to implement process improvements.
Ensure minimal disruption during transitions and maintain data integrity throughout.
Client Communication:
Act as the primary point of contact for clients regarding data management services.
Understand client requirements, expectations, and objectives.
Communicate project updates, challenges, and resolutions to clients in a clear and timely manner.
Quality Assurance:
Establish and enforce data quality standards, policies, and procedures.
Implement measures to continuously monitor and improve data quality.
Address data quality issues promptly and effectively.
Strategic Planning:
Develop and execute strategic plans for the data management services team.
Identify opportunities for innovation, efficiency, and client satisfaction.
Contribute to the development of long-term data management strategies.
Cross-functional Collaboration:
Collaborate with other departments, including IT, Analytics, and Operations, to ensure integrated and cohesive data management processes.
Implement best practices and industry standards for data management.
Qualifications:
Bachelor’s degree in a relevant field (Data Management, Information Technology, etc.); Master’s degree preferred.
Extensive experience in data management, with a proven track record of leadership.
Strong understanding of data governance, quality assurance, and data integration.
Excellent communication, negotiation, and client management skills.
Proficiency in data management tools and technologies.
Disclaimer: This job description is intended to provide a general overview of the responsibilities and qualifications for the position of Data Management Services Manager. The specific duties and qualifications may be subject to change based on business needs. Any modifications will be communicated to the candidate during the hiring process.",USD 30K - 56K *
453,TC CS IAM(IMP) Data Analyst Senior,EY,"Bengaluru, KA, IN, 560048",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        EY-Consulting - Data and Analytics – Senior – PLSQL
EY's Consulting Services is a unique, industry-focused business unit that provides a broad range of integrated services that leverage deep industry experience with strong functional and technical capabilities and product knowledge. EY’s financial services practice provides integrated consulting services to financial institutions and other capital markets participants, including commercial banks, retail banks, investment banks, broker-dealers & asset management firms, and insurance firms from leading Fortune 500 Companies. Within EY’s consulting Practice, Data and Analytics team solves big, complex issues and capitalize on opportunities to deliver better working outcomes that help expand and safeguard the businesses, now and in the future. This way we help create a compelling business case for embedding the right analytical practice at the heart of client’s decision-making.
  The opportunity
We’re looking for candidates with 5-8 years of strong expertise in PLSQL having Data warehouse and Data Modelling knowledge.
  Your key responsibilities
Develop PL/SQL Packages, Procedures, Functions, Triggers, Views and Exception handling to process various type of data including XML, gXM.
Write complex codes and long queries and participate in code reviews.
Provide technical assistance, problem resolution and troubleshooting support.
Performance tuning of existing applications.
Identify automation opportunities.
Understand existing data landscape/data warehouse, contribute to production support evaluation and BAU operations.
Extensive data analysis to arrive at optimal solution and data model.
Need to work as a Senior team member to contribute in various technical streams.
Get involved in business development activities like creating proof of concepts (POCs), point of views (POVs), assist in proposal writing and service offering development, and capable of developing creative power point content for presentations.
Interface and communicate with the onsite teams directly to understand the requirement and determine the optimum solutions.
Create technical solutions as per business needs by translating their requirements and finding innovative solution options.
Provide product and design level functional and technical expertise along with best practices.
Participate in organization-level initiatives and operational activities.
Ensure continual knowledge management and contribute to internal L&D teams.
  Skills and attributes for success
Excellent analytical and organization skills.
Use an issue-based approach to deliver growth, market and portfolio strategy engagements for corporates.
Strong communication, presentation and team building skills and experience in producing high quality reports, papers, and presentations.
Experience in executing and managing research and analysis of companies and markets, preferably from a commercial due diligence standpoint. 
  To qualify for the role, you must have
BE/BTech/MCA/MBA with 6-11 years of industry experience in PLSQL, data analysis and data modelling skills.
Expertise on SQL, procedural SQL languages , able to create packages handling XML , GXML data
Well versed with latest Oracle versions, new features.
Ready to cross-skill.
Knowledge in ETL tools like Informatica, SAP BODS, DataStage, ODI, SSIS etc. SAP BODS is an advantage.
Exposure to SSIS, SSRS, SQL Server, PL/SQL , DB2, Oracle, Teradata, Netezza.
Domain Knowledge on Banking sector is preferable.
Should have understanding and experience of software development best practices.
Excellent business communication, Consulting, Quality process skills and team player.
  What we look for
A Team of people with commercial acumen, technical experience and enthusiasm to learn new things in this fast-moving environment.
An opportunity to be a part of market-leading, multi-disciplinary team of 1400 + professionals, in the only integrated global transaction business worldwide.
Opportunities to work with EY Consulting practices globally with leading businesses across a range of industries.
  What working at EY offers
At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.
You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:
Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you
    EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 92K - 144K *
454,Data Analyst,Skan,"Bengaluru, Karnataka, India",Entry-level / Junior,"As a Data Analyst, you will be responsible for building, modulating and understanding the data produced by the tool to efficiently transform the data into customer friendly dashboards which show business value insights as part of Skan implementation for our prospects and current customers. You will work closely with our Customer Success and Service Delivery teams in understanding, discovering, defining and quantifying potential business value improvements that Skan can help achieve. The role will be focused on modifying or creating dashboards so that the customer realizes the value of Skan’s data. You will also participate in standardizing templates and value driven outcomes by industry and process which can be subsequently leveraged in similar projects. You will have the opportunity to use data to drive business decisions, write SQL queries, data mine and visualize techniques. 
What You’ll Do: 
Ability to interpret data and build/modify dashboards jointly with customers, and based on data, propose potential process improvement solutions with internal teams and customer stakeholders. 
Work with data to arrive at key metrics and KPI’s for our customers. E.g. NPS (Net Promoter Score), FPR (First Pass Rate) etc.  
Create dashboards with a high level of creativity to bring out powerful business value through insights and stories and present to internal stakeholders. 
Uncover trends and correlations through data mining and analysis to develop insights that can improve the business and help make effective decisions. 
Analyze unique operational data to find new and deep insights that bring our customers' value. 
Utilize Power BI and experiment with infographics to make our rich data as actionable as possible. 
Collaborate and innovate with our data science team to unlock new value drivers from our data. 
Participate in customer value engineering meetings and gain first-hand experience on business value. 
Participate in standardizing the value engineering framework and report templates at Skan. 
Requirements
Need to haves 
4+ years of business intelligence or data analytics experience – experience with Snowflake and Microsoft PowerBI preferred. 
3+ years’ experience working with BI tools or any data-specific role with a sound knowledge of database management, data modeling, business intelligence, SQL querying, data warehousing, and online analytical processing. 
In-depth understanding and experience with Microsoft BI stacks such as Power Pivot, SSIS, SSRS, and SSAS. 
Experience using Python to parse, structure, and transform data. 
Affinity for numbers and metrics. 
Ability to create user friendly and concise dashboards which enable the customer to understand their process better. 
Clear and effective communication skills. 
Team Player with willingness to learn. Ability to coordinate with different teams across the organization. 
Analyzing industries, overall economic and corporate trends. 
Conduct and facilitate internal and external research and discovery around customer business processes. 
Hands-on experience with PowerBI. 
 Nice to haves 
Previous industry experience in Banking, Finance or Healthcare 
Data Analytics certification. ",USD 56K - 94K *
455,Data Engineer | 4 to 9 Years | Bangalore & Pune,Capgemini,"Hyderabad, AP, IN",Mid-level / Intermediate,"Job Description
Write and implement software solutions that integrate different systems
Identify and suggest ways of improving efficiency and functionality
Come up with reusable code that is efficient and easily testable
Use backend logic to integrate user-facing features
Write and implement Low-Latency Applications
Implement security and data protection
Certified candidates in Python/SQL/AWS technologies preferably
Primary Skills
Solid experience coding in Python and preferably in finance, risk or banking domain experience & experience in Object Oriented Programming
knowledge of unit tests frameworks like: pytest, unittest
Agile Should be aware of SAFe
Secondary Skills
Experience in best code deployment practices
Knowledge of Scrum / Kanban
Ability to test and debug tools in Python. Also, debug and troubleshoot existing code",USD 90K - 150K *
456,Data Analyst,S&P Global,IN - AHMEDABAD,Entry-level / Junior,"The Team:
PETA (Private Equity, Traditional & Alternative Data Insights & Intelligence) primarily focuses on maintaining and updating profiles of Private Equity and Venture Capital firms. With global coverage, we aim to deliver research, content, and analytics about the public and private capital markets to investment banks, investment managers and alternative investment firms.
The team also establishes relationships with Private Equity Firms to gather rare insights about public & private investments, exits, and investment strategies. This effort is coupled with our real time monitoring of global industry trade publications and websites/news aggregators to cover and track all public/private investment markets.

The Impact:
This role will influence the Private Equity/Venture Capital dataset. In addition to collecting and validating the data, this role may require working with peers, other stakeholders and on process improvement projects. This position is an excellent stepping-stone to understand PE/VC domain, that will allow you to gain a comprehensive understanding of their working, and enable you to learn facets of PE/VC, and as well as apply this knowledge to your daily responsibilities.

What’s in it for you:
Primarily responsible for day-to-day collection and validation of data related to PE/VC firms. Once strong fundamental understanding of the dataset and proficiency at workflows is developed, this role would require working with new talent to develop/enhance their skillset and working on process improvement projects including LEAN/automation projects that supports multiple SPGMI products and also an opportunity to venture into the field of data analysis and explore the world of Automation and Artificial Intelligence if have a knack for the same.
Responsibilities:
High quality data collation, analysis, extraction and entering the data in work tools as per guideline specifications
Understand the working of the dataset, be aware of the workflows and have strong working knowledge of work tools
Deliver on predefined individual and team targets including delivering outcomes with quality and excellence.
Provide input and ideas for new collection methods and product enhancements related to the dataset
Work on projects as an when they come up and ensure that they are completed within the given time span maintaining the desired quality
Troubleshoots problems or issues and provide support to the team
Support team in enhancing the workflow/processes for department.
Create tech expertise within department.

What We’re Looking For:
• MBA/ M.COM candidates with good academic track record
• Ability to multi-task and work in a team environment, while following flexible schedule to meet deadlines
• Well versed with secondary research sources
• Certification and working knowledge/experience in MS-office (Excel, Word, PowerPoint)
• Background in Finance or related fields is preferred
• Comfortable taking initiative and demonstrating resourcefulness
• Strong attention to detail and persistent approach to work
• Excellent communication skills, both written and oral
• Strong quantitative, analytical and interpretive skills
• Ability to conduct efficient thematic online research
• Knowledge of any database or automation tools would be an added advantage.
• Adaptability to working in any shifts
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), DTMGOP203 - Entry Professional (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 56K - 94K *
457,Associate Director Clinical Data Management,Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.
Functional Area Description
CDM is responsible for integrity, reliability, completeness and quality of clinical trial data and provides end to end clinical data management leadership for trials across the BMS R&D portfolio.
Responsibilities will include, but are not limited to:
Program Management
• Act as a Program Lead to provide oversight of a program within the organization providing oversight to a group of studies and Data Management staff ensuring that the studies within the program are delivered per corporate goals and objectives
• Establish a governance framework for a program or asset to ensure monitoring of risks and mitigation strategies across different studies within the program
• Developing strong and productive working relationships with cross functional stakeholders responsible to provide strategic support to project team
• Responsible for attending program level strategic meetings
• May act as a driver to set program level data collection and review standards with cross functional team in partnership with global standards
Line Management
• Line management responsibility of Data Management staffbased on business requirements
• Manages the resource assignments ensuring appropriate support is in place to provide data quality oversight for clinical trials
• Forecast’s future resource needs based on the book of work and initiatives; proposing solutions to meet potential resource constraints
• Assigns resources to initiatives in line with their development plans and providing appropriate guidance to staff to influence results and drive to completion
• Works proactively with staff to understand individual strengths, opportunities, and career goals; supporting development of plans that capitalize on strengths and address opportunities; providing regular feedback to promote development.
• Effectively coaches and mentors’ staff, seeking out training opportunities where needed, to develop the next generation leaders. 
• Develops and promotes a workplace culture that values diversity of thought, promotes integrity, creates accountability, supports effective decision making, and provides opportunities to grow.
Project Management and Leadership
• Efficiently plans, coordinates, and delivers complete, high quality and reliable clinical trial data in a timely manner for assigned projects
• Provides clinical data management leadership within the study team to align on and drive data collection requirements for one or more complex clinical development projects
• Responsible for end-to-end clinical data management activities and may serves as a primary point of contact for internal and external study team members
•  Provides strong quality and project oversight over third party vendor responsible for data management deliverables
• Takes a leadership role to gather content and integration requirements for EDC and close collaboration with partners supporting other data collection systems (eCOA, External Data, Safety Gateway). Enforces data standard conventions and quality expectations for clinical data per defined processes
• May author, review/revise DM related study plans including Data Quality Management Plan, Data Validation Plans, Data Review Plan, eCRF Completion Guidelines and other study documents to ensure quality and standardization
• Participate in Data Quality Review meetings with cross functional study team members to ensure on-going review of trial data currency, quality and completeness
• Represents DM on cross-functional project teams, portfolio review meetings & Submission Teams
• Lead or support the Health Authority inspections and audits
FSP/CRO/Vendor Oversight
• May act as core member of the study team and provides FSP/CRO/Vendor oversight for end-to-end Data Management activities, manages data currency throughout the trial, and overall monitoring DM deliverables according to the Service Level Agreement (SLA)
Continuous improvement initiatives
• Supports change management initiatives with broad impact as a lead or participant in initiatives, and/or authors (or participates in) functional SOPs/WP/GD
• Utilizes knowledge of data management processes to evaluate and recommend new technologies and systems for improved data management functionality
• May mentor new or existing team members, as applicable
• Lead CAPA management activities and ensure timely closure of CAPA action items
• Holds accountability to resolve complex issues and proactively develop solutions, within the function and across functions. Leveraging technical/functional expertise to develop solutions.  Using clear communications and collaborative strategies to drive to resolution
• Authors procedural documents (SOPs, work instructions, job aids) and coordinating reviews/approvals.  Ensuring procedural documents are reflective of industry standards and regulatory requirements, include optimal processes and are regularly maintained. 
#HYDDD
#LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 30K - 56K *
458,Data Engineer,Coursera,India,Senior-level / Expert,"Coursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 136 million registered learners as of September 30, 2023.
Coursera partners with over 300 leading university and industry partners to offer a broad catalog of content and credentials, including courses, Specializations, Professional Certificates, Guided Projects, and bachelor’s and master’s degrees. Institutions around the world use Coursera to upskill and reskill their employees, citizens, and students in fields such as data science, technology, and business. Coursera became a B Corp in February 2021.
Join us in our mission to create a world where anyone, anywhere can transform their life through access to education. We're seeking talented individuals who share our passion and drive to revolutionize the way the world learns.
We at Coursera are committed to building a globally diverse team and are thrilled to extend employment opportunities to individuals in any country where we have a legal entity. We require candidates to possess eligible working rights and have a compatible timezone overlap with their team to facilitate seamless collaboration. As a remote-first company, our interviews and onboarding are entirely virtual, providing a smooth and efficient experience for our candidates.
Job Overview:
Data Engineering is unique at Coursera. Our team doesn’t simply build reports on demand; rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.
We’re looking for a talented and driven data engineer with a keen eye for data.  In this role, you’ll directly work with cross-functional teams to design, develop, and deploy partner data solutions. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and software engineering skills, who shares our passion for education.
Responsibilities:
Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake
Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights
Be a technical leader for the team; guide technical and architectural designs for the major team initiatives; mentor junior members of the team
Build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data
Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently
Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches
Qualifications:
2-5 years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science
Strong software engineering skills and at least one scripting language (e.g., Python)
Proficient with relational databases and SQL
Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred
Ability to communicate technical concepts clearly and concisely
Independence and passion for innovation and learning new technologies
Bonus
Hands-on experience with AWS, Databricks, Delta Lake, Airflow, DBT, Redshift
If this opportunity interests you, you might like these courses on Coursera:
Big Data Specialization
Big Data Essentials - HDFS, MapReduce and Spark
Data Warehousing for Business Intelligence
#LI-BL1
 Coursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.
  If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.
  For California Candidates, please review our CCPA Applicant Notice here.
For our Global Candidates, please review our GDPR Recruitment Notice here.",USD 121K - 186K *
459,Senior Data Scientist,Cargill,"Bengaluru, Karnataka, India, 560087",Senior-level / Expert,"Job Purpose and Impact
Intelligent Supply Chain Senior Data Scientist will work collaboratively in multidisciplinary teams to define, develop and deploy complex supply chain digital solutions at scale. In this role, you will deploy predictive, prescriptive and optimization models at scale for digital supply chain products that help deliver significant value to our customers, businesses and functions.
Key Accountabilities
Design, implement, and deploy forecasting, predictive solutions
Contribute to design, and implementation of new features, and deploy predictive models and solutions for intelligent supply chain products at scale.
Work and consult on multidisciplinary teams of data engineers, software engineers, data scientists, and business subject-matter experts to deliver highly complex large-scale projects on time.
Take ownership and work with limited supervision for the entire supply chain data science workflow including well defined, highly complex project scoping, exploratory data analysis, model development, deployment and monitoring.
Provide expert thought leadership in the area of business analytics and work with limited direction, using additional research and interpretation to identify issues or problems. You may provide direction to supporting team members and other duties as assigned.
Qualifications
MINIMUM QUALIFICATIONS
Master’s degree in Management, Computer science, Statistics, Data Science OR related field OR Equivalent Experience. Applied Machine Learning experience (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning).
Strong mathematical background (linear algebra, calculus, probability and statistics).
Strong coding skills in Python (or similar object-oriented programming language)
Minimum of 4 years of related work experience.
PREFERRED QUALIFICATIONS
Five or more years’ experience in Supply chain  
PhD in Computer science, Artificial Intelligence, Optimization, Operational Research, or Math OR related field.
Professional experience applying predictive models for Supply Chain solutions.
Experience with timeseries forecasting such as ARIMA, Prophet, DeepAR, etc.
KEY BEHAVIORS
Can do attitude and seeks to make a difference.
Curiosity and willingness to learn about our Supply Chain Opportunities.
Knows the most effective and efficient processes to get things done, with a focus on continuous improvement.",USD 135K - 205K *
460,"Database Developer, PSQL, ETL Tools - Assistant Vice President",State Street,"Bengaluru, India",Executive-level / Director,"Job Description
DESCRIPTION
Data Operations and Solutions Team (DOST), serves as a techno-functional team that drives data related projects and the overall data strategy for Finance. DOST owns and manages key Finance, Treasury and Risk data repositories support critical and regulatory processes  across Finance, Treasury and Risk. The team also drives data solutions to ensure consistent use of authoritative sources of data, and implements effective governance and controls for management of data across the data supply chain. Lastly, the team represents Finance in Enterprise Data Governance initiatives and forums; provides oversight over data governance in Finance. 
 Responsibilities:
Design & implement Data models that can be used to various business purposes such as Analytics & Reporting
Design and build queries, reports, and dashboards using business intelligence tools adhering to established frameworks and standards
Actively participate in and influence discussions around infrastructure needs, and design
Interface directly with clients and project team members to understand the needs and objectives of the business
Perform data analysis to drive high quality data solutions that enable dynamic data analytics for our customers
Consistently deliver high-quality business solutions and services to clients on schedule
Bring structure to ambiguous business problems and recommend visualization solutions that can be easily interpreted by users
Serve as end user support for the organizational user base
Follow, maintain and improve all documentation and procedures for report design and production
Sponsor teamwork and encourage collaboration
Influence business process improvements by integrating data/tools with people/purpose and DART vision
Qualifications:
15 years of experience as a business/reporting analyst, in a dynamic business environment, with demonstrated reporting, analytical, and database experience
Self-motivated, well-rounded,  analytical self-starter with ability to work in a dynamic, collaborative, Agile team environment with aggressive deadlines, regular releases and multiple priorities
Sound understanding of best practices/ methodologies; experience with relational structures,  structured query language (SQL), data warehouse and reporting techniques
Proficient in programming languages such as Python, R, and SQL. They should also have experience with data analysis and visualization tools such as Tableau, PowerBI, or Excel.
Ability to create information links, Document Properties, Property Controls in Spotfire
Strong analytic skills with the ability to gather, synthesize, and organize data to solve complex problems
Excellent verbal, written communication and presentation skills
Ability to work collaboratively and effectively with business and systems personnel",USD 49K - 91K *
461,Software engineering PMTS (AI /ML),Salesforce,India - Bengaluru,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
The Salesforce Trusted Services cloud is looking to establish a team of experienced software engineers who are passionate about solving complex problems, owning a product from end-to-end, and taking advantage of the latest AI/ML technologies. As a member of the team, you will be involved in building a cutting-edge, next-generation version of the Salesforce Data Detect product (formerly Einstein Data Detect).

Salesforce is the poster child of trusted enterprise cloud services. In Trusted Services, nothing is more important to our continued success than the security and privacy of our customer’s data. We are an integral part of the Salesforce Customer 360 vision, and our focus and passion is building the next-generation of Salesforce Privacy and Security products.

In this role, you will design, implement, and optimize ML algorithms for the accurate detection of sensitive data across diverse data types and formats. You will be part of a fast-growing team focused on building a re-imagined version of the Data Detect product. And with customer trust as our #1 value, you will ensure that quality, performance, security, and observability are inherent attributes of the product.

What you’ll do
* Train and evaluate ML models using state-of-the-art techniques, ensuring high precision and recall in identifying sensitive entities.
* Work closely with back-end engineers to seamlessly integrate ML models into data processing pipelines, ensuring scalability and efficiency in real-time data analysis.
* Develop and implement strategies for custom entity recognition, tailoring the AI models to identify customer-specific sensitive information.
* Develop efficient data classification mechanisms to categorize information based on its sensitivity and establish appropriate access controls.
* Create and enhance pattern recognition systems to identify sensitive data patterns, including personally identifiable information (PII) and other customer-specific confidential information.
* Collaborate with internal cross-functional teams to gather their data detection requirements and perform feature engineering and extraction
* Provide input into priorities, deadlines, and deliverables.
* Stay abreast of industry trends and emerging technologies to continuously enhance the capabilities of the Data Detect product.

Required Skills
* Master's or Ph.D. in Computer Science, Machine Learning, or a related field.
* 15+ years of experience in Software development and engineering, should have 6+ years of relevant experience in Data Science, AI / ML Engineering and AI/ML Ops etc.
* Proven experience in developing and deploying machine learning models, with a focus on data security and privacy.
* Proficiency in Python, TensorFlow, PyTorch, or similar.
* Solid understanding of feature engineering, model training, and evaluation techniques.
* Knowledge of software development methodologies (Agile, Scrum, etc.).
* Excellent problem-solving and communication skills.
Preferred Skills
* Familiarity with data encryption, tokenization, and other data protection methods.
* Experience with machine learning algorithms, deep learning techniques, and natural language processing of structured and unstructured data.
* Familiarity with Named Entity Recognition (NER) and NLP techniques to identify and categorize sensitive data.
* Experience with model training, validation, and optimization.
* Experience with data preprocessing and feature engineering.
* Experience designing and implementing advanced algorithms for the accurate detection of sensitive data across various data types and formats.
* Familiarity with cloud platforms and distributed computing for scalable ML solutions.
* Familiarity with relevant data security, privacy, and compliance regulations (e.g., GDPR, CCPA, and HIPAA).
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 45K - 84K *
462,Machine Learning Specialist for Intelligent Automation,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Collaborate with cross-functional teams, including automation developers and business analysts, to understand the requirements of Intelligent Automation projects and identify areas where Machine Learning can be leveraged.
Design and develop machine learning models and algorithms tailored to the specific needs, ensuring scalability, accuracy, and reliability.
Implement and maintain ML pipelines for data preprocessing, feature engineering, model training, evaluation, and deployment.
Perform data analysis and identify relevant data sources to extract valuable insights for enhancing automation workflows.
Conduct thorough testing and validation of ML models to ensure their robustness and accuracy in real-world scenarios.
Monitor and optimize ML models' performance, making necessary adjustments and improvements as needed.
Document all ML-related processes, code, and project details comprehensively for future reference and knowledge sharing.
Be the go-to expert for all Python-related automation development, including automation infrastructure, ensuring its smooth functioning, performance optimization, and security.
Qualifications
Bachelor's or Master's degree in Engineering
Additional Information
• Bachelor's or Master's degree in Engineering (Preferred: Computer Science, Data Science, Machine Learning, or a related field.)• Proven work experience as a Machine Learning Specialist or a similar role, with 6-8 years of relevant industry experience.• Strong proficiency in Python programming and its associated libraries for Machine Learning, such as NumPy, Pandas, SciPy, Scikit-learn, TensorFlow, or PyTorch.• Hands-on experience in designing and implementing machine learning models for various applications, with a focus on natural language processing (NLP), computer vision, or predictive analytics.• Solid understanding of ML algorithms, statistical concepts, and data evaluation techniques.• Familiarity with RPA technologies and the ability to integrate ML solutions seamlessly into existing RPA workflows.• Strong problem-solving skills, attention to detail, and the ability to work independently or as part of a team.• Excellent communication skills, both verbal and written, to effectively convey technical concepts to non-technical stakeholders.• A passion for innovation and a desire to contribute to the automation revolution",USD 45K - 84K *
463,Data Analyst (Fresher),Wizikey,"Chandigarh, India",Entry-level / Junior,"Company Description
Wizikey is a PR & Communications analytics software that uses AI technology to monitor news, provide media insights, and automate reporting. It helps companies track their news presence, gather competitive intelligence, and connect with relevant reporters. With Wizikey, businesses can measure their PR efforts, optimize strategies, and drive better outcomes. Trusted by over 100+ businesses, including Reliance, Infosys, MapmyIndia, Blusmart, Physics Wallah and WebEngage, Wizikey enhances brand visibility globally.
  Job Description
Collaborate with the product management team to define product goals, strategies, and roadmaps.
Conduct market research to identify industry trends, user needs, and competitive landscapes.
Gather and analyze user feedback, surveys, and usage data to identify areas for improvement.
Perform quantitative and qualitative analyses on product performance metrics, customer behavior, and user experience.
Develop and maintain product dashboards and reports to track key performance indicators (KPIs) and communicate insights to stakeholders.
Work closely with UX designers to evaluate user interface and user experience (UI/UX) designs for optimal usability.
Assist in the prioritization of product features and enhancements based on data-driven insights.
Collaborate with engineering teams to provide clear requirements and specifications for product development.
Participate in product testing and quality assurance processes to ensure product functionality and usability.
Stay up to date with industry trends, emerging technologies, and best practices in product analysis.
Qualifications
Bachelor's degree in business, economics, computer science, or a related field.
1-3 years of professional experience in product analysis, data analysis, or a similar role.
Strong analytical skills with the ability to interpret complex data sets and draw meaningful insights.
Proficiency in data analysis tools such as Excel, SQL, or Python.Familiarity with product management methodologies and practices.
Excellent communication skills to effectively collaborate with cross-functional teams and present insights to stakeholders.
The detail-oriented mindset with a focus on accuracy and precision.
Self-motivated and proactive attitude with the ability to work both independently and in a team environment.
A passion for technology, SaaS industry, and entrepreneurial mindset
Additional Information
""Wizikey encourages and celebrates entrepreneurial culture. When you set out to create a new industry, you need to build a team of immensely talented folks from Technology and Communications and give them the freedom to experiment, learn and keep building. And with every addition of talent, this gets new fuel and the magic happens. And that is why we call ourselves Wizards"" ",USD 56K - 94K *
464,Data Scientist,Equifax,IND-Mumbai-Equifax Credit Information Services,Mid-level / Intermediate,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills,collaborate with bright minds, and make a meaningful impact, we want to hear from you.
Synopsis of the role
The role of an Associate, Presales will be highly specialized and it will involve reviewing data to discover insights and offering expertise in data management. They will use the results of their analysis to make predictions and help guide business strategy and decision-making.

What you’ll do
Work with the Equifax bureau in India to build bureau-based Analytics capabilities and use the new age technology to
implement those solutions.
Expected to demonstrate independence in execution, results interpretation and presentation, and the production of
documentation strong enough to evidence a sound challenge to both internal and external parties.
Understand client’s business requirements in terms of business needs and be a part of a High-class delivery team to
deliver unparalleled business solutions using best in class techniques.
Manage pre-sales tracker and pipeline to track key account movements, win/loss probabilities, competition mapping,
buyer personas, engagement history and conversions/losses
Knowledge of credit bureau, housing and/or demographic data is a plus. Manipulate large amounts of data and
integrate diverse data sources into solutions.
Understanding of key business and risk KPI’s for retail banking products, drawing insights from bureau datasets

What experience you need 
2 to 4 years experience in handling BFSI analytics/implementing models/Big data/Cloud solution architect
Good knowledge of SAS, SQL, Python, R.
Understanding of Retail banking products.
Analytical skill, logical thinking and problem-solving capabilities.
Adaptability to work in project-based engagements across different kinds of banking clients.
Should be a team player.
Analytical skill, logical thinking and problem-solving capabilities.

What could set you apart
Adaptability to work in project-based engagements across different kinds of banking clients
Knowledge on statistical and probability concepts
Self-starter with high energy levels and ability to work in a fast-paced environment
Self-motivation, discipline, task focus, the ability to structure and present work and a proven record of delivering high
quality results to strict deadlines.
We offer hybrid mode of working, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible? Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Equifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Primary Location:
IND-Mumbai-Equifax Credit Information Services
Function:
Function - Data and Analytics
Schedule:
Full time",USD 86K - 160K *
465,Data Scientist,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
The Global Data Office

With data being the fuel that drives our future - our strategies, policies, and business successes around data will define our future growth prospects. Unlocking the value available through the innovative use of data on behalf of consumers, businesses, and communities is key to our future. With our ongoing commitment to Visa’s Data Values and the responsible use of data, we at Visa have a bold vision to continue to grow and accelerate our data-related businesses and capabilities.
 Led by Visa’s first Chief Data Officer, the Global Data Office coordinates high-impact, complex, company-wide projects related to data business strategy, critical investments, policy development, and marketplace execution. Working closely with Visa’s Chief Privacy Officer, the Technology organization, the wider data community, and the full set of Visa’s global lines of business, the Global Data Office is evolving Visa’s data-related work with momentum and enthusiasm. Driven by its commitment to trusted use of data, Visa is seeking enthusiastic leaders who are change-agents and passionate about the future of data around the world.
 The Global Data Solutions team is part of the Global Data Office. To ensure that Visa’s payment technology is truly available to everyone, everywhere requires the success of our key bank or merchant partners and internal business units. We support these partners by using our extraordinarily rich data set that spans more than 3 billion cards globally and captures more than 100 billion transactions in a single year. Our focus lies on building creative solutions that have an immediate impact on the business of our highly analytical partners. We work in complementary teams comprising members from Data Science, Data Engineering and various groups at Visa. To support our rapidly growing group we are looking for Data Scientists who are equally passionate about the opportunity to use Visa’s rich data to tackle meaningful business problems. You will join one of the Data Science focus areas with an opportunity for rotation within the organization to gain broad exposure to Visa’s business.
The role will be based in Bengaluru, India.
 Primary responsibilities
Be an out-of-the-box thinker who is passionate about brainstorming innovative ways to use our unique data to answer business problems.
Partner with key stakeholder/clients to understand the problem statement and convince them with data.
Extract and understand data to form an opinion on how to best help our partners and derive relevant insights.
Develop visualizations to make your complex analyses accessible to a broad audience.
Find opportunities to craft solutions and products out of analyses that are suitable for multiple clients.
Work with stakeholders throughout the organization to identify opportunities for leveraging Visa data to drive business outcomes.
Mine and analyze data from company databases to drive optimization and improvement of product, marketing techniques and business strategies for Visa and its clients.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, advertising targeting and other business outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:

Post-graduate degree or PhD in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics or Bachelors in fields such as Engineering, or equivalent.
Minimum of  4+ years of analytics expertise in applying analytical solutions to business problems
Proven skills in translating analytics output to actionable recommendations, and delivery of the same to key stakeholders
Experience with extracting and aggregating data from large data sets
Experience in understanding and analyzing data using statistical software (e.g., Python, R, SQL or others)
Competence in Excel, PowerPoint and BI tools such as Tableau, PowerBI etc.


Preferred Qualifications:

Experience in cards/payments, retail banking, or retail merchant industries
Experience in presenting ideas and analysis to stakeholders


Strategic and Functional Excellence

A professional capacity for strong enthusiasm and accountability
High attention to detail and quality
Highly adaptive, comfortable working within a complex environment.
Excellent written, verbal, and presentation communications skills appropriate for a wide, global audience.
Strong business acumen
Leadership and Stakeholder Management

Strong interpersonal skills to build credibility with team members and leaders across the function as well as the organization
Team-oriented, collaborative, and flexible, with proven ability to build strong working relationships with internal and external partners
Self-starter who can responsibly own and advance work, take well-informed decisions, without needless delays
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 126K - 198K *
466,Data Scientist,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Experience in creating advanced statistical methods. Mine and analyze data, applying statistical methods as necessary, pertaining to customers’ discovery, and viewing experiences to identify and create critical insights
Research, develop and apply data science, machine learning, and statistical methods to large data sets. Mine data using modern tools and programming languages
Experience in creating statistical models and/or optimization frameworks for improving processes/products/profits
Translate analytic insights into concrete, actionable recommendations for business or product improvement
Create and deliver proof of concepts using state-of-the-art algorithms to demonstrate the value of our AI and ML solutions.
Partner closely with digital leaders throughout the lifecycle of project. Ensure that necessary data is captured; analytic needs are well-defined up front and coordinate the analytic needs
Should have independently handled a project technically and experienced in turning ideas into actionable designs
Maintain proficiency within the data science domain by keeping up with technology and trend shifts
Qualifications
Bachelors or master's in computer science or related field
Additional Information
• 4 - 6 years of experience working as a data scientist• Extensive know-how of Python and R, experience in object-oriented programming languages with high code quality (Clean Code). Python environments, Jupyter notebooks.• Exploratory Data Analysis implementation and statistical concepts.• Solid understanding of Feature Engineering, Feature Selection.• Python libraries such as numpy, pandas, sklearn, pytorch, keras, scipy. • Proven track record in machine learning, neural networks, pattern analysis, time series forecasting, data analysis as well as data-pipeline technologies (e.g., Kubernetes, Docker, NoSQL-Databases, Workflow-Engine, Spark, Hadoop.) • Solid understanding of statistics; knowledge of Cloud Technologies (ideally Microsoft Azure) and SQL are beneficial• Excellent communication, presentation & cross-functional collaboration skills",USD 135K - 205K *
467,Data Analyst | 4 to 9 Years | Bangalore & Pune,Capgemini,"Hyderabad, AP, IN",Entry-level / Junior,"Job Description
Data Analyst- Banking or Risk background, Hadoop, Pyspark, Scala, SQL, SAS
Key Words-PLSQL/SQL/Data Analyst/Data Analysis/Data Mapping/Informatica,Talend,Tableau Datastage, Any ETL tool/Power BI/Qlik/reporting/Python/SA
Experience with SQL, Database knowledge, running complex queries when required
Good experience or understanding of SAS
Good hands-on experience in data extraction and transformation using SQL or Oracle PL/SQL
Good understanding of reporting skills - using SQL or via excel
Passionate about Manual research activities - invoices/searches
Primary Skills
Good working experience with excel& Good Analytical Skills
Should be able to drive the Project Individually and provide the solutions as per the client expectation and desired timelines
Candidate must possess Good Communication skills and Cross Functionalities
Secondary Skills
Nice to have: Exposure to Tableau, Python and R
Certified candidates in relevant technologies preferably",USD 56K - 94K *
468,Senior Data Engineer-2,Mastercard,"Pune, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer-2
Overview
As the Senior Data Engineer, you will design and develop enhanced data services and cloud enablement for Data and Services. You will push the limits of the state of the art with best-in-class data product enablement in the cloud and will design the roadmap develop data & analytics solutions that sit atop vast datasets. The challenge will be to dynamically deliver value in the near term while developing capabilities and process that lay the groundwork for the future. Your roadmap will enable a frictionless customer and developer experience, exposing data components for direct to customer use or as components for new product constructs. You will have the opportunity to create high performance analytic and ML solutions based on data sets measured in the billions of transactions and front-end visualizations to unleash the value of big data.

Role
As the Senior Data Engineer, you will:
• Design and develop new data capabilities and infrastructure related to accessing and using MA, third party, and partner data to power Mastercard data products and solutions.
• Design required new data pipes, data transfers, and compliance related infrastructure to enable that use of the data in the cloud.
• Identify data-related capabilities and infrastructure requirements resulting from new and evolving product constructs and how those requirements can be developed cloud natively.
• Understand the Data and Services business strategy, information infrastructure and data needs for both new and existing products and services across various product initiatives.
• Collaborate with relevant data management, data governance and technical teams to enable long term viability of information assets and enterprise requirements.
• Develop a horizontal technology roadmap in conjunction with Data Strategy & Management team input to enable technology solutions for managing data that meet the needs of multiple business stakeholder groups.
• Identify existing data capability and infrastructure gaps or opportunities within and across initiatives and provide subject matter expertise in support of remediation.

All About You
• You are curious about and motivated by the future trends in data, AI/ML, analytics, and digital experience
• Experience in data product development, analytical models, and model governance
• Experience in anonymizing data and managing the use of data
• Experience in data hygiene procedures, identity resolution capabilities or data management a plus
• Exceptional interpersonal skills with proven experience in relationship building and partnering. Must work well in both team and individual settings and must be able to work with a geographically dispersed team.
• Strong analytic capabilities and written and oral communication skills. Attention to detail is a must.
• Strong project management skills and a demonstrated ability to understand complex information product constructs
• Familiarity with industry best practices for collection and use of data
• Motivated self-starter with ability to excel at multi-tasking in a fast-paced environment, outstanding English written and verbal communication skills
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 121K - 186K *
469,Senior Electrical Engineer (Chennai/Noida/Mumbai),Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Ramboll was founded in 1945 in Denmark. Today, we employ 16,000 engineering, design and consultancy specialists. We hold a leading position in the Nordic market (Denmark, Sweden, Norway, and Finland) and have more than 300 offices in 35 countries.
Job Description
We invite you to bring your Electrical System experience into play as you will provide electrical engineering services on projects to Ramboll and its Clients, in coordination with Architects and structural consultants, for all stages; i.e concept, schematic, detailed design, tender & construction. This shall include technical and project leadership within the electrical engineering team. To succeed in this role you must have B.Tech/ M.Tech in Electrical Engineering with 8 to 10 years of professional experience in the relevant field. Are you our new Senior Engineer- Electrical, Buildings? Click the apply-button to send your application.
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies and people around the world.
You will join our Buildings Department
As our new Senior Engineer– Electrical, Buildings you will be part of our global High-Rise department, Ramboll’s dedicated team of high-rise experts which have designed over 150 tall building projects globally, including some of the most technically challenging. You would be responsible for coordinating with project managers and/or engineers for design and draughting work in the High-Rise department in India offices and supporting the global department which also has offices in Copenhagen, Dubai and Singapore.
Your key tasks and responsibilities will be:
As a Senior Electrical Engineer, you shall be responsible for the design and delivery of all electrical and associated ELV systems of a wide range of projects in the building services. Key responsibilities and duties are listed, but not limited to, the below:
Technical engineering of all electrical systems and including:
Lead discipline on projects.
Developing and guiding junior engineers.
Applying policies relating to health & safety, quality, and training.
Preparation of load estimation for the project and conducting primary technical calculations, drawings, reports, specifications and reviews on design deliverables related to electrical system design.
Develop a thorough design philosophy, effectively contributing to the inception, development, and detailed delivery of projects across all stages.
Coordinate and liaise with all other design team members, including architects and structural engineers plus client, project managers and QS.
To act as discipline lead on projects to successfully deliver high quality discipline projects in accordance with corporate and client requirements.
Capability of leading MEP for small to medium sized projects.
Attend external meetings and prepare design presentations and design reports.
Where design on middle east projects is being performed remotely with other Ramboll offices or by subconsultant, collaborate closely with those remote design teams and ensure compliance with local requirements and where directed, assist and represent the satisfactory performance of their services to local clients and stakeholders.
Provide electrical engineering technical support and engage personally where required to successfully enable Local Authorities’ approvals on all projects.
Support client and sustainability sub-consultant in studies, calculations and reports for sustainability options within the project.
Mentor and coach junior and graduate engineers.
Check and review electrical design work undertaken by junior and graduate engineers.
Responsible for the correctness, accuracy, and complete multi-disciplinary coordination of the design documentation in accordance with QA/QC review processes.
Have a good knowledge of buildability & construction techniques.
Demonstrated critical thinking skills, ability to work methodically and analytically in a quantitative problem-solving environment.
Forecast, plan and manage own workload and progress against agreed plan and criteria.
Evaluate and advise to project lead engineer on electrical related design changes to ensure change management.
Strong attention to detail, team working, collaboration, organization, and problem-solving skills.
Have a basic understanding of the financial and commercial management of projects.
Provide technical support to respond to prequalification documents, RFPs, and other client inquiries.
Excellent written and verbal communication skills.
Ensure that Health & Safety is embedded into all work practices in line with company policies.
Maintain and participate in Continuing Professional Development (CPD) events to develop own expertise.
Qualifications
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this Senior Electrical Engineer role, we believe your starting point is:
B.E /M.E in Electrical with 8 to 10 years of professional experience, out of which a minimum of 4 years should be in Middle East projects as an added advantage.
Proven track record in building services design with different types of sectors, including high rise, commercial, residential, retail, healthcare, industrial, educational, refurbishment, etc.
Proven record as a Project Engineer on several projects.
Experienced in working within teams on multi-disciplinary projects and interacting with a wide range of architectural, engineering and planning disciplines.
Advanced knowledge of electrical engineering principles for LV, Lighting, ELV and FA/FLS designs.
Good system overview knowledge of buildings mechanical and public health systems.
An ability to adapt to different working styles and the unique business culture of the Middle East.
Excellent knowledge of local and international design standards, including BS-EN, CIBSE, ASHRAE, NFPA etc.
An excellent knowledge and experience of local statutory authorities’ regulations and submission requirements across Middle East, mainly UAE and KSA, such as DEWA, ADDC, SEC, SBC, Etisalat, Du, Civil Defence etc and procedures for Local Authority approvals.
Proven ability to carry out both manual and computer aided calculations, problem solving, technical analyses, etc.
Proficient in LV power system modelling and analysis software such as Amtech (or similar), lighting software (Dialux Evo, Relux, or similar), Lightning Protection (Strike Risk or similar) and generator sizing.
Competent use of relevant software such as MS Office suite.
Knowledge and experience of AutoCAD, Autodesk Revit and Navisworks would be recommended.
Detailed knowledge of BIM automation / digitalisation techniques and standards.
Knowledge of sustainable design practices and technologies, preferably having worked on LEED or Estidama certified projects.
Personal qualities that will help you succeed in this role include: self-motivated, team player and able to work independently with minimum supervision and a flexible attitude in an environment with frequently changing deadlines and can be relied on to meet deadlines.
Additional Information
Welcome to our Buildings division
As one of the top 10 building designers in the world, Ramboll works on more than 10,000 building projects each year. 5,000 experts across the world specialise in creating more innovative, sustainable and liveable buildings. We place particular emphasis on our liveable buildings concept where we balance the cultural, social and physical values of buildings, to improve the quality of life for building users.
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 45K - 84K *
470,Data Analyst,Marlabs,"Bengaluru, IN",Entry-level / Junior,"Position Role                      :IT - P2 Analyst / Architect (2-5 years of exp.)
Position Location              :Bangalore
A *Data Analyst* occupies an entry-level role 3+ years of experience in a data analytics. In this role, you need to be adept at translating numeric data into a form that can be understood by everyone in an organization. Moreover, you need to have required proficiency in several areas, including programming languages such as python, tools such as excel, fundamentals of data handling, reporting, and modeling.  With enough experience under your belt, you can gradually progress from a data analyst to assume the role of a data engineer and a data scientist.
  *Data Engineers* are the intermediary between data analysts and data scientists. As a data engineer, you will be responsible for the pairing and preparation of data for operational or analytical purposes. A lot of experience in the construction, development, and maintenance of the data architecture will be demanded from you for this role. Usually, in this role, you will get to work on Big Data, compile reports on it, and send it to data scientists for analysis.",USD 56K - 94K *
471,Senior Machine Learning Engineer,G2,Bengaluru,Senior-level / Expert,"About G2 - The Company
G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.
G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here!
About G2 - Our People 
G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.  
As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community  strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs). 
We support our employees by offering generous benefits, such as flexible work, ample parental leave. Click here to learn more about our benefits. 
This is a hybrid position, with the team meeting in person two days a week at our Bengaluru office. 
About the Role
As a Senior Machine Learning Engineer, you'll play a key role in deploying machine learning models, establishing efficient MLOps practices, driving data engineering initiatives, and developing a scalable ML platform. Your responsibilities include deploying models seamlessly into production systems, optimizing them for performance, architecting MLOps pipelines for streamlined operations, and establishing a robust ML platform.
In this role, you will:- 
Data/ML Pipelines and Deployment:
Own the end-to-end deployment process for ML models, ensuring seamless integration into production systems.Optimize models for performance, scalability, and resource efficiency.Drive data engineering efforts, designing and optimizing scalable data pipelines for machine learning services.Develop and maintain robust ML/Data engineering processes, ensuring high data quality and reliability.
Work with cross-functional teams to integrate the machine learning services into the product.
MLOps and Platform:
Lead the design and implementation of a scalable ML platform, facilitating efficient model development and deployment.Architect infrastructure in support of rapid experimentation and evolving requirements.Implement CI/CD pipelines to ensure continuous integration and deployment of ML models.
Establish MLOps pipelines, automating model training, deployment, and monitoring processes.
Implement engineering standards and best practices.
Mentorship and Guidance (20%):
Provide technical guidance to the team, enabling skill development and fostering best practices.Guide the data science team with the latest MLOps practices.
Collaborate with larger engineering team to facilitate brainstorming sessions and ideate on platform best practices
Requirements:- 
6+ years of experience in the field of machine learning engineering.
4+ years of hands-on experience in deploying ML models and MLOps practices.
2+ years of experience in data engineering.
Proficiency in Python,  coupled with hands-on experience in ML frameworks such as Tensorflow, Scikit-Learn, and PyTorch.
Expertise in designing scalable data and ML pipelines.
Experience in managing ML infrastructure.
Hands-on experience with Docker, Kubernetes, and Helm.
Hands-on experience with SQL/No-SQL
Hands-on experience with AWS/Azure Data/ML-related  services.
Hands-on experience with Flask/FastAPI/Django REST services.
Thorough understanding of distributed systems and design patterns.
Proficiency in tools like MLFlow, DVC, Kubeflow, and Airflow.
Experience in startup environments.
Experience as Machine Learning Engineer or Architect.
Experience in System Design.
Experience in Platform Engineering and Related Concepts.
Our Commitment to Inclusivity and Diversity
At G2, we are committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, or marital, veteran, or physical or mental disability status. 
Learn more about our commitments here Commitments",USD 150K - 230K *
472,Sr Staff Machine Learning Engineer,ServiceNow,"Bengaluru, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
12+ years of related experience with a Bachelor's degree; or 8 years and a Master's degree; or a PhD with 5 years' experience; or equivalent work experience
Expertise in Java or Python, OOP, Design Patterns, time and space-efficient algorithms
Experience building new products that use challenging algorithms
Expertise in coding efficient, object-oriented, modularized and quality software
Knowledge of core AI/ML techniques and algorithms
Knowledge of unit testing, profiling, and code tuning
FD21
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 150K - 230K *
473,Computer Vision Intern,Bureau,Bengaluru,Entry-level / Junior,"About Bureau 
At Bureau, we take care of risks so that our clients take care of their business. Bureau is a no-code Identity Decisioning Platform that enables seamless customer onboarding and fraud-free customer interactions. Our no-code identity orchestration platform protects and accelerates onboarding, verification, and transactions — without introducing friction for the end users. Our innovative technologies and data-driven approach enable our clients to mitigate risks, enhance security, and build trust with their customers. We prefer trustworthiness over creditworthiness!
We are seeking a highly motivated and skilled Computer Vision Intern to join our dynamic team. As a Computer Vision Intern, you will have the opportunity to work on cutting-edge projects, applying your knowledge and expertise to solve real-world challenges. This internship will provide hands-on experience in the field of computer vision and machine learning.
Responsibilities:
Collaborate with the team to understand project requirements and objectives.
Develop and implement computer vision algorithms for image and video analysis.
Work on tasks such as object detection, image segmentation, and feature extraction.
Assist in the design and implementation of machine learning models for computer vision applications.
Explore and experiment with state-of-the-art computer vision techniques.
Collaborate with cross-functional teams to integrate computer vision solutions into larger systems.
Conduct research on emerging trends and technologies in computer vision.
Qualifications:
Currently pursuing a degree in Computer Science, Electrical Engineering, or a related field.
Strong programming skills in Python.
Familiarity with popular computer vision libraries and frameworks (OpenCV, TensorFlow, PyTorch).
Solid understanding of image processing, computer vision algorithms, and machine learning concepts.
Previous coursework or projects related to computer vision is a plus.
Strong problem-solving and analytical skills.
Excellent communication and collaboration abilities.",None
474,Data Scientist (all genders),HRS,"Chandigarh, Mid-Senior level, IN",Entry-level / Junior,"Job Title: Data Scientist (m/f/d)
BUSINESS TRAVEL CLUB
The HRS Business Travel Club (BTC) is the Business Unit managing and developing the HRS E-Commerce platforms of the well-known hotel portal businesses of HRS.de and HOTEL.DE that gradually transform into much more than “just” a platform. BTC provides its members, individual business travelers and SMEs, with a distinct range of exclusive services, which shape tomorrow´s upgraded travel experience. The goal of BTC is to deliver growth as well as sustainable profitability over time by enhancing customer loyalty between the Brand and its Customers, enabling the Brands Repositioning in the marketplace and unlocking additional potentials via optimized Supplier Management. Thus, BTC and its products, plays an important role in HRS´s DACH strategy as it revolves around a disruption of the interplay between hotel and workplace supply and e-commerce and a domination of the Business Travel DACH market. 
Your mission is to further develop and shape the ""The HRS Business Travel Club"" and its solutions and make it the next innovation of the HRS Group together with a great team.
  POSITION
We are looking for a Cologne based Data Scientist (m/f/d) who helps building a next-generation Customer Data Platform enabling our customers to find their perfect hotel for every trip, and helping our hotel partners growing their business.
  CHALLENGE
Work on analyzing, understanding, challenging and documenting requirements towards the Customer Data Platform (CDP) within HRS Group together with business and steering teams from sales & marketing, as well as management ensuring continued development of the CDP to serve HRS Group’s strategic vision.
Translate requirements into technical- and analytical designs and ensure implementation and testing of the proposed solutions leveraging state-of-the-art cloud technologies for data engineering and data science.
Develop new analytics solutions helping identify customer needs and uncover potential for innovative Marketing approaches in line with HRS Group’s overall audience-based Marketing strategy.
Collaborate with data engineers and data scientists across HRS Group to establish best-practices, exchange on latest trends, and stay abreast of your area of responsibility
Work together with the management team to continuously refine and develop HRS Group’s audience analytics capabilities and audience strategies
  FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
A degree in business computer science, mathematics or a comparable qualification.
Proven hands-on experience in data engineering or data science.
Superior expertise in Python, R, and SQL
Knowledge of cloud technologies such as AWS, GCP, Azure, esp. Kubernetes, Docker, Google BigQuery, and Apache Airflow
Sound project campaign management capabilities, and commercial awareness.
Ideally, experience with analytical CRM, CDPs, Marketing Automation, or integrated Sales & Marketing setups.
Fluent in German and English.
  PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.

Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
  LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 126K - 198K *
475,Data Analyst Qliksense,Capco,India,Entry-level / Junior,"Joining Capco means joining an organisation that is committed to an inclusive working environment where you’re encouraged to #BeYourselfAtWork. We celebrate individuality and recognize that diversity and inclusion, in all forms, is critical to success. It’s important to us that we recruit and develop as diverse a range of talent as we can. We believe that everyone brings something different to the table – so we’d love to know what makes you different.
We are/have:
Experts in banking and payments, capital markets and wealth and asset management
Deep knowledge in financial services offering, including e.g. Finance, Risk and Compliance, Financial Crime, Core Banking etc.
Committed to growing our business and hiring the best talent to help us get there
Focused on maintaining our nimble, agile and entrepreneurial culture
  QlikView/QlikSense Developer
  Job Description Statement
  We are expanding our team to include Qlik technologists. This Senior Visualization Developer will be responsible for designing and delivering Qlik data models and dashboards to support our needs. The candidate would-be hands-on developer, actively participating in Agile Process, keen on learning new technologies, setting high standards for himself and in the team. The role requires complete comprehension of enterprise data models and utilization of both relational and dimensional data sources. The ideal candidate will have experience in Qlik design and development with a general understanding of BI and reporting.
  Responsibilities
Leverage Qlikview technology (Qlikview, Qliksense, N-printing) and other BI tools for reporting analytics and data visualization and delivery
Facilitate the performance tuning of reports and universes and timely issue resolution related to reporting support.
Ensure high quality BI solution deliveries.
Server Performance, capacity, utilization monitoring and Health monitoring Optimization and Performance tuning of QlikSense & Qlikview applications
Define best practices for QlikSense & Qlikview deployment and create reusable templates
Perform detailed analysis of source systems and source system data and model that data in Qlik.
Hands on experience with Qlik sense Extensions (Javascript/Angular)
Advanced knowledge using set analysis & variables.
Familiarity with section access, databases, universes, and business process flows
Design, develop, and test Qlik scripts to import data from source systems and test Qlik dashboards to meet client requirements.
Team player exhibiting professional maturity, personal integrity, and excellent interpersonal skills, can-do attitude
Create and maintain technical design documentation
Perform quality coding to business and technical specifications
Extracting, transforming, and loading data from multiple sources into QlikView applications
    Desired Skills &Experience
Experience in developing Qlik Solutions
Experience in sourcing data from disparate systems with a good understanding of their Data Models and ETL procedures
Hands-on professional with thorough knowledge of scripting, data source integration and advanced GUI development in Qlik
Full understanding of the processes of data quality, data cleansing and data transformation
Ability to write complicated yet efficient SQL queries and stored procedures
Experience in end-to-end implementation of Business Intelligence (BI) projects, especially in scorecards, KPIs, reports & dashboards
Experience in Qlik Sense Mashups,Cloud
  Other Skills
A bachelor’s degree in computer science, information technology, information systems, or a related discipline
7+ years of experience utilizing Qlik to implement analytical solutions accessing and integrating data from multiple sources
7+ years of experience developing Business Intelligence (BI) and Analytical Solutions
Enthusiastic about learning large and complex systems
Detail-oriented with strong organizational, analytical and communication skills
Results-driven with the ability to take initiatives, handle multiple tasks and shifting priorities and meet deadlines
Able to multi-task in a fast-paced, dynamic environment
Excellent problem-solving skills, logical process thinking and end-to-end system concepts
WHY JOIN CAPCO?
You will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry.
We offer:
A work culture focused on innovation and creating lasting value for our clients and employees
Ongoing learning opportunities to help you acquire new skills or deepen existing expertise
A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients
A diverse, inclusive, meritocratic culture
 ",USD 56K - 94K *
476,Data Scientist for 3rd Party Data Management,SAP,"Bengaluru, KA, IN, 560066",Entry-level / Junior,"We help the world run better
Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.Apply now! 
  WHAT YOU'LL DO:
  We are looking for an IT Technology Consultant (f/m/d) to strengthen our global engineering team dedicated to ingesting, processing and distributing external data at SAP, you will be in charge of delivering against a portfolio of data engineering/software engineer related topics such as:
- Building data pipelines to ingest data coming from more than 20 different data sources
- Improving internal processing engines of data (cleaning-up, normalization, quality control, matching, merging) with a strong performance component
- Building and managing data related simple full stack apps
- Building and managing data related analytical dashboards
- Delivering on requirements coming from a large spectrum of requirements: from data management expert to marketing & sales operatives on the ground
- Comply with our corporate and unit strategies when it comes to technical decisions
  WHAT YOU BRING:
  As data/software engineer, you will be expected to solve technical challenges & innovate in a highly complex enterprise environment. To do so, you will be expected to posess a certain skillset, including:
- Programming experience with SQL is mandatory
- Programming experience in at least one of the following languages: python, java, scala, spark (pyspark), javascript
- Experience dealing with REST APIs, SFTP Servers, SDKs
- Basic understanding of CI/CD concepts
- Experience with Databricks is a big plus
- Experience with SAP technological platform is a big plus: SAP Hana, SAP BTP, Cloud Foundry, SAP Dataspshere
- Understanding of Data lakes/lakehouses concepts is a plus
- Knowledge of SAFe or other agile methodologies is a plus
  MEET YOUR TEAM:
  Enterprise Data Technology (EDT) is part of the IES (IT) organization and responsible for providing consultancy & technology expertise in data management, delivering impactful data projects to the entire SAP organization
      We build breakthroughs together
SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together.
We win with inclusion
SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.
SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com
For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.
EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.
Successful candidates might be required to undergo a background verification with an external vendor.
Requisition ID: 366889  | Work Area: Information Technology  | Expected Travel: 0 - 10%  | Career Status: Professional  | Employment Type: Regular Full Time   | Additional Locations: #LI-Hybrid.
 ",USD 126K - 198K *
477,Project Data Manager,Novo Nordisk,"Bengaluru, Karnataka, IN",Mid-level / Intermediate,"        Position Title : Project Data Manager
  Job : Data Management Specialist
  DEPARTMENT:  Phase 2-4, Rare Disease and Advanced Therapies, Trial Data Management – Bangalore.
  Are you someone who is passionate about Project Leadership, Data Literacy, and Generate data insights from Data analytics tools and be the part of an incredible team who change patient lives? Do you have an innovative mindset to drive change in a future-ready environment and support your colleagues and stakeholders by challenging the status-quo in a friendly and open-minded way? If so, there is a job opportunity waiting for you as Project Data Manager. At Novo Nordisk, we will challenge you to do the best work of your life. Apply Now.
  About the Department
The Trial data management department was established in Bangalore, India in the month of September 2007 and has significantly grown. It is a young, enthusiastic, and dynamic team with varied skillsets and professionals from diverse backgrounds such as pharmacy, life-sciences, physiotherapy, computer/information sciences and business administration. The key objective of the department is to ensure high quality data delivery to the stakeholders. The involvement of various groups in data management is significant in key stages of trial setup, conduct and closeout.
  Project Data Manager will be part of Rare Disease and Advanced Therapies team, Trial Data Management Bangalore where overall Novo Nordisk phase 2-4 clinical trials project responsibility is anchored.
  The Position
The Project Data Manager (PDM) is overall responsible for the data management deliverables in a Clinical Development Project. The Project Data Manager is a leader within the DM community and represents the project’s data management area both inside and outside the project. In addition, the PDM is a sparring partner to management and other project stakeholders.
The Project Data Manager demonstrates subject matter expertise with in-depth knowledge and experience and extensive business understanding across the SVP area. The PDM is perceived as an expert within one or several key data management processes and handles specialist tasks of high complexity critical to Data Management. The PDM works independently with minimal guidance and acts as a resource for colleagues with less experience. The PDM uses best practices and knowledge of internal or external business issues to improve processes.
  Participate and Provide input in early trial design to optimise the design, pro-actively identify gaps, risks and issues for upcoming trials and projects. Take accountability for end-to-end DM deliverables from data collection to SDTM.
Ensure data quality on the trials and timely achievement of major DM deliverables. Maintain project overview, including project level oversight of vendor performance.
Accountable for timely and quality DM deliverables, alignment across trials in a project supporting direction within the DM Project and Trial.
Contribute and support with development of high-performance teams, build a TDM project team. Empower the CTDMs to make decisions and set direction for their trial. Support complex issue resolution on the trial.
The Project Data Manager is accountable for setting and supporting direction within the Data Management Project and Trial. Lead the Project DM triage and ensure collaboration with the lead CDP and lead SDTMP. Set expectations with CTDM PoC, lead CDP and lead SDTMP about communication and status updates. Provide input to TDM strategy together with management and support the TDM strategy to action.
Accountable and driving the projects across Rare Disease and Advanced Therapies therapeutic area phase 2-4 clinical trials across the globe.
      Qualifications
MSc/BSc in Natural/Life Science or comparable degree in medicine, nursing, pharmacy, veterinary science or clinical information management or equivalent qualifications and a degree in computer science or equivalent professional experience.
Minimum 8  years of experience in data management and the majority of this within Pharma Industry or Development.
PhD with 4-5 years relevant experience /Masters with 6-8 years relevant experience/ Bachelor with 10+ years relevant experience or equivalent knowledge through relevant practical experience.
Therapeutic area knowledge on Rare Disease and the advanced cell therapies associated with the rare disease clinical trials will be an added advantage.
Experience in driving automation, proven facts on utilising AI & ML for clinical trial data management will be highly preferred.
Knowledge on industry trends, regulatory requirements and experience in Health Authorities inspections.
Excellent knowledge within a specific process and extensive business understanding across SVP area. In depth understanding of GCP and relevant regulatory requirements.
Analytical understanding of the processing and flow of clinical data ,project management experience and project leadership in an international organisation.
Ability to build and maintain solid international networks. Substantial experience in global end cross-cultural collaboration.
Good project management and leadership skills. Good presentation, communication and negotiation skills.
Strategic thinking, Experience with mentoring, team building and best practice sharing.
Fluent in written and verbal English.
    Working at Novo Nordisk
At Novo Nordisk, we do not wait for change. We drive it. We are a dynamic company in an even more dynamic industry, and we know that what got us to where we are today is not necessarily what will make us successful in the future. We embrace the spirit of experimentation, striving for excellence without fixating on perfection. We never shy away from opportunities to develop, we seize them. From research and development, through to manufacturing, marketing, and sales – we are all working to move the needle on patient care.
  Contact
To submit your application, please upload your CV online (click on Apply and follow the instructions). 
  Deadline
4th Jan 2024
We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 73K - 115K *
478,Lead Engineer - HVAC (Noida/Chennai/Mumbai),Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Work at the heart of sustainable change
Ramboll is a global architecture, engineering, and consultancy company. We believe that the purpose of sustainable change is to create a thriving world for both nature and people. So, that’s where we start – and how we work. At Ramboll, our core strength is our people, and our history is rooted in a clear vision of how a responsible company should act. Being open and curious is a cornerstone of our culture. We embrace an inclusive mindset that looks for fresh, diverse, and innovative perspectives. We respect, embrace, and invite diversity in all forms to actively cultivate an environment where everyone can flourish and realise their full potential.
Job Description
Main Job Responsibilities:
Be responsible for delivering work to a fee agree with Project Manager
 Quality task delivery to agreed deadline and fee
 Attend to project / site technical matters
 Present to clients if required at times
 Construct project teams from internal and external resources
   Attend team meetings and play an active role in the development of procedures within your team
 Have an understanding of business plan, mission statements and key challenges
 Have knowledge of concept design, buildability, detailed design, construction techniques, procurement routes, risk assessment and claim assessment
 Prepare drawings and calculations. Check drawings / review calculations from Engineers ( or CAD at time)
 Have knowledge of our delivery in CAD standards
 Contribute to project QA policy
 Implement project QA policy
 Supervise office filing system set-up and maintenance to office standard.
 Review and comment on company procedure documents using the feedback system
 Apply policies relating to health & safety, quality and training
 May serve as a project engineer and as a designated client contact on smaller, less complex projects
 Qualifications
Required Knowledge & Skill :
Excellent organizational skills, effective time management, including the ability to deal with conflicting demands in order to meet deadlines, prioritize heavy workload and have a willingness to work flexibly.
Preparation of heat load calculations with the Use of HAP latest versions.
Preparation of HVAC design Reports
Design HVAC systems and single line diagrams for the system.
Spatial planning at the concept stage.
Designing of HVAC system layouts in coordination with Architects, client and structural consultants.
Preparation of specification, bill of quantities and price estimates.
Assist during vendor bidding and negotiation meetings along with the client to represent the technical queries.
Coordination within departments such as Electrical / PHE and others to ensure that the services are well coordinated. 
  Qualification and Experience required:
Must possess with 10-15 years of professional experience in HVAC Design
Additional Information
 About Ramboll
Founded in Denmark, Ramboll is a foundation-owned people company. We have more than 18,000 experts working across our global operations in 35 countries. Our experts are leaders in their fields, developing and delivering innovative solutions in diverse markets including Buildings, Transport, Planning & Urban Design, Water, Environment & Health, Energy, and Management Consulting. We invite you to contribute to a more sustainable future working in an open, collaborative, and empowering company. Combining local experience with global knowledge, we together shape the societies of tomorrow.
 Equality, diversity, and inclusion is at the heart of what we do
We believe in the strength of diversity and know that unique experiences and perspectives are vital for creating truly sustainable societies. Therefore, we are committed to providing an inclusive and supportive work environment where everyone can flourish and reach their potential. We welcome applications from candidates of all backgrounds and encourage you to contact our recruitment team to discuss any accommodations you need during the application process",USD 45K - 84K *
479,"Principal Engineer (Python, AWS Data Engineer)",Verisk,"Hyderabad, India",Senior-level / Expert,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
Requirements:
8+ years of proven experience in software development and system maintenance.
Highly proficient experience and understanding in the following technologies: Python 2/3, Linux, AWS, OLTP and OLAP databases, any Data Warehouse
Ability to learn and adapt to continuously changing technology.
Demonstrated experience with N-tiered applications and multi-tier architecture.
Highly experienced at developing elegant-yet-simple systems using best practices and design patterns.
Highly experienced with multi-threading, memory management, networking, I/O concepts, and performance aspects of common classes and algorithms.
RDBMS based on MPP/Cluster, Jupyter, Docker, Kubernetes, Spark, Git, CI/CD.
Experience with any of the following technologies a plus: Snowflake (DBaaS), Greenplum.
Highly experienced at leading teams, interacting with business partners or customers, and guiding project direction.
Excellent understanding of object-oriented design concepts and software development processes and methods.
Superior organization skills, skilled at recognizing priorities and keeping a team focused most important features.
Must have passion for development and latest technologies
Leadership and ability to guide design and technical meetings
Demonstrated ability to work independently with minimal supervision.
.NET and Angular experience desirable
Tableau/Tableau server experience desirable
Qualifications
Accountable for leading application development supporting business objectives while demonstrating independence in software development lifecycle phases from concept and design to testing.
Lead new and existing applications along with enhancements to applications and infrastructure.
Perform hands-on coding while designing and architecting data processing and analytics solutions.
Serve as a liaison to internal customers, research groups and various business support areas.
Provides technical guidance to junior programmers and other software engineers.
Ability to troubleshoot and maintain mid-level to complex applications.
Completes all responsibilities as outlined on annual Performance Plan.
Completes all special projects and other duties as assigned.
Must be able to perform duties with or without reasonable accommodation.
#LI-NK1
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 45K - 84K *
480,DMU Integration Engineer (Airframe),Airbus,Bengaluru (Airbus),Mid-level / Intermediate,"Job Description:
Airbus India is looking for a Propulsion/Cabin/Airframe Integration Engineer - DMU to join our Cabin Design and DMU Integration Team which is responsible for Cabin design, and  Integration activities. Within the overall framework, Integration involves performing integration activities (DMUi, SSCI and IFM) for various ATAs for cabin as well as airframe perimeter.
The span and the variety of projects ongoing in the integration perimeter offer great opportunities for technical and leadership development.
Qualification & Experience:
We seek out innovative minds. We value attention to detail, and we care deeply about outcomes. We are looking above all for passionate people, eager to learn, willing to share, establishing innovative ways of working and influencing stakeholders.  
Bachelor/ Master Degree in Aerospace, Automotive or Mechanical, Electrical/Electronics Engineering.
2 - 5 years of experience in one or more areas out of  electrical/mechanical system installation, design and configuration management 
Technical Skills:
Strong experience with Catia V5 for the creation & validation of 3D models (System Installation) and exposure to DMUi & SSCI activities would be an added advantage.
DMU understanding and navigation of Product Structure with clear understanding.
Knowledge on Aircraft build process and basic understanding of Aircraft systems.
Experience in handling PDM/VPM tools and link to CAD models with design in a context environment.
Ability to perform trades in System installation for ESI and MSI.
Good Project Management skills to drive the performance KPIs & improvements proactively.
Good understanding of Aircraft Function, Operation & Processes.
Awareness of Airbus processes & methods would be an added advantage.
Soft skills:
Very good communication and presentation skills 
Ability to demonstrate effectiveness in holding conversations with customers and customer-centric outreach. 
Ability to work in a fast paced environment with changing priorities and requirements.
Demonstrate agility and autonomy in a transnational environment.
Demonstrate ability to work as a team in a highly collaborative environment.
Ability to coordinate the efforts of a large team of diverse specialists & experts.
Ability to lead in an environment of constant change involving multiple internal processes.
Responsibilities:
Integration engineer is responsible for the technical content of configured multi- system cDMU (Configured DMU) to be compliant with Airbus Design Rules, safety, maintainability, industrialization and multi-System integration constraints. 
He/she is responsible in his/her zone for the design integration. He/she is empowered to reject Design Solutions not respecting quality, design rules and integration constraints.
The main challenges of the Mission are to:
Ensure the consistency between the Configured DMU and the design intent for the Airbus design teams.
Propose and implement the improvements in terms of System Installation with impact on weight, lead-time and cost of the aircraft.
Create a global network within integration community and other organizations to work beyond siglum
Lead , convince, and influence with no hierarchical link
Set up and steer new governance and process for a new development
Propose and implement digitization ideas through new ways of working.
Reporting of all activities as per Airbus procedures.
Willing to travel internationally and work in a multi-cultural environment on a need basis.
Key skills : System Installation, DMU, Cabin
Job Disclaimer and Notification:
We bring to the notice of all concerned that Airbus Group India Pvt. Ltd (hereinafter  referred to as ""AIG"") follows a fair and merit-based employee selection and recruitment  practice. 
Airbus Group India does not: 
∙ Send job offers from free email services including but not limited to Gmail,  Rediffmail, Yahoo mail, Hotmail and others. 
∙ Authorize anyone to either collect money or arrive at any monetary arrangement in  return for a job at AIG. 
∙ Charge / accept any form of consideration or security deposit from job seekers and  applicants during any stage of the selection and/ or recruitment process. ∙ Request for your credit card number or bank account number. 
It has come to our attention that fake job offers under the aegis of Airbus India or  Airbus Group India Pvt. Ltd. have been circulated by unauthorized personnel. On receipt of an interview call for any job at AIG, the candidate may take some  measures such as visiting the official website or career site of Airbus to get the contact  details to enquire with the Human Resources department of Airbus India regarding such jobs and/or the interview details and any other relevant information. 
For further information on Airbus India Careers, please click here. 
Please check www.airbus.com to get the contact details and enquire with the company  to confirm if any information that you have received are genuine; do not respond to any  fraudulent communication. 
AIG will not be responsible to anyone acting on an employment offer not directly made  by Airbus Group India Pvt Ltd. Anyone making an employment offer in return for money  or other type of gain is not authorized by AIG and is not offering an approved job. AIG  reserves the right to take legal action, including criminal action, against such  individuals/entities.
This job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Company’s success, reputation and sustainable growth.
Company:
Airbus Group India Private Limited
Employment Type:
Permanent
-------
Experience Level:
Entry Level
Job Family:
Structure Design & Integration
By submitting your CV or application you are consenting to Airbus using and storing information about you for monitoring purposes relating to your application or future employment. This information will only be used by Airbus.
Airbus is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.
Airbus is, and always has been, committed to equal opportunities for all. As such, we will never ask for any type of monetary exchange in the frame of a recruitment process. Any impersonation of Airbus to do so should be reported to emsom@airbus.com.
At Airbus, we support you to work, connect and collaborate more easily and flexibly. Wherever possible, we foster flexible working arrangements to stimulate innovative thinking.",USD 30K - 56K *
481,Data Engineer Fresher,MRI Software,"Bengaluru, India Office",Entry-level / Junior,"At MRI Software, we're in search of a dedicated Junior Data Engineer to become a vital part of our dynamic team. As a Junior Data Engineer, you'll have the chance to contribute to our rapidly growing group of analytics experts. Your role will involve enhancing and refining our data and pipeline architecture, as well as streamlining data flow and collection to benefit cross-functional teams.
Position Overview: Joining our Business Intelligence team, you'll play a crucial role in ensuring the seamless implementation and ongoing maintenance of our Data Warehouse (DWH), Reporting, and ETL pipelines.
Essential Qualifications:
Demonstrated aptitude for navigating complex datasets from diverse sources, formats, and structures, with a strong preference for experience in the Real Estate domain.
Practical hands-on experience with Azure Data Factory or Azure Synapse Analytics.
Proficiency in SQL, PL/SQL, ETL tools, and techniques for enhancing performance across the ETL technology stack.
Practical familiarity with data storage, database management, ETL implementations, and visualization creation.
Exposure to version control systems such as Github or Gitlab, as well as deployment and continuous integration tools.
Familiarity with STAR and SNOWFLAKE schema techniques, with a proven track record of their application.
Understanding of data warehouse schemas and OLAP techniques.
Desirable Skill Set:
Some experience in coding with Python/Spark for data processing.
Exposure to web data extraction, handling unstructured data, advanced text parsing, and machine learning concepts.
Key Responsibilities:
Participate in the design, development, and implementation of database and ETL pipelines.
Contribute to the creation of scalable designs adaptable to an agile delivery environment.
Assist in architecting, planning, and implementing end-to-end Data Warehouse and Business Intelligence systems, incorporating best practices from Data Architecture, Integration, and Management realms.
Compile extensive and intricate datasets meeting functional and non-functional business requirements.
Other Requirements:
A background of 1 years in information technology, primarily in analytics, business intelligence, consulting, or strategy, showcasing proficiency in translating data into actionable insights using SQL/PLSQL.
Effective organizational, time management, and communication skills.
A working grasp of current trends and techniques within the relevant technical track is a plus.",USD 60K - 125K *
482,Senior Data Engineer,Swiss Re,"Hyderabad, TG, IN",Senior-level / Expert,"About the Role:
As a Data Engineer, you will be responsible for leading the design and implementation of complex data pipelines and analytics solutions to support key decision-making business processes in our Reinsurance Client Solutions business domain. You will lead the development of strategic use cases within our Data Integration and Analytics platform. You will gain exposure to projects that are leveraging cutting edge technology that applies Big Data and Machine Learning to solve new and emerging problems for Swiss Re Reinsurance Client Solutions.
  You will be expected to work with business experts to understand client requirements and design and develop solutions to meet those needs. You will have end-to-end ownership of deliverables, gaining a full understanding of the Reinsurance data, Client data, and the business logic required to deliver analytics solutions.
  Key responsibilities include:         
Work closely with Product Owners, Business Analysts and Architects to understand requirements, formulate solutions and evaluate the implementation effort.
Design, develop and maintain scalable data transformation pipelines.
Design and implement analytics models and visualizations to provide actionable data insights.
Evaluate new capabilities of the analytics platform, develop prototypes and assist in drawing conclusions about the applicability to our solution landscape.
Collaborate within a global development team to design and deliver solutions.
Assist colleagues and clients with data-related functional and technical issues.
  About the Team:
This position is part of the Swiss Re Solutions Data & Technology organization. We are enabling our Clients to make data driven decisions at all stages of their value chain with the help of Swiss Re data and expertise.
  About You:
You relish the challenge of solving complex big data analytics problems using state-of-the-art technologies as part of a growing global team of data engineering professionals. You are a self-starter with strong problem-solving skills and capable of owning, designing and implementing solutions from start to finish. Key qualifications include:
  Experience designing and implementing data analytics solutions on enterprise data platforms and distributed computing (Spark/Hive/Hadoop preferred).
Proven track record of understanding and transforming customer requirements into a best-fit design and architecture.
Demonstrated experience in end-to-end data management, data modelling, and data transformation for analytical use cases.
Working experience in Palantir Foundry platform is preferred.
Proficient in Python/PySpark.
Proficient in SQL (Spark SQL preferred).
Experience with JavaScript/HTML/CSS a plus.
Experience working in a Cloud environment such as Azure or AWS is a plus.
Experience with Scrum/Agile development methodologies.
At least 5 years of experience working with large scale software systems.
Bachelor's degree level or equivalent in Computer Science, Data Science or similar discipline.
Knowledge of Insurance Domain or Financial Industry is a strong plus.
Experienced working in multicultural globally distributed teams.
Self-starter with a positive attitude and a willingness to learn, who can manage their own workload.
Strong analytical and problem-solving skills.
Strong interpersonal and communication skills, demonstrating a clear and articulate standard of written and verbal communication in complex environments.
  About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127805 
   ",USD 121K - 186K *
483,Senior Data Scientist,Ninja Van,"Hyderabad, India",Senior-level / Expert,"Ninja Van is a late-stage logtech startup that is disrupting a massive industry with innovation and cutting edge technology. Launched 2014 in Singapore, we have grown rapidly to become one of Southeast Asia's largest and fastest-growing express logistics companies. Since our inception, we’ve delivered to 100 million different customers across the region with added predictability, flexibility and convenience. Join us in our mission to connect shippers and shoppers across Southeast Asia to a world of new possibilities. 

More about us: 
- We process 250 million API requests and 3TB of data every day.
- We deliver more than 2 million parcels every day.
- 100% network coverage with 2600+ hubs and stations in 6 SEA markets (Singapore, Malaysia, Indonesia, Thailand, Vietnam and Philippines), reaching 500 million consumers.
- 2 Million active shippers in all e-commerce segments, from the largest marketplaces to the individual social commerce sellers.
- Raised more than US$500 million over five rounds.

We are looking for world-class talent to join our crack team of engineers, product managers and designers. We want people who are passionate about creating software that makes a difference to the world. We like people who are brimming with ideas and who take initiative rather than wait to be told what to do. We prize team-first mentality, personal responsibility and tenacity to solve hard problems and meet deadlines. As part of a small and lean team, you will have a very direct impact on the success of the company.
Roles and Responsibilities
Own projects end-to-end, right from formulating the problem, through developing a solution, monitoring and maintaining solution performance.
Communicate and collaborate with business stakeholders to identify opportunities to leverage on data assets for the organisation.
Develop data products centered on machine learning / artificial intelligence to support business and operational needs, impacting growth.
Work with engineering and product teams to drive productionisation of data products creating value to our stakeholders.
Accelerate growth of our research arm, to build a world-class data organisation focused on rapid experimentation and discovery.
Mentor and coach junior data scientists.
Requirements
Bachelor’s degree in Data Science, Statistics, Machine Learning, Mathematics, Computer Science, Economics, or any other related quantitative field.
5 years of working experience working in data science capacity within a fast-paced and complex business setting.
Proficiency in data analysis language (Python / R) and strong in fundamentals of machine learning libraries.
Deep knowledge in statistics, probability and foundational machine learning.
Strong communication skills in writing and presentation.
While we use SQL, Python (and their libraries) in our daily work, we welcome new ideas from you to further develop our toolset.
Tech Stack
Backend: Play (Java 8+), Golang, Node.js, Python, FastAPI
Frontend: AngularJS, ReactJS
Mobile: Android, Flutter, React Native
Cache: Hazelcast, Redis
Data storage: MySQL, TiDB, Elasticsearch, Delta Lake
Infrastructure monitoring: Prometheus, Grafana
Orchestrator: Kubernetes
Containerization: Docker, Containerd
Cloud Provider: GCP, AWS
Data pipelines: Apache Kafka, Spark Streaming, Maxwell/Debezium, PySpark, TiCDC
Workflow manager: Apache Airflow
Query engines: Apache Spark, Trino

Submit a job application
By applying to the job, you acknowledge that you have read, understood and agreed to our Privacy Policy Notice (the “Notice”) and consent to the collection, use and/or disclosure of your personal data by Ninja Logistics Pte Ltd (the “Company”) for the purposes set out in the Notice. In the event that your job application or personal data was received from any third party pursuant to the purposes set out in the Notice, you warrant that such third party has been duly authorised by you to disclose your personal data to us for the purposes set out in the the Notice. ",USD 135K - 205K *
484,Data Operation Engineer,Wabtec,Bengaluru - KA - IND (ITC Greens),Senior-level / Expert,"Wabtec Corporation is a leading global provider of equipment, systems, digital solutions and value-added services for freight and transit rail. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation and Faiveley Transport, the company has unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems. Wabtec is focused on performance that drives progress, creating transportation solutions that move and improve the world. Wabtec has approximately 27,000 employees in facilities throughout the world. Visit the company’s new website at: http://www.WabtecCorp.com.

It’s not just about your career… or your job title…it’s about who you are and the impact you are going to make on the world. Do you want to go into uncharted waters…do things that haven’t been done to make yours and someone else's life better? Wabtec has been doing that for decades and we will continue to do so! Through our people, leadership development, services, technology and scale, Wabtec delivers better outcomes for global customers by speaking the language of industry.
Job Title – Data Operation Engineer.
Position: Engineer, IT Operations II 
Band:  I
Summary:
Wabtec IT Data & Analytics (DnA) Team…at the forefront of the business priorities in building a next generation data and analytics ecosystem…is looking for a Sr. Operations Engineer to lead the operations of large-scale data analytics solutions and platform operations.
This hands-on position is responsible for DevOps support to provide technical expertise and lead a team of data operations contractors in maintaining our Data Lake platform, application support and maintenance operations. We expect this person is self-motivated, a quick learner and who has worked on AWS & has experience on working with cloud platform hosting BigData / Hadoop distributed data environment. This Operations Engineer is a technical professional responsible for participating in the design, development, testing, implementation, and the support of the Cloud platform ecosystem. This role also supports efforts to create infrastructure to streamline development and deployment of applications using modern Cloud DevOps practices.
If you are enthusiastic and passionate about NextGen platform hosting and maintaining infra- operations, then we are looking for you!
Duties and Responsibilities: 
Responsible for maintaining large scale production EMR cluster
Well versed with AWS - EMR/ S3, and other AWS services and dashboards. Preferred - AWS certification for EMR cluster management
Strong knowledge of Kerberos for operation and debugging issues in Hadoop
Point of contact for Hadoop related issues coming from Application teams and internal clusters, responsible for troubleshooting and recommendation for Spark and MR jobs. Should be able to use existing logs to debug the issue
Responsible for implementation and ongoing administration of Hadoop infrastructure including monitoring, tuning, and troubleshooting
Improve scalability, service reliability, capacity, and performance of the cluster and applications running in the cluster
Triage production issues when they occur with other operational teams
Conduct ongoing maintenance across our large-scale deployments across the time zones and countries
Write automation code for managing large Big Data clusters
Identify ways to improve infra reliability, efficiency, and quality.
Minimum Qualifications & Eligibility Requirements:   
Bachelor's Degree in Information Systems, Information Technology (IT), Computer Science, or Engineering from an accredited college or university
Overall 8+ Years of Professional experience in Information Technology with Platform Operations or DevOps or similar
Minimum of 4+ years of experience working with cloud-based platforms in an enterprise environment with large scale Data hosting on Bigdata technologies or Data Lake process
Strong Experience in Hadoop Administration - AWS EMR is preferred
Strong Experience in Hadoop - HDFS, MapReduce, Yarn, Pig, Zookeeper.
Strong Experience in Hadoop SQL tools - Hive and Presto
any Scripting Knowledge - Shell, Perl, python, groovy, terraform, ansible
Strong Experience in Linux OS
Experience on AWS services/network - Instances, Security Groups, Bootstrap actions, S3 Buckets, VPC/Subnet
Strong Experience with Hadoop security and Governance - LDAP Integrations, Kerberos.
Strong Performance tuning experience on Hive, Presto and MapReduce/Yarn.
Strong Experience in monitoring, debugging, and troubleshooting of services.
Knowledge on Datadog
Familiarity or expertise with various tools & technologies include Python/ Spark / Scala / Sqoop & scalr, terraform, ansible, Jenkins, CICD, and S3/ Glue /EMR/ RedShift/ RDS/ Kinesis/ Elastic search etc is a plus
Knowledge, Skills and Abilities:
Critical thinking, decision making, troubleshooting and problem-solving skills
Ability to support multiple initiatives simultaneously and work in a fast-paced environment
Excellent verbal & written communication skills, including communicating technical issues to non-technical audiences
Ability to acquire any specialized domain knowledge required to be more effective in all platform operations activity
Ability to operate in a fast-paced environment with a sense of of urgency, ownership, and accountability
Adaptable/Flexible: being open to change in response to new information, different or unexpected circumstances, and having the ability to navigate ambiguous situations 
Highly self-motivated with the ability to work independently, passionate about business & attention to details
Job Description
Summary:
Wabtec IT Data & Analytics (DnA) Team…at the forefront of the business priorities in building a next generation data and analytics ecosystem…is looking to work into the large-scale data analytics solutions and platform operations.
This hands-on position is responsible for AWS Cloud Bigdata platform to provide technical expertise in maintaining our Data Lake platform and Cloud based applications. We expect the candidate is self-motivated, a quick learner, critical thinker and has hands-on experienced into setup data architecture platform, microservice architecture, setup real-time data pipeline, AWS cloud (EMR, IAM, ELB, Glue, EKS, Lambda, RDS etc.), Python, Pyspark, Kafka/Kinesis, Denodo, Mulesoft & have experience to host Bigdata / Hadoop distributed data environment.
This Data Integration Architect is a technical professional, responsible for participating in the design Data Integration layer, AWS cloud platform, big data development, and the monitor of the Operation Cloud platform ecosystem.
If you are enthusiastic and passionate about NextGen Data Integration platform hosting and maintaining in AWS cloud, then we are looking for you!
Duties and Responsibilities:
· Architecture, Planning, and Implementation of Data Integration layer for end-to-end Data Lake and DWH application utilizing best practices from Architecture and Data Management solution. (AWS Cloud based project experience – must to have)
· Perform hands-on project implementation using Python, Pyspark and various AWS integration services like EMR, Glue, Step function, MSK, EKS, RDS, Lambda, and other major AWS platform services.
· Responsible to develop new Source integration pipeline for Enterprise Data Lake & other operation platform using big data and AWS services.
· Responsible for implementation and ongoing administration of existing Spark, EMR integration pipeline including performance of the cluster, monitoring, tuning, and troubleshooting of big data processing.
· Write automation code for managing large Big Data clusters and have a working practice of DevOps/DevSecOps tools.
· Identify ways to improve Data Integration layer, Cost efficiency, Performance, Scalability, and quality.
Minimum Qualifications & Eligibility Requirements:
· Bachelor's Degree in Information Systems, Information Technology (IT), Computer Science, or Engineering from an accredited college or university
· Overall 12+ Years of Professional experience in Information Technology with Big data Platform Development/AWS Cloud domain.
· Minimum of 8+ years of experience into Data architecture with AWS cloud-based data integration platforms in an enterprise environment with large scale Data hosting on Bigdata technologies or Data Lake systems.
· Expertise with various big data tools & technologies include Python, Spark, Hadoop, Hive and
AWS services like EMR, Glue, Lambda.
· Strong Experience in Performance tuning, monitoring, debugging, and troubleshooting of AWS & Big data platform.
Knowledge, Skills, and Abilities:
· Critical thinking, decision making, troubleshooting and problem-solving skills
· Ability to support multiple initiatives simultaneously and work in a fast-paced environment
· Excellent verbal & written communication skills, including communicating technical issues to non-technical audiences
· Ability to acquire any specialized domain knowledge required to be more effective in all platform operations activity
· Ability to operate in a fast-paced environment with a sense of urgency, ownership, and accountability
· Adaptable/Flexible: being open to change in response to new information, different or unexpected circumstances, and having the ability to navigate ambiguous situations
· Highly self-motivated with the ability to work
Wabtec Corporation is committed to taking on the world’s toughest challenges. In order to fulfill that commitment we rely on a culture of leadership, diversity and inclusiveness. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We believe in hiring talented people of varied backgrounds, experiences and styles…people like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.",USD 45K - 84K *
485,Senior Full Stack Data Scientist,Workday,IND.Pune,Senior-level / Expert,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
Workday’s Audit, Risk, and Intelligence Team (WARI) is committed to redefining finance functions through innovative data science (DS) and machine learning (ML) solutions. We specialize in developing automation that demonstrates Workday's AI capabilities to streamline processes and uncover groundbreaking insights. Our solutions enable finance and internal audit professionals to reallocate their efforts towards high-value tasks, improve financial forecasts, optimize resource allocation, and reduce costs. Our data science solutions also play a crucial role in detecting and preventing fraudulent activities, safeguarding against financial losses.
About the Role
As our Sr. Full Stack Data Scientist (located in Pune, India), you'll lead cross-functional data science efforts to understand business requirements and design, build, and implement innovative solutions that enhance statistical modeling and machine learning.
Reporting to the Sr. Manager, Data Science, this role will evangelize machine learning, with a focus on identifying efficiencies, anomalies, risks, and gaps in business processes. The bulk of the work will involve data exploration, feature engineering, researching and building machine learning (ML) models and meaningfully collaborating with cross-functional business technology teams on model operationalization.
In addition, this role may serve as a domain authority on auditing machine algorithm development with a focus on ensuring trust, reliability, accuracy, and fairness of model results. Finally, the Senior Full Stack Data Scientist will act as a crucial interface between Internal Audit, Finance, Business Technology and Product Teams.
Primary Responsibilities:
Implement ML lifecycle from conceptualization to operationalization, including hypothesis generation, data exploration, feature engineering, model development, and results communication.
Lead and project manage cross-functional efforts to operationalize ML-based solutions.
Analyze and explore data to identify relationships, patterns, trends, risks, and opportunities.
Formulate, build, test, and implement statistical and machine learning models to identify efficiencies, anomalies, non-compliance, and anomalous behavior in business transactions.
Design and run experiments to validate hypotheses and improve model performance.
Promote risk and fraud prediction ML use cases to contribute to product development initiatives.
Educate business teams on data science, AI, and machine learning principles and techniques.
Evangelize data science and machine learning use cases by driving exploration, user engagements, consensus, and customer adoption.
Prioritize tasks to improve productivity and ensure timely results.
Collaborate with cross-functional teams to engineer workarounds and navigate project challenges.
About You
The ideal candidate is a professional who's more than a technical authority - you are a problem-solver, collaborator, and importantly a self-motivated leader. You have a curious and creative mind, always seeking new ways to approach and address sophisticated data problems. You are adaptable and flexible, able to work with different teams and technologies to deliver results. You communicate clearly and effectively, sharing your findings and insights with others in a way that's understandable and practical. And you're passionate about your work, driven by a desire to use data to make a real impact in the world.
Basic Qualifications:
7+ years of hands-on experience in efficiently implementing machine learning projects. Preferably in the domains of anomaly and fraud detection, statistical methods, experimental techniques, or similar. 
Other Qualifications:
Expertise in statistics and statistical concepts, including regression analysis, hypothesis testing, and statistical inference.
Strong programming skills in Python, R, and SQL.
Expertise in applied machine learning models and deep learning frameworks (Tensorflow, PyTorch or Keras).
Proficiency in machine learning techniques such as dimensionality reduction, resampling, ensemble learning, anomaly detection, feature scaling and feature selection.
Proficiency in data visualization tools such as Matplotlib, Seaborn, Tableau, Power BI, or similar.
Expertise in evaluating models using visualization techniques such as confusion matrices, ROC curves, and precision-recall curves.
Experience writing sophisticated SQL queries and ETL processes, including for data extraction, transformation, and loading into a data lake.
Ability to design and conduct experiments and evaluate model performance through cross-validation, hyper-parameter tuning, and similar techniques.
Experience in Natural Language Processing using deep learning (RNN, CNN, LSTM, etc.).
Strong ability and willingness to lead ML operationalization engagements with diverse, multi-functional business and technology teams.
Understanding of software development life cycle and artifacts required for different phases and stage gates.
Excellent project management and communication skills to present insights and recommendations to partners.
Ability to explain sophisticated technical concepts to non-technical people.
Experience with large-scale language models such as GPTs, BERT, or other LLMs is a strong plus.
Experienced in applying concepts/philosophies for appropriate problem-solving and decision-making
Proven track record to be highly collaborative
Excellent interpersonal abilities, and communication skills
Driven to make a positive difference with the team and with the company


Our Approach to Flexible Work
 With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!",USD 135K - 205K *
486,GIS Data Engineer I,HERE Technologies,"Navi Mumbai, India",Mid-level / Intermediate,"What's the role?
Responsibilities: A GIS Data Engineer isresponsible for the analysis and transformation of , with decreasing support from supervisors or seniors and having passion for spatial data.MAIN RESPONSIBILITIES • Run, modify, and execute data engineering processes and projects for the conversion and use of internal and external digital sources in the creation and maintenance of the HERE databases and related products. Assume full accountability and ownership to successfully complete these projects, following existing workflows• Create new workflows and processes with standardization to be used across teams within Data Capture and Ingestion• Leverage data engineering technologies like FME, ArcGIS, Python, SQL and others to transform and integrate data, or create products• Ability to assess and manage the transition of workflows from batch processing to flow• Provide basic GIS and spatial data consultancy for sources and processes.• Participate in departmental and cross-functional projects, which will help to increase efficiency, quality and/or reduce costs within Core Map Group. Apply influence within own local team• Develop engineering and consultancy mindset with focus on value and cost efficiency. Deliver what is needed as end result (not necessarily what was requested at the beginning)• Increase understanding of the HERE Databases content and product specification and the various tools and technologies utilized for database creation in general, E2EQualifications: • Undergraduate degree, but graduate degree preferred in computer science, geodesy, geography or related field• 2 + years related work experience or equivalent combination of education and related work experience• Demonstrated experience with ArcGIS and FME or similar spatial tools• Exposure to some programming and scripting, and ability to learn other tools and programming languages• Developing knowledge of GIS related program language desirable• Experience with the HERE database preferred• Challenger mindset• Developed organizational and multi-tasking ability with the ability to function in a team environment• Punctual, independent worker, able to work under time-pressure• English + other language preferred
Who are you?
HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.
Who are we?
HERE Technologies is a location data and technology platform company. We empower our customers to achieve better outcomes – from helping a city manage its infrastructure or a business optimize its assets to guiding drivers to their destination safely.
  At HERE we take it upon ourselves to be the change we wish to see. We create solutions that fuel innovation, provide opportunity and foster inclusion to improve people’s lives. If you are inspired by an open world and driven to create positive change, join us. Learn more about us on our YouTube Channel.",USD 90K - 150K *
487,Data Engineer III - IN (R-17837),Rackspace,India - Remote,Senior-level / Expert,"Lead Engineer (Data engineer – III) 

JOB DESCRIPTION

•Responsible for carrying out Bug Fixes on existing solution
•Application Design and Roadmap
•Knowledge Base creation and management
•Performing Data Patching
•Recommending Service Upgrades
•Business Logic clarifications/Non run book based (including but not limited to analyzing existing reports and explaining calculations / transformations)
•Cost / Performance optimization of data pipeline / reports  
•Collaborate with customer and DataOps support team to solve issues and facilitate requests by using ITSM processes
•Identify, suggest and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
•Manage and Maintain analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
•Setup tools to deploy and monitor the performance of the systems in production.

REQUIREMENTS

•Demonstrate knowledge and real-world experience on Big data technologies. A successful history of handling performance issues, processing, extracting issues and fixing bugs.
•Experience managing and optimizing ‘big data’ data pipelines, architectures and data sets.
•We are looking for a candidate with 7 + years of experience in a Data Engineer role. They should also have experience using the following software/tools:
Experience working on Azure data factory, Azure Synapse, Power Apps, Logic Apps.
Experience with relational SQL databases such as Oracle, SQL Server, MySQL and reading, writing and deducing technical logics from stored procedures
Experience on visualization tools such as PowerBI/Tableau
Experience supporting and working with cross-functional teams in a dynamic environment.
•Good Academic track record preferred. 
•Certified DP-203, PL-300 and AZ-900 preferred.

QUALIFICATIONS

•Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field
•7-10 years of relevant experience.
•Negotiable salary.


About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
  More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",USD 121K - 186K *
488,"DevOps Engineer, MLOps",Epiq,"IND-Hyderabad-Sohini Tech Park, 3rd Floor, Financial District",Mid-level / Intermediate,"It's fun to work at a company where people truly believe in what they are doing!
Job Description:
Summary
We are seeking a highly skilled DevOps Engineer with good knowledge of ML-Ops for designing, implementing, and maintaining the infrastructure for our company's software development and machine learning operations.
As a DevOps Engineer, you will work closely with software developers, data scientists, and other stakeholders to ensure that the software development and machine learning processes are efficient, secure, and scalable. You will also be responsible for automating the software development and machine learning workflows to enable faster and more frequent releases.
Job Responsibilities:
Design, implement, and maintain the infrastructure for software development and machine learning operations.
Collaborate with software developers, data scientists, and other stakeholders to ensure efficient, secure, and scalable software development and machine learning workflows.
Automate the software development and machine learning workflows using DevOps and ML Ops tools and frameworks.
Monitor and optimize the software development and machine learning workflows to ensure their efficiency and accuracy.
Develop and maintain the tools and frameworks necessary for DevOps and ML Ops
Ensure the security and privacy of the software development and machine learning workflows and data.
Troubleshoot and resolve issues related to the infrastructure and workflows. Conduct root cause analysis, and implement fixes by creating needed artifacts and/or checks & balances in the workflows
Stay up to date with the latest advancements in DevOps and ML Ops and recommend new tools and techniques to improve our operations.
Requirements / Skills :
Bachelors / master’s degree in information or computer science required – B.Tech, MCA, MS Computers.
3+ years of experience in DevOps and ML Ops or related field
Strong programming skills in Python, Java, or other programming languages
Experience with DevOps tools such as Jenkins, GitLab, or CircleCI
Experience with cloud-based infrastructure such as AWS, and Microsoft Azure
Familiarity with ML frameworks such as TensorFlow, PyTorch, or scikit-learn
Strong analytical and problem-solving skills
All-round communication skills and ability to work collaboratively.
Competencies
Integrity – Behaves in an honest, fair, and ethical manner; shows consistency in words and actions; does what she/he commits to doing; respects the confidentiality of information or concerns shared by others; is honest and forthright with people; carries his/her fair share of the workload; takes responsibility for own mistakes.
Client Focus – Takes action with the clients, both internal and external, and sees their needs as a primary focus; builds a sustaining collaborative and productive relationship with clients; seeks to understand client situations, issues, expectations, etc.; takes appropriate action to meet client needs and address concerns; implements or utilizes methods to monitor and evaluate client feedback.
Results-Driven – Sets stretch goals for personal and team accomplishment and works tenaciously to achieve those goals; acts with a sense of urgency; takes the initiative on actions; identifies what needs to be done and takes action before being asked; does more than what is normally required in a situation; establishes metrics to monitor progress and measure success; maintains focus by avoiding or overcoming roadblocks.
Entrepreneurial Orientation – Proposes innovative business opportunities/ideas to customers and business partners; encourages and supports entrepreneurial behavior in others; demonstrates willingness to take calculated risks to achieve business goals.
Decisiveness – Makes well-informed, effective, and timely decisions even when data is limited, or solutions produce unpleasant consequences; perceives the impact and implications of decisions; can make tough decisions.
#LI-Hybrid
#LI-RE1
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
It is Epiq’s policy to comply with all applicable equal employment opportunity laws by making all employment decisions without unlawful regard or consideration of any individual’s race, religion, ethnicity, color, sex, sexual orientation, gender identity or expressions, transgender status, sexual and other reproductive health decisions, marital status, age, national origin, genetic information, ancestry, citizenship, physical or mental disability, veteran or family status or any other basis protected by applicable national, federal, state, provincial or local law. Epiq’s policy prohibits unlawful discrimination based on any of these impermissible bases, as well as any bases or grounds protected by applicable law in each jurisdiction. In addition Epiq will take affirmative action for minorities, women, covered veterans and individuals with disabilities. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. Epiq is pleased to provide such assistance and no applicant will be penalized as a result of such a request.  Pursuant to relevant law, where applicable, Epiq will consider for employment qualified applicants with arrest and conviction records.",USD 30K - 56K *
489,Data Engineer,Commonwealth Bank,Bengaluru - Manyata Tech Park Road,Mid-level / Intermediate,"About CBA:
Commonwealth Bank of Australia (CBA) is the biggest bank in Australia. Our purpose is to improve the financial wellbeing of our customers and communities. CBA India Services is the newest workplace of CBA that will complement the work of teams based out of Australia and other international locations to help deliver our strategy of ‘building tomorrow’s bank today for our customers by leveraging world-class technology.
What is Chief Data Analytics Office (CDAO)?
Our Chief Data Analytics Office (CDAO) team provides the building blocks of success with billions of data points that drives industry-leading experiences for our customers. Made up of data engineers, data architects, insights analysts, data scientists, visualization experts, and more, the Data and Analytics business provides extensive learning and growth opportunities to every team member.
Who are we looking for?
We are looking for an experienced Data Engineer with a passion for data and databases, who enjoys analyzing problems and solving them on a daily basis and who is adept at working on Big Data technologies in a collaborative environment.
What would be your Roles and Responsibilities?
In your role as a Data Engineer, you will be
Reporting to a Data Engineering Manager ( Chapter Lead)
Utilizing Big Data technologies to solve our customers' data centric problems.
Working closely with the Solution Designers and Business Analysts to perform Data Ingestion, Enrichment  and Egression
Working across the Group Data Warehouse, Big Data Platform, Ab Initio and Data Stage.
Designing and building group data products by integrating diverse data from hundreds of internal and external sources
Adopting tools, programming languages  and templates to improve our data quality and efficiency
Building and optimizing Big Data pipelines, architecture and data sets
Working with and extracting data from large disconnected / unstructured datasets
Required to maintain and build excellent relationships with CDAO peers and stakeholders as well as actively contribute to business outcomes and team culture
What skills will you need to be successful in this role?
A degree in Engineering / Computer Science or a related discipline
Minimum of 3+ years of hands-on experience in Software Engineering or development using Scala or Java to build solution in Hadoop, Hive and Spark technologies.
Minimum 3+ years  of hands-on experience on Teradata / Oracle / SQL Server / MySQL  (Mandatory for Teradata Engineers and Desirable for Big Data Engineers)
A good high level understanding of any source control tools like GitHub/ BitBucket etc.
Minimum of 3+ years of experience on Shell Scripting
Should be well aware of AGILE processes and methodologies
A natural ability to effectively communicate, educate and influence the different stakeholders/ peers, to solve challenging problems, while working in collaboration with other cross-functional engineering and solution design teams
A positive desire to contribute towards initiatives, along with a strong ‘can- do’ attitude in juggling between constantly changing priorities
If you're already part of the Commonwealth Bank Group (including Bankwest, x15ventures), you'll need to apply through Sidekick to submit a valid application. We’re keen to support you with the next step in your career.
We're aware of some accessibility issues on this site, particularly for screen reader users. We want to make finding your dream job as easy as possible, so if you require additional support please contact HR Direct on 1800 989 696.
Advertising End Date: 24/12/2023",USD 90K - 150K *
490,Staff Data Engineer(Snowflake/ETL),Tide,"Hyderabad, Remote",Senior-level / Expert,"  Who are Tide:
At Tide, we’re on a mission to save businesses time and money. We’re the leading provider of UK SME business accounts and one of the fastest-growing FinTechs in the UK. Using the latest tech, we design solutions with SMEs in mind and our member-driven financial platform is  transforming the business banking market. Not only do we offer our members business accounts and related banking services, but also a comprehensive set of highly connected admin tools for businesses. 
Tide is about doing what you love. We’re looking for someone to join us on our exciting scale up journey and be a part of something special. We are wanting passionate Tideans to drive innovation and help build a best-in-class platform to support our members. You will be comfortable in ambiguous situations and will be able to navigate the evolving FinTech environment. Imagine shaping how millions of Tide members discover and engage with business banking platforms and building this on a global scale.
What we’re looking for:
As part of the team, you will be responsible for building and running the data pipelines and services that are required to support business functions/reports/dashboard.. We are heavily dependent on Snowflake, Airflow, Fivetran, dbt , Looker for our business intelligence and embrace AWS as a key partner across our engineering teams.
As a Analytics Engineer you’ll be:
Design & architect complex Data Warehousing/Data Lake solutions on Snowflake
Designing, developing, and implementing scalable, automated processes for data extraction, processing, and analysis in a Data Mesh architecture
Mentoring other Junior Engineers in the Team
Be a “go-to” expert for data technologies and solutions
Ability to provide on the ground troubleshooting and diagnosis to architecture and design challenges
Troubleshooting and resolving technical issues as they arise
Looking for ways of improving both what and how data pipelines are delivered by the department
Optimising with the capability to do performance tune complex SQL queries on Snowflake along with deep understanding of different data partition strategies
Working with Data Analysts to ensure that all data feeds are optimised and available at the required times. This can include Change Capture, Change Data Control and other “delta loading” approaches
Support data governance, data improvement, and other data platform initiatives
Responsible to design solution for data integration, data management, metadata management, and data quality 
Discovering, transforming, testing, deploying and documenting data sources
Applying, help defining, and championing data warehouse governance: data quality, testing, coding best practises, and peer review
What makes you a great fit: 
You have 10-12 years of experience with increasing responsibilities implementing data solutions with a focus on snowflake or similar warehouse
You have In-depth understanding of Data Warehouse, ETL concept and data modelling principles 
You have good knowledge of Data modelling approaches like Kimball and Datavault etc., along with strong Data Warehousing and Data Modelling fundamentals like Star Schema, Snowflake Schema, Dimension Tables and Fact Tables.
You have good understanding of Cloud based data solution components and architecture covering data ingestion, data processing, data cataloguing, security, devops, consumption, etc
You have experience implementing core Snowflake concepts such as data sharing, UDFs, zero copy clones, time travel, micro partition, stored procedures, data import/export, external tables, 
You have experience architecting analytical databases in Data Mesh architecture
You have ability in problem solving and proactively engage with other cross functional teams to help resolve issues and blockers 
You have ability to consider alternative solutions/components and make design decisions backed by justification
You have drive technical discussions / demos / presentations with client stakeholders, demonstrating deep expertise and quality of designs
You have Perform design/code reviews of the team to identify issues/risks and mitigations
You have experience with  python, governance tool (e.g. Atlan, Alation, Collibra) or data quality tool (e.g. Great Expectations, Monte Carlo, Soda) will be added advantage• Strong analytical and problem-solving skills
You have experience with Agile Development methodology
You have strong communication skills
What you’ll get in return: 
Make work, work for you! We are embracing new ways of working and support flexible working arrangements. With our Working Out of Office (WOO) policy our colleagues can work remotely from home or anywhere in their home country. Additionally, you can work from a different country for 90 days of the year. Plus, you’ll get:
Competitive salary
Self & Family Health Insurance
Term & Life Insurance
OPD Benefits
Mental wellbeing through Plumm
Learning & Development Budget
WFH Setup allowance
25 Annual leaves
Family & Friendly Leaves
Tidean Ways of Working 
At Tide, we’re Member First and Data Driven, but above all, we’re One Team. Our Working Out of Office (WOO) policy allows you to work from anywhere in the world for up to 90 days a year. We are remote first, but when you do want to meet new people, collaborate with your team or simply hang out with your colleagues, our offices are always available and equipped to the highest standard. We offer flexible working hours and trust our employees to do their work well, at times that suit them and their team.
Tide is a place for everyone
At Tide, we believe that we can only succeed if we let our differences enrich our culture. Our Tideans come from a variety of backgrounds and experience levels. We consider everyone irrespective of their ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status. We believe it’s what makes us awesome at solving problems! We are One Team and foster a transparent and inclusive environment, where everyone’s voice is heard.
#LI-NN1 #LI-Remote
 ",USD 121K - 186K *
491,Software Engineer - Data Ops,Freshworks,"Bengaluru, India",Entry-level / Junior,"Company Description
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end-user. More than 50,000 companies -- from startups to public companies -- around the world use Freshworks software-as-a-service to enable a better customer experience (CRM) and employee experience (ITSM, HRSM).Headquartered in San Mateo, California, Freshworks has a dedicated team operating from 13 global locations to serve customers, including American Express, Sony, Vice Media, TaylorMade, Sotheby’s, Stitchfix, OfficeMax, Multichoice, Delivery Hero, ITV, and Klarna.Freshworks transforms the way world-class organizations collaborate with customers and co-workers. The suite includes Freshdesk (omnichannel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshteam (HR management system).
Job Description
We are looking for a candidate with 2+ years of experience in the below,
Oversee the day-to-day operations including monitoring, data observability, data ingestion, regular checks for issues, anomalies, and bottlenecks & issue resolution
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, etc
Implement monitoring systems and processes to track the performance and observability of data
Identify bottlenecks, and proactively address performance issues to ensure high availability and responsiveness
Lead data incident management processes, including data outages, breaches, or data-related disruptions
Work collaboratively with Data teams and ML teams on on any new/enhancement requests 
Should be willing to support month/week ends and work in flexible working hours when required 
Qualifications
Good knowledge in Data Structures and Algorithms
Good in SQL, and RDBMS concepts 
 Any one of the following programing languages, Scala, Python or Java 
Knowledge of Big data ecosystem
Good understanding of AWS or any cloud platform 
Additional Information
All your information will be kept confidential according to EEO guidelines.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 22K - 42K *
492,Senior Consultant - Tech Consulting -Azure Data Engineer - Kochi,EY,"Bengaluru, KA, IN, 560001",Senior-level / Expert,"Senior Consultant/ Consultant Azure Data Engineer
  Overview:
We are seeking a skilled data engineer with 4+ years of experience. The ideal candidate will be responsible for designing, developing, and maintaining data solutions on the Microsoft Azure platform. Expertise in Azure Data Factory, Azure Databricks, and SQL are critical requirements.
Responsibilities:
Work closely with stakeholders to understand business problems and requirements.
Design, develop, and maintain data pipelines and workflows using Azure Data Factory (ADF) to extract, transform, and load data from various sources into data repositories
Implement data ingestion and transformation processes using Azure Databricks and Apache Spark to acquire data from diverse sources, such as databases, APIs, flat files, or streaming data sources, and load it into target data repositories.
Develop and optimize SQL queries for data retrieval, analysis, and reporting purposes.
Design and maintain data models, data schemas, and data dictionaries to ensure data consistency and accuracy.
Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and translate them into technical solutions.
Implement scheduling and monitoring mechanisms to ensure timely execution and availability of data pipelines.
Troubleshoot and resolve data quality issues
  Qualifications:
Bachelor’s or Master’s degree in Computer Science, Statistics, Mathematics, or a related field
4+ years of experience as a Data Engineer.
Proven experience with Azure Data Factory (ADF), Azure Databricks, and SQL.
Strong programming skills in Python or another programming language.
Experience with data modelling and data quality management.
Excellent communication and collaboration skills.
Ability to work independently and as part of a team.
Excellent problem-solving and analytical skills
Strong communication and presentation skills
Ability to work independently and collaboratively in a team environment.
Good to have:
Familiarity with data visualization tools such as Power BI, Tableau, Qlik Sense, etc.
Experience in the airline domain.
What we look for 
People with the ability to work in a collaborative way to provide services across multiple client departments while adhering to commercial and legal requirements. You will need a practical approach to solving issues and complex problems with the ability to deliver insightful and practical solutions.
What working at EY offers 
EY is committed to being an inclusive employer and we are happy to consider flexible working arrangements. We strive to achieve the right balance for our people, enabling us to deliver excellent client service whilst allowing you to build your career without sacrificing your personal priorities. While our client-facing professionals can be required to travel regularly, and at times be based at client sites, our flexible working arrangements can help you to achieve a lifestyle balance.

About EY
As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.
If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible",USD 45K - 84K *
493,Java Spark Developer – Chennai - Officer/C11,Citi,RAMANUJAN IT CITY SEZ TARAMANI CHENNAI,Senior-level / Expert,"Overview of Citi:
Citi, the world leading global bank, has approximately 200 million customer accounts and a presence in more than 160 countries and jurisdictions worldwide. Citi provides consumers, corporations, governments and institutions with a broad range of financial products and services, including consumer banking and credit, corporate and investment banking, securities brokerage, transaction services, and wealth management. Citi enables clients to achieve their strategic financial objectives by providing them with cutting-edge ideas, best-in-class products and solutions, and unparalleled access to capital and liquidity.
Job Purpose :
We are looking to bring in a Java/Spark Big Data Developer  in the Enterprise Data Services team under Enterprise Operations and Technology, to help the implementation of next generation Data Platform using cutting edge Data Management Technologies. The Candidate is required to possess relevant design and development experience in the Big Data Eco-System and should be a strong team player. Exposure to Finance OR Risk Functions on the Retail Banking products or Wholesale/Investment banking is preferred. This is a significant opportunity for an experienced developer with experience in modern data platforms to move into a role working with a variety of development teams, including close collaboration with an on-site Data Governance team.

To be successful in this role, you will need to have proven experience in development of solutions/platforms for Financial markets environment. It is expected that you will have superior technical knowledge of current programming languages, technologies and other leading edge development tools
What we offer :
• Be a part of development team to develop, enhance, support and maintain solutions for GFTS Data Services applications. 
• Participate in technical discussions/brainstorming sessions and define ideas and strategies for existing and future platforms 
• Gain exposure to Wholesale, Retail business across data, risk and finance
• Work across diverse set of data platforms and have an opportunity to be part of re-architecture and re-platforming initiatives on modern Big Data technologies
GFTS Data Services platform is a global Data Repository of Contracts, Position and Balances for all of Citi’s assets and liability. This data repository is build on Enterprise Data Standards and anchored to the financials, for the use of Finance and Risk; regulatory and management reporting. The team is working on an exciting modernization and simplification program, aligned with latest technologies. GFTS Data Services is building a sophisticated next generation Data solution.  The Pune team is the global center for the creation of API-based, Event Driven platform using cutting edge technologies and techniques.
The volume and variety of data involved in these Finance and Risk Functions results in one of most challenging and appropriate use cases for big data technologies.
The specific team you will be joining is responsible for developing and maintaining solutions related to Data Quality platform for GFTS Data Services. This team will be focusing on rule base validation engine, ETL layer build out and rule repository, with provisioning of API based on-demand platform.

Responsibilities
• Develop java based high throughput data intensive applications to serve function of data integration, data consumption and data generation
•  Develop robust Data Quality core framework for measurement
• Utilize in-depth knowledge and skills across multiple Applications Development areas to provide technical oversight across systems and applications
• Requirement analysis including interaction with Business Users
• Help build continuous integration environment 
• Perform Unit Testing, System Testing for all applications developed / enhancements and ensure that all critical and high-severity bugs are addressed.
• Engage in end to end system design and development processes
• As and when required, work on BAU development requests 
• Ensure that application development and enhancement is in line with Citi’s Coding Standards.
• Partners with multiple Technology teams to ensure appropriate integration of functions to meet goals; identifies and defines necessary system enhancements to deploy new products and process enhancements. 
• Solves / works a variety of high impact, high-profile problems / projects with considerable business impact through in-depth evaluation of complex business processes, system processes and industry standards. 
• Provides expertise in area and an advanced level of understanding of the principles of applications programming.
• Develops standards for coding, testing, debugging and implementation.
• Providing expertise in technical analysis and solving technical issues during project delivery.
• Responsible for applications systems analysis and programming activities.
Qualification
• Strong Core Java / Scala working experience
• Strong Experience in Big data technologies like Apache Spark, HDFS, Hive, Hbase
• Working experience with Any Hadoop Distribution   - Cloudera/Hortonworks
• Comfortable working with large data volumes and be able to demonstrate a firm understanding of logical data structures and analysis techniques
• Experienced with Linux/Unix platform  
• Experience in RDMS and No SQL databases 
• Experience in Service oriented architecture, and data standards like JSON, Avro, Parquet
• Experience using ALM and CICD tools like Bitbucket, TFS, Jenkins, uDeploy, BMC RLM or related tools in an agile methodology.
• Experience in SCMs like GIT; and tools like JIRA
• Experienced with automated build and test processes
• Able to demonstrate an expertise in identifying and resolving data quality issues – in data sets at rest and in flight
• Familiar with the financial services industry and/or regulatory environments
• Capable of assisting with the design of solutions and mentoring other developers within the same team
• Demonstrated leadership skills
• Consistently demonstrates clear and concise written and verbal communication
• Ability to work as part of team and independently
• Interpersonal skills to interact with team members and clients
• Prior experience working with remote teams
• Candidate should be willing to work extended hours in order to interact with global partners/teams or as per project demand. 
 
Good to have
• Python
• Kafka or other equivalent messaging services 
• Exposure on Public Cloud  - GCP/AWS/Azure
 
Educational Qualification:
• Bachelor’s degree/University degree or equivalent experience
• Master’s degree preferred
-------------------------------------------------
Job Family Group:
Technology
-------------------------------------------------
Job Family:
Applications Development
------------------------------------------------------
Time Type:
Full time
------------------------------------------------------
Citi is an equal opportunity and affirmative action employer.
Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.
View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.
View the EEO Policy Statement.
View the Pay Transparency Posting",USD 37K - 70K *
494,Machine Learning Engineer 5,Adobe,Bengaluru,Senior-level / Expert,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. 

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

 The Opportunity:

The Firefly GenAI India engineering team is looking for an ML Engineer to work on enabling exciting experiences for the Creative Cloud clients.

What you'll do:
Contribute to the backend services for Firefly that power the generative AI features on Firefly website, Photoshop, Illustrator, Express, Stock, Premier and other applications/surfaces
Develop GPU optimized, efficient model pipelines for new Firefly features related to images, video and audio
Ensure a scalable, reliable cloud service with observability, logging and tracing to enable quick detection, understanding and resolution of run-time issues
Contribute to Project Colligo, the AI superhighway for inference that will manage and serve a collection of ML models in a highly scalable and resilient system
Ensure a scalable, reliable cloud service with observability, logging and tracing to enable quick detection, understanding and resolution of run-time issues
Develop high-performance, reliable, testable and maintainable code
Work closely with teams across Adobe, in different geographies. The technology you produce will have visibility at the highest levels of the company and materially affect the positive impact products have on our customers
 What you need to succeed:
B.Tech or M.Tech. degree in Computer Science, Engineering or equivalent
6+ years of experience building, optimizing and operating GPU intensive ML workloads in production environments.
Several years experience architecting cloud services and infrastructure for large scale use (5B+ requests per month)
Understanding of model serving, orchestration, scaling, GPU resource management
10+ years software engineering experience
Experience in distributed computing
Technology Skills: Python, ML, Pytorch, AIT, CUDA, GPU drivers, Kubernetes, AWS
 Bonus Qualifications:
CUDA programming experience
Machine learning models integration into web applications
Scala, Java, C++
Experience with CI/CD systems
Experience with Agile development processes including Scrum
Experience building and training ML models
Experience in Video domain.
Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.
 Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.",USD 150K - 230K *
495,Engineering Manager - Data Engineering,Bosch Group,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
We are looking for an engineering manager to lead our team responsible for Data Engineering Enablers in the exciting and cutting-edge space of autonomous driving.  In this role, you will responsible for  developing and establishing a highly competent team of experts and developers and at the same time understand our business, product, and technology, and apply that knowledge to create new product ideas and identify opportunities.
 What you would do:
Build and manage the data engineering team at RBEI
Enable the talent acquisition process: Interviewing, hiring, and training
Coach, lead, and motivate engineering team to deliver on projects
Develop evaluation criteria that will serve to measure progress and effectiveness of team operations and of product / services
Define and build the plan to implement the team objectives consistent with organization objectives
Plan and formulate programs, monitor progress against project schedules and budgets; allocation of resources as required to accomplish goals
Partner with business users, data scientists, and application experts in delivering a data engineering roadmap that enables faster development of AI based functions for automated driving
 This should describe you:
You have experience with creating large scale data pipelines and deploying them on cloud platforms.
You have demonstrated ability in building product strategy, product design methods, user journey, product features and roadmap definition
You are exceptional at building and managing a team of talented engineers with the ability to pioneer in this space.
You understand the big picture but can operate on a smaller problem area and deliver results
You have extensive knowledge of engineering practices and principles as well as understanding of scientific methods of problem solving
You have strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress
Qualifications
Preferred qualifications: 
15+ yrs. work experience with a Bachelor’s, Master’s, or Advanced Degree in an analytical field such as computer science or relevant engineering area.
5+ yrs experience in managing large teams (20+ associates)
Working knowledge of Data Engineering and associated technologies like application development, cloud technologies etc...
Excellent program and product management skills with strong agile development experience",USD 90K - 150K *
496,Analytics Engineer,Swiss Re,"Bengaluru, KA, IN",Mid-level / Intermediate,"About The Team
Data & Analytics Reinsurance is a key tech partner for our Reinsurance divisions, supporting in the transformation of the data landscape and the creation of innovative analytical products and capabilities. We use modern approaches to managing the product lifecycle, design thinking and rapid prototyping to quickly test for value and ensure we build powerful insights and deploy them into production as part of analytical products. Both our team and our partners are spanning across different countries and serving a global customer basis.
About The Role
In your role as an Analytics Engineer in Data & Analytics Re, you collaborate with data engineers, business analysts and product owners to build impactful products tackling a variety of business challenges, such as improving our portfolio strategy, costing accuracy and financial performance. It is your responsibility to advise & support in product development as well as to implement sophisticated applications, reports and dashboards by transforming data in pipelines, creating visualizations and simulation engines. Additionally, you will shape the Analytics Ontology, the go-to asset for self-service analytics.
Key responsibilities
Data Exploration & Consulting: Acting as a connector between business and data, advising on how best to use data and analytics to improve business outcomes
Data Modelling: Building a user-centric data asset that is modelled around how our business understands the data
Application Development & Data Visualization: Building impactful applications to support key business processes, with a focus on rapid prototyping & quick iterations
Product Management: Following best practices in lean agile development
About You
University degree with a quantitative background, 5+ years of data-related work experience in the Financial Industry, Consulting or Tech
Strong ability to analyze data within the business landscape while applying conceptual and problem-solving skills
Excelling in stakeholder management and ability to clearly communicate complex technical concepts.
Proficiency in spoken and written English communication is important.
Experience in building applications and/or data visualizations
Experience coding in Python
Working knowledge of Power BI is a plus
Experience in writing SQL scripts for testing and analyzing data
Experience with information modelling, understanding of data modelling concepts and working with data pipelines
Hands-on experience with Apache Spark and a basic understanding of distributed systems is a plus
Working knowledge of advanced analytics (i.e. Machine Learning, Statistics) is a plus
Domain experience in the (Re-)Insurance industry, Life & Health is preferred
And most importantly, you are a people person that loves collaborating with others to find excellent solutions to complex business problems!
    About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127806 
   ",USD 90K - 172K *
497,Data Science Manager,Commonwealth Bank,Bengaluru - Manyata Tech Park Road,Mid-level / Intermediate,"Role: Data Science Manager
Years of experience: 7-10 Years
Location: Bangalore-Manyata Tech Park
Mode of Work: Hybrid
At CommBank, we never lose sight of the role we play in other people’s financial wellbeing. Our focus is to help people and businesses move forward to progress. To make the right financial decisions and achieve their dreams, targets and aspirations. Regardless of where you work within our organisation, your initiative, talent, ideas and energy all contribute to the impact that we can make with our work. Together we can achieve great things.
Your Business & Team:
Group Audit & Assurance (GA&A) provides independent, objective and commercial risk focused assurance to the Board Audit Committee to assist the Group in securing and enhancing the financial wellbeing of its stakeholders.
The department consists of over 210 professional audit personnel who conduct internal audit, credit portfolio assurance and retail network assurance reviews group wide. The team works closely with senior management and staff across the business, including Line 1 and Line 2 risk management, and external auditors. GA&A provides feedback to management on improving their control environment, as well as sharing learnings, including commercial insights and productivity opportunities.
CBA GA&A’s Analytics team comprises of professionals with diverse career backgrounds in analytics, audit, media, and user/customer experience within both private and public sectors.
The Analytics team is of strategic importance to GA&A, being responsible for leveraging data analytics to enhance and expand audit processes to provide greater assurance. To achieve this, we utilise a broad range of analytical tools including Python, R, Alteryx, Jupyter Notebooks, Tableau, Teradata SQL, SAS, and other specialised tools.
Your impact and contribution:
Perform high quality, risk-focused analytics providing management with powerful insights for improving the control environment in line with Group strategic objectives.
Assist the function in becoming more efficient and effective through the use of data analytics, machine learning and automation.
Your reporting lines:
Your manager is the Executive Manager Data Science.
Your manager once removed (MoR) is the Head of Analytics, Group Audit & Assurance.
Your responsibilities:
Solve complex analytical problems by applying innovative and resourceful thinking.
High quality and timely delivery of advanced data analytics and machine learning projects.
Self-motivated and consistently deliver effective Automation/AI solutions in line with Methodology and quality standards.
Work closely with the other teams to understand the risk and control environment.
In-depth understanding of AI use cases in thematic risk areas and demonstrate the ability to manage the end-to-end ML process from inception to model deployment.
Present data-driven insights in a clear and concise manner to senior internal and external stakeholders.
Solve systematic problems by applying first principles and critical thinking skills.
Your Skills and Experience:
Key skills:
Risk Mindset – All CommBank employees are expected to proactively identify and understand, openly discuss and act on current and future risks;
Stakeholder Management – Demonstrated ability to translate complex concepts into simplified stakeholder key messages and present to senior leaders;
Commercial acumen – Demonstrated understanding of risk-reward concept and translating this into portfolio insights or credit strategies;
Subject matter expert – Proven experience in using best practice across analytics, data management, risk management, and governance.
Required experience:
Tertiary qualification in relevant field.
Experienced data scientist with strong Python, EDA skills and minimum 2 years’ ML projects experience.
Demonstrated good team player.
Excellent written and verbal communication skills in English.
Experience with languages/packages such as SQL, Python/R and ML toolchain.
Your development:
If you live the values we can offer great opportunities, whether you want to move across the organisation or up into a leadership role, the Code of Conduct guides our decision making so we can do what’s right in every situation.
If you're already part of the Commonwealth Bank Group (including Bankwest, x15ventures), you'll need to apply through Sidekick to submit a valid application. We’re keen to support you with the next step in your career.
We're aware of some accessibility issues on this site, particularly for screen reader users. We want to make finding your dream job as easy as possible, so if you require additional support please contact HR Direct on 1800 989 696.
Advertising End Date: 28/12/2023",USD 70K - 220K *
498,Senior Data Engineer,Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
With over 9 million badges earned to-date, Trailhead has reinvented the way people learn Salesforce and is helping people get new skills and further their careers. The Trailhead audience, Salesforce admins, developers, and users, are instrumental to the success of Salesforce customers, and by helping them adopt Salesforce successfully and learn our latest technologies, we can help them succeed in their journeys.
 THE ROLE
Team Trailhead at Salesforce is looking for a Data Engineer (LMTS) to join our Learning Technology team.This position requires an individual with strong Salesforce platform knowledge, technical prowess, especially in migrating data into Salesforce cloud and establishing data pipeline into data warehouse. In this role, you will work closely with engineering teams, operations teams, and vendor teams to implement data migration from 3rd party system to Salesforce cloud and warehouse data pipelines.


RESPONSIBILITIES
A Data Engineer will be responsible for designing, developing & maintaining all parts of the data pipeline to migrate data from 3rd party systems to Salesforce cloud.
A Data Engineer will be responsible for implementing data pipelines to drive insights through data science, reporting & analytics.
Demonstrating exceptional analytical, troubleshooting, and problem-solving expertise
Quickly develop and maintain technical and domain expertise in assigned areas of product functionality.
Take ownership of issues that may arise and see through them until completion.
Demonstrate ability to meet deadlines, handle and prioritize simultaneous requests, and manage laterally and upwards
Collaborate with the Applications team to support changes and enhancements in Salesforce
Be responsible for the technical solution design, lead the technical architecture and implementation of data acquisition and integration projects, both batch and real time.
Communicate with product owners and analysts to clarify requirements. Craft technical solutions and assemble design artifacts (functional design documents, data flow diagrams, data models, etc.).
Identify incomplete data, improve quality of data, and integrate data from several data sources. Proactively identify performance & data quality problems and drive the team to remediate them.
Advocate architectural and code improvements to the team to improve execution speed and reliability.
Clearly articulate pros and cons of various technologies and platforms in open source and proprietary products. Implement proof of concept on new technology and tools to help the organization pick the best tools and solutions.
Harness operational excellence & continuous improvement with a can do leadership demeanor.
Strong SQL optimization and performance tuning experience in a high volume data environment that uses parallel processing.


PROFESSIONAL EXPERIENCE/SKILLS REQUIRED
Experience will be evaluated based on alignment to the core competencies for the role (e.g. extracurricular leadership roles, military experience, volunteer work, etc.)
Minimum 7 years of relevant hands-on experience in various Salesforce cloud products such as Sales Cloud, Service Cloud, Experience Cloud, Data Cloud
Experience migrating data from 3rd party systems to Salesforce could.
Experience building programmatic ETL pipelines with SQL based technologies and platforms.
Solid understanding of databases, and working with sophisticated datasets. Data governance, verification and data documentation.
Work with different technologies (Python, shell scripts) and translate logic into well-performing SQL, automate data pipelines using scheduling tools like Airflow.
Experience in Snowflake, MySQL, Postgres, Salesforce data loader, SQL, SSQL, Python, Airflow, AWS,, Tableau,
Knowledge of data modeling techniques and high-volume ETL/ELT design.
Experience developing in an enterprise environment such as source code control, IDE, continuous deployment, release management (Git, Eclipse, CircleCI, link VSCode)
Experience supporting Salesforce integrations with external systems and ETL tools.
Ability to work under pressure, highly adaptable, and well-organized
Experience working scrum/agile project management methodologies and SDLC.
Hands-on on Salesforce.com knowledge of product and functionality a plus.
Strong problem solving with acute attention to detail and ability to meet tight deadlines and project plans.
Ability to research, analyze, interpret, and produce accurate results within reasonable turnaround times with an iterative mentality with rapid prototyping designs.
Ability to work effectively in an unstructured and fast-paced environment both independently and in a team setting, with a high degree of self-management with clear communication and commitment to delivery timelines.
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 121K - 186K *
499,Project Owner - Data Ops and Analytics,Axion Ray,Bengaluru,Mid-level / Intermediate,"About Axion Ray:

Axion Ray’s mission is to improve the quality and safety of engineered products - airplanes, electric vehicles, and medical devices, by creating the world’s best proactive management platform, powered by the latest advances in artificial intelligence. We're revolutionizing the way next-gen vehicles are made and are partnering with forward-looking engineering leaders to create and deploy AI models that will accelerate our speed to an electric and supersonic future. Axion leverages bleeding-edge tech & AI stack - including Generative AI and NLP/LLMs - to solve real-world problems.

Our team includes experts in Enterprise AI from Palantir, McKinsey & QuantumBlack, and other top tech companies.

Since our founding at the onset of 2021, we’ve deployed across some of the largest Automotive and Aerospace companies in the world. If you want the chance to help build the future of engineering, join us!

Position Summary:

We are seeking a highly motivated and experienced Analyst III - Project Manager to take ownership of our projects, ensuring high-quality data operations and efficient project management. The ideal candidate will have a strong background in project ownership, data management, and a proven ability to lead and mentor a team of analysts.

What you'll do:

1. Lead Point of Contact for projects, ensuring seamless coordination with Senior Analysts and Product Lead.
2. Assist in identifying and addressing issues that may arise during project execution.
3. Possess a strong understanding of coding and algorithms. Conduct thorough data quality checks to ensure accuracy and reliability.
4. Provide training and mentorship to a team of Analysts, ensuring continuous skill development keeping a track on their day to day tasks.
5. Effectively communicate and maintain project deadlines and proactively identify key challenges ensuring early resolution.

Who you are:

1. Bachelor's degree in engineering, science, mathematics, or a related field.
2. 1 - 3 years of relevant experience working with a Analytics/ Manufacturing/ Aerospace/ Automotive/ Medical-Device company.
3. Proven experience in project management and data quality assurance.
4. Strong analytical and problem-solving skills, with a keen eye for detail.
5. Excellent communication and interpersonal skills.
6. Proficient in Python and Excel. 
7. Prior experience in mentoring and training team members.
8. Can collaborate with stakeholders including senior analysts, team leads, data scientists, and product leads.
9. Can work on engagements from understanding the business objective through data exploration, identification and validation.",USD 30K - 56K *
500,Data Analyst,ANZ Banking Group Limited,"Bengaluru, IN",Senior-level / Expert,"Core skills and expertise required:
About the role
Role: Data Analyst
Job type: Permanent, 4.4
Job Location: RMZ Ecoworld, Bengaluru
  At ANZ our purpose is to shape a world where people and communities thrive. We’re making this happen by improving the financial wellbeing and sustainability of our customers so they can achieve incredible things– whether they’re buying a home, building a business or saving for things big or small.
  The Data Analyst is critical to making this happen and will:
Address and solve complex business issues using large amounts of data
Have a clear understanding of the end-to-end analytics journey as well as define and deliver the Australia Data roadmap
Continuous generation, monitoring, presenting and conducting of 'fact-based' analysis of relevant customer insights to use at any time for the development and improvement of relevant and innovative propositions
Generate, monitor, present and analyse relevant customer insights, costs, benefits, and risks for customers, clients and cohort products; this could include business casing, what if scenarios and opportunity sizing & assessments
What will you bring?
To grow and be successful in the role, you will ideally bring the following:
4 to 6 years of overall work experience
Strong communication and presentation skills
Good understanding of concepts in applied probability and statistics
Hands-on experience in RDBMS technologies like SQL Server, Oracle DB, Teradata or Big Data
Hands-on knowledge and experience with tools and techniques for analysis, data manipulation and presentation (e.g. SAS, SQL, Tableau, VBA, QlikView BI)
Analytical and inquisitive mindset to continuously improve the level of insight surfaced
Ability to effectively communicate to all stakeholders (technical and non-technical)
Strong ability to translate data insights into practical business recommendations.
Core skills and expertise required:
Customer Focus - Monitors customer satisfaction and draws on understanding of customer to deliver customer centric solutions
Continuous Improvement & Change – Understands, accepts and supports the need for change and adapts own behaviours to changing circumstances and provides input to change projects
Problem Solving - Comprehensive understanding of a range of problem solving techniques
Market / Industry Knowledge - Builds on domain knowledge base
Influence & Relationship Building - Uses an understanding of others’ point of view and empathy to gain buy-in to develop existing relationships and help build new ones
Data Visualisation and story telling - Key understanding of the business strategy and implications on Data and Analytic needs ; Ability to story-tell through Visualisations
Data Mining / Sourcing Skills - Strong analytics capabilities to identify market opportunities using statistical & modelling Techniques
Understanding depth & breadth of data - Some capabilities to source, join and derive insights from disparate data sources across several domain
Financial/ Business/ Commercial/ Market Acumen - An understanding of Banking and the products, markets, industries, channels and customer segments dimensions and awareness of scenarios modelling optimisation Opportunities
So, why join us?
Our purpose is to shape a world where people and communities thrive. That's why we strive to create balanced, sustainable economy in which everyone can take part and build a better life. By helping people make the most of what they have, we transform ideas, hard work and ambition into reality.
  Career development means different things to different people. It may simply mean developing a skill, broadening your experience by moving sideways or stretching yourself by moving to a different business. How you manage and develop your career is up to you, but ANZ is committed to helping you do this by providing you with the support, tools and resources you need.
  We work flexibly at ANZ and encourage you to talk to us about how this role can be flexible for you and any adjustments you may require to our recruitment process or the role itself.
  If you are a candidate with a disability, let us know how we can provide you with additional support.
Job Posting End Date
 , 11.59pm, (Melbourne Australia)",USD 92K - 145K *
501,Cloud Technical Lead - AI & ML,"Insight Enterprises, Inc.","Gurugram Gurgaon HR, IN",Senior-level / Expert,"Requisition Number: 95234 
Job Description: AI/ML Lead (Azure Technologies)
  Position Overview: We are seeking an experienced AI/ML Lead with a strong focus on Azure technologies to join our dynamic team. As the AI/ML Lead, you will play a crucial role in driving our organization's AI and machine learning initiatives. You will be responsible for leading the development, deployment, and optimization of AI/ML models, with an emphasis on the Azure stack. The ideal candidate will have a solid background in AI/ML, experience with LLM (Large Language Models), fine-tuning of models, and a deep understanding of Azure technologies.
  Responsibilities:
1. Lead and manage the end-to-end development and deployment of AI/ML models using Azure technologies.
2. Collaborate with cross-functional teams to understand business requirements and translate them into AI/ML solutions.
3. Design and implement scalable, reliable, and efficient AI/ML pipelines on the Azure stack.
4. Conduct data exploration, pre-processing, feature engineering, and model selection to drive model performance.
5. Fine-tune and optimize AI/ML models for improved accuracy, speed, and efficiency.
6. Stay up to date with the latest advancements in AI/ML, particularly in the context of Azure technologies, and drive innovation within the organization.
7. Mentor and provide technical guidance to junior members of the AI/ML team.
8. Collaborate with infrastructure and operations teams to ensure seamless integration and deployment of AI/ML models in production environments.
9. Monitor and evaluate the performance of deployed models, identify areas for improvement, and implement necessary enhancements.
10. Ensure compliance with data privacy and security standards throughout the AI/ML development lifecycle.
      Qualifications:
1. Proven experience (8+ years) working on AI/ML projects, with a focus on Azure technologies.
2. Extensive knowledge and hands-on experience with LLM (Large Language Models) and fine-tuning techniques.
3. Strong proficiency in programming languages such as Python, R, C#.
4. In-depth understanding of machine learning algorithms, statistical modelling, and natural language processing techniques.
5. Experience designing and implementing AI/ML pipelines using Azure technologies, including Azure Machine Learning, Azure Databricks, and Azure DevOps.
6. Familiarity with cloud-native development practices and containerization technologies (e.g., Docker, Kubernetes).
7. Solid understanding of data engineering principles, data warehousing, and data architecture.
8. Excellent problem-solving and analytical skills, with the ability to work on complex AI/ML challenges.
9. Strong communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams.
10. Proven ability to lead and mentor a team of AI/ML professionals.
11. Azure certifications(e.g., Azure AI Engineer, Azure Data Scientist) willbe a plus.
Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
  Insight India Location:Level 16, Tower B, Building No 14, Dlf Cyber City In It/Ites Sez, Sector 24 &25 A Gurugram Gurgaon Hr 122002 India",USD 45K - 84K *
502,Data Analyst Associate,Huron,Bengaluru India - South,Senior-level / Expert,"The Opportunity
Huron helps its clients drive growth, enhance performance and sustain leadership in the markets they serve. We help healthcare organizations build innovation capabilities and accelerate key growth initiatives, enabling organizations to own the future, instead of being disrupted by it. Together, we empower clients to create sustainable growth, optimize internal processes and deliver better consumer outcomes.

Health systems, hospitals and medical clinics are under immense pressure to improve clinical outcomes and reduce the cost of providing patient care. Investing in new partnerships, clinical services and technology is not enough to create meaningful and substantive change. To succeed long-term, healthcare organizations must empower leaders, clinicians, employees, affiliates and communities to build cultures that foster innovation to achieve the best outcomes for patients.

Joining the Huron team means you’ll help our clients evolve and adapt to the rapidly changing healthcare environment and optimize existing business operations, improve clinical outcomes, create a more consumer-centric healthcare experience, and drive physician, patient and employee engagement across the enterprise.

Join our team as the expert you are now and create your future.
Position Summary
SUMMARY:

As a Data Analyst, you will support business operations by compiling data, conducting analyses, and creating reports to support the identification of meaningful trends. Data validation, interpretation, impactful analysis, and storytelling are critical skillsets required for the role. Outputs will be used by Huron consultants, Huron operators, and clients to identify areas of opportunity to drive performance improvement, trend and monitor progress against goals, and compare against baseline and best practice measures.

JOB DETAILS:

• Overall 3 to 6 years of relevant experience in healthcare
• Investigate trends through the use of standardized and ad hoc analyses to uncover insights that will support strategic and operational data-driven decision-making.
• Package analysis findings into standard format for consumption (e.g., summary report, scorecard, dashboard), flagging notable areas for immediate review and action.
• Support a variety analytical needs to identify trends and anomalies, leveraging statistical analysis techniques to assess revenue cycle performance.
• Build data visualizations, create dashboards, compile report sets and scorecards to support operational leaders.
• Conduct root cause analysis on revenue cycle issues and identify potential solutions.
• Perform data mapping, standardization, validation and quality assurance, ensuring highest standards of data integrity and accuracy throughout the data collection to reporting and final deliverables.
• Apply proven methodologies and best practices to unique situations and requests; collaborate with Huron team members and client stakeholders to design and implement effective solutions to complex business problems.
• Provide status reports; routinely and effectively communicate progress, risks, and final deliverable results to counterparts and stakeholders.
• Attend performance indicator metric review and project specific calls as appropriate.











SKILLS AND QUALIFICATIONS:

• Proven critical thinking skills in both data collection and complex analysis; ability to identify data gaps and risks, and develop sound conclusions
• Relevant US Healthcare / hospital or physician revenue cycle experience with a focus on data analysis
• Professional and polished written and verbal communication skills; ability to effectively summarize information and present findings and recommendations to internal and client leadership; skilled at interactions with varying levels from staff to leadership
• Ability to work independently as well as in a team environment
• Advanced or highly proficient in Microsoft Office (Word, PowerPoint, Excel)
• Ability to access and navigate client specific systems and databases
• Ability to effectively facilitate meetings and provide status reports on progress
• Demonstrated ability to effectively prioritize and manage multiple concurrent tasks with a high sense urgency and attention to detail.
Preferred but not required:
• Experience in visualization – custom dashboards and reporting, using tools like Tableau, PowerBI, Quicksight, Alteryx
• Experience in data literacy – ability to leverage large data sets, custom query, SQL

Education/Certifications:

• Any bachelor’s degree / Diploma
Qualifications
SUMMARY:
As a Data Analyst, you will support business operations by compiling data, conducting analyses, and creating reports to support the identification of meaningful trends.  Data validation, interpretation, impactful analysis, and storytelling are critical skillsets required for the role.  Outputs will be used by Huron consultants, Huron operators, and clients to identify areas of opportunity to drive performance improvement, trend and monitor progress against goals, and compare against baseline and best practice measures.
JOB DETAILS:
Overall 3 to 6 years of relevant experience in healthcare
Investigate trends through the use of standardized and ad hoc analyses to uncover insights that will support strategic and operational data-driven decision-making.
Package analysis findings into standard format for consumption (e.g., summary report, scorecard, dashboard), flagging notable areas for immediate review and action.
Support a variety analytical needs to identify trends and anomalies, leveraging statistical analysis techniques to assess revenue cycle performance.
Build data visualizations, create dashboards, compile report sets and scorecards to support operational leaders.
Conduct root cause analysis on revenue cycle issues and identify potential solutions.
Perform data mapping, standardization, validation and quality assurance, ensuring highest standards of data integrity and accuracy throughout the data collection to reporting and final deliverables.
Apply proven methodologies and best practices to unique situations and requests; collaborate with Huron team members and client stakeholders to design and implement effective solutions to complex business problems. 
Provide status reports; routinely and effectively communicate progress, risks, and final deliverable results to counterparts and stakeholders.
Attend performance indicator metric review and project specific calls as appropriate.
SKILLS AND QUALIFICATIONS:
Proven critical thinking skills in both data collection and complex analysis; ability to identify data gaps and risks, and develop sound conclusions
Relevant US Healthcare / hospital or physician revenue cycle experience with a focus on data analysis
Professional and polished written and verbal communication skills; ability to effectively summarize information and present findings and recommendations to internal and client leadership; skilled at interactions with varying levels from staff to leadership  
Ability to work independently as well as in a team environment
Advanced or highly proficient in Microsoft Office (Word, PowerPoint, Excel)
Ability to access and navigate client specific systems and databases
Ability to effectively facilitate meetings and provide status reports on progress
Demonstrated ability to effectively prioritize and manage multiple concurrent tasks with a high sense urgency and attention to detail.
Preferred but not required:
Experience in visualization – custom dashboards and reporting, using tools like Tableau, PowerBI, Quicksight, Alteryx
Experience in data literacy – ability to leverage large data sets, custom query, SQL
Education/Certifications:
Any bachelor’s degree  / Diploma
Posting Category
Healthcare
Opportunity Type
Regular
Country
India",USD 92K - 145K *
503,Senior Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru: We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
Tesco Business Services is a multi-disciplinary team that brings Tesco's Service Model to life. It aims to create a sustainable competitive advantage for Tesco by standardising processes, reducing cost to serve, enabling agility in the business and empowering colleagues to do even more for their customers. With cross-functional expertise, multi-locational teams supported by strong governance, Business Services reduces complexity and provides high quality services for its customers. The goal is to offer world-class service with real expertise delivering value for Tesco customers, and our shareholders. The organisation will create centres of excellence for improving economies of scale – freeing up our functional experts to deliver an enhanced customer experience. Learn more about Business Services and how we enhance customer experiences, provide cost leadership and indirect benefits for Tesco as we continue to serve enhances customer experiences.
Job Description
Understands business needs and in depth understanding of Tesco processes - Builds on Tesco processes and knowledge by applying CI tools and techniques. - Responsible for completing tasks and transactions within agreed KPI's - Solves problems by analyzing solution alternatives -Engaging with business & functional partners to understand business priorities, ask relevant questions and scope same into a analytical solution document calling out how application of data science will improve decision making - In depth understanding of techniques to prepare the analytical data set leveraging multiple complex data set sources - Building Statistical models and ML algorithms with practitioner level competency - Writing structured, modularized & codified algorithms using Continuous Improvement principles (development of knowledge assets and reusable modules on GitHub, Wiki, etc) with expert competency - Building easy visualization layer on top of the algorithms in order to empower end-users to take decisions - this could be on a visualization platform (Tableau / Python) or through a recommendation set through PPTs - Working with the line manager to ensure application / consumption and proactively identifying opportunities to help the larger Tesco business with areas of improvement - Keeping up-to-date with the latest in data science and retail analytics and disseminating the knowledge among colleagues
Qualifications
Skills Required: Operational skills relevant for this job: - Logical Reasoning; Adv Excel - Adv SQL; Hive; python; Tableau; Dash - Basic Statistical Concepts - Central measures of data; Linear & Logistics regression - Adv Statistical Concepts - ML - Regression; Classification; Clustering; Time Series - Gen AI - LLMs; RAG framework
- 2 - 4 years experience in data science application in Retail or CPG Preferred - Functional experience: Marketing, Supply Chain, Customer, Merchandising, Operations, Finance or Digital
Additional Information
Last Date of Application-9th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
504,Data Analyst - Data Ops,Arcadia,"Chennai, Tamil Nadu, India",Entry-level / Junior,"Who We Are :
Arcadia is the technology company empowering energy innovators and consumers to fight the climate crisis. Our software and APIs are revolutionizing an industry held back by outdated systems and institutions by creating unprecedented access to the data and clean energy needed to make a decarbonized energy grid possible.
In 2014, Arcadia set out on its mission to break the fossil fuel monopoly and since then we have been knocking down the institutional barriers to unlock decarbonization. To date, we have connected hundreds of thousands of consumers and small businesses with high-quality clean energy options. Fast forward to today, and now, we’re thinking even bigger. We have launched Arc, an industry-defining SaaS platform that empowers developers and energy innovators to deliver their own custom, personalized energy experiences, accelerating the transformation of the industry from an analog energy system into a digitized information network.
Tackling one of the world’s biggest challenges requires out-of-the-box thinking & diverse perspectives. We’re building a team of individuals from different backgrounds, industries, & educational experiences. If you share our passion for ushering in the era of the clean electron, we look forward to learning what you would uniquely bring to Arcadia! Visit www.arcadia.com.
HQ: Washington, DC & Chennai
$1.5B valuation; $380M funding to date
  Job Description – Data Analyst – Data Ops
Position Summary:
The position involves understanding the domain and process of generating, monitoring and delivering energy data to Customers.
Should possess good communication, analytical skills, team interaction and proficiency in using computer systems towards speedy on-boarding of Customers, set-up and initiation of processes as per Customer requirements, delegation of tasks to team members, troubleshooting issues / escalations, verifying and ensuring data accuracy from team, tracking and reporting and customer interaction
The candidates must have knowledge and prior experience using software systems for monitoring / tracking / reporting as well as proficiency in MS Excel (using Pivots, formulae etc.). 
Candidates who have experience with tracking and reporting using SQL queries (any database) would be an added advantage.
  Other Perks and Benefits
Competitive compensation based on market standards 
We are working on a hybrid model.
Apart from Fixed Base Salary potential candidates are eligible for following benefits
Flexible Leave Policy
Office is located in the heart of the city in case you need to step in for any purpose
Medical Insurance (1+5 Family Members)
Flexible Benefit Plan
Annual performance cycle
Quarterly engagement activities
L&D Program to foster professional growth
Eliminating carbon footprints, eliminating carbon copies.
Here at Arcadia, we cultivate diversity, celebrate individuality, and believe unique perspectives are key to our collective success in creating a clean energy future. Arcadia is committed to equal employment opportunity regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, protected veteran status, or any status protected by applicable federal, state, or local law. While we are currently unable to consider candidates who will require visa sponsorship, we welcome applications from all qualified candidates eligible to work in Chennai, India.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Thank you",USD 60K - 94K *
505,Senior Data Engineer,Bazaarvoice,Bengaluru,Senior-level / Expert," About Bazaarvoice
 At Bazaarvoice, we create smart shopping experiences. Through our expansive global network, product-passionate community & enterprise technology, we connect thousands of brands and retailers with billions of consumers. Our solutions enable brands to connect with consumers and collect valuable user-generated content, at an unprecedented scale. This content achieves global reach by leveraging our extensive and ever-expanding retail, social & search syndication network. And we make it easy for brands & retailers to gain valuable business insights from real-time consumer feedback with intuitive tools and dashboards. The result is smarter shopping: loyal customers, increased sales, and improved products.
 The problem we are trying to solve : Brands and retailers struggle to make real connections with consumers. It's a challenge to deliver trustworthy and inspiring content in the moments that matter most during the discovery and purchase cycle. The result? Time and money spent on content that doesn't attract new consumers, convert them, or earn their long-term loyalty.
 Our brand promise : closing the gap between brands and consumers.
 Founded in 2005, Bazaarvoice is headquartered in Austin, Texas with offices in North America, Europe, Asia and Australia.
 It’s official: Bazaarvoice is a Great Place to Work in the US , Australia, India, Lithuania, France, Germany and the UK!

Our teams create Bazaarvoice products that help companies understand the competitive positioning of their products.  A big area of business growth for Bazaarvoice will come from the efforts of our data teams.  Across more than 11,500 of the world’s leading brands and retailers, Bazaarvoice sees more 11 million reviews, images and questions added each month across millions of products.  Our data teams leverage these data sets to help our brand and retail clients build better products, build stronger relationships with their shoppers, and make decisions on when and where to offer products. 

Bazaarvoice provides consumer generated content to over 700 million devices and ½ billion unique users every month.  That content is hosted and collected on over 5000 brand and retail websites around the world.  Our Mission: build smarter shopper experiences across the entire customer journey.   We’re looking for candidates who want to build software that impacts over 500 million users, helping them make smart buying decisions, work with TB-scale datasets and globally distributed systems. 
 We are looking for a talented Software Engineer to design, build, and maintain scalable, big data pipelines. The position will focus on building and improving services that make it easier for internal teams to harness the power of existing data pipelines to keep data flowing through Bazaarvoice systems to support client use cases.
 Necessary skills and experience:
5+ years of experience building and supporting scalable, distributed systems using open source tools.
Proven hands-on experience with Object Oriented programming languages and with at least 1 scripting language (ex. Java/C++/etc and Python/Ruby/etc.)
An ability to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviews
Familiarity with modern build tools such as Maven, Jenkins, Github, etc.
Comfort delivering within Agile development methodologies ex. Scrum/Kanban
Strong analytical, technical, and communication skills
Interest in NLP and sentiment analysis.

Preferred Qualifications for the Role:
Experience building large-scale data processing systems and data warehousing solutions
Familiarity with one or more big-data technologies such as Hbase, Hadoop, Hive, Kafka, etc.
Working knowledge of at least 1 public cloud hosting provider (AWS (preferred), Google Cloud, Azure or similar)
#LI-Hybrid #LI-SR1

Why join Bazaarvoice?
 Customer is key
We see our own success through our customers’ outcomes.  
We approach every situation with a customer first mindset.
 Transparency & Integrity Builds Trust
We believe in the power of authentic feedback because it’s in our DNA. 
We do the right thing when faced with hard choices. Transparency and trust accelerate our collective performance.
 Passionate Pursuit of Performance
Our energy is contagious, because we hire for passion, drive & curiosity. 
We love what we do, and because we’re laser focused on our mission.
 Innovation over Imitation
We seek to innovate as we are not content with the status quo. 
We embrace agility and experimentation as an advantage.
 Stronger Together
We bring our whole selves to the mission and find value in diverse perspectives. 
We champion what’s best for Bazaarvoice before individuals or teams.  
As a stronger company we build a stronger community.
 Commitment to diversity and inclusion
 Bazaarvoice provides equal employment opportunities (EEO) to all team members and applicants according to their experience, talent, and qualifications for the job without regard to race, color, national origin, religion, age, disability, sex (including pregnancy, gender stereotyping, and marital status), sexual orientation, gender identity, genetic information, military/veteran status, or any other category protected by federal, state, or local law in every location in which the company has facilities. Bazaarvoice believes that diversity and an inclusive company culture are key drivers of creativity, innovation and performance. Furthermore, a diverse workforce and the maintenance of an atmosphere that welcomes versatile perspectives will enhance our ability to fulfill our vision of creating the world’s smartest network of consumers, brands, and retailers.",USD 121K - 188K *
506,Research Data Analyst,Komodo Health,"Chennai, Tamil Nadu, India",Entry-level / Junior,"We Breathe Life Into Data
At Komodo Health, our mission is to reduce the global burden of disease. And we believe that smarter use of data is essential to this mission. That’s why we built the Healthcare Map — the industry’s largest, most complete, precise view of the U.S. healthcare system — by combining de-identified, real-world patient data with innovative algorithms and decades of clinical experience. The Healthcare Map serves as our foundation for a powerful suite of software applications, helping us answer healthcare’s most complex questions for our partners. Across the healthcare ecosystem, we’re helping our clients unlock critical insights to track detailed patient behaviors and treatment patterns, identify gaps in care, address unmet patient needs, and reduce the global burden of disease. 
As we pursue these goals, it remains essential to us that we stay grounded in our values: be awesome, seek growth, deliver “wow,” and enjoy the ride. At Komodo, you will be joining a team of ambitious, supportive Dragons with diverse backgrounds but a shared passion to deliver on our mission to reduce the burden of disease — and enjoy the journey along the way.
The Opportunity at Komodo Health
This role is critical to designing and implementing data processing and analysis programming pipelines for Life Science/HEOR/RWE research studies utilizing the Komodo Healthcare Map.
Looking back on your first 12 months at Komodo Health, you will have…
Develop programming pipeline to perform large-scale data extraction, transformation, and validations to facilitate high-quality HEOR/RWE studies using SQL
Implement and execute analytic plans for observational research studies using Komodo data
Perform complex statistical modeling in a programming language such as R/Python/SAS
Take ownership of the analysis pipeline to generate results, and ensure that results align with study objectives and statistical approaches in the research protocol
Present interim and final results internally for review by stakeholders, incorporate feedback to the analysis pipeline and iterate on analytic plans as needed.
Create final deliverables in industry standard to share with external clients
Design and implement standardized programs for reproducible research
What you bring to Komodo Health:
Background in Statistics, Biostatistics, Data Science, Public Health, Epidemiology, or other relevant disciplines
Experience working with large-scale databases using SQL (data query, data cleaning, data transformation)
Experience working with a large healthcare database (preferably administrative claims or EHR)
Experience working in a research team collaborating with subject-matter experts on epidemiological research studies
Basic understanding of concepts used in epidemiological study design
Experience performing statistical analysis (descriptive analytics, regression, hypothesis testing, and visualization)
Proficient in implementing statistical methods in programming languages such as R/Python/SAS
Willingness to learn new tools and methods in order to deliver best-in-class results
Nice to have:
Advanced SQL skills, familiar with frameworks such as dbt
Familiar with standard programming practices such as version control and git
Extensive knowledge of epidemiological study design
Advanced knowledge in statistical modeling in the healthcare research area: PSM, KM, Cox model
Experience working with the healthcare system
Published manuscripts using claims data
Experience with other programming languages
#LI-REMOTE #LI-CT1
Where You’ll Work
Komodo Health has a hybrid work model; we recognize the power of choice and importance of flexibility for the well-being of both our company and our individual Dragons. Roles may be completely remote based anywhere in the country listed, remote but based in a specific region, or local (commuting distance) to one of our hubs in San Francisco, New York City, or Chicago with remote work options. 
What We Offer
On top of our commitment to providing competitive, fair pay for all roles at Komodo Health, we’re proud to offer robust and inclusive benefits to all Dragons at Komodo Health. We offer global time off programs, extensive internal and external career development and learning opportunities, and multiple affinity groups celebrating our team’s diversity.
Equal Opportunity Statement
Komodo Health provides equal employment opportunities to all applicants and employees. We prohibit discrimination and harassment of any type with regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. ",USD 60K - 94K *
507,"Sr Manager, Data Science and Digitalization",HashiCorp,India - Noida,Senior-level / Expert,"We are looking for a Sr Manager on FP&A Digitization team responsible for leading and shaping our analytics strategy, driving insights, and leveraging advanced analytics to optimize business performance. You will play a critical role in developing and executing data-driven initiatives.
This role will work closely with  FP&A digitization team, FP&A leaders, and GTM (Sales and operation teams ). Successful candidates will exhibit technical acumen looking at business problems through an analytics lens. with a passion for making an impact, through creative storytelling and timely actions.
This position offers an exciting opportunity to lead a talented team of data scientists and BI developers and cross-functional stakeholders to drive actionable insights.

What You Will Do
Develop and execute the overall business analytics strategy ( Descriptive to Predictive/Prescriptive) on BI and Data science, aligned with the company's goals and objectives.
Led and managed a Cross-functional team of BI and data scientists, providing mentorship, guidance, and fostering a culture of innovation and excellence.
Collaborate closely with cross-functional teams (Corporate, GTM, and R&D) to identify business challenges and opportunities that can be addressed through analytics techniques.
Provide leadership to deliver and scale- high-quality UI/UX ( visualization) on the BI platform (tableau) and implement highly interactive and insightful business KPIs and metrics.
Drive the development and deployment of machine learning models and predictive analytics to optimize business processes, improve FP&A forecasts, and drive revenue growth.
Stay up to date with the latest advancements in data science, machine learning, and AI technologies, and identify opportunities for their application within the organization.
Ensure data quality and integrity by establishing robust data governance practices and implementing effective data management strategies.
Present data-driven insights and recommendations to senior leadership and other stakeholders clearly and concisely with the ability to convey complex technical concepts to both technical and non-technical stakeholders.
Collaborate with other partners ( IT, Sales strategy, R&D, etc.) to leverage additional data sources and expertise, as needed.
Education
Degree in Management/ Statistics/ Mathematics/ Business Analytics from Tier-1 college. Overall, 12 - 15 years of experience in analytics and/or data science
Skillset and Experience
Proven experience (4+ years) in a leadership role within a data science or analytic function, preferably in a fast-paced and data-intensive industry. 
Demonstrated experience in leading and managing a high-performing cross-functional team of business analyst, data scientists, and Business Intelligence
Knowledge of SaaS consumption-based business model in a B2B environment
Expert knowledge of widely used statistical algorithms for supervised and unsupervised learning ( clustering)
Delivered high-accuracy solutions and a deep understanding of Forecasting Techniques.
Experience working in GTM function at a SaaS company, e.g. key go-to-market funnel optimization, customer acquisition, pipeline conversion, customer insights, retention, churn, etc will be an added advantage.
Nice to have
Engagement manager in tech roles
Client-facing experience.
Consulting background
Experience in Pricing Analytics [Good to have]. #LI-Onsite #LI-SG1
   Canada, Colorado, California, Washington and New York Applicants: To view base salary ranges for this role in your location and to learn more about which roles are eligible for bonus pay or commissions, please visit our Pay Transparency Calculator below. Individual pay within the range will be determined based on job related-factors such as skills, experience, and education or training. Information on our benefits can be found via the link below. Intern ranges can be found below.
Pay Transparency Calculator: https://bit.ly/3B7gwql
Benefits: https://www.hashicorp.com/careers/benefits
Intern Ranges: https://bit.ly/3H2soha",USD 45K - 84K *
508,Data Scientist,Magna International,"Bengaluru, IN",Senior-level / Expert,"Group Description
At Magna, we create technology that disrupts the industry and solves big problems for consumers, our customers, and the world around us. We’re the only mobility technology company and supplier with complete expertise across the entire vehicle.
We are committed to quality and continuous improvement because our products impact millions of people every day. But we’re more than what we make. We are a group of entrepreneurial-minded people whose collective expertise gives us a competitive advantage. World Class Manufacturing is a journey and it’s our talented people who lead us on this journey.
  Role Summary
We are looking for a Data Analyst / Scientist to analyze large amounts of raw information to find patterns that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our company analyze trends, close the data loop and and make better decisions.
Key Responsibilities
Lead the data projects, apply, and inspire the adoption of advanced data science and analytics across the team and projects.
Develop strategy and applications of statistical analysis, Machine Learning, Compute vision, and AI tools to improve product development, manufacturing, predictive maintenance, and business processes.
Identify valuable data sources and automate collection processes.
Undertake preprocessing of structured and unstructured data.
Analyze large amounts of information to discover trends and patterns.
Build predictive models and machine-learning algorithms.
Present information using data visualization techniques.
Propose solutions and strategies to business challenges.
Collaborate with engineering and product development teams Perform additional duties as assigned.
Leverage internal and external expertise as required.
Act with honesty and integrity and make ethical business choices in accordance with Magna’s Compliance Policies and Procedures.
Key Qualifications/Requirements
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred.
Minimum six plus (6+) years of related experience required.
Proven experience in ETL concepts.
Experience in data mining.
Understanding of machine-learning and operations research.
Knowledge of R, node.js, SQL and Python; familiarity with other programing languages is an asset, DevOps – GIT, Docker, CI/CD.
Deep Learning frameworks and tools such as TensorFlow.
Experience using business intelligence tools (e.g. MS Power BI, Grafana, etc) and cloud data frameworks.
Familiar with pipeline creation, e.g. with DataBricks and Jupyter notebooks.
Analytical mind and business acumen.
Good math skills (e.g. statistics, algebra).
Problem-solving attitude.
Excellent English communication skills (verbal and written) and profound presentation skills.
Knowledge of different project management methodologies such as Waterfall and Agile.
Ability to learn, be self-motivated and driven to identify high value opportunities, gain information, develop understanding, and engage in implementation.
Additional Information
Regular travel less than 5% of the time.

For dedicated and motivated employees, we offer an interesting and diversified job within a dynamic global team together with the individual and functional development in a professional environment of a global acting business. Fair treatment and a sense of responsibility towards employees are the principle of the Magna culture. We strive to offer an inspiring and motivating work environment.
  We offer attractive benefits (e.g. discretionary performance bonus) and a salary which is in line with market conditions depending on your skills and experience.
Awareness. Unity. Empowerment.
At Magna, we believe that a diverse workforce is critical to our success. That’s why we are proud to be an equal opportunity employer. We hire on the basis of experience and qualifications, and in consideration of job requirements, regardless of, in particular, color, ancestry, religion, gender, origin, sexual orientation, age, citizenship, marital status, disability or gender identity. Magna takes the privacy of your personal information seriously. We discourage you from sending applications via email to comply with GDPR requirements and your local Data Privacy Law.",USD 136K - 205K *
509,Senior Data Scientist - India,Globant,"Pune, Maharashtra, IN",Senior-level / Expert,"We are a digitally native company that helps organizations reinvent themselves and unleash their potential. We are the place where innovation, design and engineering meet scale.  
Globant is 20 years old, NYSE listed public organization with more than 26500 employees worldwide working out of 25 countries globally.
www.globant.com

We are looking for evolutionary Senior Data Scientist to join our Data Studio. 
We are hiring strategic Data Scientists to join our Data & AI Studio. Our expertise allows us to create a wide variety of end to end solutions for industries including finance, travel, media & entertainment, retail, health, among others. We democratize data and foster organizational changes towards a data-driven culture. Join us in discovering the real value of Data.
  Right now, we are looking for Senior Data Scientist to join our team at Globant!
Location:  Pune\ Bengaluru\ Indore\ Ahmedabad
Experience Range: 4-8 Years
  Responsibilities
• Develop predictive models using supervised and unsupervised machine learning/deep learning
• Build models for legal predictive analytics, natural language understanding, conversational AI, robotic accounting, forecasting and anomaly detection
• Provide expertise in data wrangling, exploratory data analysis and feature engineering with large data sets
• Support the development of proofs of concept to demonstrate the application of AI/ML capabilities in solving customer problems in collaboration with product and other development Teams
• A self-starter who can align the technology solution with a business goal
  Qualifications
• Undergraduate or Graduate degree (MS or PhD) in Computer Science, Engineering, Mathematics or equivalent, specializing in machine learning or a related field
• 3+ years’ experience in supporting development of production-ready solutions leveraging AI technologies: NLP, Deep Learning, Machine Learning
• Strong hands-on expertise in Python and open source libraries/frameworks/tools such as NumPy, SciPy, scikit-learn, pandas, matplotlib, spaCy, NLTK, jupyter, anaconda, transformers, etc.
• Experience with deep learning frameworks such as TensorFlow, Keras, PyTorch
• Experience in applying deep learning to NLP
• Computer vision modeling a plus
• Experience with designing, building, and optimizing data and model training pipelines
• Experience in SageMaker or Azure ML Studio a plus
• Experience with cloud-based platforms (AWS or Azure) for solution delivery
• Experience working with agile and Software Development Lifecycle tools (e.g. JIRA, Confluence,Git) and Test-Driven Development (TDD)

You will get the chance to:
  Develop your career in our Studios. Each Studio represents deep pockets of expertise on the latest technologies and trends and delivers tailored solutions focused on specific challenges.
Develop your career within an industry or multiple industries.
Be empowered to choose your career path: we have more than 600 simultaneous projects, so you can choose where and how to work.
Be part of an agile pod. Driven by a culture of self-regulated teamwork, each team -or POD- works directly with our customers with a full maturity path that evolves as they increase speed, quality and autonomy.

What will help you succeed:
Experience with Python is must have
Experience with model deployment on AKS, API development, Flask, etc is required
Well versed with Natural Language Processing techniques
Business Skills
Client Handling & Communication
Problem-solving / critical thinking
Systems Thinking
Interest and passion for Technology
Willingness to help teams become agile, high performing and  foster a culture of team-work and sustainable

Are you ready?",USD 136K - 205K *
510,Business Data Analyst,NetApp,"Bengaluru, Karnataka, IN, 560071",Entry-level / Junior,"About NetApp
We’re forward-thinking technology people with heart. We make our own rules, drive our own opportunities, and try to approach every challenge with fresh eyes. Of course, we can’t do it alone. We know when to ask for help, collaborate with others, and partner with smart people. We embrace diversity and openness because it’s in our DNA. We push limits and reward great ideas. What is your great idea?
""At NetApp, we fully embrace and advance a diverse, inclusive global workforce with a culture of belonging that leverages the backgrounds and perspectives of all employees, customers, partners, and communities to foster a higher performing organization."" -George Kurian, CEO
Job Summary
Our Customer Success team is one of NetApp’s strongest assets, enabling us to strengthen our customer relationships by delivering on our promise of superior technology and proven results. As NetApp Customer Success embarks on the next phase of growth, we are looking for a highly motivated hands-on Customer Success Operations Lead to support our team. 
We are seeking a highly organized and detail-oriented professional to join our Customer Success team as a Customer Success Operations and System Tools Specialist. In this role, you will play a crucial part in optimizing our customer success operations and leveraging system tools to enhance efficiency, customer satisfaction, and overall business success.
Job Requirements
1.    Customer Data Management:
•    Maintain and update customer records in the Customer Relationship Management (CRM) system.
•    Ensure accuracy and completeness of customer information to support effective customer engagement.
2.    System Tools Administration:
•    Administer and configure customer success tools and platforms to meet business requirements.
•    Collaborate with cross-functional teams to integrate customer success tools with other systems as needed.
3.    Reporting and Analytics:
•    Generate and analyze reports to provide insights into customer success performance.
•    Utilize data to identify trends, opportunities, and areas for improvement.
4.    Process Optimization:
•    Work closely with the Customer Success team to streamline processes and workflows.
•    Implement best practices and identify automation opportunities to increase operational efficiency.
5.    Training and Support:
•    Train Customer Success team members on the effective use of system tools.
•    Provide ongoing support and troubleshooting assistance to users.
6.    Collaboration:
•    Collaborate with Sales, Marketing, and Product teams to ensure alignment on customer data and processes.
•    Participate in cross-functional projects to enhance overall customer experience.
Preferred Skills:
•    Experience with popular customer success tools such as Gainsight, Totango, or similar platforms.
•    Experience on BI Tools Experience is a Plus Like Tableau, PowerBi 
•    Snowflakes and SFDC Connectivity Through API experience will be a plus 
•    Knowledge of data analysis tools and techniques.
•    Project management skills and experience.
•    Familiarity with SaaS and subscription-based business models.
•    Familiarity with Customer Relationship Management (CRM) systems and other customer success tools.
•    Strong analytical skills with the ability to translate data into actionable insights.
  Education
•    Experience 8 – 12 years in Customer Success Operation and System Tools Administration 
•    Bachelor's degree in Business, Information Technology, Computer science  or a related field or Masters in Computer Application 
Did you know…
Statistics show women apply to jobs only when they’re 100% qualified. But no one is 100% qualified. We encourage you to shift the trend and apply anyway! We look forward to hearing from you.
Why NetApp?
In a world full of generalists, NetApp is a specialist. No one knows how to elevate the world’s biggest clouds like NetApp. We are data-driven and empowered to innovate. Trust, integrity, and teamwork all combine to make a difference for our customers, partners, and communities. 
 
We expect a healthy work-life balance. Our volunteer time off program is best in class, offering employees 40 hours of paid time off per year to volunteer with their favorite organizations.  We provide comprehensive medical, dental, wellness, and vision plans for you and your family.  We offer educational assistance, legal services, and access to discounts. We also offer financial savings programs to help you plan for your future.  
 
If you run toward knowledge and problem-solving, join us. ",USD 30K - 79K *
511,Business Intelligence Analyst,NetApp,"Bengaluru, Karnataka, IN, 560071",Entry-level / Junior,"About NetApp
We’re forward-thinking technology people with heart. We make our own rules, drive our own opportunities, and try to approach every challenge with fresh eyes. Of course, we can’t do it alone. We know when to ask for help, collaborate with others, and partner with smart people. We embrace diversity and openness because it’s in our DNA. We push limits and reward great ideas. What is your great idea?
""At NetApp, we fully embrace and advance a diverse, inclusive global workforce with a culture of belonging that leverages the backgrounds and perspectives of all employees, customers, partners, and communities to foster a higher performing organization."" -George Kurian, CEO
Job Summary
Our Customer Success team is one of NetApp’s strongest assets, enabling us to strengthen our customer relationships by delivering on our promise of superior technology and proven results.
As NetApp Customer Success embarks on the next phase of growth, we are looking for a highly motivated hands-on Customer Success Operations Lead to support our team.
Job Requirements
Responsibilities
    Develop and deliver digital initiatives to improve the effectiveness and efficiency of sales and adoption capabilities for NetApp prospects and customer, including:
    Digital customer journey and experience
    Customer journey development
    Go-to-market (GTM) and/or customer consumption campaigns, including collaboration with Customer Success, Marketing, Product, Data Teams, and Sales and customer success Operations
    Digital journey development, content creation and curation, and metrics
    Enhance and augment digital experience for named CSM-led customers
    Cross-functionally align the digital experience across email campaigns, in-app, the customer portal, Product feedback, etc. for a non-fragmented customer experience
    Define, lead and track strategic and operational digital programs to successful completion
    Design, evaluate, and measure digital programs against internal targets for continuous improvement
    Leverage data and analytics to develop, lead, and measure results for GTM sales and consumption-related initiatives, programs, and campaigns
    Drive the ARR growth and Product usage KPIs as an underpinning performance metrics
Requirements
    Demonstrated progressive experience with Digital Programs, Customer Marketing, or related experience with a technical SaaS or subscription software service
    Management experience in running digital or named CSM teams
    Rich knowledge and track record with email campaigns, in-app experience, webinars/events, and certifications
    Demonstrated progressive customer success experience leading relevant teams (Customer Success Managers, Account Management, Customer Marketing, Demand Gen) and/or operations
    Experience with defining and leading digital engagement strategies (i.e., digital journey creation, content marketing, etc.)
    Experience with software development tools, practices, and methodologies is a plus
    Experienced leading cross-functional initiatives in mid-sized or large organizations (i.e., 1000+ employees)
    Management experience with a team of at least 5 team members
    Experience with digital engagement approaches and methods (i.e., Digital Customer Success / tech touch, Digital Marketing)
    Demonstrated success with cross-functional coordination, including planning, execution tracking, decision making, and OKR management 
    Ability to learn NetApp cloud products as part of the role 
Education
B.E (CSE), B.tech, B.Sc Match or Statistics. Certification in PMP. 
Must have 5-8 years of experience in Operations, Analytics (preferably in Customer Success)
Did you know…
Statistics show women apply to jobs only when they’re 100% qualified. But no one is 100% qualified. We encourage you to shift the trend and apply anyway! We look forward to hearing from you.
Why NetApp?
In a world full of generalists, NetApp is a specialist. No one knows how to elevate the world’s biggest clouds like NetApp. We are data-driven and empowered to innovate. Trust, integrity, and teamwork all combine to make a difference for our customers, partners, and communities. 
 
We expect a healthy work-life balance. Our volunteer time off program is best in class, offering employees 40 hours of paid time off per year to volunteer with their favorite organizations.  We provide comprehensive medical, dental, wellness, and vision plans for you and your family.  We offer educational assistance, legal services, and access to discounts. We also offer financial savings programs to help you plan for your future.  
 
If you run toward knowledge and problem-solving, join us. ",USD 55K - 91K *
512,MANAGER - BUSINESS PROCESS MODELS (Retail Credit Risk),ANZ Banking Group Limited,"Bengaluru, IN",Mid-level / Intermediate,"About the role
  At ANZ our purpose is to shape a world where people and communities thrive. We’re making this happen by improving the financial wellbeing and sustainability of our customers so they can achieve incredible things– whether they’re buying a home, building a business or saving for things big or small.
  The ANZ Australia Risk division are expanding their presence in Bengaluru, with a great career opportunity to join the Global Capability Centre at ANZ and be part of the team to deliver on the Australia Risk strategy.  Join an innovative, vibrant team that includes credit risk, operational risk, compliance, and governance professionals, modelling and portfolio management experts. Experience an exciting team environment that genuinely focuses on your growth and development.
  The Manager- Business Process Models role is responsible for managing activities that ensure Australia Retail Business Process models are fit-for-purpose and used effectively.  The role involves building models and coaching analysts to build models, supporting model implementations and model governance including model monitoring and validation reviews, providing expertise on the use of models in credit risk strategies across the credit lifecycle, and sharing insights on drivers of model trends.
  This role is responsible and accountable for the following core activities:
Improving the efficiency and effectiveness of credit risk processes and strategies through the development, implementation, and management of customised modelling solutions (in the areas of origination, limit management, collections, compliance, and other credit risk lifecycle event domains).
Acting as a key point of contact between Retail Risk teams, nominated business units, and other teams in the ANZ model governance community for model management issues.
Developing models for use cases related to business process improvements in accordance with Risk policy.
Project management of model development initiatives; providing regular updates to the Head of Australia Retail Risk Models and key stakeholders on project status and managing issues and risks associated with the delivery. 
Providing technical advice, technical training and coaching to modelling analysts where required.
Acting as a subject matter expert in modelling methodology and providing consultative advice to Australia Retail Risk teams and ANZ Australia Business Units on model-related matters including model usage.
Providing insight on the drivers of model outcomes
Undertaking research and investigating new analytical approaches or advanced modelling techniques for solving business problems
Ensuring all models delivered comply with ANZ Group governance requirements, policies, processes, and standards and with legal and regulatory requirements.
Maintenance of relevant business-process-model-related controls and practices that appropriately reflect developments in the non-financial risk environment for the purpose of ensuring compliance with relevant regulatory standards, and internal governance expectations.
Providing input into the risk data and analytics environment, embedding data governance requirements and managing day-to-day data integrity issues where required.
Support the Stream Lead – Business Process Models to prepare data and metrics-driven rationale for determining prioritisation of model development projects and remediation plans.
  Role Location: Bengaluru
Role Type: Permanent
What will you bring?
  To be successful in this role, you will ideally bring the following:
  7-10 years of experience in analytics and credit risk modelling with technical expertise in modelling methodology for decisioning models, capital models and/or business process improvement models
Retail banking portfolio knowledge with credit risk management related work experience
Experienced in advanced machine learning techniques, sound understanding of risks associated with machine learning models and ability to design controls to mitigate these risks (preferred)
Proven capability to provide technical review and assessment of Retail models, including during development and as part of ongoing model management.
Well-developed written and oral skills, and excellent at presenting highly complex problems and processes in simple terms that are easily consumed by a broad range of stakeholders, adjusting the level of messaging to suit the audience.
Proven ability to communicate up (one level above) and amongst peer groups.
Collaborative mindset and driven towards efficiency and knowledge sharing within and across teams.
Strong analytical, numerical, research and problem-solving skills.
Proven technical capabilities and experience with data analytics/science and/or decision systems techniques and tools (e.g., SAS, SAS Viya, SQL, R, Python, PowerCurve, AbInitio, etc.).
Understanding of model deployment options depending on use case, and ability to collaborate with data scientists and non-specialist engineers to productionise models.
Passion for pro-actively identifying continuous improvement opportunities.
Strong technical skills with solid leadership skills, with ~30% of role behavioural-related involving stakeholder engagement, with the remaining ~70% of the role technical-related (having already exhibited experience in previous technical roles via individual’s career path). 
  You’re not expected to have 100% of these skills. At ANZ a growth mindset is at the heart of our culture, so if you have most of these things in your toolbox, we’d love to hear from you.
So, why join us?
  There’s something special about being part of ANZ.  From the moment you join us, you’re part of a team working towards a common goal: improving the financial wellbeing and sustainability of our millions of customers.
  As a Purpose-led bank, we’ve committed to delivering commercial and societal outcomes across environmental sustainability, financial wellbeing and household affordability.  We deliver these sustainability commitments with our customers, in our business and across the communities where we operate.
  But it’s not just our customers who’ll feel your impact. You’ll feel it too. Because at ANZ, you’ll have the resources and community you need to take the next big step in your career, towards even bigger things in the future.
  We offer a range of benefits tailored to the countries in which we operate including Health and Wellbeing programs and flexible working arrangements.
  You’ll also enjoy working in a diverse and inclusive workplace where the different backgrounds, perspectives and life experiences of our people are celebrated. We encourage you to talk to us about any adjustments you may require to our recruitment process or the role itself. If you are a candidate with a disability, let us know how we can provide you with additional support.
  To find out more about working at ANZ or to view other opportunities visit www.careers.anz.com. You may apply for this role by visiting ANZ Careers and searching for reference number 56656.
Job Posting End Date
 27/12/2023, 11.59pm, (Melbourne Australia)",USD 30K - 56K *
513,Senior Associate - Python Developer - AI and Machine Learning and Chat GPT,Publicis Groupe,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Re:Sources is the backbone of Publicis Groupe, the world’s third-largest communications group. Formed in 1998 as a small team to service a few Publicis Groupe firms, Re:Sources has grown to 5,000+ people servicing a global network of prestigious advertising, public relations, media, healthcare and digital marketing agencies. We provide technology solutions and business services including finance, accounting, legal, benefits, procurement, tax, real estate, treasury and risk management to help Publicis Groupe agencies do what they do best: create and innovate for their clients.   
In addition to providing essential, everyday services to our agencies, Re:Sources develops and implements platforms, applications and tools to enhance productivity, encourage collaboration and enable professional and personal development. We continually transform to keep pace with our ever-changing communications industry and thrive on a spirit of innovation felt around the globe. With our support, Publicis Groupe agencies continue to create and deliver award-winning campaigns for their clients.
Job Description
Job Title: Python Developer - AI and Machine Learning
Location: Gurgaon Job Type: Full-Time Position
Overview: We are looking for a skilled Python Developer with expertise in
Open AI, Gen AI, Chat GPT, machine learning, regression, linear algorithms, and prompt engineering.
The ideal candidate will play a critical role in designing, implementing, and maintaining AI/ML-driven solutions that solve complex problems and drive innovation in the field of AI and machine learning.
Key Responsibilities: 1. Collaborate with data scientists and AI engineers to understand project requirements and translate them into scalable Python code.
2. Develop, implement, and optimize machine learning models using Python libraries such as TensorFlow, PyTorch, or scikit-learn.
3. Design and implement machine learning algorithms, including supervised and unsupervised learning methods, reinforcement learning, and deep learning techniques. 4. Develop and implement evaluation metrics and methodologies to assess algorithm performance.
5. Stay up-to-date with the latest advancements in machine learning and artificial intelligence, and apply new techniques and technologies to enhance existing algorithms.
6. Create and optimize prompts that elicit desired responses from AI language models, taking into consideration various use cases and user requirements.
7. Analyze user interactions and feedback to iteratively enhance prompts for better model performance.
8. Develop and implement evaluation metrics and methodologies to assess the effectiveness of prompts in achieving desired outcomes.
9. Work closely with Open AI and Gen AI APIs to integrate their capabilities into our AI solutions.
10.Perform data preprocessing, feature engineering, and data augmentation to prepare datasets for training and evaluation.
11.Conduct model evaluation, hyperparameter tuning, and performance optimization to achieve state-of-the-art results.
12.Collaborate with the research team to stay updated on the latest advancements in AI and machine learning.
13.Design and implement regression and linear algorithms to address specific business challenges.
14.Create and maintain documentation for code, algorithms, and models.
15.Ensure code quality, maintainability, and scalability by following best practices and code review processes.
16.Stay informed about emerging trends in AI, machine learning, and related technologies.
17. azure cloud, azure cognitive services would be an added advantage.
Qualifications: • Bachelor’s or master’s degree in computer science, Data Science, or a related field.
• Proven experience (X years) as a Python Developer with a focus on AI and machine learning.
• Strong knowledge of Python programming and proficiency in relevant libraries (e.g., TensorFlow, PyTorch, scikit-learn).
• Expertise in working with Open AI and Gen AI APIs.
• Solid understanding of machine learning concepts, regression, and linear algorithms.
• Experience with prompt engineering and natural language processing (NLP) is a plus.
• Excellent problem-solving skills and attention to detail.
• Strong communication and teamwork skills.
• Ability to work independently and meet project deadline
Qualifications
Bachelor’s or master’s degree in computer science, Data Science, or a related field. Python Must 
Additional Information
7+ Years. 
  Publicis Groupe Commitment to Diversity & Equity Policy:
Publicis Groupe is deeply committed to diversity and inclusion in spirit and in action at every level of the organization. It reflects our core values and embodies our purpose of building a great company enabling human potential. We have a deep-rooted appreciation for how diversity of thought drives innovation, and we ground that value in a culture of collaboration and connected thinking.  
Diversity & inclusion are business imperatives on which Publicis Groupe will not negotiate. While fostering a work environment that is inclusive of all talent is a collective responsibility, it is leadership’s job to nurture the career aspirations and goals of all our talent. Promoting gender equality starts at the top and the Groupe will not tolerate anyone speaking for our organization who does not value the importance of inclusion. Publicis Groupe works very hard to champion diversity and will continue to insist that each agency’s leadership be champions of both diversity and inclusion.
Our Core values “ VIVA LA DIFFERENC’E is based on the very aspect of celebrating differences 
Our strategy focuses on bringing together teams with diverse perspectives, disciplines, and experiences, because diversity of thought best serves our clients and their customers who they aspire to impact
Equal Employment Commitment:
We provide equal opportunities to all our employees and to all eligible applicants for employment in our company. We do not unfairly discriminate on any ground, including race, caste, religion, color, ancestry, marital status, gender, sexual orientation, age, nationality, ethnic origin, disability or any other category protected by applicable law.
When recruiting, developing and promoting our employees, our decisions will be based solely on performance, merit, competence and potential.
We shall have fair, transparent and clear employee policies which promote diversity and equality, in accordance with applicable law and other provisions of this Code. These policies shall provide for clear terms of employment, training, development and performance management.",USD 30K - 56K *
514,STREAM LEAD - BUSINESS PROCESS MODELS (Retail Credit Risk),ANZ Banking Group Limited,"Bengaluru, IN",Senior-level / Expert,"About the role
  At ANZ our purpose is to shape a world where people and communities thrive. We’re making this happen by improving the financial wellbeing and sustainability of our customers so they can achieve incredible things– whether they’re buying a home, building a business or saving for things big or small.
  The ANZ Australia Risk division are expanding their presence in Bengaluru, with a great career opportunity to join the Global Capability Centre at ANZ and be part of the team to deliver on the Australia Risk strategy.  Join an innovative, vibrant team that includes credit risk, operational risk, compliance, and governance professionals, modelling and portfolio management experts. Experience an exciting team environment that genuinely focuses on your growth and development.
  The Stream Lead for Business Process models is responsible for the development and ongoing management of models that support the improvement of retail credit risk processes and strategies across the credit lifecycle of Australia Retail Risk portfolios. In addition, this role is also responsible for model governance (including model monitoring, supporting validation (or peer) reviews and model implementations), providing expertise on the use of business process models in credit risk strategies and sharing insights on drivers of model outcomes/ trends.
  Stakeholder management and engagement is crucial at this level and the Stream lead for Business Process models is expected to work collaboratively with key stakeholders involved in model development and model usage across business units and risk teams, as well as provide updates and engage with members of the modelling governance community.
  This role is responsible and accountable for the following core activities:
Improving the efficiency and effectiveness of credit risk processes and strategies through the development, implementation, and management of customised modelling solutions (in the areas of origination, limit management, collections, compliance, and other credit risk lifecycle event domains).
Delivery, project planning and relevant stakeholder management for business process modelling initiatives.
Supporting the career development of team members and uplifting capability across the team to enable delivery of current and future elements of long-term strategy.
Providing technical advice, technical training and mentoring to team members where required.
Acting as a senior subject matter expert in modelling methodology and providing consultative advice to Australia Retail Risk teams and ANZ Australia Business Units on model-related matters including model usage.
Providing insight on the drivers of model outcomes.
Undertaking research and investigating new analytical approaches or advanced modelling techniques for solving business problems.
Ensuring all models delivered comply with ANZ Group governance requirements, policies, processes, and standards and with legal and regulatory requirements.
Maintenance of relevant business-process-model-related controls and practices that appropriately reflect developments in the non-financial risk environment for the purpose of ensuring compliance with relevant regulatory standards, and internal governance expectations. 
Providing strategic input into the risk data and analytics environment, embedding data governance requirements, and managing day-to-day data integrity issues where required.
Management of data stewardship functions in relation to advanced analytics platforms used by Australia Retail Risk.
  Role Location: Bengaluru
Role Type: Permanent
What will you bring?
  To be successful in this role, you will ideally bring the following:
  9+ years of experience in analytics and credit risk modelling with technical expertise in modelling methodology for decisioning models, capital models and/or business process improvement models.
Retail banking portfolio knowledge with credit risk management related work experience
Experienced in advanced machine learning techniques, sound understanding of risks associated with machine learning models and ability to design controls to mitigate these risks (preferred)
Sound understanding of model deployment options depending on use case, and ability to collaborate with data scientists and non-specialist engineers to productionise models.
Experienced in the deployment of machine learning models (preferred)
Excellent communication (written & oral) and interpersonal skills.
Strong analytical, numerical, research and problem-solving skills.
Proven technical capabilities and experience with data analytics/science and/or decision systems techniques and tools (e.g., SAS, SAS Viya, SQL, R, Python, PowerCurve, AbInitio, etc.). 
Strong proven leadership skills, with ~70% of the role leadership-related, requiring strong people management, stakeholder engagement skills and executive presence, with the remaining ~30% of the role technical-related (having already exhibited experience in previous technical roles via individual’s career path). 
Demonstrated ability to build and maintain relationships with various stakeholders and to influence change.
Collaborative mindset and driven towards efficiency and knowledge sharing within and across teams. 
Passion for pro-actively identifying continuous improvement opportunities.
Effective people and project management skills - with the ability to motivate and manage a team of managers and/or analysts.   
  You’re not expected to have 100% of these skills. At ANZ a growth mindset is at the heart of our culture, so if you have most of these things in your toolbox, we’d love to hear from you.
So, why join us?
  There’s something special about being part of ANZ.  From the moment you join us, you’re part of a team working towards a common goal: improving the financial wellbeing and sustainability of our millions of customers.
  As a Purpose-led bank, we’ve committed to delivering commercial and societal outcomes across environmental sustainability, financial wellbeing and household affordability.  We deliver these sustainability commitments with our customers, in our business and across the communities where we operate.
  But it’s not just our customers who’ll feel your impact. You’ll feel it too. Because at ANZ, you’ll have the resources and community you need to take the next big step in your career, towards even bigger things in the future.
  We offer a range of benefits tailored to the countries in which we operate including Health and Wellbeing programs and flexible working arrangements.
  You’ll also enjoy working in a diverse and inclusive workplace where the different backgrounds, perspectives and life experiences of our people are celebrated. We encourage you to talk to us about any adjustments you may require to our recruitment process or the role itself. If you are a candidate with a disability, let us know how we can provide you with additional support.
  To find out more about working at ANZ or to view other opportunities visit www.careers.anz.com. You may apply for this role by visiting ANZ Careers and searching for reference number 55484.
Job Posting End Date
 27/12/2023, 11.59pm, (Melbourne Australia)",USD 45K - 84K *
515,SAP BTP Prompt Engineering Staff,EY,"Noida, UP, IN, 201301",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        SAP BTP Prompt Engineering:
3-5 years of experience as a Machine Learning Engineer, with a focus on generative AI models and neural networks. 
Strong programming skills in Python, C++, or Java. 
Experience with deep learning frameworks such as TensorFlow or PyTorch. 
Knowledge of machine learning algorithms such as decision trees, random forests, and clustering algorithms. 
Familiarity with cloud computing platforms such as AWS or Azure.
Ability to conduct thorough testing and validation of generative models. 
To work closely with cross-functional teams, including data scientists, product managers, and development teams. 
Need to have an up-to-date knowledge on the latest developments in AI and machine learning.
  EY | Building a better working world 
  EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.
  Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.
  Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 45K - 84K *
516,Manager - HR Data Analyst - RPO,Vodafone Idea Limited,"Pune, IN",Entry-level / Junior,"Vodafone Idea Limited is an Aditya Birla Group and Vodafone Group partnership. It is India’s leading telecom service provider. The Company provides pan India Voice and Data services across 2G, 3G and 4G platform. With the large spectrum portfolio to support the growing demand for data and voice, the company is committed to deliver delightful customer experiences and contribute towards creating a truly ‘Digital India’ by enabling millions of citizens to connect and build a better tomorrow. The Company is developing infrastructure to introduce newer and smarter technologies, making both retail and enterprise customers future ready with innovative offerings, conveniently accessible through an ecosystem of digital channels as well as extensive on-ground presence. The Company is listed on National Stock Exchange (NSE) and Bombay Stock Exchange (BSE) in India.
Role
Manager HR Analyst
Job Level/ Designation
Manager- M1
Function / Department
HR Recruitment
Location
Pune
Job Purpose
Data Analyst, Talent Acquisition will own the data analysis for Talent Acquisition team. In this role, he/she will collaborate directly with Talent Acquisition leaders & team members to inspect recruiting processes and identify insights that increase recruiting efficiency, candidate experience, and our ability to hire talent. The analysis will contribute deeply to the development of Vi talent acquisition strategy and drive impact against our hiring objectives.
  Key Result Areas/Accountabilities
Develop dashboards, templates, and documentation for the TA function
Produce and present weekly, monthly, and quarterly talent acquisition reporting and insights
Evaluate and report on key metrics around recruitment and hiring globally
Analyze and report on candidate and EXX experience survey results
Ensure high integrity and accuracy of recruiting data through audits and governance
Identify business process improvements to optimize data collection opportunities
Closely work with SF tech team to extract system data and drive efficiencies
  Core Competencies, Knowledge, Experience
3+ years of industry experience
Proficient with report creation and data visualization with Qlikview/Tableau/ Excel/Sheets and PowerPoint/Presentations
Worked on Success Factor
Advanced MS Excel skills (Power Query, Power Pivot, Macro, Lookups)
SQL Query Language
Demonstrated ability to turn data into insights and communicate those insights in an effective manner.
Demonstrated knowledge of recruitment processes and most commonly used KPIs in Talent Acquisition.
  Must have technical / professional qualifications
Edu Qualification – B TEch
    Vodafone Idea Limited (formerly Idea Cellular Limited)
An Aditya Birla Group & Vodafone partnership",USD 60K - 94K *
517,Manager (DB/ETL),dentsu international,"Pune, India",Mid-level / Intermediate,"Company Description
Merkle, a dentsu company, is a leading data-driven customer experience management enterprise specializing in delivering unique, personalized customer experiences across platforms and devices. With over 30 years of experience, Merkle partners with Fortune 1000 companies and non-profit organizations to optimize their customer portfolios. Its expertise in data, technology, and analytics enables it to gain insights into consumer behavior, driving hyper-personalized marketing strategies. Merkle's consulting, creative, media, analytics, data, identity, CX/commerce, technology, and loyalty & promotions capabilities combine to drive improved marketing results and a competitive edge. With over 14,000 employees, Merkle is headquartered in Columbia, Maryland, with more than 50 additional offices worldwide. Its innovative solutions enable brands to build meaningful customer relationships and enhanced customer experience.
Job Description
Experience : 8 to 12 Years
Must Have Skills : 
Database (Oracle / SQL / Teradata / Redshift / Big query etc)
SQL / PL SQL query writing
ETL tool (Talend or Informatica or any one ETL tool)
Python and UNIX shell scripting
Tidal (any scheduling tool), Matillion (ETL)
Stakeholder Management
Good communication skills
Good to Have Skills : 
MS Office, Client-facing skills
Databricks
Snowflake DB / RedShift
Cloud computing (one or more of AWS, Azure, GCP)
Roles & Responsibilities : 
Play solo role which requires coding being part of internal product team
Design simple to medium processes for clients
Work on Data warehousing, data mart, databases, and data ingestion and transformation
Opportunity to be on a learning part to be a Data Engineer
Use DB skills (Oracle, SQL server, Teradata, Vertica, redshift, Big query, Azure DW etc)
Collaborate with local leadership as well as our global teams to build best in class solutions.
Provide full support to Client, Data Scientists and Analytical Consultants working on marketing solution
Will work on Unix scripting &/or Python as well as ETL (Training will be provided for ETL such as Talend)
Cross functional team work internally and with external clients
Code management systems which includes code review and deployment",USD 30K - 56K *
518,Manager - Data Engineering,Marsh McLennan,Pune - Business Bay,Mid-level / Intermediate,"Company:
Marsh
Description:
WE WILL COUNT ON YOU:
Conceptualize, design and develop a comprehensive, thoughtful, and best-in-class Restful API to provide access to Marsh’s core services and data.
Create detailed API documentation to enable third party developers to easily integrate with Marsh’s platform.
Create and maintain API client libraries to provide easy to use interface for third party integrations and developers.
Track the API performance metrics and work to improve the stability, scalability, and availability of APIs
Monitor API usage to identify tends and anticipate business needs
Displays outward thinking, develop strategies for the full software development lifecycle of new and emerging technologies and demonstrates viability.
Collaborate with developers, product managers, and other stakeholders to understand the business needs and develop solutions that meet those needs.
Troubleshoot incidents, identify root causes, fix, and document problems, and implement preventive measures
Performs other duties as assigned.
WHAT YOU NEED TO HAVE:
Bachelor’s degree (or equivalent) in computer science, information technology, or mathematics
5+ years of experience of developing and maintaining Restful APIs
5+ years of designing and developing Restful Web Services
In-depth knowledge of web technologies including HTTP, XML/JSON, web security, authentication/authorization protocols.
Good understanding of relational database, and NOSQL databases
Hands on experience in developing and deploying services in cloud environment (AWS, Azure )
Knowledge of application development lifecycle, agile methodology, API best practices and DevOps.
Experience with Unit Testing (JUnit, Mockito, Jenkins), Maven, git. AWS OpenSearch
Proficient in at least one scripting language (Python, java, java script, ruby), CI/CD, Maven, AWS OpenSearch, NoSQL, MongoDB, AWS Micro services, AWS Glue, Lambda, API Gateway, API Management.
Strong problem solving and communication skills
Ability to work independently and collaboratively in a fast-paced environment with rapidly changing expectations and requirements(Agile)
WHAT MAKES YOU STAND OUT?
Prior Experience working with Apigee/API IBM or API Manager Solutions.
Prior experience working in insurance services.",USD 90K - 150K *
519,Senior Data Scientist,Avaloq,"Pune, India",Senior-level / Expert,"Company Description
Founded and headquartered in Switzerland, Avaloq is continuously expanding its global footprint with around 2,500 colleagues in 10 countries, and more than 160 clients in 35 countries. We are an industry-leading provider of wealth management technology and services for financial institutions around the world, including private banks and wealth managers, investment managers, as well as retail and neo banks. Our research led approach and continual innovation is powered by the passion and creativity of our colleagues.
We are always looking for talented people to join us on our mission to orchestrate the financial ecosystem and democratize access to wealth management. Avaloq offers the opportunity to work closely with some of the world’s leading financial institutions as we jointly develop and shape careers. Championing a collaborative, supportive and flexible work environment empowers our colleagues to reach their full potential.
Job Description
Develops Power BI reports powered by Python to provide insights and recommendations to improve decision-making. You are expected to lead an end-to-end project, from gathering the business requirements, data sources up to the deployment of the project in production.

Your key tasks 
Develop, maintain, and deploy Power BI dashboards.
Educate stakeholders and users on how to use these reports.
Extract, transform and load data from different data sources using Python. Good understanding of data modelling is a must.
Using Python, perform data modelling between different data sources (joins, merging, designing the correct data model).
Transform the organization from reactive to proactive by introducing forecasting of business outcomes using predictive analytics.
Set-up auto-scheduling of Python scripts to process data from the data warehouse without manual intervention.
Collaborate with different stakeholders to collect and understand the business requirements of a specific project.
Collaborate with the team of Group Analytics and other teams to be able to get an access from various data sources.
Analyze and interpret data in a way that a stakeholders and users can easily understand the data.
Be able to implement row level security to your Power BI report to protect the data of your stakeholders.
Present your Power BI report to your teammates and manager to get an idea or recommendation on how you will visualize your report for your stakeholders
Qualifications
4-5 years’ hands-on experience with data analysis, reports visualization in Power BI (certification is a plus), and Python.
University degree in Computer Science, Mathematics, or other quantitative degree.
Proficiency in using MS Power BI (DAX, Power Query, Data engineering).
At least intermediate knowledge of MS SQL Server, and good understanding of data/feature engineering.
Excellent proficiency in Python is a must with good understanding of the following packages: pandas, sklearn, numpy, seaborn.
In-depth understanding of statistics and machine learning, ideally with hands-on experience in end-to-end development (regression, classification, black-box models, NLP).
Previous data science consulting experience is a plus.
Working knowledge of Git Terminal/GUI & source code repository hosting services (e.g., Bitbucket).
Data Visualization Portfolio (preferably with machine learning).
MS Power Platform or Fabric/Azure experience is preferred.
Ability to communicate with clarity and translate technical concepts into non-technical language, understanding what communication style is required for internal and external stakeholders.
Passion for discovering solutions hidden in large data sets and working with stakeholders to improve and creatively engineer desired business outcomes. Strong problem-solving skills with an emphasis on product and service development.
Drive to learn and master new technologies and techniques. Does not settle for ‘just enough,’ but stays on the hunt for answers to challenges to find sustainable and scalable solutions.
Proven ability to engage and motivate people and teams across all levels of the business. Collaborative and approachable team player.
Seeks to understand - demonstrates strong ability to ‘listen’ and understand before making recommendations.
Leads with trust - builds relationships based on trust, integrity and reliability.
Coaches – consistently maximizes on opportunities to give and receive feedback.
Adaptable – appreciates and embraces change and continuous improvement.
Diversity & inclusion – champions and role models inclusivity in approach to decision-making, proactively cultivates psychologically safe working environments.
  Additional Information
We realize that managing work life balance is a challenge we all face in our daily lives and in order to support with this we are pleased to offer hybrid and flexible working for most of our Avaloqers to maintain work life balance and still continue our fantastic Avaloq culture in our global offices. 
In Avaloq we are proud to embrace diversity and understand the success of our business is built on the power of different opinions, we are whole heartedly committed to fostering an equal opportunity environment and inclusive culture where you can be your true authentic self. 
We hire, compensate and promote regardless of origin, age, gender identity, sexual orientation or any other fantastic traits that make us all unique, we have done our best to write this advert in an inclusive and neutral way. 
Please be aware that we will not accept speculative CV submissions for any of our roles from recruitment agencies, and any unsolicited candidate submissions will be exempt from any payment expectations.  
 #LI-Hybrid",USD 136K - 205K *
520,Sr. AWS Data Engineer Job,Yash Technologies,"Bengaluru, KA, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire AWS Professionals in the following areas :
  Job Description:
  Our Digital Service Line is currently looking for industry-leading seasoned ""Sr. AWS Data Engineer"" professionals with hands-on experience.
The shortlisted candidate should have the ability to analyse technical needs and work with the customers to develop project scope of work documents and Project Plans.
The responsibilities are primarily technical, although there is a strong element of functional understanding of the business process.
    Role:
The ability to easily find, access, and analyze data across an organization is key for every modern business to be able to efficiently make decisions, optimize processes, and to create new business models.
Experience required: 5-7 years

As a Sr Data Engineer in the Healthcare Digital & Data - Data Governance & Architecture team you will work hands-on to deliver and maintain the pipelines required by the  Healthcare business functions to derive value from their data. For this, you will bring data from a varied landscape of source systems into our cloud-based analytics stack and implement necessary cleaning and pre-processing steps in close collaboration with our business customers. Furthermore, you will work closely together with our Data Governance and Quality & Compliance teams to ensure that all data assets are governed according to the FAIR principles. To keep the engineering team scalable, you and your peers will create reusable components, libraries, and infrastructure that will be used to accelerate the pace with which future use-cases can be delivered.

What we offer
You will be part of a team dedicated to delivering state-of-the-art solutions for enabling data analytics use cases across the Healthcare sector of a leading, global Science & Technology company. As such, you will have the unique opportunity to gain insight into our diverse business functions allowing you to expand your skills in various technical, scientific, and business domains. Working in a project-based way covering a multitude of data domains and technological stacks, you will be able to significantly develop your skills and experience as a Data Engineer.


Who you are
M.Sc./PhD in Computer Science or related field and 8+ years of work experience in a relevant capacity
Experience in working with cloud environments such as, Hadoop,  AWS, GCP, and Azure.
Experience with enforcing security controls and best practices to protect sensitive data within AWS data pipelines, including encryption, access controls, and auditing mechanisms.
Agile mindset, a spirit of initiative, and desire to work hands-on together with your team
Interest in solving challenging technical problems and developing the future data architecture that will enable the implementation of innovative data analytics use-cases.
Experience in leading small to medium-sized teams
Experience in creating architectures for ETL processes for batch as well as streaming ingestion
Knowledge of designing and validating software stacks for GxP relevant contexts as well as working with PII data
Familiarity with the data domains covering the Pharma value-chain (e.g. research, clinical, regulatory, manufacturing, supply chain, and commercial)
Strong, hands-on experience in working with Python, Pyspark & R codebases, proficiency in additional programming languages (e.g. C/C++, Rust, Typescript, Java, ...) is expected
Knowledge of database technologies for OLTP and OLAP workloads and a firm grasp of SQL.
Experience working with Apache Spark and the Hadoop ecosystem.
Working with heterogenous compute environments and multi-platform setups.
Experience in working with cloud environments such as, Hadoop,  AWS, GCP, and Azure.
Basic knowledge of Statistics and Machine Learning algorithms is favorable.
  This is the respective role description:

The ability to easily find, access, and analyze data across an organization is key for every modern business to be able to efficiently make decisions, optimize processes, and to create new business models. The Data Architect plays a key role in unlocking this potential by defining and implementing a harmonized data architecture for Healthcare. Together with a team of Data Engineers, the Data Architect is responsible for the delivery and maintenance of reliable data pipelines for the ingestion of data from a heterogenous ecosystem as well as the creation of specialized, cloud-based data processing and analytics stacks. He/she will work hand in hand with our Data Governance team to ensure that all data assets are covered by our governance process. During the process the Data Architect will collaborate closely with our business, corporate functions, as well as out IT organization, in order to gather requirements and shape a global framework of engineering best practices.
    At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
521,Lead MLOPs Engineer,S&P Global,IN - HYDERABAD ORION,Senior-level / Expert,"The Team: The Data Science/AI/ML team is a newly formed innovation and deployment team within S&P Global Ratings that will be responsible for building and executing a bold vision around using Machine Learning, Artificial Intelligence, Data Science, knowledge engineering, and human computer interfaces for augmenting various business processes.
The Impact: This role will have a significant impact on the success of our data science, AI, and Machine Learning projects ranging from choosing which projects should be undertaken, to delivering highest quality solution, ultimately enabling our business processes and products with AI and Machine Learning solutions.
What’s in it for you: This is a high visibility role with an opportunity to make a very meaningful impact on the future direction of the company. You will work with senior leaders in the organization to define, build, and transform our business.
Responsibilities:
ML Model Deployment: Assist in deploying machine learning models into production environments. 
AI ML pipeline and model Monitoring: Contribute to the monitoring and maintenance of model performance and infrastructure health. 
Automation: Participate in the development and maintenance of automated MLOps pipelines. 
Collaboration: Collaborate with cross-functional teams to integrate machine learning models into production systems. 
Documentation: Maintain documentation of MLOps processes and procedures. 
Work closely with members of technology teams in the development, and implementation of Enterprise AI platform 
Problem Solving: Assist in troubleshooting and resolving MLOps-related issues. 
Qualifications:
5+ years of relevant professional experience in Machine Learning/Artificial Intelligence with a solid foundation in software engineering, excellent design principles, best-in-class code habits, and experience working on advanced models. 
3+ year’s experience with Python, Java, Kubernetes, and data and workflow orchestration tools
Experience working with business stakeholders and users, providing research direction and solution design and writing robust maintainable architectures and APIs.
At least 2 years of experience designing/building data-intensive solutions using distributed computing.
Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform.
Proficient programming skills at a high-level language (e.g. Java, Scala, Python, C/C++, Perl, R
Solid knowledge of at least one machine learning research frameworks
Familiarity (ideally 1-2+ years’ experience) with containerization, scripting, cloud platforms, and CI/CD.
3+ years’ experience with Python, Java, Kubernetes, and data and workflow orchestration tools
1+ years’ experience with Elasticsearch, SQL, NoSQL,  Apache spark, Flink, Databricks and Mlflow.
Prior 1-3 experience with operationalizing data-driven pipelines for large scale batch and stream processing analytics solutions
Good to have experience with contributing to GitHub and open source initiatives or in research projects and/or participation in Kaggle competitions
Ability to quickly, efficiently, and effectively define and prototype solutions with continual iteration within aggressive product deadlines.
Demonstrate strong communication and documentation skills for both technical and non-technical audiences.
Preferred Qualifications:
You are a Software Engineer with Data Science experience or a Data Scientist with Software Engineering experience. You have deployed advanced models in production environments. You have created models that drive performance in complex situations and have helped to define and implement best practices and standards. You are comfortable collaborating with and educating other Machine Learning Engineers on the team.
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.2 - Middle Professional Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 73K - 166K *
522,"Sr Manager, Data Engineering",HashiCorp,India - Noida,Senior-level / Expert,"We are looking for a Sr. Manager, Data Engineering to be part of our FP&A’s Digitization team in Noida, Uttar Pradesh, India. This role is expected to be 30% hands on execution building the solutions while the rest is overseeing the delivery and solutioning for the team.
In this role you can expect to drive the following-
Data Strategy and Alignment
Work closely with Lead- business analysis and analytics to understand requirements and provide data ready for analysis and reporting.
Apply, help define, and champion data governance : data quality, testing, documentation, coding best practices and peer reviews.
Continuously discover, transform, test, deploy, and document data sources and data models.
Develop and execute data roadmap (and sprints) - with a keen eye on industry trends and direction.
Data Stores and System Development
Design and implement high-performance, reusable, and scalable data models for our data warehouse to ensure our end-users get consistent and reliable answers when running their own analyses.
Focus on test driven design and results for repeatable and maintainable processes and tools.
Create and maintain optimal data pipeline architecture - and data flow logging framework.
Build the data schema, features, tools, and frameworks that enable and empower BI and Analytics teams across FP&A function.
Project Management
Drive project execution using effective prioritization and resource allocation.
Resolve blockers through technical expertise, negotiation, and delegation.
Strive for on-time complete solutions through stand-ups and course-correction.
Team Management
Manage and elevate team of 2 members.
Do regular one-on-ones with teammates to ensure resource welfare.
Periodic assessment and actionable feedback for progress.
Recruit new members with a view to long-term resource planning through effective collaboration with the hiring team.
Process design
Set the bar for the quality of technical and data-based solutions the team ships.
Enforce code quality standards and establish good code review practices - using this as a nurturing tool.
Set up communication channels and feedback loops for knowledge sharing and stakeholder management.
Explore the latest best practices and tools for constant up-skilling.
Data Engineering Stack
Programming : Python ( expert)level. Ability to create API’s on python.
Database : PostgreSQL, Amazon Redshift
Warehouse : Snowflake, S3
ETL : DBT + Custom-made Python
Business Intelligence / Visualization : M+ Google Data Studio
Frameworks : Spark + Dash + Stream Lit
Collaboration : Git, Notion
Cloud Platform- AWS
Qualification Prerequisites
Industry experience of minimum 12 years (2 years+ in snowflake)
Experience managing a team of at least 4 developers end-to-end
Strong hands-on data modelling and data warehousing skills
Snowflake Certification is mandatory.
Strong experience applying software engineering best practices to data and analytics scope (e.g. version control, testing, and CI/CD)
Strong attention to detail to highlight and address data quality issues
Excellent time management and proactive problem-solving skills to meet critical deadlines #LI-Onsite #LI-SG1
 Canada, Colorado, California, Washington and New York Applicants: To view base salary ranges for this role in your location and to learn more about which roles are eligible for bonus pay or commissions, please visit our Pay Transparency Calculator below. Individual pay within the range will be determined based on job related-factors such as skills, experience, and education or training. Information on our benefits can be found via the link below. Intern ranges can be found below.
Pay Transparency Calculator: https://bit.ly/3B7gwql
Benefits: https://www.hashicorp.com/careers/benefits
Intern Ranges: https://bit.ly/3H2soha",USD 121K - 188K *
523,"Associate Director, Data Product Manager",Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Key Responsibilities:
Accountable for delivering high quality, data products and analytic ready data solutions for GDD Portfolio and Trial Operations including (R&D Strategy and Planning, GDD Finance, Resources, Clinical Trial Operations).
As a data product manager, he/she will be responsible for defining data product strategy and roadmaps, identification of product scope, feature stories, value proposition and success criteria for the data products.
Responsible for managing a team of ~10 data professionals including Data Architect, Data Engineers, UX designer, Data Scientist, Data product analysts, scrum master etc.
Responsible for defining product schedule, budget, and timely delivery of the data solutions.
As a people lead, accountable for attracting, developing, and retaining exceptional talent and directing day to day activities of the team and partnering with US GDD data teams
Closely partner with the Enterprise Data and Analytics Platform team, other functional data pods and Data Community lead to shape and adopt data and technology strategy.
Serves as the Subject Matter Expert on GDD Data & Analytics Solutions and build domain knowledge of the GDD specific area
Accountable for evaluating GDD Data enhancements and projects, and assessing capacity and prioritization along with onshore and vendor teams
Knowledgeable in evolving trends in Data platforms and Product based implementation
Manage and provide leadership for the resources supporting projects, enhancements, and break/fix efforts
Has End to End ownership mindset in driving initiatives through completion
Comfortable working in a fast-paced environment with minimal oversight
Mentors other team members effectively to unlock full potential and positive work environment that fosters innovation.
Prior experience working in an Agile/Product based environment.
Provides strategic feedback to vendors on service delivery and balances workload with vendor teams
Stays current with emerging trends in specialty area.  Identifies future state and dimensions of change (org, tech, cultural) to achieve. Creates transition plans for new processes, implements and monitor’s change. Ensures alignment of plans with the enterprise's strategic vision and translates the vision to connect to team's work
Qualifications & Experience:
Advance Degree (or Bachelor’s Degree) in Computer Science, Mathematics, Engineering, Biotechnology or a related field.
5-7 years of hands-on experience working on implementing and operating data capabilities and cutting-edge data solutions, preferably in a cloud environment.  Breadth of experience in technology capabilities that span the full life cycle of data management including data lakehouses, master/reference data management, data quality and analytics/AI ML is needed. 
Hands-on development experience managing and delivering data solutions with AWS technologies like AWS Glue, Redshift, RDS (PostgreSQL), S3, EMR, Kinesis, Athena, Lambda, and IAM roles and permissions, /Azure/GCP, Cloudera Data Platform, Tableau labs is a plus.
Strong understanding of cloud infrastructure, Identity Access Management, Integration services (e.g., IAM, KMS, SQS, SNS etc.) is a plus.
1-3 years of experience leading a data organization with accountability to deliver tangible business value through data and analytical solutions.
Functional knowledge or prior experience in Lifesciences Research and Development domain is a plus.
Experience and expertise in establishing agile and product-oriented teams that work effectively with teams in US and other global BMS site.  
Initiates challenging opportunities that build strong capabilities for self and team
People manager level with supervisory responsibility for Individual Contributor and People Manager positions
Gives others challenging opportunities to build strong capabilities for team
Demonstrates a focus on improving processes, structures, and knowledge within the team. Leads in analyzing current states, deliver strong recommendations in understanding complexity in the environment, and the ability to execute to bring complex solutions to completion.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.

#HYDIT #LI-Hybrid
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 120K - 145K *
524,Staff Engineer - Data Science,Seagate Technology,"Pune, IN",Senior-level / Expert,"About our group:
If you're a Master of the “big picture”, with demonstrated success in development of, ML and AI solutions, then we want to talk with you. Snap up on this opportunity for your next big career challenge to create business value as you showcase your strength in development and scaling of ML and Big Data Solutions. You'll join our Global Data Analytics group and will be based in our Pune, India office 
In this highly visible role, you will help to develop and maintain the next generation enterprise data and advanced analytics platform for both on premise and cloud services. You will be a vital component in engaging architectural decisions, reviewing of designs, scrum leading, development, and in operations of the Analytical solutions. 
About the role - you will:
Be part of a product team of 8-10 Data science, ML and Platform Engineers that are the crux for developing and maintaining Machine Learning /advanced analytics platforms and Big Data solutions for Seagate factories and Lyve Cloud 
Work with customers and business stakeholders to understand the needs and develop Analytics product roadmap and strategy 
Collaborate with data scientists, data engineers and Business SMEs to design and develop end-to-end Analytics platform  
Design, scale and deploy Machine Learning pipelines 
About you:
You’re a passionate professional who is up to the challenge of blending the fast-changing technology landscape of Generative AI with the complex and high-impact space of HiTech and Manufacturing analytics 
Strong appetite for constant learning, thinking out of the box, questioning the problems & solutions with the intent to understand and solve better 
You’re uncompromisingly detail oriented, well organized with solid time management skills, and you have solid, effective verbal and written communications abilities  
Ability to motivate people and instill ownership, reliability, teamwork, and commitment in the team 
Excellent interpersonal skills to develop relationships with different teams and peers in the organization 
Your experience includes:
Excellent technical skills with a proven and successful history working with data at scale and empowering organizations through data 
In depth knowledge and working experience on the various aspects of training and deployment of deep learning solutions 
Strong understanding of machine learning algorithms & principles 
Experience building deep NN models for image classification, object detection and semantic segmentation 
Familiarity with CPU/GPU architectures and numeric libraries 
Hands-on experience in distributed training of deep architectures: multi-GPU, multi-node, synchronous and asynchronous 
DevOps, Continuous Delivery, and Agile development 
Creating a culture of technical excellence by leading code and design reviews, promoting mentorship, and identifying and promoting educational opportunities for engineers 
Location:
Our site in Pune is dynamic, both in our cutting-edge, innovative work, as well as our vibrant on-site food, and athletic and personal development opportunities for our 400+ employees. You can enjoy breakfast, lunch, or dinner from one of four cafeterias in the park. Take a break from your workday and participate in one of our many walkathons or compete against your colleagues in carrom, chess and table tennis. Learn about a technical topic outside your area of expertise at one of our monthly Technical Speaker Series or attend one of the frequent on site cultural festivals, celebrations, and community volunteer opportunities.
  Location: Pune, India
Travel: None",USD 45K - 84K *
525,"Senior Data Engineer, Analytics","Vimeo, Inc.","Bengaluru, India",Senior-level / Expert,"Senior Data Engineer - Analytics
Vimeo is looking for an experienced Senior Data Engineer - Analytics to join our Data Architecture and Analytics Engineering team and work closely with Data Analysts and Data Scientists to create and maintain robust, scalable, and sustainable data models that provide decision-making insights for senior leadership including executives.  The ideal candidate is someone who enjoys exploring financial data and is a self-starter with a bias for action and results, with experience in a fast-paced, data-driven environment.
 What you'll do:
Build data models that can support dynamic and efficient data analysis, and collaborate with other teams to maintain and evolve those models over time
Ensure alignment to coding standard methodologies and development of reusable code
Partner with Data Analysts to understand business processes and identify opportunities to build scalable and efficient data models that can be used for scalable, refreshable analysis and reporting
Create and enable the generation of ad-hoc / on-demand data sets for use by analysts and data scientists
Work with Engineering teams to set up monitoring and alerting systems for business and product KPIs
  Skills and knowledge you should possess:
BS/MS in Computer Science or a related technical field.
5+ years working with Analytics and Data Engineering teams with a mixed data engineering and analytics background 
5+ years of experience in scalable data architecture, fault-tolerant ETL, and monitoring of data quality in the cloud
Experience working on or leading initiatives around data governance, master data management, data catalogs, and enterprise data warehouse architecture
Strong analytical skills, data sensibility, and an able communicator
Open to working on multiple projects simultaneously
Proficiency in:
SQL
Python 
Dimensional Modeling
Data pipeline development, workflow management, and orchestration tools
ETL optimization and best practices
Snowflake or other column-oriented and cloud-based databases
Looker or any similar Business Intelligence tool
Relational Databases
  Nice-to-haves/Bonus Points
DBT
Git / Github
MySQL is a big plus
Looker/Tableau is a big plus
large data sets (terabyte scale)
Apache Airflow
 About Us:
Vimeo (NASDAQ:VMEO) is the world’s most innovative video experience platform. We enable anyone to create high-quality video experiences to connect better and bring ideas to life. We proudly serve our growing community of nearly 300 million users — from creative storytellers to globally distributed teams at the world’s largest companies. Learn more at www.vimeo.com.
Vimeo is headquartered in New York City with offices around the world. At Vimeo, we believe our impact is greatest when our workforce of passionate, dedicated people, represents our diverse and global community. We’re proud to be an equal opportunity employer where diversity, equity, and inclusion is championed in how we build our products, develop our leaders, and strengthen our culture.",USD 121K - 188K *
526,Software Engineer II Data Engineering,Poshmark,"Chennai, India",Mid-level / Intermediate,"Confidence can sometimes hold us back from applying for a job. Here’s a secret: there's no such thing as a ""perfect"" candidate. Poshmark is looking for exceptional people who want to make a positive impact through their work and help create an organization where everyone can thrive. So whatever background you bring with you, please apply if this role would make you excited to come to work every day.
The Big Data team is a central player in the Poshmark organization. Our mission is to build a world-class big data platform to bring value out of data for us and for our customers. Our goal is to democratize data, support exploding business, provide reporting and analytics self-service tools, and fuel existing and new business critical initiatives.
The Data Engineering team at Poshmark is looking for an experienced software engineer to take care of Poshmak’s growth data, ensuring real-time access to quality data for all the stakeholders. The role requires strong understanding of software engineering best practices and excellent software development skills to build and maintain real-time and batch data pipelines with a focus on scalability and optimizations. In addition, the role also requires collaborating with Data Science, Analytics and other Engineering teams to build newer ETLs analyzing terabytes of data.
The role also requires being able to write clean and scalable code to pull datasets from disparate sources involving External APIs, S3 transfers, Web Scraping. You will work with cutting edge technologies and frameworks like Scala, Ruby, Apache Spark, Airflow, Redshift, Databricks, Docker. You will also manage the growth data infrastructure comprising ETL pipelines, Hive tables, Redshift tables, BI tools. We are looking for a software engineer who can help us define the next phase of growth data systems in terms of scalability and stability.
Responsibilities
Design, Develop & Maintain growth data pipelines and integrate paid media sources like Facebook and Google to drive insights for business. 
Build highly scalable, available, fault-tolerant data processing systems using AWS technologies, Kafka, Spark, and other big data technologies. These systems should handle batch and real-time data processing over 100s of terabytes of data ingested every day and a petabyte-sized data warehouse.
Responsible for architecting/designing/developing critical data pipelines at Poshmark.
Productionizing ML models in collaboration with the Data Science and Engineering teams.
Maintain and support existing platforms and evolve to newer technology stacks and architectures.
Participate and contribute to constantly improving best practices in development.
Desired Skills 
Excellent technical problem solving using data structures and algorithms, with emphasis on optimization and code quality.
2 + years of relevant software engineering experience using object oriented programming languages like Scala / Java / Ruby / Python / C++ etc.
Expertise in architecting and building large-scale data processing systems using Big Data technologies like Spark, Hadoop, EMR, Kafka/ Kinesis, Flink, Druid.
Expertise in SQL with knowledge on any existing data warehouse technology like Redshift
Expertise in Google Apps Script, Databricks or API Integrations is a plus.
Be self-driven, take complete ownership of initiatives, make pragmatic technical decisions and collaborate with cross-functional teams.
 About Us
Poshmark is a leading social marketplace for new and secondhand style for women, men, kids, pets, home, and more. By combining the human connection of physical shopping with the scale, ease, and selection benefits of e-commerce, Poshmark makes buying and selling simple, social, and sustainable. Its community of more than 80 million registered users across the U.S. and Canada, is driving the future of commerce while promoting more sustainable consumption. For more information, please visit www.poshmark.com, and for company news and announcements, please visit investors.poshmark.com. You can also find Poshmark on Instagram, Facebook, Twitter, Pinterest, and YouTube.
Why Poshmark?
At Poshmark, we’re constantly challenging the status quo and are looking for innovative and passionate people to help shape the future of Poshmark. We’re disrupting the industry by combining social connections with e-commerce through data-driven solutions and the latest technology to optimize our platform. We’re nothing without our amazing team who deliver an unparalleled social shopping experience to the millions of people we connect each day.
We built Poshmark around four core values: 1) focus on people to create empowered communities that drive success; 2) together we grow to support each other to strive for our dreams; 3) lead with love to foster genuine connections built upon a foundation of respect; and 4) embrace your weirdness to accept and empower one another on their own unique journey. We’re invested in our team and community, working together to build an entirely new way to shop. That way, when we win, we all win together. Come help us build the most connected shopping experience ever.  We will set you up with comprehensive global and in-country benefits to support you and your family needs.
Poshmark is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
View Poshmark's Job Applicant Privacy Policy here.",USD 90K - 150K *
527,EY - GDS Consulting - D&A - Data Scientist - SM,EY,"Bengaluru, KA, IN, 560016",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        The Opportunity
The AI team with EY GDS caters to clients across the globe through EY’s partner firms. The candidate should be able to manage multiple Data Science engagements, interact with clients and EY stakeholders, bringing in innovative ideas, methodologies and techniques; should be adept in developing high performing individuals and teams; should be capable of motivating team members and be a leader of the pack. Should be capable of identifying the most appropriate tools, methods and processes that is needed to solve the problem in hand.
   Your key responsibilities
  Hands-on work and delivery of Advanced analytics/ML/AI projects 
Extensive hands own working experience in NLP ,Text & Predictive Analytics
Mentoring of the juniors
  Skills and attributes for success
Should work with the leadership in developing future strategies to position the Data Sciences team as the best-in-class within EY; develop POVs on Trusted AI, Explainable AI and any current trends in AI and Data Science.
Should have good presentation and articulation skills to explain the intricacies of Advanced Analytics solutions to a client in simple English. Must have a grab-the-opportunity attitude and a pleasing personality.
Should be an expert in one or more of these areas: Statistical Modeling, Operations Research, Machine Learning. Should have an aptitude to learn other areas if not already skilled.
Should have handled deployment of ML models on-prem or on cloud.
Analytic Problem Solving – Should have the capability to look at a problem from a top-down view and not through the lens of a technique.
Planning: Should have the ability to contribute to operational and strategic planning.
Industry Knowledge - Knowledge of what is happening in the world of Data Science and AI and the  ability to apply this knowledge appropriately to diverse situations.
Integrated View- Ability to bring together both diverse point of views, data sources, techniques, to solve the client’s problem.
Relationship Management - Ability to establish and build healthy working relationships and partnerships with clients, EY partners, senior leadership, peers and juniors.
Knowledge of analytical toolsets - Understands the elementary functions of Data Science packages of Python, R or SAS
Getting Work Done Through Others – The ability to get work done through others. In this role, the person would be handling a team size of 15-30 people or more. People who prefer an Individual Contributor role need not apply.
Inspiring Others – Should have the ability to motivate others. Should be a total people person.
  To qualify for the role, you must have
Bachelor's Degree in Statistics, Econometrics, Quantitative Methods or related field (Engineers with Data Science experience can also apply)
Candidates with a or master’s degree or PhD in quantitative field preferred.
Candidate with an MBA degree highly preferred.
10 years (M) / 15 years (SM) experience in applied advanced analytical role
5 years of experience (M) and 10 years (SM) of project and people management experience
5 years of practical experience and familiarity with advanced data modeling techniques (linear/logistic regression, ARIMA, Cluster Analysis, Machine Learning, etc.)
5 years (M) and 10 years (SM) of experience working with business partners and building relationships
    Ideally, you’ll also have
  Client management skills
  What we look for
  People with technical experience and enthusiasm to learn new things in this fast-moving environment
  What we offer
EY Global Delivery Services (GDS) is a dynamic and truly global delivery network. We work across six locations – Argentina, China, India, the Philippines, Poland and the UK – and with teams from all EY service lines, geographies and sectors, playing a vital role in the delivery of the EY growth strategy. From accountants to coders to advisory consultants, we offer a wide variety of fulfilling career opportunities that span all business disciplines. In GDS, you will collaborate with EY teams on exciting projects and work with well-known brands from across the globe. We’ll introduce you to an ever-expanding ecosystem of people, learning, skills and insights that will stay with you throughout your career.
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
  EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 136K - 205K *
528,Cloud BI Data Engineer,NTT DATA,"Noida, UP, IN",Senior-level / Expert,"Req ID: 254597 
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Cloud BI Data Engineer to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).
  In these roles you will be responsible for: 
Applications development, enhancement and support for the data lake and warehouse and data extracts sent to Tableau reports
Troubleshoot the problems/issues and providing hot fixes to meet productions SLAs 
Proactive monitoring to identify and alert on the problems 
Incident & Request Management 
Interim support and maintenance to UAT environments
Perform code deployments into Stage and Production
Perform data loads in Stage and Production environments
Maintain and Support the Staging environments to be in sync with the production databases
Follow the change control practices and ensure the changes are deployed in a controlled manner
Strong collaboration with development/engineer teams to share knowledge and hand off code curation and operation
Problem Management – RCA & Corrective actions
Continuous Service Improvements aligned to NTT DATA framework
  Requirements for this role include: 
Must have skills: 
AWS Postgres on Redshift (Data Loading experience mandatory into Redshift)
Data Modelling and SQL stored procedures
Python
JSON files manipulation
Experience working in agile teams
  Nice to have skills but not critical or necessary:
Airflow
Kafka (or message queues in general)
Tableau
  What are the required skills for this role?  (3-5 at the most).  
Points to emphasize:
Use quantifiable terms such as years of experience or numbers that highlight scope (# people managed, budget owned, sales quotas, etc) 
Do not use subjective terms like “good” 
Focus on the performance of the position to accomplish business-related goals that are relevant to the Roles/Responsibilities listed above.
Preferences:  - Optional (nice-to-have’s)
Ability to communicate (oral/written) effectively to exchange information with our client. 
Commerce graduate with English as a compulsory subject
  Required schedule availability for this position is Monday-Friday (09:00am to 60:00pm IST).  The shift timings can be changed as per client requirements.
Additionally, resources may have to do overtime and work on weekend’s basis business requirement.
  #LI-INPAS
  About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",USD 37K - 70K *
529,Senior Healthcare Research & Data Analyst,Clarivate,R131-Bengaluru,Senior-level / Expert,"We’re currently looking for a Senior healthcare research and data analyst who is excited about integrating various data streams and derive meaningful insights for Life Sciences companies.
You are a self-starter and problem solver who can bring structure and organization to a variety of complex customer challenges and drive innovation by bringing together multiple data streams, distributed cross-functional teams. You are an analytical thinker, and technically strong, with solid communication skills to clearly articulate ideas and potential solutions to both internal and external customers.
About you (Skills & Experience Required)
Must possess a unique blend of technical savviness, analytical skills, and innovative thinking
Knowledge of scientific approach and methodologies.
Knowledge and understanding of the principles, concepts, methods, and standards of statistical research.
Ability to apply a range of advanced statistical techniques in support of scientific research studies and/or experiments.
Ability to process computer data and to format and generate reports.
Ability to consult with scientific investigators, interpret research requirements, and determine statistical analysis strategies.
Ability to plan, create, program and manage complex statistical computer databases.
Ability to analyze, interpret, and draw conclusions from complex statistical information.
Knowledge of current and emerging trends in advanced statistical analysis for scientific application.
Knowledge of SAS programming and/or other statistical software.
Knowledge of scientific reporting and manuscript preparation requirements and standards.
Ability to work in a team environment to design, analyze, and report on research projects.
Strong analytical communication, critical thinking and problem solving skills.
Ability to provide technical guidance and leadership to professional personnel in area of expertise.
In-depth knowledge and understanding of probability and medical statistics theory.
Knowledge of data management principles and regulatory requirements for clinical trials and medical research.
Strong focus and quality and timely delivery of work.
Capable of understanding data, analyzing it, identify patterns/correlations, deriving insights from these analyses
Flexible, multi-tasker who enjoys a fast paced and challenging work environment. Ability to manage multiple deadlines and simultaneous projects
Excellent collaboration and communication skills. Ability to think and articulate clearly, concisely, and accurately
4 + years’ industry experience
Bachelor (BA/BS) degree is required, MBA or similar experience or degree preferred
What will you be doing in this role? 
Support product and project development, especially around data collection, analysis, liaising directly with the Product Strategy leadership
Translate business priorities to technical priorities to ensure back-end elements achieve desired business results
Identify key metrics and measure the outcome of the products or projects
Work with cross-functional teams, including operations, technology, and content as needed
Drive the collection, integration and analysis of various data sources to derive meaningful insights for our customers within Life Sciences companies
Hours of Work 
Standard working hrs is 12-9PM IST timings (9 hours per day including 1 hour lunch break).
At Clarivate, we are committed to providing equal employment opportunities for all persons with respect to hiring, compensation, promotion, training, and other terms, conditions, and privileges of employment. We comply with applicable laws and regulations governing non-discrimination in all locations.",USD 92K - 145K *
530,Client Technology: SAP AI Developer Supply Chain Mgmt,EY,"Bengaluru, KA, IN, 560048",Senior-level / Expert,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all. 
        SAP – AI/Gen AI Engineer
EY is a global leader in assurance, tax, transaction, and advisory services. Technology is at the heart of what we do and deliver at EY. Technology solutions are integrated in the client services we deliver and are key to our innovation as an organization. 
Fueled by strategic investment in technology and innovation, Client Technology seeks to drive growth opportunities and solve complex business problems for our clients through building a robust platform for business and powerful product engine that are vital to innovation at scale. As part of Client Technology, you’ll work with technologists and business experts, blending EY’s deep industry knowledge and innovative ideas with our platforms, capabilities, and technical expertise. As a catalyst for change and growth, you’ll be at the forefront of integrating emerging technologies from mobile application into every corner of what we do at EY. That means more growth for you, exciting learning opportunities, career choices, and the chance to make a real impact. 
  Your key responsibilities  
Monitor technology trends and perform R&D activities in AI/ML area.
Assist in the collection and documentation of users’ requirements, development of user stories, estimates and work plans 
Ensure modern AI/Gen AI best practices are applied 
Develop, validate and deploy AI models.
Cooperate with architects to design the system 
Establish and maintain development standards/best practices 
Present effects of work to different stakeholders (e.g., demo)  
Analyze the ML algorithms that could be used to solve a given problem and ranking them by their success probability.
Share the knowledge on the best ML Engineering practices with the team
Define validation strategies for ML solutions.
  Skills and attributes for success  
7+ years of experience in ML development and MLOps.
Strong programming skills, with expertise in languages like Python with a good knowledge of ML, Data and API libraries.
Expertise in creating end-to-end data pipelines (sourcing, exploration, automation, etc.)
Experience with ML model and its development.
Should have knowledge in ModelOps/MLOps, AutoML, AI Ethics, Trust and Explainable AI
Understanding of some of the popular ML frameworks such as SparkML, Tensorflow, scikit-learn, XGBoost, H2o etc.
Experience working in a cloud environment (SAP, AWS, Azure, GCP) or a containerized environment (Mesos, Kubernetes)
Interest in understanding functional and industry business challenges.
Desirable to have knowledge of supply chain management processes and potential GenAI use case in supply chain automation
Ideally, you’ll also have  
Expertise in Big Data, Data Modeling
Experience working with SAP platforms SAP AI Core, SAP Data Intelligence, Embedded Analytics in S/4HANA or SAP Analytics Cloud
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world
Verifying data quality, and/or ensuring it via data cleaning
Defining data augmentation pipelines
Training models and tuning their hyperparameters
  Experience  
Experience in LLM's, LSTM, RNN, Tensorflow, H2O are added advantage
Experience in deploying AI/ML platforms on Kubernetes and Containerization
Experience working with large data sets leveraging distributed systems e.g. Spark/Hadoop.
Experience in managing AI/ML cluster features like API endpoints management, Security, SSO, Auditing, version control, etc
What we look for
A self-starter, independent-thinker, curious and creative person with ambition and passion
        EY | Building a better working world 

 
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  ",USD 60K - 192K *
531,Data Engineer 2,Amadeus,Bengaluru,Mid-level / Intermediate,"Job Title
Data Engineer 2
Key responsibilities
•                 Design, implement, deploy, and maintain data marts, ETL (extract, transform, load) processes and systems. A.k.a. as our assets.
•                 Ensure the reliability, scalability, and performance of our data assets.
•                 Design and maintain quality indicators as well as the corresponding monitoring and alerting means.
•                 Troubleshoot and document issues respecting Amadeus standards.
•                 Continuous improvement mindset applied to data related issues, systems, and processes.
•                 Technical and expertise awareness to keep up with industry standards, security recommendations and best practices within Offer organization.
 About the ideal candidate:
•                 Hands-on experience writing Production quality code in Scala (preferred) or PySpark or Java.
•                 Hands-on experience on big data technologies, including the mapr filesystem, Apache Spark, Hadoop, Kafka & Impala.
•                 Proven experience with the Apache Spark Architecture and components.
•                 Hands-on experience on scripting languages including Bash scripting and Python.
•                 Knowing different kinds of database technologies, including of course SQL.
•                 Previous work with no-SQL databases, like MongoDB will be a plus.
•                 Solid knowledge of build tools and in particular Maven and SBT.
•                 Experience on building and maintaining DevOps pipelines will be a plus.
•                 Familiarity with analytics platforms like Tableau will be a plus.
Cloud:
•                Familiarity with Azure cloud technologies.
•                Familiarity with Azure Databricks and Databricks SQL.
•                Familiarity with Snowflake Data Cloud will be a plus.
 Qualifications
•                Education: University degree in computer science or related field or relevant experience
•                Professional experience of 2 – 9 Yrs
•                Proven track record of experience working in data engineering domain.
•                Strong experience defining ETL processes.
•                Experience with data modeling and data visualization concepts and tools.
•                Knowledge of Software Design under Agile frameworks (Scrum, Kanban, SAFe, …).
•                Proven experience on design and maintaining applications using Scala, (Py)Spark, MAPR distribution, Hadoop ecosystem, Kafka, Impala.
•                Hands-on experience on Microsoft Azure, Databricks.
Other:
·       Good English verbal and written communication skills
·       Strong team player with collaborative mindset
·       Excellent problem-solving and analytical skills.
·       Fast, thorough, and autonomous learner who also understands prioritization
·       Innovative thinker
·       Ability to maintain a proactive and positive attitude in a fast paced, changing environment
·       Thrives in a multi-cultural, global organization
·       Open-minded, should be able to adapt to working in a multi-cultural team atmosphere
·       Flexible to adapt to changing project needs driven by the customers
·       Ability to think out of the box, develop tools to enhance productivity
  What we can offer you:
•                The opportunity to work for one of the world’s top leading travel tech companies; a company that originated in technology innovation and sees the world with a technology-first perspective
•                Skills development and opportunities to try new ideas
•                A global diverse work environment
Diversity & Inclusion
We are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.",USD 90K - 150K *
532,Data Analyst - Senior Member of Technical Staff (8-12 years),VMware,IND-Bengaluru-Kalyani Vista II,Senior-level / Expert,"Search Jobs
Job Description
Experience: 8-12 years
The VMware by Broadcom End-User Computing team is securing and enabling the future of anywhere work for our global customers. As digital workspaces continue to evolve, we are designing and engineering VMware Anywhere Workspace, a holistic platform built on our industry-leading solutions for virtual apps, desktops, unified endpoint management and security. We’re currently delivering upon our Autonomous Workspace vision, the next evolution of our digital workspace offering that leverages data and artificial intelligence, to create workspaces that are self-configuring, self-healing, and self-securing. Together, our work is enabling people to broadly optimize both employee experience and security, while modernizing IT.
The Elevator Pitch: Why will you enjoy this new opportunity?
You are talented Data Engineer who is excited about redefining, re imagining, and contributing towards building a modern data infrastructure. We believe data engineering and analytics is about harnessing the power of data, built on solid foundation of software engineering, data modelling , DevOps skills & more. We recognise that you may have varied mix of skills, experiences & strengths, be it, big data, cloud data warehouse, data pipelines, stream processing , data modeling or dashboarding. We want to talk to you.
Our goal is to transform the way customers interact with the digital workspace by providing a platform for data aggregation, reporting, data visualization, analytics, machine learning, and custom workflows.
As a member of the EUC Horizon Data Analytics  team, you'll have the opportunity to work with highly skilled, passionate software engineers across Bangalore, Palo Alto.  The EUC Horizon Data Analytics team vision is to become the central leading-edge innovator of business insights and analytics solutions. The mission is to help our stakeholders and customers realize the possibility of data analytics to enable growth opportunities.
If you are ready to accelerate, innovate and lead, join our End User Computing Horizon Data Analytics team as we challenge constraints and solve tomorrow’s problems today!
Success in the Role: What are the performance goals over the first 3-9 months you will work toward completing?
As a Data Engineer you will be expected to build end-to-end analytical and dashboarding solutions that are highly scalable, performant, secure, and resilient
Partner closely with Customer Success, Product Management, Field Engineering and Support teams to understand their business challenges and develop appropriate analytics, reporting and visualization solutions to address them
What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis? 
Act as BI Data and analytics expert. Analyze data to answer business questions, recommend analytic solutions to provide business insight, and craft dashboards for long term business needs using Industry leading BI tools : Tableau, Power BI,Mode Analytics, SQL skills, R/Python , various machine learning or statistical libraries and tools
You will participate in all the development phases dashboards & analytics  including requirements, design, coding, unit testing, debugging and performance tuning.
Work and execute on projects with both structured and unstructured data in a big data environment, Own and deliver key product features
Actively contribute to a culture of high ownership, continuous improvement and engineering excellence
Support communication, training, and documentation to enable successful user adoption
Collaborate with other team members and need to provide support and mentoring
Proactively engage with Business stakeholders with a consultative approach
Always be on the lookout for ways to improve our development practices and processes
VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. VMware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.
Search Jobs",USD 92K - 145K *
533,Senior Data Engineer - India,Globant,"Pune, Maharashtra, IN",Senior-level / Expert,"We are a digitally native company that helps organizations reinvent themselves and unleash their potential. We are the place where innovation, design and engineering meet scale. Globant is 20 years old, NYSE listed public organization with more than 27,000+ employees worldwide working out of 25 countries globally.
www.globant.com
  We are looking for ingenious Conga/Apttus Developers to join our Salesforce Studio. Globant’s Salesforce Studio uses technology ecosystem, to enable organizations to transform their business, drive desired outcomes, and build customer loyalty and growth. We build better experiences and augmented digital engagements for our vast clientele. Come join the team and seek reinvention with Salesforce
  Experience: 4 - 12 Years
Job Location :  Pune, Bengaluru, Ahmedabad, Indore, Hyderabad
  Job Description: We are seeking a highly skilled Azure Databricks Data Engineer to join the data engineering team and play a crucial role in an optimization initiative. The current problem is that read speed is compromised and faster responses from delta are required. The ideal candidate should have extensive experience in Python programming and be proficient in PySpark and Databricks. The selected candidate will be responsible for designing and implementing efficient data pipelines and solutions for data-driven projects in Azure Data Factory and Azure Databricks 
  Responsibilities:
Design, build, and maintain scalable data pipelines using PySpark and Databricks
Optimize data processing and storage for maximum performance and efficiency
Troubleshoot and debug data-related issues, and implement solutions to prevent reoccurrence
Collaborate with data scientists, software engineers, and other stakeholders to ensure that data solutions are aligned with business goals
Requirements:
Strong experience in Python programming and PySpark, and SparkSQL
Clear understanding of Spark Data structures, RDD, Dataframe, dataset
Expertise in Databricks and ADLS
Expertise handling data type, from dictionaries, lists, tuples, sets, arrays, pandas dataframes, and spark dataframes
Expertise working with complex data types such as, structs, and JSON strings.
Clear understanding of Spark Broadcast, Repartition, Bloom index filters
Experience with ADLS optimization, partitioning, shuffling and shrinking
Ideal experience with disk caching
Ideal Experience with cost based optimizer
Experience with data modeling, data warehousing, data-lake, delta-lake and ETL/ELT processes in ADF
Strong analytical and problem-solving skills
Excellent documentation, communication and collaboration skills",USD 121K - 188K *
534,Core Services Data Operations - Senior Engineer,FICO,"Bengaluru, India",Senior-level / Expert,"FICO (NYSE: FICO) is a leading global analytics software company, helping businesses in 90+ countries make better decisions. Join our world-class team today and fulfill your career potential!
The Opportunity: 
“The Data Operations Senior Engineer role provides you with the opportunity to work with best-in-breed solution architecture for moving data from source to destination. You will partner with members of analytics, software development and application delivery teams as part of strategically important, highly visible initiatives.”- Sr. Director, Data Interchange Operations
What You’ll Contribute
Performs installation, monitoring, testing, configuration, migration, maintenance and troubleshooting of assigned technology.
Works directly with internal and external customers via email, phone, instant message where appropriate, gathering requirements and providing solutions.
Works directly with vendors to resolve software configuration issues.
Manages system/application environment and ongoing operations.
Researches, designs, implements and tests technology solutions.
Proactively monitors and reports performance and utilization of our team's servers and software.
Troubleshoots software and/or hardware issues/failures.
Resolves alerts and performs remediation activities.
Participates in on-call rotation and provides off-hours support.
Actively manages problem tickets and tasks.
Collects and presents data for reporting and planning.
Assists with developing tactical strategies, processes and procedures related to systems/application administration.
Collaborates with other lines of business on new initiatives.
Determines best course of action for meeting business needs.
Provide input into infrastructure architecture designs.
Writes / modifies scripts used to automate routine functions.
Participates in Disaster Recovery planning and exercises.
Ensures execution and alignment to architectural standards and blueprints.
Contributes input to infrastructure architecture and design.
 What We’re Seeking
Experience configuring, managing and troubleshooting Windows and Linux operating systems.
Experience configuring, managing and troubleshooting networks and firewall.
Experience writing and debugging Windows batch and Linux bash scripts; python, java and javascript experience is a plus.
Experience managing RDBMS such as Oracle and MSSQL, and database administration tasks.
Experience administering/managing technical solutions in large-scale system implementations.
Experience with SSH public/private key authentication and PGP public/private key encryption/decryption.
Experience with open-source file transfer tools (FileZilla, CuteFTP, WinSCP, etc).
Experience with public clouds such as Amazon AWS, Microsoft Azure.
Experience with RESTful and SOAP APIs, json and xml.
Proficiency in spreadsheet and word processing software
Ability to evaluate alternatives and present solutions that are consistent with business objectives and strategy.
Ability to manage tasks independently and work with multiple priorities, sometimes under limited time constraints.
Effective interpersonal skills and ability to maintain positive working relationship with others.
Ability to communicate detailed technical information clearly and articulately
Ability to adapt to a rapidly changing environment.
Experience analyzing business requirements and translating them into technical solutions.
Experience using Agile methodology.
Provide sales/PS teams with architectural presentations, RFP contributions and technical guidance to support go-to-market activities for managed file transfer solutions.
 Our Offer to You
An inclusive culture strongly reflecting our core values:  Act Like an Owner, Delight Our Customers and Earn the Respect of Others.
The opportunity to make an impact and develop professionally by leveraging your unique strengths and participating in valuable learning experiences.
Highly competitive compensation, benefits and rewards programs that encourage you to bring your best every day and be recognized for doing so.
An engaging, people-first work environment offering work/life balance, employee resource groups, and social events to promote interaction and camaraderie.
 Why Make a Move to FICO?
At FICO, you can develop your career with a leading organization in one of the fastest-growing fields in technology today – Big Data analytics.  You’ll play a part in our commitment to help businesses use data to improve every choice they make, using advances in artificial intelligence, machine learning, predictive and prescriptive modeling, and much more.
FICO makes a real difference in the way businesses operate worldwide:
Credit Scoring — 150+ billion FICO Scores have been sold to date, making it the most used credit score in the world.
Fraud Detection and Security — 2.6+ billion payment cards globally are protected by FICO fraud systems.
Lending — 3/4 of US mortgages are approved using the FICO Score.
Anti-Money Laundering — our solutions check more than half a billion transactions a day to prevent criminal schemes such as terrorist financing
Global trends toward digital transformation have created tremendous demand for FICO’s solutions, placing us among the world’s top 100 software companies by revenue. We support many of the world’s largest banks, insurers, retailers, telecommunications providers and other firms reach a new level of success.
Our success is dependent on really talented people – just like you – who thrive on the collaboration and innovation that’s nurtured by a diverse and inclusive environment. We’ll provide the support you need, while ensuring you have the freedom to develop your skills and grow your career.  Join FICO and help change the way business thinks!
Learn more about how you can fulfill your potential at www.fico.com/Careers
FICO promotes a culture of inclusion and seeks to attract a diverse set of candidates for each job opportunity. We are an equal employment opportunity employer and we’re proud to offer employment and advancement opportunities to all candidates without regard to race, color, ancestry, religion, sex, national origin, pregnancy, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Research has shown that women and candidates from underrepresented communities may not apply for an opportunity if they don’t meet all stated qualifications. While our qualifications are clearly related to role success, each candidate’s profile is unique and strengths in certain skill and/or experience areas can be equally effective. If you believe you have many, but not necessarily all, of the stated qualifications we encourage you to apply.
Information submitted with your application is subject to the FICO Privacy policy at https://www.fico.com/en/privacy-policy",USD 45K - 84K *
535,Azure Data Engineer Consultant - Tech Consulting - Mumbai,EY,"Mumbai, MH, IN, 400028",Senior-level / Expert,"Requisition Id : 1448936

Azure Data Engineer Consultant - Tech Consulting - Mumbai

The opportunity
  EY – Data and Analytics (D&A) – Azure Data Engineer
We’re looking for candidates with strong technology and data understanding in big data engineering space, having proven delivery capability. This is a fantastic opportunity to be part of a leading firm as well as a part of a growing Data and Analytics team.

Your key responsibilities
Develop & deploy azure databricks in a cloud environment using Azure Cloud services
ETL design, development, and deployment to Cloud Service
Interact with Onshore, understand their business goals, contribute to the delivery of the workstreams
Design and optimize model codes for faster execution
Develop data models in azure synapse
Skills and attributes for success
  3 to 8 years of Experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, and data warehouse solutions
Extensive hands-on experience implementing data migration and data processing using Azure services: Databricks, ADLS, Azure Data Factory, Azure Functions, Synapse/DW, Azure SQL DB, etc.
Hands on experience in programming like python/pyspark
Well versed in DevOps and CI/CD deployments
Must have hands on experience in SQL and procedural SQL languages
Strong analytical skills and enjoys solving complex technical problems
To qualify for the role you must have
  Be a computer science graduate or equivalent with 3 to 8 years of industry experience
Have working experience in an Agile base delivery methodology (Preferable)
Flexible and proactive/self-motivated working style with strong personal ownership of problem resolution.
Strong analytical skills and enjoys solving complex technical problems
Proficiency in Software Development Best Practices
Excellent debugging and optimization skills
Experience in Enterprise grade solution implementations & in converting business problems/challenges to technical solutions considering security, performance, scalability etc
Excellent communicator (written and verbal formal and informal).
Participate in all aspects of solution delivery life cycle including analysis, design, development, testing, production deployment, and support. 
Client management skills
  EY | Building a better working world 

 EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.  

 Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.  

 Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.  

Ideally you’ll also have

• Strong communication, facilitation, relationship-building, presentation and negotiation skills.
• Be highly flexible, adaptable, and creative.
• Comfortable interacting with senior executives (within the firm and at the client)
• Strong leadership skills and supervisory responsibility.

What we look for

People with the ability to work in a collaborative way to provide services across multiple client departments while adhering to commercial and legal requirements. You will need a practical approach to solving issues and complex problems with the ability to deliver insightful and practical solutions.

What working at EY offers

EY is committed to being an inclusive employer and we are happy to consider flexible working arrangements. We strive to achieve the right balance for our people, enabling us to deliver excellent client service whilst allowing you to build your career without sacrificing your personal priorities. While our client-facing professionals can be required to travel regularly, and at times be based at client sites, our flexible working arrangements can help you to achieve a lifestyle balance.
  About EY

As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.

If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible",USD 45K - 84K *
536,Data Integration Developer Job,Yash Technologies,"Bengaluru, KA, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Datastage Professionals in the following areas :
  Job Description:
    Our Digital Service Line is currently looking for industry-leading seasoned ""Data Integration"" professionals with hands-on experience.
The shortlisted candidate should have the ability to analyse technical needs and work with the customers to develop project scope of work documents and Project Plans.
The responsibilities are primarily technical, although there is a strong element of functional understanding of the business process.
  The scope of the project is to develop Data Integrations and Replications between Salesforce.com and boundary systems using DataStage (“DS”) and AIP (IIB, ITX, MQ, CI) Technologies for Batch and Real time interactions. Also, to support the existing data integrations and replications in Production Environment
(DataStage – L1.5, L2 and L3, AIP - L3). Currently these boundary systems are visualized as JDE/Siebel systems as per the Vendor scope sheet (note – scope could also include integrations to additional systems as requirements are being finalized).

Following are the activities and their detailed description of the work that will be performed for successful Data integration.

1.1 In-Scope-

Architecture
Assess the current client Data Integration Architecture and provide recommendations about what can be done to improve

Development
User Stories mentioned in the Vendor scope sheet for the build, including Requirement Analysis, Design, Development, Unit testing for AIP & DS areas
Analysis and resolution rejects/issues from data loads into all environments.
Support testing activities associated with SIT, UAT, Release, Deployment, Production activities for AIP & DS areas
Analysis of data load volumes prior and after loads in all environments, and resolution of any issues.
DB Queries indexing will be performed every Program Increment PI and reviewed with client Integration Lead and client DBA Leads.
Error handling of AIP and DataStage code according to client quality checklist.
Development team with Integration lead will request the Control-M job scheduling.
  Environment Management
Management of the connections to different environments based on the release plan.
Participate in the Planning for any infrastructure upgrades (Salesforce or boundary systems), patches and impact assessment on the program needs to be in scope, while the execution of upgrades is out of scope and to be managed by client.
Configuration Management of DataStage Jobs and AIP Code.
Initial Master data load for source will be provided by client and target. Its applicable for all environments. Any additional data require for testing will be created working with client PO/Business team.

Testing
Planning & Loading of the data that will be required in supporting all test cycles, releases and source by client /target system by Service Provider’s data refreshes. Vendor to provide data requirements with client responsible for creating data in source system
Scope to include execution of SIT, Validation (OQ), Production (IQ/PQ) and Performance.
Support User Acceptance testing (UAT) performed by client. 
Includes row counts, data map and update testing where applicable to each story.

Deployment
Provide inputs to Release Planning activities
Development support of Production Deployment and Hypercare for AIP & DS areas
Hyper Care support period of 2 weeks for both the technical and the business go-lives (note: these could occur at the same time or different times, and when at separate times 2 weeks of Hyper Care will be provided for each) Documentation.
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
537,Principal Data Scientist,GSK,Bengaluru Luxor North Tower,Senior-level / Expert,"Overall responsibilities
Business and data understanding:   Working with other data scientists, you know how to build your understanding of the business context, systems, environment, strategy and people aligned to the given area.  This also includes an understanding of the relevant internal and external high-volume data sources, validity and domains of such data to align with the intended business objective.    You will conduct data acquisition from multiple data sources and wrangle data sets selecting appropriate techniques, such as parsing, or an algorithm, to create a data structure relevant to the problem.  This can include but not limited to techniques such as ETL batch processing, streaming ingestion, scrapers, APIs and crawlers.  NOTE:  adjust here based on your teams process of identifying DS project scope.  Could also be the case, for example, “After receiving an explorative brief, you will build your understanding of the business context, systems, environment, strategy and people to convert it into a valued deliverable.”
Data preparation:  You will create required data set(s) utilizing your understanding of complex business problems, data formats, applicability of the data to the problem and standard modelling techniques.  You can perform techniques to validate the quality of the data, and can fuse data from various sources using knowledge of data pre-processing techniques.
Modelling:  For the intended business objective, you can utilize advanced modelling techniques, such as predictive modelling, advanced clustering, association rules, to create a model or models that perform to particular requirements and specifications. You are able to anticipate how a model’s requirements or the available data, might change over time and be able to design a product that will be able to cope with these requirements. 
Test & validate the model:  You are able to apply best practice model fit testing, tuning and validation techniques, such as chi square, ROC curve, root mean square error, to assess model performance, compare results from various methodologies and suggest improvements.  You both give and seek feedback and ideas with others from across differing business areas, as relevant, to create better products and continually advance your data science skills. 
Communication of insights:  You are able to design rich data visualisations and use them to communicate complex messages to business leaders  in a clear and simple way, with the ability to respond effectively to challenges.   
In the role, you will
Work in a stimulating and supportive environment; Be part of a dynamic, growing community of data analysts and data scientists at GSK; Have career-long access to our GSK Data Academy - a dedicated, tailored learning programme that blends your on-the-job learning with targeted coaching, peer-to-peer mentoring, expert-led workshops and a network of learning providers; Work on high impact strategic priorities; deploy GSK's large, varied data-sets to tackle analytics challenges; Be at the forefront of GSK's data and analytics transformation
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
 ",USD 173K - 235K *
538,MLOps Engineer,S&P Global,IN - HYDERABAD ORION,Mid-level / Intermediate,"The Team: The Data Science/AI/ML team is a newly formed innovation and deployment team within S&P Global Ratings that will be responsible for building and executing a bold vision around using Machine Learning, Artificial Intelligence, Data Science, knowledge engineering, and human computer interfaces for augmenting various business processes.
The Impact: This role will have a significant impact on the success of our data science, AI, and Machine Learning projects ranging from choosing which projects should be undertaken, to delivering highest quality solution, ultimately enabling our business processes and products with AI and Machine Learning solutions.
What’s in it for you: This is a high visibility role with an opportunity to make a very meaningful impact on the future direction of the company. You will work with senior leaders in the organization to define, build, and transform our business. As a MLOps Engineer, you will contribute to the deployment, monitoring, and management of machine learning models and data pipelines. You will work with a peer group of MlOps engineers to develop MLops modules and engineering solutions.
In this role, you will play a key role in implementing our machine learning operations, ensuring the seamless deployment, monitoring, and management of our machine learning models and data pipelines. You will be work closely in a world class AI ML team comprised of experts in AI ML modeling, ML engineers and data science and data engineering teams. You will contribute to engineering and developing solutions for ML operations and be a critical part of leading S&P’s AI-driven transformation to drive value internally and for our customers.
Responsibilities:
ML Model Deployment: Assist in deploying machine learning models into production environments. 
AI ML pipeline and model Monitoring: Contribute to the monitoring and maintenance of model performance and infrastructure health. 
Automation: Participate in the development and maintenance of automated MLOps pipelines. 
Collaboration: Collaborate with cross-functional teams to integrate machine learning models into production systems. 
Documentation: Maintain documentation of MLOps processes and procedures. 
Work closely with members of technology teams in the development, and implementation of Enterprise AI platform 
Problem Solving: Assist in troubleshooting and resolving MLOps-related issues. 
Qualifications:
Bachelor's degree in Computer Science, Engineering, or a related field.
2+years experience  in cloud engineering MLOps, machine learning engineering, Big Data, or a related role.
1+ year’s experience with Python, Java, Kubernetes, and data and workflow orchestration tools
Knowledge of  containerization, scripting, cloud platforms, and CI/CD.
Experience of  Elasticsearch, SQL, NoSQL,  Apache spark, Flink, Databricks and Mlflow, 
Knowledge of operationalizing data-driven pipelines for large scale batch and stream processing analytics solutions
 Plus: Experience with contributing to GitHub and open source initiatives or in research projects and/or participation in Kaggle competitions
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
IFTECH202.1 - Middle Professional Tier I (EEO Job Group)",USD 73K - 134K *
539,"Associate, Internal Audit Data Analytics",BlackRock,HA3-Gurgaon - DLF Cyber City,Entry-level / Junior,"About this role
Internal Audit’s primary mission is to provide independent assurance to the Board of Directors and Executive Management regarding the management of BlackRock’s businesses. The team engages with senior leaders and all of BlackRock’s individual business units globally to understand and advise on the risks in their business, evaluate the effectiveness of key processes and assist in the design of best practices that can improve their results. Internal Audit reports directly to the Audit Committee of the Board of Directors, and our work builds confidence that BlackRock will meet its obligations to clients, shareholders, employees and other stakeholders.
As part of the third line of defense, you will have the opportunity to be part of a team that provides independent opinion on the firm’s control environment as it relates to the ever evolving technology landscape that is relied upon to deliver its objectives. We are looking for individuals that want to be part of a global team that embraces analytics, audit, technology and learning and able to bring their creative mindsets to enhance audit techniques.
Data Analytics
 Internal Audit’s Data Analytics (DA) team leverages various data science, business intelligence, and analytical methods to assess BlackRock’s control environment. DA team members may design and perform certain testing as part of audits of BlackRock business units (including investment and asset management, risk management, operations, finance, and legal and compliance) and technology controls across application systems and infrastructure components (such as databases, operating systems, data centers and messaging platforms).  The DA team is also responsible for building and maintaining an inventory of self-service tools for the auditors, supporting the risk assessment of auditable units for the annual planning process, and assisting the development of timely and accurate Internal Audit management information.
Role Description:
 The DA Associate will engage collaboratively with business & technology teams, internal risk partners and with IT teams to support the goals of Internal Audit.  Our DA team is looking for an analytical self-starter, eager to learn new technologies and work with others to deploy and explain them. We value creativity and encourage our team members to challenge the status quo of how audits and audit testing used to be performed.  Successful DA team members embrace a fast-paced environment and add value to the performance of audits by working alongside audit teams and by helping to evolve our audit processes, tools and methodologies.
Specific responsibilities will include:
Develop code to execute audit tests, build tools, and/or execute data centric activities supporting the department and ensure that all code is properly documented and maintained.
Contribute to the strategic development of the DA program including the design and implementation of tools and technologies, development, delivery, and distribution of data analytics presentations, training, and methodology.
Propose alternative and creative approaches to audit testing, leveraging technology to either gain efficiencies or provide additional coverage.
Participate in short term data analysis activities aimed at supporting audit delivery and/or other ad-hoc requests including closure verification of issues, regulatory inquiries, strategic initiatives.
Networking to cultivate strong relationships with firm-wide partners to ensure successful analytic activities such as retrieval of new data sets, learning technology architecture, troubleshooting, etc.
Skills and Experience:
Bachelor’s or Master’s degree in information systems, data analytics, data science, computer science, economics, risk management or another quantitative related field
At least 5-7 years in data analytics and/or audit, risk management function, preferably within the wealth management/asset management/banking industry.
Strong SQL skills required, along with programming experience in Python or R , experience of any other scripting languages (VBA, PowerShell, etc.).
Working experience of any Business Intelligence tool (PowerBI, Tableau) is preferred.
Experience with both structured and unstructured data as well as experience with Data Warehousing, Extract Transform and Load (ETL). Hands on experience on techniques like text analytics, web scraping, Selenium, N-Gram analysis, Sentiment Analysis, etc. is preferred.
Awareness of development life cycle and tools like Azure Dev Ops, JIRA.
Team player with attention to detail with demonstrated analytical and problem-solving skills.
Strong interpersonal and communication skills (verbal, written, and listening).
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 22K - 42K *
540,"Senior Software Engineer, Data Platform",Houseware,Bengaluru Office/Remote,Senior-level / Expert,"About Houseware:
The data landscape is evolving, and at Houseware, we're leading the charge. In the modern business world, data warehouses have become the center of data gravity. Recognizing this shift, Houseware is redefining product analytics by building solutions natively on the warehouse. We eliminate the need for external SaaS vendors and enable businesses to harness the full power of their own data.
Our team comprises seasoned engineers with a track record of building SaaS products for early-stage startups. We thrive on tackling 0->1 problems, have a strong product-thinking approach, and carry a bias towards action.
The Role:
As a Senior Software Engineer for the Data Platform team at Houseware, you will be instrumental in our journey to create the next generation of Product Analytics solutions. Your focus will be on designing, building, and maintaining our warehouse-native, multi-tenant data platform that helps our customers understand the most complex of user behaviours.
Key Responsibilities:
Design, develop, test, deploy, maintain and improve our multi-tenant data platform, ensuring high scalability and performance.
Develop our state of the art Query Engine that generates complex yet efficient SQL queries.
Construct scalable backend APIs in Go capable of handling high-volume traffic.
Setup and maintenance of cloud infrastructure for backend systems & data warehouses, keeping reliability and security front and center
Improve engineering standards and hold a high bar for code quality and simplicity.
Set benchmarks for software design, data storage and communication, and mentor the engineering team in these areas.
Work cross-functionally with other teams to align engineering efforts with business objectives.
Lead projects from initial scoping to final general availability release.
Perform performance analysis on existing systems & workloads, using results to improve scanning, indexing, caching, and data partitioning strategies.
Keep an eye on how much the data platform costs every month and removing inefficiencies wherever possible.
Push the boundaries on how our customers analyze their product data.
Requirements:
3+ years of experience in a Software Engineering or similar role building solutions on top of distributed compute systems like Apache Spark, Apache Trino (Presto previously), Snowflake, BigQuery.
In depth understanding of SQL and distributed compute systems.
Proven track record in building production APIs at scale.
Prior experience working in Infrastructure/Devops(AWS & Terraform is a plus)
A knack for problem-solving and thinking from first principles. You don't shy away from any problem, no matter the scale or impact.
A bias towards shipping early and iterating. We believe in making small incremental changes to existing systems instead of large multi-quarter undertakings.
Data Savviness - strong understanding of data visualizations and data-driven decision making.
Experience with Go and Python.
Excellent communication skills, both written and verbal.
Nice-to-Have:
Experience building product analytics solutions or working with clickstream analytics.
Familiarity with cloud data warehouse technology and applications.
We're offering the chance to be a part of a vibrant, inclusive work environment, focused on innovation and growth. At Houseware, we prioritize work-life balance and the professional development of our team members. If you're passionate about data, enjoy solving complex problems, and want to influence the future of product analytics, we would love to hear from you.
Some more perks of joining Houseware!
Employee Health Insurance: Comprehensive insurance coverage.
Device Policy: Providing the latest Macbook Pro.
Leave Policy
Hybrid work Setup
Two retreats a year
Travel Policy, including Ola Corporate for intra-city travel to customer offices
In-office catering and lunch service",USD 31K - 58K *
541,Senior Software Engineer - Bigdata,Bazaarvoice,Bengaluru,Senior-level / Expert," About Bazaarvoice
 At Bazaarvoice, we create smart shopping experiences. Through our expansive global network, product-passionate community & enterprise technology, we connect thousands of brands and retailers with billions of consumers. Our solutions enable brands to connect with consumers and collect valuable user-generated content, at an unprecedented scale. This content achieves global reach by leveraging our extensive and ever-expanding retail, social & search syndication network. And we make it easy for brands & retailers to gain valuable business insights from real-time consumer feedback with intuitive tools and dashboards. The result is smarter shopping: loyal customers, increased sales, and improved products.
 The problem we are trying to solve : Brands and retailers struggle to make real connections with consumers. It's a challenge to deliver trustworthy and inspiring content in the moments that matter most during the discovery and purchase cycle. The result? Time and money spent on content that doesn't attract new consumers, convert them, or earn their long-term loyalty.
 Our brand promise : closing the gap between brands and consumers.
 Founded in 2005, Bazaarvoice is headquartered in Austin, Texas with offices in North America, Europe, Asia and Australia.
 It’s official: Bazaarvoice is a Great Place to Work in the US , Australia, India, Lithuania, France, Germany and the UK!

What is the Big Data Analytics Platform at Bazaarvoice?
Authentic data is the lifeblood of the Bazaarvoice business. It is imperative that our data is consumable, interpretable, and instantly available to fuel insights across our brand, retailer and consumer customers. The Big Data Analytics Platform team owns and innovates a portfolio of data platform technologies as a service to other engineering teams at Bazaarvoice - including data lakes, metadata management, analytics streaming, and more. 

Who are we looking for?
Bazaarvoice is looking for a seasoned Software Engineer to join us in building the future of ecommerce data strategy. You are a good fit if you are excited by the opportunity to work alongside a slew of other smart and passionate people who challenge one another to build better data systems each and every day.

Software Engineers at Bazaarvoice:
Collaborate with Product Managers, Product Designers, and other Software Engineers to deliver new functionality and iterative improvements to member-facing products and internal tools
Support the translation of complex functional and technical requirements into design docs, epics, and individual release assignments
Execute upon technical roadmap across collaborative and individual software development tasks
Collaborate with Engineering leadership to define the software development and delivery processes
Participate in code reviews, demos, and communities of practice with other engineers
Maintain current technical knowledge to support rapidly changing technology, always on a look out for new technologies and work with the management and development team in bringing new technologies
Accountable for owned systems and technological roadmap to meet SLAs
Participates in the on-call engineering rotation
Collaborate and communicate on the go to market strategy for the products and services the team owns closely working with sales, support, or other departments as needed

This Senior Software Engineer role requires:
5+ years experience in software/data engineering roles
Veteran knowledge in at least one programming language such as Java, Scala, Python, JavaScript, or similar 
Solid experience working within cloud technologies such as AWS
Experience in building large scale, high-performance, and scalable solutions
Experience of Agile or Kanban / Lean software development methodologies
High attention to detail, flexible, and able to work concurrently on multiple projects
Ability to troubleshoot, research, and work through complex problems
Excellent written and verbal communication skills
Excellent interpersonal skills
Strong ability to communicate effectively and collaborate with others
Track record of taking ownership and delivering outcomes

You are:
Naturally curious and inquisitive, seek knowledge, and apply knowledge
Technically curious and well informed; have opinions that are rooted in knowledge and experience
On top of trends in the industry or marketplace and develop plans to prepare for opportunities or problems.
Outcome-oriented, with a strong drive to meet their personal objectives and standards of excellence
Proactively reviewing your own performance to develop your skill set and keep relevant knowledge up to date

You have experience with most of:
Experience with Java, Python, Scala
Experience with modern CI/CD and engineering tooling – we leverage Amazon Web Services, CloudFormation, Terraform, Jenkins, and a variety of vendor services.
Experience with microservice-oriented architectures.
Experience with agile methodologies.
Experience with Big Data Technologies - Hive, EMR, Spark
Experience with Data Streaming Technologies - Kafka, Kinesis
Experience with Database Technologies including MySQL, Postgres, Redshift, Athena, Elasticsearch, DynamoDB
#LI-Hybrid #LI-SR1

Why join Bazaarvoice?
 Customer is key
We see our own success through our customers’ outcomes.  
We approach every situation with a customer first mindset.
 Transparency & Integrity Builds Trust
We believe in the power of authentic feedback because it’s in our DNA. 
We do the right thing when faced with hard choices. Transparency and trust accelerate our collective performance.
 Passionate Pursuit of Performance
Our energy is contagious, because we hire for passion, drive & curiosity. 
We love what we do, and because we’re laser focused on our mission.
 Innovation over Imitation
We seek to innovate as we are not content with the status quo. 
We embrace agility and experimentation as an advantage.
 Stronger Together
We bring our whole selves to the mission and find value in diverse perspectives. 
We champion what’s best for Bazaarvoice before individuals or teams.  
As a stronger company we build a stronger community.
 Commitment to diversity and inclusion
 Bazaarvoice provides equal employment opportunities (EEO) to all team members and applicants according to their experience, talent, and qualifications for the job without regard to race, color, national origin, religion, age, disability, sex (including pregnancy, gender stereotyping, and marital status), sexual orientation, gender identity, genetic information, military/veteran status, or any other category protected by federal, state, or local law in every location in which the company has facilities. Bazaarvoice believes that diversity and an inclusive company culture are key drivers of creativity, innovation and performance. Furthermore, a diverse workforce and the maintenance of an atmosphere that welcomes versatile perspectives will enhance our ability to fulfill our vision of creating the world’s smartest network of consumers, brands, and retailers.",USD 45K - 84K *
542,Assistant Manager-Data Analyst,Guidehouse,"GH Office: Chennai, India",Entry-level / Junior,"Job Family:
EBO Accounts Receivable (India)

Travel Required:
Up to 25%

Clearance Required:
None
What You Will Do:
Design efficient database that meets the need and expectation of all its users.
Ensure all data is intelligently stored and processed.
Translate business requirements into specifications that will be used to implement the required reports and dashboards, created from potentially multiple data sources.
Participate with other specialist/leads/managers to understand reporting requirements and work on building solutions or reporting system as per business needs.
Structure company data, do Data Modelling and assist with schema design.
Collate, prepare, and present statistical information for internal and external use.
Provide technical assistance and cross training to other team members.

What You Will Need:
Proficient with SQL, MS Office Applications like Excel, Access, Power BI.
Excellent interpersonal (verbal and written) communication skills are required to support working in project environments that includes internal, external and customer teams.
Data Modelling.
Requires strong analytical, conceptual, and problem-solving abilities
Ability to manage multiple priorities, and assess and adjust quickly to changing priorities.
At least 5 years as a DBA in managing and tuning databases.
Bachelors in computer science/ IT.

What Would Be Nice To Have:
Reporting and Analysis: Power BI,
VBA Develop automation scripts using Excel Macros.
MS Excel Expertise in Excel reporting and dashboards.
MS Access database and application development.
Communicate seamlessly with Client Business lines, Leadership team and other internal stakeholders.
Willing to work in rotational shifts and mandatory work from office
Good to have but not mandatory – Python, Power Automate, Power Apps.

What We Offer:
Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.
About Guidehouse
Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation.

If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.

Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.",USD 60K - 94K *
543,Senior Software Engineer - Search (Solr / Elasticsearch),Elsevier,India-Bengaluru (Helios Business Park),Senior-level / Expert,"Senior Software Engineer
Do you enjoy developing enterprise software solutions for global customers?
Have you experience in working on complex problems?
About the Role
The Senior Software Engineer role will help us create next-generation research and analytic tools.  We are looking for someone with technical savvy, strong communication skills and interested in our new technology hub for Nexis Solutions.
About the Team:
The Nexis Solutions Search Team works on projects and builds features that power the search functionality for many of our products.  We partner with our application teams to provide an intuitive, fast, and accurate search experience for our customers.  We ingest billions of documents across multiple content types and build the APIs that are the interface to the search engine.
Responsibilities:
Serve as acknowledged ""go-to"" person on coding and technical issues.
Interface with other technical personnel or team members to finalize requirements.
Work closely with other development team members to understand complex product requirements and translate them into software designs.
Write and review portions of detailed specifications for the development of search engine plug-ins of moderate complexity.
Complete complex bug fixes.
Design and work with complex data models.
Mentor junior software developers interested in search engineering.
.
   Requirements:
Expertise in containerization techniques such as Docker and Cloud orchestration platforms such Kubernetes.
Expertise in enterprise development languages such as Java or Scala.
Expertise in test-driven development and maintenance including techniques for applying best practices for overall project benefit. (Java and Cucumber scripting).
Software development process expert in applicable methodologies (e.g., Agile, Test Driven Development).
A proven expert in partnering and leading internal and external technology resources in solving complex business needs.
Ability to partner and lead internal and external technology resources in solving complex business needs.
Strong proficiency with data manipulation language including optimization techniques.
Advanced problem-solving experience involving leading teams in identifying, researching, and coordinating the resources necessary to effectively troubleshoot/diagnose complex project issues; prior success extracting / translating findings into alternatives / solutions; and identifying risks / impacts and schedule adjustments to facilitate management decision-making.
Advanced communication (verbal and written) and customer service skills. Strong interpersonal, communication, and presentation skills applicable to a wide audience including senior and executive management, customers, etc., including diction/terminology and presenting information in a concise and effective manner to clients, management, and various departments using assorted communication mediums.
Benefits:
        ·       Group Health Insurance Policy (covering self and family)
        ·       Group Life insurance/accident policy
        ·       Generous long-service awards
        ·       New Baby gift
About LexisNexis
Nexis Solutions, a division of LexisNexis, is looking for a Senior Software Engineer to help recruit, build and maintain a high performing development team in India.  This role will provide leadership and technical guidance for software engineers in the development of next-generation research tools.  We are the leading global provider of news and business information, constantly innovating to help our customers succeed by combining information and analytics to increase productivity, improved decision making and outcomes.  Our goal is to improve how our customers search and find answers to their research questions. We are looking for someone who can bring technical savvy, hands-on skill, strong communication skills and team motivation in a new technology hub for Nexis Solutions.  This person must display leadership qualities and be enthusiastic in tackling problems and creating new products, as we continue to push research technology solutions forward.
About RELX
RELX is a global provider of information-based analytics and decision tools for professional and business customers.  We help scientists make new discoveries, doctors and nurses improve the lives of patients and lawyers win cases. We prevent online fraud and money laundering and help insurance companies evaluate and predict risk. Our events enable customers to learn about markets, source products and complete transactions. In short, we enable our customers to make better decisions, get better results and be more productive. The Group serves customers in more than 180 countries and has offices in about 40 countries. It employs over 33,000 people, of which around 1/4th are technologists.
We want RELX to be a great place to work, where our employees feel valued, have equal opportunities and benefit from pay equality, regardless of their gender, gender identity, national origin, race, ethnicity, religion, sexual orientation, age or disability status. Inclusion and diversity are important to our future. We need the engagement of people from a wide range of backgrounds, experiences, and ideas to achieve real innovation for our customers around the world.
Apply today, or to learn more about opportunities with LexisNexis or RELX Global, join us here:

LexisNexis Careers | Legal & Professional | Legal Tech Jobs
www.relx.com/careers/join-us
LexisNexis, a division of RELX Group, is an equal opportunity employer: qualified applicants are considered for and treated during employment without regard to race, color, creed, religion, sex, national origin, citizenship status, disability status, protected veteran status, age, marital status, sexual orientation, gender identity, genetic information, or any other characteristic protected by law. We are committed to providing a fair and accessible hiring process. If you have a disability or other need that requires accommodation or adjustment, please let us know by completing our Applicant Request Support Form: https://forms.office.com/r/eVgFxjLmAK .
Please read our Candidate Privacy Policy.",USD 45K - 84K *
544,Senior Software Engineer - Data Engineering (Java/Spark) - REF8502E,Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
About the role:
As part of the Data engineering team, the candidate will be working within an agile team that iterates quickly on delivering new features for the Zscaler Digital Experience (ZDX) SaaS-based product. Candidate will contribute to the design and development of backend microservices to expand the solution offering to collect and analyze telemetry/health data and use this data to help detect performance problems with customer applications such as SaaS applications, UCaaS (Unified-Communication as a Service) apps, and Enterprise apps.
What you will do:
You will be responsible for product features related to data transformations, enrichment, and analytics
You will discuss with product managers, UX designers, and other backend teams to understand requirements and translate the same into functional specifications 
You will seize every opportunity to refactor code in the interests of maintainability and reusability
Lead and provide technical direction and mentorship to junior engineers and bring out the best in them
The ideal candidate has a proven track record of building large scale enterprise products, and is a creative thinker, problem solver, learner, and a fantastic manager of people, and is motivated with engineering excellence.
Requirements:
Education: BS Computer Science or Equivalent
Minimum 4+ years of software development experience
Experience in Core Java, Concurrency, and Distributed Computing
Experience in building high performance, scalable web services
Experience using batch and stream processing frameworks like Spark/Kafka Streaming, Spring batch or equivalent
Experience developing microservices and API's
Proficiency with Tomcat installation and configuration.
Proficiency with Maven (preferred) or Gradle builds and dependency management systems.
4+ years of experience writing unit test, stubs, mocks in a TDD environment using JUnit, REST Assured, or TestNG
Experience with CI & CD systems such as Jenkins or Bamboo
Metrics-driven development experience and experience using metrics systems like Grafana, Prometheus, etc
Desired skills:
Ability to write code that can perform efficiently in a big data setup
Experience with big-data technologies like Spark, Redshift, etc.
Strong knowledge of various DBMS systems including NoSQL architectures and design principles
Experience tuning JVM for optimal application performance
Successfully delivered software products from ideation through to implementation and support
Experience with any Graph Database like AWS Neptune, Neo4j, Spark Graphx, etc.
Understanding of statistics and machine learning.
#LI-SK3
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 121K - 188K *
545,Technical Architect - Data Modeling 1 Job,Yash Technologies,"Indore, IN",Senior-level / Expert,"YASH Technologies is a leading technology integrator specializing in helping clients reimagine operating models, enhance competitiveness, optimize costs, foster exceptional stakeholder experiences, and drive business transformation.
  At YASH, we’re a cluster of the brightest stars working with cutting-edge technologies. Our purpose is anchored in a single truth – bringing real positive changes in an increasingly virtual world and it drives us beyond generational gaps and disruptions of the future.
  We are looking forward to hire Data Modeling Professionals in the following areas :
  Experience
12-14 Years
Job Description
The Data Modeler’s role is to direct, evaluate, review, and manage database resources and services across the organization while ensuring high levels of data quality with the goal of contributing to key business needs. This individual is also responsible for applying DA Chapter Standards s to ensure the integrity and availability of the CDP Data Model and Software Tools. Where required, the Data Modeler will monitor, maintain, and performance-tune production databases.
  Data Modeller Requirements
Bachelor’s degree in Computer Science, Informatics, Data Analytics or any relevant majors and 3 years of experience or 8 years of equivalent experience
3-4 years designing and implementing Business Intelligence solutions using the Microsoft Business Intelligence Suite (SSIS, SSAS, Excel, Power BI).
4 years dimensional Modelling and design.
3-4 years developing solutions using MS SQL Server and ER Studio, Databricks, Azure Data Factory.
3-4 years developing Tabular and Multidimensional Data Models.
3-4 years using DAX and MDX to implement measures and calculated columns in SSAS.
1-2 years working experience with reporting and query tools and practices, Power Query, Pivots in Excel, Databricks
1-2 year working experience / exposure to Data Curation L3, L4
Highly self-motivated and directed, with keen attention to detail.
Proven analytical and problem-solving abilities.
Collaborate, prioritize and execute tasks in a high-pressure in an Agile environment (SAFe, SCRUM and Devops), working with cross functional teams.
Strong customer service orientation meeting timelines or delivery.
Required Technical Competencies
  Responsibilities:
Define and apply data modelling and design standards, tools, best practices, and related development for the CDP data model.
Work with business and delivery team to implement data strategies, build data flows, and develop conceptual/logical/physical CDP data model.
Understand the business process and workflow with the Site SME and CDP BA , develop the conceptual , logical and physical data model
Coordinate data model development with the higher-level data architecture to ensure cross-application consistency.
Work proactively to address CDP analytical requirements and validate against the existing CDP data model
Respond to and resolve database access and performance issues.
Apply Data Modelling practices and tools for data extraction, queries, and data manipulation in accordance with Data Analytics standard, policy, and procedures
Ensure the stability and reliability of data access and data quality across the organization via ongoing database support and maintenance.
Monitor database system details within the database, including stored procedures, execution time, and implement of efficiency improvements.
  At YASH, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. We leverage career-oriented skilling models and optimize our collective intelligence aided with technology for continuous learning, unlearning, and relearning at a rapid pace and scale.
  Our Hyperlearning workplace is grounded upon four principles
Flexible work arrangements, Free spirit, and emotional positivity
Agile self-determination, trust, transparency, and open collaboration
All Support needed for the realization of business goals,
Stable employment with a great atmosphere and ethical corporate culture",USD 45K - 84K *
546,Data Operations Associate,G2,Bengaluru,Senior-level / Expert,"About G2 - The Company
G2 is where you go for software. When you join us, you join the global team behind the largest and most trusted software marketplace. Every month, 5.5 million people come to G2 to inform smarter software decisions based on honest peer reviews. Authenticity is our focus, and every day we help thousands of companies, and hundreds of employees, propel their potential. Ready for meaningful work that starts and ends with compassion and heart? You’ve come to the right place.
G2 is going through exciting growth! We’ve recently secured our Series D funding of $157 million, which will further allow us to grow and develop our product and people. Read about it here!
About G2 - Our People 
G2 was founded to create a place where people will love to work. We have big goals, and are grounded in our PEAK values—high performance and entrepreneurship, while also being authentic and kind. Employees are led by conscious leaders who are connected by shared commitments and 7 core leadership principles. We celebrate each other's successes, forgive mistakes, and support one another during challenging times. Together, we will grow and reach the top, while staying true to our values, ethics, and people.  
As we foster our high-performance and entrepreneurial culture, we strive to create meaning in work and provide more than just a job: a true calling. At the heart of our community and culture are our people. Our global G2 team comes from a wide range of backgrounds and experiences, and that’s what makes our G2 community  strong and vibrant. We want everyone to bring their authentic selves to work, and we do this through our company and team events, our G2 Gives charitable initiatives, and our Employee Resource Groups (ERGs). 
We support our employees by offering generous benefits, such as flexible work, ample parental leave, and unlimited PTO. Click here to learn more about our benefits. 
G2 is excited to offer a remote work environment for our employees, unless otherwise stated in the job description. If you are interested and eligible to partake in a hybrid office plan, please ask your recruiter for more information. 
About The Role
G2 is looking for a Data Operations Associate to join our data operations functions within Product R&D. This role will be responsible for working on the daily sprint tasks assigned and completing them within the deadline,following SOPs,upskilling themselves to the latest technology that the team uses, following process,quality and accuracy benchmarks, and adhering to the team guidelines and policies shared during training.
In this role you will:- 
Day-to-day execution of data processes that support G2 products
Collaborating with the team to understand the technology and business requirements
Accountable for quality, accuracy, and efficiency of processes
Upskilling with tools / softwares required for working smoothly on various processes
Ensure all products and vendors on G2 are accurately represented and maintained
Minimum Qualifications:
We realize applying for jobs can feel daunting at times. Even if you don’t check all the boxes in the job description, we encourage you to apply anyway. 
0 - 1 year of working experience
Graduate from any discipline
Good with time management and multitasking skills
Experience with using spreadsheets (Google Sheets, Excel)
Attention to detail and strong organizational skills
Some software experience a plus
Our Commitment to Inclusivity and Diversity
At G2, we are committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. We consider applicants without regard to race, color, creed, religion, national origin, genetic information, gender identity or expression, sexual orientation, pregnancy, age, or marital, veteran, or physical or mental disability status. Learn more about our commitments here. ",USD 37K - 70K *
547,Lead-Data Analysis,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardizing processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardization and build centralized capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimizing processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
-Driving CI culture; implementing CI projects and innovation for withing the team
-Driving Data analysis for testing key business hypothesis and asks; developing complex visualizations; self-service tools and cockpits for answering recurring business asks and measurements
- Experience in handling quick turnaround business requests; leading partner communication and solving business asks holistically going beyond the basic partner asks
- Ability to select the right tools and techniques for solving the problem in hand
- Ensuring analysis; tools/ dashboards are developed with the right technical rigor meeting Tesco technical standards
- Applied experience in handling large data-systems and datasets
- Extensive experience in handling high volume; time pressured business asks and ad-hocs requests
- Ability to develop production ready visualization solutions and automated reports
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Understands business needs and in depth understanding of Tesco processes
- Help mentor team members and guide daily work and projects to meet encouraged performance metrics
- Come up with new insights and analysis to support business priorities and solve business problems
Qualifications
4-7 years of experience in relevant field preferred; Proven track record of handling ad-hoc analysis; developing dashboards and visualizations
Exposure to analysis work within Retail domain and Finance function area
Technical Skill:
Adv Excel; Adv VBA ; Logical Reasoning Strong Verbal and Written Communication
Adv SQL writing; SQL Server
Knowledge of Tableau and data visualization
Strong Automation skills in using Alteryx/python
Additional Information
Last Date of Application- 12th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
548,Senior Analytics Engineer,EarnIn,Bengaluru,Senior-level / Expert,"About EarnIn
As one of the first pioneers of earned wage access, our passion at EarnIn is building products that deliver real-time financial flexibility for those with the unique needs of living paycheck to paycheck. Our community members access their earnings as they earn them, with options to spend, save, and grow their money without mandatory fees, interest rates, or credit checks. Since our founding, our app has been downloaded over 13M times and we have provided access to over $15 billion in earnings.
We’re fortunate to have an incredibly experienced leadership team, combined with world-class funding partners like A16Z, Matrix Partners, DST, Ribbit Capital, and a very healthy core business with a tremendous runway. We’re growing fast and are excited to continue bringing world-class talent onboard to help shape the next chapter of our growth journey.
About the Role: 
This is a high-impact role with a lot of excitement. You will work across the team, help drive data-driven decisions, establish new business metrics, and own automated reporting systems. You will develop solutions to complex business problems characterized by imperfect data. You will gather, transform, and present data to enable data-driven decision-making. You will help scale the analytics we are offering to both internal and external stakeholders. This position will be based in Bangalore/Bengaluru and will be hybrid. 
Responsibilities
Streamline data flows from source and produce high quality data and pipelines (15%)
Develop and maintain data pipelines, ETL processes, and data integration workflows to ensure efficient and accurate data acquisition from various internal & external sources using SQL, Python, or other scripting languages
Work with data infrastructure to triage infra issues and drive to resolution and serve as the key point to bridge between data infrastructure and end customers
Design, build, and optimize data architecture & models to support business reporting and analytics needs. Understand evolving business requirements to optimize/update data pipelines in SQL
Monitor and optimize the performance of data systems, troubleshoot issues, and propose solutions for data-related problems
Design, develop and maintain scaled, automated, user-friendly systems, reports, dashboards, etc. that will support our financial needs (45%)
Build and deliver high quality visualization and reporting solutions to support Finance business needs
Design and create customized reports for all new financial reconciliation needs catering to their specific needs
Automate reporting for Finance using Python, Periscope, Tableau, Amplitude and other Earnin in-house business intelligence tools and platforms
Interface with Finance, Engineering and Analytics to understand data needs and deliver high quality data products (30%)
Get familiar with finance domain at Earnin and identify opportunities for process automation
Take ownership of debt facility analytics and other core finance areas as needed
Build data functional expertise and own data quality for allocated areas of ownership. 
Create quality controls on data feed to ensure high quality data delivered for end product
Design, build and launch new data extraction, transformation and loading processes in production as and when required
Implement data governance practices, including data security, privacy, and compliance measures
Deep analysis to uncover areas of opportunity and present recommendations that will help shape the strategy and operations of business stakeholders
Create project related documentation for requirements, design, processing methodologies and changes planned and other relevant areas
Provide analytical support for financial needs such as annual audits, new product revenue reporting and external lender inquiries.
Be a data and functional expert at Earnin (10%)
Stay up to date with industry trends and emerging technologies in the field of business intelligence and data analytics.
Be a data SME related to finance domain
Identify and recommend BI and data tools that can be used within the company for increased productivity and scalability
Requirements:
Master degree in Compute Science, Engineering or Analytics related fields
2+ years of relevant work experience in Analytics, Business Intelligence, Data Science etc
3+ years experience in custom ETL design, implementation and maintenance.
2+ years experience with schema design and dimensional data modeling.
2+ years experience in writing complex SQL queries and Python 
2+ years experience working with Snowflake / Databricks or similar distributed compute systems
3+ experience with business intelligence tools such as Tableau, Power BI, or QlikView.
2+ years of working with relational databases (Redshift, PostgreSQL) and big data structures
1+ Experience with any cloud platform (Ex: AWS) and big data technology (Ex: Spark)
2+ years of experience in collaborating with cross-functional teams
Ability to analyze data to identify deliverables, gaps and inconsistencies
Strong problem-solving and analytical skills",USD 127K - 190K *
549,Senior Software Engineer - Data Engineering (Java/Spark) - REF8499G,Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
About the role:
As part of the Data engineering team, the candidate will be working within an agile team that iterates quickly on delivering new features for the Zscaler Digital Experience (ZDX) SaaS-based product. Candidate will contribute to the design and development of backend microservices to expand the solution offering to collect and analyze telemetry/health data and use this data to help detect performance problems with customer applications such as SaaS applications, UCaaS (Unified-Communication as a Service) apps, and Enterprise apps.
What you will do:
You will be responsible for product features related to data transformations, enrichment, and analytics
You will discuss with product managers, UX designers, and other backend teams to understand requirements and translate the same into functional specifications 
You will seize every opportunity to refactor code in the interests of maintainability and reusability
Lead and provide technical direction and mentorship to junior engineers and bring out the best in them
The ideal candidate has a proven track record of building large scale enterprise products, and is a creative thinker, problem solver, learner, and a fantastic manager of people, and is motivated with engineering excellence.
Requirements:
Education: BS Computer Science or Equivalent
Minimum 4+ years of software development experience
Experience in Core Java, Concurrency, and Distributed Computing
Experience in building high performance, scalable web services
Experience using batch and stream processing frameworks like Spark/Kafka Streaming, Spring batch or equivalent
Experience developing microservices and API's
Proficiency with Tomcat installation and configuration.
Proficiency with Maven (preferred) or Gradle builds and dependency management systems.
4+ years of experience writing unit test, stubs, mocks in a TDD environment using JUnit, REST Assured, or TestNG
Experience with CI & CD systems such as Jenkins or Bamboo
Metrics-driven development experience and experience using metrics systems like Grafana, Prometheus, etc
Desired skills:
Ability to write code that can perform efficiently in a big data setup
Experience with big-data technologies like Spark, Redshift, etc.
Strong knowledge of various DBMS systems including NoSQL architectures and design principles
Experience tuning JVM for optimal application performance
Successfully delivered software products from ideation through to implementation and support
Experience with any Graph Database like AWS Neptune, Neo4j, Spark Graphx, etc.
Understanding of statistics and machine learning.
#LI-SK3
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 121K - 188K *
550,Data Integration Engineer,Acoustic,"Pune, Maharashtra, India",Senior-level / Expert,"DemandTec team, part of Acoustic, is looking for a dynamic Data Integration Engineer
with end-to-end vision of what and how data would be processed and used by Merchandising applications hosted in SaaS environment. This candidate would work with a team of talented Engineers in delivering quality features using agile development methodology. Candidate should be proficient in ETL technologies with modern Big Data technologies to efficiently process ever increasing data volumes in near real-time to support merchandising apps and analytics. Ideal candidate would have performance and scalability front and center in design decisions and implementation. To succeed in this role, you need to be versatile, smart and have innate desire to build product features the right way. Finally you should be able to collaborate and communicate with major stakeholders - product manager, other application teams,
support and operations.
 Responsibilities:
·       Design and develop high performance data integration jobs using IBM DataStage and Java
·       Work with product managers to understand customer data requirements 
·       Understand impact of various types of Retailer data on Merchandising applications
·       Build SaaS based enterprise web applications using latest web technologies
·       Collaborate with QA team to ensure data integration enhancements meet functional and performance criteria
·       Work with Technical Services and Support to promptly address customer issues
·       Champion Agile development practices with frequent releases to Production
·       Conduct design & code reviews
Requirements
·       5+ yrs of experience designing ETL jobs to process large data volumes - preferably using IBM DataStage
·       2+ yrs of experience with database stored procedures and SQL Queries - preferably in DB2.
·       Strong analytical and problem solving skills
·       2+ yrs of experience in Java- and Web-based application development.
·       2+ yrs of Linux with strong scripting experience - such as Shell, Perl, Python or Ruby.
·       Ability to set priorities and undertake complex tasks with minimal supervision 
·       Good written and verbal communication skills 
·       SaaS and Cloud Experience a plus
 Education:
   Bachelor's degree in Computer Science or equivalent",USD 45K - 84K *
551,Senior Consultant Data Engineer – Cloud,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Ready to make a global impact by industrializing AI?
 Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS powers and automates industrialization of data, models, and applications for predictive and generative AI. Combined with strong governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!
 This role is for a Senior Consultant Data Engineer – Cloud, with a strong development background, whose primary objective will be to extend our AI as a Service platform to the Public Cloud while enhancing, optimizing our existing codebase and development procedures, as well as developing new solutions. We are seeking for an experienced professional with a solid background in public cloud and AI/ML production systems.
 The ideal candidate will have a strong mix of hands-on technical knowledge and leadership skills, with the ability to inspire and drive the team towards achieving our technical objectives They should be hands-on, knowledgeable about cloud technologies, business drivers, and emerging AI/ML trends, and experienced with public cloud services such as AWS, GCP and Azure. The role demands a proactive leader who can guide the team through uncertainty, educate stakeholders, and influence decisions as needed. The candidate should possess strong interpersonal skills, excellent written and verbal communication, and the ability to handle complex projects and deadlines. A problem-solving mindset and a hands-on approach are key to succeeding in this role.
 This role offers ample opportunities for learning and growth, and the chance to be part of delivering the next big thing for our AI as Services team. If you are experienced and passionate about cloud technology, AI, and machine learning, and are excited about making a significant impact, we would love to hear from you.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
10 years of relevant work experience with a bachelor’s degree or 8 years of relevant work experience with an advanced degree (e.g., Masters, MBA, JD, MD) or 3 years relevant work experience with a PhD.

Preferred Qualifications
5 or more years of related hands-on experience in delivering robust and scalable solutions on public cloud platforms such as AWS, Google Cloud Platform, and Microsoft Azure, preferably in an AI/ML production environment.
Expertise in one or more of Golang, Java, Rust and C/C++.
Proven hands-on experience in delivering robust and scalable solutions on public cloud platforms such as AWS, Google Cloud Platform, or Microsoft Azure.
Strong understanding of cloud architecture and service offerings including compute, storage, databases, networking, AI, and ML.
Experience in Cloud AI/ML Solutions such as - AWS Sagemaker, Comprehend, GCP AutoML etc.Expertise in AWS EKS, ElasticCache, CloudWatch
Strong cloud security and best practices for cloud infrastructure management.
Experience in Cloud Big Data Services.
Demonstrated expertise in designing, developing, and deploying cloud-based applications.
Proven knowledge of successful design, and development of data driven real time and batch systems.
Hands-on with Ray (on-prem, K8s, AWS, GCP or Azure)
Strong System Design / Software Design Skills
Well versed with common software development tools, CICD, Agile methodologies and scrum practices
Professional Cloud Provider Certifications in infrastructure , solutioning and AI/ML platforms shall be a plus.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
552,Staff Data Scientist,Course Hero,India - Remote,Senior-level / Expert,"Course Hero is hiring! The new Staff Data Scientist will be a key member of the Content Quality Prediction / Publishing Strategy and Antifraud team in India, owning and driving content performance prediction, fraud modeling and detection, and related data science initiatives. You will be working cross-functionally with Product, the rest of Analytics, TechOps, Engineering and Operations. The Data Science & Analytics team at Course Hero is central to our organization and heavily influences the strategy and tactics of our company’s roadmap.

We are full stack Data Scientists; problem solvers that start from DWH tables or raw data, explore data, build models, and productionalize into our common Data Eng and ML Ops framework.  You will also be telling the story behind your insights -- painting a picture to our functional partners, explaining what the numbers are telling us, and recommending new actions, including product changes and associated A/B tests. 

Here are some ways you’ll make an impact:
Using exploratory data analysis, unsupervised and supervised modeling, statistics, and related techniques to understand and predict the value of the entire range of user-generated and AI-generated content on Course Hero and associated domains - from documents like essays and notes, to conversational utterances like questions and study assistance inquiries.
Detecting the lowest value content too, which is often spam and/or fraud.
Build models that prescribe an optimal strategy of publishing content, given the above noted prediction scores.
Investigate other forms of malicious abuse of the platform including, payment fraud, and marketplace fraud.
Evaluate and AB test third-party vendor tools to help with fraud detection and mitigation.

Are you our Staff Data Scientist?
7+ years data science experience of continually increasing complexity and impact
BS & MS degree in an applicable quantitative field like Math, Statistics, Engineering, Economics, Physical or Social Science, or similar
Excellent proficiency in Python (or R) and hands-on skills in SQL
Deep understanding of statistics and probability, quantitative sciences, data analysis, predictive and ML modeling; excellent breadth of knowledge across DS domains including NLP
Strong problem-solving and communication skills; a bias towards taking action quickly, making things happen, learning and correcting course as you receive feedback
Ability to communicate with a broad set of stakeholders including executives, product leaders, and engineering, including the ability to tell stories with data
Track record of delivering decision support models and quantitative analysis with actionable insights and high business impacts
Detail-oriented, data-driven problem-solving skills with investigation instincts, uncovering root causes and hidden links from seemingly unrelated signals

Bonus Points:
Experience with user generated content (social media posts, user profiles, user comments, user posts on professional job boards, listing boards, etc.)
Understanding of knowledge graphs and network science
Understanding of pattern detection modeling techniques and/or biostats
Experience using third-party tools for fraud detection, investigation, and monitoring
Passion for evolving education to help students graduate

This role is based in India and is remote within India.  Candidates must commit to overlapping 1 hour with normal business hours of Pacific Standard time 2-3 times per week. 

Benefits & Perks!
Competitive salary
Equity/stock options
Annual performance bonus
Health insurance coverage (7 Lakhs for self and family)
Life Insurance 3X the CTC
Accidental Insurance 3X the CTC
Learning
Learning and Development Policy Reimbursement of Courses
Flexibility
Privilege Leave Paid Leaves
Casual Leaves
Mandatory Leaves
Special Leaves
Flexible Holiday
Reset Days
Menstrual Leaves
Maternity Leaves & Flexible Paternity Leave
Compassionate Leave
Marriage Leave
Work From Home
Workstation Setup Reimbursement
Internet Bill Reimbursement
Remote Friendly culture 
Fun
Annual Workations
#LI-Remote
Equal Employment Opportunity Statement (EEO)
We are an equal opportunity employer and value diversity and inclusion within our company.  We will consider all qualified applicants without regard to race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, or ability status. We will ensure that individuals who are differently abled are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment as provided to other applicants or employees. Please contact us to request accommodation.
  About Course Hero:
Course Hero is on a mission to help students graduate, confident and prepared. The online learning platform offers over 60 million course-specific study resources created by and for students and educators, as well as 24/7 tutor help. More than 65,000 verified college educators use Course Hero to collaborate with other faculty and share resources to hone new strategies for instruction. Everyday, students, educators and tutors help more than 20 million students make every study hour count.
Join us on our mission!",USD 31K - 58K *
553,Sr Data Engineer,S&P Global,IN - HYDERABAD SKYVIEW,Senior-level / Expert,"Job Role: Senior Data Engineer
Grade : Internal purpose only
What is in for you:
As a Data Engineer at S&P Global, you will utilize your extensive technical skills to architect, build, and maintain our evolving data infrastructure, which is essential for supporting our advanced analytics and machine learning initiatives. You will work closely with various stakeholders to acquire, process, and refine vast datasets, focusing on creating scalable and optimized data pipelines. Your work will be pivotal for enabling data scientists to extract meaningful insights and develop AI-driven solutions that serve various business purposes, from internal decision-making to product development.
Responsibilities:
 • To collaborate with stakeholders, including data scientists, analysts, and other engineers, to understand and refine requirements related to data processing and transformation needs.
 • To design, construct, install, and maintain large-scale processing systems and other infrastructure.
 • To build high-performance algorithms, prototypes, and conceptual models and enable the efficient retrieval and analysis of data.
• To implement ETL processes to acquire, validate, and process incoming data from diverse sources.
• To ensure data architecture and model adhere to compliance, privacy, and security standards.
• To work in conjunction with data scientists to optimize data science and machine learning algorithms and models.
• To provide technical expertise in the resolution of data-related issues, including data quality, data lineage, and data processing errors.
• To manage the deployment of analytics solutions into production and maintain them.
• To maintain high-quality processes and deliver projects in collaborative Agile team environments.
Requirements:
• 5 - 7+ years of programming experience particularly in Python, R, Java or C#.
• 3 - 4+ years of experience working with SQL or NoSQL databases.
• 1+ years of experience working with Pyspark.
• University degree in Computer Science, Engineering, Mathematics, or related disciplines.
• Strong understanding of big data technologies such as Hadoop, Spark, or Kafka.
• Demonstrated ability to design and implement end-to-end scalable and performant data pipelines.
• Experience with workflow management platforms like Airflow.
• Strong analytical and problem-solving skills.
• Ability to collaborate and communicate effectively with both technical and non-technical stakeholders. • Experience building solutions and working in the Agile working environment
• Experience working with git or other source control tools
Nice to have:
• Experience working with Oil, gas, and energy markets.
• Familiarity with BI Visualization applications (e.g. Tableau, Power BI).
• Understanding of cloud-based services, preferably AWS.
• Experience working with Unified analytics platforms like Databricks.
• Experience in managing and deploying containerized applications using Docker, Kubernetes, or similar technologies.
• Machine learning/Data Science experience
About S&P Global Platts
At S&P Global Platts, we provide the insights; you make better informed trading and business decisions with confidence. We’re the leading independent provider of information and benchmark prices for the commodities and energy markets. Customers in over 150 countries look to our expertise in news, pricing and analytics to deliver greater transparency and efficiency to markets. S&P Global Platts coverage includes oil and gas, power, petrochemicals, metals, agriculture and shipping.
S&P Global Platts is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.platts.com.
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 121K - 188K *
554,Senior Data Engineer - Cloud,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Ready to make a global impact by industrializing AI?
 Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS powers and automates industrialization of data, models, and applications for predictive and generative AI. Combined with strong governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!
 This role is for a Senior Data Engineer – Cloud, with a strong development background, whose primary objective will be to extend our AI as a Service platform to the Public Cloud while enhancing, optimizing our existing codebase and development procedures, as well as developing new solutions. We are seeking for a talented professional with a solid background in public cloud and AI/ML production systems.
 The ideal candidate for this role will have the ability to learn quickly and deliver solutions within strict deadlines in a fast-paced environment. They should have a passion for optimizing existing solutions and making incremental improvements. Strong interpersonal and effective communication skills, both written and verbal, are essential. Additionally, they should have knowledge of Agile methodologies, common scrum practices and tools.
 This role offers ample opportunities for learning and growth, and the chance to be part of delivering the next big thing for our AI as Services team. If you are passionate about cloud technology, AI, and machine learning, and are excited about making a significant impact, we would love to hear from you.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:
3 years of relevant work experience with a bachelor’s degree or 1 years of relevant work experience with an advanced degree (e.g., Masters, MBA, JD, MD, or PhD).

Preferred Qualifications:
Strong Python experience with development experience in one or more the following: Go, Rust, Java.
2 years of relevant experience with AWS, GCP, or Azure, preferably in an AI/ML production environment.
Hands-on experience with model inference engines such as TensorFlow Serving, Triton, or other AI accelerators.
Hands-on with Kubernetes/EKS and HashiCorp Nomad is considered a significant advantage.
Hands-on with Redis and Kafka.
Hands-on with Ray (on-prem, K8, AWS or GCP).
Familiarity in building large scale distributed, high performance systems in payments or other domains.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 188K *
555,Data Scientist,Target,"Tower 02, Manyata Embassy Business Park, Racenahali & Nagawara Villages. Outer Ring Rd, Bengaluru 540065",Entry-level / Junior,"Data Scientist - Target
About the role:
Target Data Sciences is offering an exciting opportunity to solve state of the art problems in retail. The opportunity will allow you to analyse large and varied data sets, build models on transactional, guest and media behaviour and write algorithms to improve guest (customer) and advertiser experience. In this role, you will have access to the best tech stack in retail along with working with a set of passionate co-workers committed to creating next gen MarTech capabilities. You can expect to be involved in:
Learning and working on different aspects of MarTech
Learning about the complex world of digital ad – tech and supporting Target’s advertising business by bringing state of art ad relevancy to life
Creating large and automated data pipelines and documenting methods and outputs
Exploring different approaches to solve a problem, testing the solutions, and reporting the results
Implementing large scale and automated models and create dashboard to capture relevant metrics and determine errors
Example problem statements:
Determine a set of optimal tactics to create media plan and manage inflight campaign performance?
Given digital ad variations how do we optimize ad impressions?
How do we set prices for digital product ad slots to achieve higher revenue?
How to systematically scale and automate such decisions impacting millions of guests?
Expected skills:
Data wrangling and pipelining skills using HiveQL, Python, Spark
Ability to write modular code and data pipelines which can be automated and scaled
Good programming skills in Python/ Scala/ Java
Logical Reasoning Skills
Indepth knowledge of Machine Learning
Ability to work with a team(s) to drive the work in a collaborative environment
Preferred Educational background:
Engineering graduates from reputed institutes with proficiency in coding and 1+ years of relevant experience
MTech or MS (Statistics, Economics, CS, Mathematics)
Preferred domain experience: in enabling data driven solutions in marketing, marketing campaign management, digital media, measuring RoI on customer marketing campaigns, customer personalisation, behavioural models.
Why work with us at Target?
We love open source
We own years of transactional, guest, financial, inventory, many other operational datasets
We offer top class growth and wellness structures
We believe in continuous learning (50 days of learning with a variety of proprietary platforms!)
Formal big box and online retailing industry is growing fast and poised to grow further",USD 58K - 132K *
556,Staff Machine Learning Engineer,Conga,"Bengaluru, India",Senior-level / Expert,"Company Description
A career that’s the whole package!
At Conga, we’ve built a community where our colleagues can thrive. Here you’ll find opportunities to innovate, support for growth through individual and team development, and an environment where all voices can be heard.
Conga crushes complexity within an increasingly complex world. With our revenue lifecycle management solution, we transform your unique complexities for order configuration, execution, fulfillment, and contract renewal processes with a single critical insights data model that adapts to ever-changing business requirements and aligns the understanding and efforts of every team.
Our mission: Empower customers to deliver transformational revenue growth by aligning teams, processes, and technology to maximize customer lifetime value.
Our approach is grounded in the Conga Way, a framework for what we stand for and everything we do as an organization — from hiring to decision making and product development. Developed with direct input from our colleagues, the Conga Way is the foundation for our culture.
Job Description
Job Title: Staff Machine Learning Engineer
Locations: Bangalore
Reports to: Director, Machine Learning
A quick snapshot…
A Machine Learning Engineer at Conga will produce a tailor-made solution for each problem. The only way to achieve optimal results is to carefully process the data and select the best algorithm for the given context. You’ll participate in building, designing, and optimizing Artificial Intelligence (AI) systems.
Why it’s a big deal…
The Machine Learning Engineer will play a vital role in the technology stack and will keep the system updated. The key role at Conga, would be to incorporate the customer’s legal contracts, and accomplishments of records by means of implementing, evaluating, and deploying strong commercial solutions. Your judgement to determine appropriate courses of action, within defined practices and procedures will be vital.
Are you the person we’re looking for?  
Related experience. At least 8+ years of experience in commercial text-based machine learning. Ability to understand complex problems, decompose them into a set of testable hypotheses, implement bug-free experiments, analyze the results, and produce insights, solutions, and next steps from the analysis. Your models are then used to automate processes like image classification, speech recognition, and market forecasting.
Algorithm and Data Visualization. You will work independently and collaborate in small teams. You will be excited to write great code, get close to the data, and create great ML models. You would be analyzing the ML algorithms that could be used to solve a given problem and ranking them by their probability of success. Exploring and visualizing data to understand it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
Skills & Experience. Proficiency with Python and basic libraries for machine learning:
Python 3.x, jupyter notebook, regular expressions.
Frameworks: PyTorch, spaCy, Kera’s Deep
Architectures: LSTM, CNN.
Other tool’s: My SQL, SQL queries, ubuntu, GitHub, AWS S3 and EC2, boto. 
 Education: A bachelor’s degree in Engineering or equivalent
Here’s what will give you an edge…
Innovative Thinking. At Conga we are working on latest technologies, along with the rules of how we use data to target. You should want to take initiative to research new tactics and find new ways to improve campaign effectiveness.    
Developing professional. As a developing professional your expertise will be visible to all levels. You regularly rely on policies and procedures to resolve a variety of issues. You’ve worked on problems that required you to review a variety of factors to analyze a situation. You’ve built productive internal and external working relationships.
Did we pique your interest? 
 If this sounds like the kind of job you would love in the kind of environment where you would thrive, please click apply. We'd love to hear from you! 
 Don’t meet every requirement for the role?  
 Studies have shown that women and members of ethnic minorities are less likely to apply to jobs unless they meet every single qualification. At Conga we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You just might be the right candidate for this or other roles.
Additional Information
Conga is proud to be an Equal Opportunity Employer and provides equal employment opportunities to all employees and applicants regardless of race, color, religion, gender, gender identity, age, national origin, disability, parental or pregnancy status, marriage and civil partnership, sexual orientation, veteran status, or any other characteristic protected by law. Reasonable accommodations will be made to meet the requirements of the Americans with Disabilities Act and will be provided as requested by candidates taking part in all aspects of the selection process. All your information will be kept confidential according to EEO guidelines. Conga is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary.",USD 45K - 84K *
557,Sr Operations Research Engineer,Sabre Corporation,India - Bengaluru-Navigator Bldg,Senior-level / Expert,"Sabre is a technology company that powers the global travel industry. By leveraging next-generation technology, we create global technology solutions that take on the biggest opportunities and solve the most complex challenges in travel.
Positioned at the center of the travel, we shape the future by offering innovative advancements that pave the way for a more connected and seamless ecosystem as we power mobile apps, online travel sites, airline and hotel reservation networks, travel agent terminals, and scores of other solutions.
Simply put, we connect people with moments that matter.
SABRE Professional Services and Consulting is looking for a talented Senior Operation Research Engineer

Role and Responsibilities
Key member of the Sabre AVPS Calibration team to leverage statistical and business expertise to translate business questions into data analysis and models, define industry aligned KPIs, and present results to a wide range of audiences including customers, teams, sales, and product development teams.
Source data from multiple different data sources, write high-quality data manipulation scripts in deployed programming language (currently R), develop and apply data mining and machine learning algorithms for advanced analysis and prediction / forecasting.
Strong communication skills to work with customers to implement solutions, calibrated parameters and support business owners and decision makers.
Execute Analytical Consulting services & designing end-to-end analytics solution for effective process flow that help an airline customer in selecting the right models, optimize practices and business processes
Primary responsibilities
Work directly with customers and internal stakeholders to implement decision support solutions
Periodically re-calibrate model parameters based on most recent available datasets
Engage directly with customers to deliver calibrated model parameters, validate forecasted results and achieve contracted KPIs in the set timelines
Collaborate internally with product development teams to conduct rigorous testing and validating new features to be released for production
Actively participate in evaluating model enhancements, introduce new features & processes aimed at increased customer adoption of the solutions
 
Qualifications and Education Requirements
Master’s degree (Preferably M.Sc. (Quantitative Subjects), M.B.A., M.E., M.Tech.) with minimum 4-5 years of relevant experience (or)
Bachelor’s degree holders (Preferably B.E., B.Tech) with minimum 5-6 years of relevant experience.
 
Must Have Skills:
Ability to understand complex business requirements and define KPIs to measure benefits and communicate complex quantitative analysis in a clear, precise, and actionable manner
Solid programming skills (expertise in any statistical tools like SQL / SAS / R / Python / other tools)
Experience with applying complex business logics to extract and cleanse large datasets from different data sources (xml, txt, xls, sql, etc)
Skills in Microsoft Tools (Preferably Excel and Power point)
Excellent communication skills, strong problem solving and analytical skills
Excellent Customer Management Skills and Ability to handle multiple projects
Nice To Have Skills:
Ability to read articles and develop new statistical, optimization and ML algorithms to fit the business needs and building predictive models for real-world business cases
Ability to quickly learn and program new tools for multi-dimensional data-driven decision support
Work with cross functional team and good presentation skills
Experience working in cloud environment
Experience working in visualization tools Google Looker
Familiarity with Airline & Travel Domain
We will give careful consideration to your application and review your details against the position criteria. You will receive separate notification as your application progresses.
Please note that only candidates who meet the minimum criteria for the role will proceed in the selection process.",USD 150K - 240K *
558,Sr Data Engineer,Aryng,"Pune, Maharashtra, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a Senior Data Engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 188K *
559,Big Data Architect,NielsenIQ,"Chennai, India",Senior-level / Expert,"Job Description
REFID948632
Principal Architect, Chennai.

Our NielsenIQ Technology teams are working on our new Connect platform, a unified, global, open data ecosystem powered by Microsoft Azure. Our clients around the world rely on NielsenIQ’s data and insights to innovate and grow. As a Platorm Architect in the architecture group, you will help define the architecture designs for platform components of the NIQ platforms that are strategically aligned to business strategy and objectives. The Tech Lead architect will partner with their architect peers and Tech lead counterparts in the development teams to take the architecture designs all the way to delivery.  This role will grow into an end-to-end platform architect as the candidate gains more knowledge of NIQ’s platform. 

Responsibilities: 
Help with architecture designs for key products on the NIQ platforms.
Drive assessments of new technologies that could be viable alternatives to existing platform selections to support front end applications, platform services and components along with the data pipelines and databases. 
Help identify future solutions and drive innovations through PoCs, technology migration planning to get to production 
Produce high level approaches for platform components as needed to help component architects use as a blueprint for their low level designs.  Many of these approaches will require an E2E understanding of the platform to ensure that they seamlessly fit in with future product and technology vision kept in focus. 
Create, maintain and promote reference architectures for the key areas of the platform.  Architecture guidelines and standards to be documented and communicated to technology and product teams.  
Responsible for innovating, evaluating, and promoting best architectural solutions for the NIQ platform. 
Qualifications
Bachelors in computer science or similar required
Master’s degree in computer science or a related field preferred  
15+ years, including strong Engineering background with Architecture / design experience for 5+ years.  
Hands-on experience in building scalable enterprise platforms  
Languages used extensively on the platform are AngularJS, Java, Spark, Scala, Python, C++ with datastores being Postgres, MongoDB, ElasticSearch, Snowflake.  Knowledge of Spring, OpenAPI, OpenTracing are a plus. 
Good knowledge of Azure Cloud technologies with solid skills working with Azure Databricks, Azure Data Factory and Azure cloud storage (ADLS/Azure Blob) is a must.  Work experience with Snowflake is a definite plus. 
Good knowledge of Containers / Kubernetes, CI/CD 
Understanding of BI tools and Analytics features is a plus 
Advanced knowledge of data structures, algorithms and designing for performance, scalability and availability  
Experience in agile software development practices 
Additional Information
Enjoy a flexible and rewarding work environment with peer-to-peer recognition platforms. 
Recharge and revitalize with help of wellness plans made for you and your family. 
Plan your future with financial wellness tools. 
Stay relevant and upskill yourself with career development opportunities.
About NIQ
NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™.
NIQ, is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population. For more information, visit NIQ.com.
Want to keep up with our latest updates?
Follow us on: LinkedIn | Instagram | Twitter | Facebook
   Our commitment to Diversity, Equity, and Inclusion
NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.
We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.
Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/
NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.",USD 45K - 84K *
560,Staff Data Engineer - Cloud,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Ready to make a global impact by industrializing AI?
 Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS powers and automates industrialization of data, models, and applications for predictive and generative AI. Combined with strong governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!
 This role is for a Staff Data Engineer – Cloud, with a strong development background, whose primary objective will be to extend our AI as a Service platform to the Public Cloud while enhancing, optimizing our existing codebase and development procedures, as well as developing new solutions. We are seeking for an experienced professional with a solid background in public cloud and AI/ML production systems.
 The ideal candidate for this role will have the ability to learn quickly and deliver solutions within strict deadlines in a fast-paced environment. They should have a passion for optimizing existing solutions and making incremental improvements. Strong interpersonal and effective communication skills, both written and verbal, are essential. Additionally, they should have knowledge of Agile methodologies, common scrum practices and tools. The candidate should also be capable of coaching and mentoring other team members, fostering a collaborative and supportive environment.
 This role offers ample opportunities for learning and growth, and the chance to be part of delivering the next big thing for our AI as Services team. If you are experienced and passionate about cloud technology, AI, and machine learning, and are excited about making a significant impact, we would love to hear from you.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
7 years of relevant work experience with a bachelor's degree or 4 years of relevant work experience with an advanced degree (e.g., Masters, MBA, MD) or 2 years of relevant work experience with a PhD

Preferred Qualifications
Strong experience with AWS, GCP, or Azure, preferably in an AI/ML production environment, with a deep understanding of cloud architecture and service offerings.
Development experience in one or more of the following: Golang, Java, Python, Rust, and/or C/C++
Demonstrated expertise in designing, developing, and deploying cloud-based applications or experience in cloud services such as compute, storage, databases, networking, AI and machine learning.
Knowledge of successful design, and development of data driven real time and batch systems.
Experience with model inference engines such as TensorFlow Serving, Triton, or other AI accelerators.
Hands-on with Kubernetes/EKS and HashiCorp Nomad is a significant advantage.
Hands-on with Redis, Kafka, and Ray (on-prem, K8, AWS or GCP)
Strong understanding of cloud architecture and service offerings including compute, storage, databases, networking, AI, and ML.
Strong cloud security and best practices for cloud infrastructure management.
Hands-on with Ray (on-prem, K8s, AWS, GCP or Azure)
Well versed with common software development tools, CICD, Agile methodologies and scrum practices
Experience in building large scale distributed high performance systems in payments or other domains
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 188K *
561,Data Engineer,Mimecast,IND - Bengaluru,Senior-level / Expert,"Who We Are:
The Corporate Data Management (CDM) team develops and maintains the corporate data and AI platforms at Mimecast. Our mission is to enable new value and intelligence to be easily extracted from Mimecast’s business system data. We’re looking for an experienced Data Engineer to help drive the design, implementation and availability of our AWS data lake and cloud-based data warehouse. The ideal candidate must have significant hands-on experience creating reliable, scalable and maintainable data platforms in AWS and Snowflake.
Key Responsibilities
Leading the design, development, and maintenance of complex data pipelines and data processes.
Architecting scalable and high-performance data systems and infrastructure.
Collaborating with stakeholders to define data strategies and requirements.
Providing technical expertise and guidance to the data engineering team.
Evaluating and implementing new technologies and tools for data processing and storage.
Designing and implementing data governance frameworks and policies.
Mentoring and coaching junior data engineers.
Conducting code reviews and ensuring adherence to best practices.
Performance tuning and optimization of data processing and storage systems.
Participating in data architecture and system design discussions.
Essential Skills and Experience
Detailed experienced in AWS data lake and warehouse tools
Expert knowledge and experience of AWS data services like AWS S3 and Glue
Expert knowledge and experience of various foundational AWS services like IAM, Trusted Advisor, CloudWatch, Lake Formation
High competency in Python, Java or similar JVM language
Experience working with DBT and SnowFlake
Experience and great understanding of modern scalable data processing and storage technologies.
Expert knowledge of containers (Docker), CI/CD tools including Cloud Formation
DEI Statement
Cybersecurity is a community effort. That’s why we’re committed to building an inclusive, diverse community that celebrates and welcomes everyone – unless they’re a cybercriminal, of course.
We’re proud to be an Equal Opportunity and Affirmative Action Employer, and we’d encourage you to join us whatever your background. We particularly welcome applicants from traditionally underrepresented groups.
We consider everyone equally: your race, age, religion, sexual orientation, gender identity, ability, marital status, nationality, or any other protected characteristic won’t affect your application.
Due to certain obligations to our customers, an offer of employment will be subject to your successful completion of applicable background checks, conducted in accordance with local law.",USD 121K - 188K *
562,Senior Manager - Data Science,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Position Summary
We are seeking an innovative and analytical thinker to support our Data Science team in the Middle East and North Africa (MENA) region based in Bangalore, India. As Senior Data Scientist, you are expected to participate in business development, develop predictive and prescriptive models, context-based prototypes, and high impact storyboards to promote a data-driven strategy and solutions approach for the company.

Principal Responsibilities
Serve as an analytics expert in designing, developing and implementing best in analytic solutions.
Experience and expertise in advance analytics in credit and fraud risk areas preferred
Create and deliver powerful insights from data through better visualization and storyboarding
Collaborate with internal and external partners to fully understand business requirements and desired business outcomes
Demonstrate execution proficiency in handing multiple medium-to-large analytics projects in a teaming environment that includes the rest of the Data Science team
Draft detailed scope for assigned projects, addressing suggested methodology and analytics plan
Execute on the analytics plan with appropriate data mining and analytical techniques
Perform quality assurance of data and deliverables for work performed by other Data Scientists and self
Ensure all project documentation is up to date and all projects are reviewed per analytics plan
Ensure project delivery within timelines and budget requirements
Build on team’s analytical skills and business knowledge
Enhance existing analytics techniques by promoting new methodologies and best practices in the Data Science field
Provide subject matter expertise and quality assurance of complex data-driven analytic projects
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Professional Experience
• Minimum of 8 plus years of analytics expertise in applying statistical solutions to business problems
• Well rounded experience across risk and portfolio analytics
• Experience working with Card Payments industry and credit bureau
• Post-graduate degree (Masters or PhD) in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Good knowledge of data, market intelligence, business intelligence, and AI-driven tools and technologies
• Experience planning, organizing, and managing multiple large projects with diverse cross-functional teams
• Demonstrated ability to incorporate new techniques to solve business problems
• Demonstrated resource planning and delivery skills

Technical Expertise
• Experience in distributed computing environments and big data platforms (Hadoop, Elasticsearch, etc.) as well as common database systems and value stores (SQL, Hive, HBase, etc.)
• Ability to write scratch MapReduce jobs and fluency with Spark frameworks
• Familiarity with both common computing environments (e.g. Linux, Shell Scripting) and commonly-used IDE’s (Jupyter Notebooks) proficiency in SAS technologies and techniques
• Strong programming ability in different programming languages such as Python, R, Scala, Java, Matand SQL
• Proficient in some or all of the following techniques Linear and Logistic Regression, Decision Trees, Random Forests, K-Nearest Neighbors, Markov Chain, Monte Carlo, Gibbs Sampling, Evolutionary Algorithms (e.g. Genetic Algorithms, Genetic Programming), Support Vector Machines, Neural Networks, etc.
• Expert knowledge of advanced data mining and statistical modeling techniques, including Predictive modeling (e.g., binomial and multinomial regression, ANOVA) Classification techniques (e.g., Clustering, Principal Component Analysis, factor analysis) Decision Tree techniques (e.g., CART, CHAID)
• Deliver results within committed scope, timeline and budget
• Very strong people and project management skills and experience
• Ability to travel within MENA on short notice
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
563,"Sr Director, Data Science",Gartner,Gurgaon - Cyber Park,Senior-level / Expert,"About the role:
This is a unique opportunity to join our fast-growing Data Science team. In the role of Sr. Director, Data Science you will be responsible for building & leading a Data Science team who creates and operationalizes Machine Learning models and automated tools that use internal and external data to identify and capture opportunities to improve client retention. We are looking for a great structured thinker & creative problem solver who can design and deliver solutions that meet stakeholder needs while powering through many constraints and dependencies. A senior leader who is aware of the larger data science landscape, who leans in and partners across multiple stakeholders to build alliances and deliver valuable and usable tools and insights.
What you will do: 
Work closely with executive business leaders across Research, Product, and other organizations to influence their priorities while translating data science implications to technical teams
Create a strategy and overall vision for where and how data science can further develop scaled insights that increase client value and retention through improved Research and Products. A few potential projects or domains you may get involved with:
Lead teams in: developing models to identify the highest value assets (including research content, analyst interactions with clients, and product functionality like the client-facing platform, peer, and tools) or applying Natural Language Processing (NLP) to sense client demand based on various data sources including search, readership, recoded interactions with Gartner experts, and associates.
Deliver advanced analytics that surface insights about Gartner Research and Products to increase the impact on retention, improve the client experience, and boost economic productivity
Lead Data Science team operations, engineers and product managers to develop analytics and ML pipelines to support scalable analysis and internal tools
Partner closely with senior leaders in Global Product Management (Customer & Market Research), Primary Research, Secondary Research, and analytics teams to deliver insights about client demand, the impact of Gartner insights, and the consumability of Gartner content
Foster a culture with a platform mindset that builds reusable data sources and globally applicable models using consistent approaches.
Be a champion for quality in all that we do; promote best-in-class quantitative methods and process documentation
Inject the most applicable technology, including Machine Learning, Artificial Intelligence, Generative AI, Natural Language Processing, and Statistical Modelling
Manage data science process efficiency, consistency, and quality. For example, coding standards, code reviews, peer reviews, ensuring code reusability, providing technical feedback, ensuring solutions are documented
Immediately build and lead a team of six new-hire data scientists
What you will need:
Degree (advanced degree preferred) in a quantitative research field (e.g., Math, Operations Research, Physical Science, Computer Science, Economics or Engineering, etc.)
12+ years of relevant experience in data science
Experience hiring, building, and managing a team of data scientists.
Well-versed in a wide range of analytical techniques such as advanced statistics, machine learning, and natural language processing
Practical, intuitive problem-solver with a demonstrated ability to translate business objectives into actionable data science tasks and translate quantitative analysis into actionable business strategies
Connections to the external ML/Data Science community and knowledge in emerging technologies
Experience and proficiency with various programming languages (Python), machine learning models, statistical packages, SQL/relational databases, cloud computing (Azure), and distributed processing (Databricks)
Desire and ability to develop and coach data scientists
Superior verbal and written communication skills
Experience influencing senior executives and working through formal and informal networks to achieve cross-functional outcomes
Demonstrated ability to conceive and propose innovative solutions to complex business problems
Demonstrated ability to develop roadmaps, lead team execution, validate models, and successfully deliver solutions
#LI-PM3
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:83968
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 45K - 84K *
564,GRR Data Engineering Analyst,Citi,NIRLON KNOWLEDGE PARK GOREGAON (EAST) MUMBAI,Entry-level / Junior,"Global Risk Review (GRR) provides independent, objective, reliable, valued, and timely assurance to the Board of Directors and Committees of Citigroup and Citibank, NA, to the Citigroup Chief Risk Officer, the Citigroup Chief Credit Officer, senior management, and regulators as to the effectiveness of credit, capital and collateral risk management and the ability of the Business and Independent Risk Management to identify, monitor, mitigate and control current and emerging risks.
Within GRR is GRR Analytics team, which is responsible for developing a structured framework and strategy to support and complement Credit Review activities through analytical insights. The primary objective of this framework and execution strategy is to enhance the efficiency and effectiveness of various credit review processes using both standardized and customized analytics.
Position Objective:
The GRR Data Engineering Analyst supports the execution and delivery of the above mandate in close coordination with the Review teams. The GRR Data Engineering Senior Analyst extracts data from golden sources and provides processed data for analytical dashboards, which will be used by regional or global GRR review teams.
Development Value:
Developmental opportunities include experience in a high visibility, dynamic function, exposure to both Consumer and Wholesale businesses, enhanced business contacts, interaction with senior leadership and significant exposure to a global mix of credit and market portfolios.
Key Responsibilities:
Support the overall framework and execution strategies to support and/or complement review activities and enhance remote review capabilities.
Support the data extraction and quality control for raw data feeds and establish data analysis procedures to support various review activities.
Support generation of standardized metrics and reports – analytical dashboards, Portfolio Tables (P-Tables), Portfolio Quality Assessment Tool (PQAT), etc.
Perform data harvesting and ingestion strategies to support a library of standard and adhoc analytical reports.
Participate as required in the validation of Corrective Action Plans (CAP), including the development of ad hoc analysis to verify sustainable resolution of Issues.
Participate in analytical projects and/or reviews as needed by GRR senior management.
Other items as required to execute efficient and effective data engineering deliverables.
Knowledge/Experience:
5+ years of experience in various data repository structures, data extraction methods, data harvesting and discovery.
5+ years of experience in analytical/statistical tools – SAS, SQL.
3+ years of development/maintenance experience with Tableau.
Experience in financial services.
Experience with different retail & wholesale lending products and different geographies will be a plus.
Skills/Competencies:
Energetic, flexible, proactive, and responsive team player with the interest to learn, take initiative and work in a fast-paced environment.
Excellent written and verbal communication skills with the ability to interact with all levels of management and to external audiences.
Detailed-oriented, high level of intellectual curiosity and strong sense of ownership.
Strong interpersonal skills with the ability to build relationships and exert influence without direct authority.
Intermediate to advanced proficiency in Microsoft Office (Excel, Power Point, SharePoint, Access, Word, Visio, etc.)
Qualifications:
Master’s in software engineering, Data engineering, Computer Science, or other data management and data visualization disciplines
Bachelor of Science (BS) degree in above disciplines with 5+ years of experience will be considered (in lieu of Master’s with 3+ years of experience)
-------------------------------------------------
Job Family Group:
Risk Management
-------------------------------------------------
Job Family:
Credit Review Risk Management
------------------------------------------------------
Time Type:
Full time
------------------------------------------------------
Citi is an equal opportunity and affirmative action employer.
Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.
View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.
View the EEO Policy Statement.
View the Pay Transparency Posting",USD 60K - 125K *
565,Databricks Developer,Labcorp,Bengaluru India,Mid-level / Intermediate,"Databricks Developer
The Databricks Developer will be responsible to implement and maintain solutions in AWS Databricks platform.  You will be responsible for coordinating data requests from the various teams, reviewing and approving efficient approaches to ingest, extract, transform and maintaining data in multi-hop model.  In addition, you’ll work with team members to mentor other developers to grow their knowledge and expertise.  You’ll be working in a fast-paced and high-volume processing environment, where quality and attention to detail are vital.
PRIMARY RESPONSIBILITIES
Design and develop high performance and secured Databricks solutions using Python, Spark, PySpark, Delta tables, UDP and Kafka
Create high-quality technical documents including, data mapping, data processes, and operational support guides
Translate business requirements into data model design and technical solutions
Develop data ingest pipelines using Python, Spark & PySpark to support near real-time and batch ingestion processes
Maintain data lake and pipeline processes which includes troubleshooting issues, performance tuning and making data quality improvements
Work closely with technical leaders, product managers, and reporting team to gather functional and system requirements
Work in fast pace environment and perform effectively in an agile development environment
KNOWLEDGE AND SKILL REQUIREMENTS
Bachelor’s degree in Computer Science or Information Systems or equivalent degree
Must have 4+ years of experience in developing applications using Python, Spark, PySpark, Java, Junit, Maven and its eco-system
Must have 4+ years of hands-on experience in AWS Databricks and related technologies like MapReduce, Spark, Hive, Parquet and AVRO
Good experience in end-to-end implementation of DW BI projects, especially in data warehouse and data mart developments
Extensive hands on RDD, Data frame and Dataset operations of Spark 3.x
Experience with design and implementation of ETL/ELT framework for complex warehouses/marts.
Knowledge of large data sets and experience with performance tuning and troubleshooting
Plus to have AWS Cloud Analytics experience in Lambda, Athena, S3, EMR, Redshift, Redshift spectrum
Must have RDBMS: Microsoft SQL Server, Oracle, MySQL
Familiarity with Linux OS
Understanding of Data architecture, replication, and administration
Experience in working with real-time data ingestion with any streaming tool
Strong debugging skills to troubleshoot production issues
Comfortable working in a team environment
Hands on experience with Shell Scripting, Java, and SQL
Ability to identify problems, and effectively communicate solutions to peers and management
Labcorp is proud to be an Equal Opportunity Employer:
As an EOE/AA employer, Labcorp strives for diversity and inclusion in the workforce and does not tolerate harassment or discrimination of any kind. We make employment decisions based on the needs of our business and the qualifications of the individual and do not discriminate based upon race, religion, color, national origin, gender (including pregnancy or other medical conditions/needs), family or parental status, marital, civil union or domestic partnership status, sexual orientation, gender identity, gender expression, personal appearance, age, veteran status, disability, genetic information, or any other legally protected characteristic. We encourage all to apply.
For more information about how we collect and store your personal data, please see our Privacy Statement. ",USD 30K - 56K *
566,Senior Generative AI Solutions Architect - Retail,NVIDIA,"India, Bengaluru",Senior-level / Expert,"At NVIDIA, our passion is working with the world's most challenging problems in LLM, Generative AI, RAGs, Computer Vision, and Accelerated Analytics using our innovative platforms. We need a passionate, hard-working, and creative individual to help us pursue major opportunities in the Retail Industry. A Senior Solution Architect brings focus and technical expertise about NVIDIA technological advances to our partners and customers. 
 
What You’ll Be Doing:
You will be part of our India Solution Architecture Team working with key Fortune 100 customers & Indian retail customers to drive NVIDIA technology adoption and secure innovative design wins in both Data Center, Edge and Cloud Deployments. 
Develop and demonstrate solutions to customers based on NVIDIA’s LLM, RAG application frameworks, LLM optimization and scaled deployment frameworks, Spark RAPIDS platform 
Perform in-depth analysis of customer SPARK workloads to ensure optimized performance on GPU architectures. 
Work closely with customers to build innovative blueprints for key Retail Industry use-cases such as LLM & RAG-based search, personalization, forecasting, supply chain optimization, recommendation, scaled deployments, and cybersecurity. 
Partner with NVIDIA Engineering, Product, and Sales teams to secure design wins for customers and growth of NVIDIA product features through customer feedback. 
What we need to see 
BTech/MS in Computer Science or equivalent experience.
Excellent in-depth hands-on understanding of NLP, LLM, Generative AI , and RAG workflows 
8+ years’ experience as a Data Scientist with a proven track record in writing code in Python, PyTorch/ TensorFlow. C++ experience is a bonus  
Ability to communicate your ideas/code clearly through GitHub, documentation, and presentations. 
Enjoy collaborating with teams across the organization such as Engineering/Research, Sales, Product, and Marketing 
Effective verbal/written communication, and technical presentation skills 
Self-starter with a passion for growth, enthusiasm for continuous learning and sharing findings across the team 
Ways to stand out from the crowd 
External customer-facing skill set and background. 
Development experience with NVIDIA software platforms, libraries, and GPUs 
Experience working in commercial SPARK Platforms - Apache Spark, Databricks, Dataproc 
Knowledge of MLOps technologies such as Docker/containers, Kubernetes, data center deployments etc 
We make extensive use of conferencing tools, but occasional travel is required for local on-site visits to customers and data science conferences.
With highly competitive salaries, a comprehensive benefits package, and an excellent engineering work culture, NVIDIA is widely considered to be one of the technology industry's most desirable employers. NVIDIA is committed to fostering a diverse work environment and is proud to be an equal-opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) based on race, religion, colour, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",USD 45K - 84K *
567,Senior Manager Big Data Administration,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
Epsilon is a leading provider of multi-channel marketing services, technologies and database solutions. Epsilon is seeking a Sr Manager of Big Data Administration  with a balance of managerial and technical skills to work out of our Bengaluru, India location and oversee a team of Big Data Administrators and Data Warehouse and implementing and supporting solutions running on premise or cloud for Database Marketing clients.
Duties and Responsibilities:
Manage, mentor and coach a team of up to 10 Database and Big Data and Administrators
Working exposure handling sizeable volume (in Gb’s) of data
Perform hands-on Big Data Administration on several client engagements.
Participate in gathering requirements and contribute to the architecture design of Big Data client solutions for Marketing and Analytics
Be proficient in cluster administration tasks including patching, upgrades, backup and recovery, troubleshooting, performance diagnostics and tuning, and SQL optimization.
Hands-on experience monitoring and reporting on Hadoop resource utilization and troubleshooting.
Hands-on experience supporting code deployments (Spark, Hive, kafka etc.) into the Hadoop cluster.
Experience in administration of Hadoop Big Data tools --experience working on batch processing and tools in the Hadoop technical stack (e.g., MapReduce, Yarn, Hive, presto, HDFS, Oozie)
Knowledge on MPP/DW appliance database like Greenplum, Teradata etc
Possess knowledge in replication to Disaster Recovery site, data encryption, backup storage and archiving procedures.
Work with client teams in the support of development and deployment of Big Data and database jobs
Work closely with IT, developers and competency teams to ensure that applications availability and performance are within agreed on service levels.
Contribute to structures design, capacity and cluster expansion planning.
Research and recommend automated approaches to Big Data and DW solution administration.
Enforce standards and best practices for availability, security, backup and recovery.
Contribute to developing and documenting Big Data and DW standards, guidelines and operational procedures.
Evaluate Big Data and DW technologies and Cloud Services and recommend to technical management.
Perform a variety of tasks relying on experience and judgment to manage time, plan and accomplish goals on several projects.
Manage on-call rotation for 24 x 7 x 365 support.
 Qualifications
10+ years of general technology experience (preferably database administration)
At least 3+ years of experience managing Data Warehousing solutions on Netezza, Teradata, Greenplum, Vertica or similar.
4+ experience managing technical teams.
Cloud Data Warehouse database technologies AWS Redshift is must and Snowflake is a plus
Knowledge of Hadoop and or Big Data cloud services such AWS EMR or Cloudera
Ability to diagnose problems and resolve issues across various tiers (application, database, network)
Strong UNIX/Linux knowledge and understanding of DW MPP architecture, technologies and concepts.
Adherence to SDLC, Change Management, troubleshooting and development methodologies.
Strong leadership and inter-personal skills to manage and mentor direct reports.
Superb analytical and problem-solving skills
Excellent written and verbal communication skills
Education/Certification
B.S. in Computer Science or related discipline or equivalent work experience required. Hadoop and/or AWS certification is a plus.
 ",USD 45K - 84K *
568,Data Engineer,S&P Global,IN - HYDERABAD SKYVIEW,Senior-level / Expert,"Role : Data Engineer
Location : Hyderabad
What is in for you: As a Data Engineer at S&P Global, you will utilize your extensive technical skills to architect, build, and maintain our evolving data infrastructure, which is essential for supporting our advanced analytics and machine learning initiatives. You will work closely with various stakeholders to acquire, process, and refine vast datasets, focusing on creating scalable and optimized data pipelines. Your work will be pivotal for enabling data scientists to extract meaningful insights and develop AI-driven solutions that serve various business purposes, from internal decision-making to product development.
Responsibilities:
 • To collaborate with stakeholders, including data scientists, analysts, and other engineers, to understand and refine requirements related to data processing and transformation needs.
 • To design, construct, install, and maintain large-scale processing systems and other infrastructure.
 • To build high-performance algorithms, prototypes, and conceptual models and enable the efficient retrieval and analysis of data.
• To implement ETL processes to acquire, validate, and process incoming data from diverse sources.
• To ensure data architecture and model adhere to compliance, privacy, and security standards.
• To work in conjunction with data scientists to optimize data science and machine learning algorithms and models.
• To provide technical expertise in the resolution of data-related issues, including data quality, data lineage, and data processing errors.
• To manage the deployment of analytics solutions into production and maintain them.
• To maintain high-quality processes and deliver projects in collaborative Agile team environments.
Requirements:
• 3-6+ years of programming experience particularly in Python, R, Java or C#.
• 2+ years of experience working with SQL or NoSQL databases.
• Experience working with Pyspark.
• University degree in Computer Science, Engineering, Mathematics, or related disciplines.
• Strong understanding of big data technologies such as Hadoop, Spark, or Kafka.
• Demonstrated ability to design and implement end-to-end scalable and performant data pipelines.
• Experience with workflow management platforms like Airflow.
• Strong analytical and problem-solving skills.
• Ability to collaborate and communicate effectively with both technical and non-technical stakeholders. • Experience building solutions and working in the Agile working environment
• Experience working with git or other source control tools
Nice to have:
• Experience working with Oil, gas, and energy markets.
• Familiarity with BI Visualization applications (e.g. Tableau, Power BI).
• Understanding of cloud-based services, preferably AWS.
• Experience working with Unified analytics platforms like Databricks.
• Experience in managing and deploying containerized applications using Docker, Kubernetes, or similar technologies.
• Machine learning/Data Science experience
About S&P Global Platts
At S&P Global Platts, we provide the insights; you make better informed trading and business decisions with confidence. We’re the leading independent provider of information and benchmark prices for the commodities and energy markets. Customers in over 150 countries look to our expertise in news, pricing and analytics to deliver greater transparency and efficiency to markets. S&P Global Platts coverage includes oil and gas, power, petrochemicals, metals, agriculture and shipping.
S&P Global Platts is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.platts.com.
S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.   
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 121K - 188K *
569,Manager - Data Science,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Position Summary
We are seeking an innovative and analytical thinker to support our Data Science team in the Middle East and North Africa (MENA) region based in Bangalore, India. As a Data Scientist, you are expected to generate data and business insights, develop predictive and prescriptive models, context-based prototypes, and high impact storyboards to promote a data-driven strategy and solutions approach for the company.

Principal Responsibilities
Serve as an analytics expert in designing, developing and implementing best in analytic solutions
Create and deliver powerful insights from data through better visualization and storyboarding
Collaborate with internal and external partners to fully understand business requirements and desired business outcomes
Demonstrate execution proficiency in handing multiple medium-to-large analytics projects in a team environment that includes the rest of the Data Science team
Draft detailed scope for assigned projects, addressing suggested methodology and analytics plan
Execute on the analytics plan with appropriate data mining and analytical techniques
Perform quality assurance of data and deliverables for work performed by other Data Scientists and self
Ensure all project documentation is up to date and all projects are reviewed per analytics plan
Ensure project delivery within timelines and budget requirements
Build on team’s analytical skills and business knowledge
Enhance existing analytics techniques by promoting new methodologies and best practices in the Data Science field
Provide subject matter expertise and quality assurance of complex data-driven analytic projects
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Professional Experience
• Minimum of 5-7 years of analytics expertise in applying statistical solutions to business problems
• Experience working in one or more of the Card Payments markets around the globe
• Post-graduate degree (Masters or PhD) in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Good knowledge of data, market intelligence, business intelligence, and AI-driven tools and technologies
• Experience planning, organizing, and managing multiple large projects with diverse cross-functional teams
• Demonstrated ability to incorporate new techniques to solve business problems
• Demonstrated resource planning and delivery skills

Technical Expertise
• Experience in distributed computing environments big data platforms (Hadoop, Elasticsearch, etc.) as well as common database systems and value stores (SQL, Hive, HBase, etc.)
• Ability to write scratch MapReduce jobs and fluency with Spark frameworks
• Familiarity with both common computing environments (e.g. Linux, Shell Scripting) and commonly-used IDEs (Jupyter Notebooks) proficiency in SAS technologies and techniques
• Strong programming ability in different programming languages such as Python, R, Scala, Java, Matlab, C, and SQL
• Experience in drafting solution architecture frameworks that rely on APIs and micro-services
• Familiarity with common data modeling approaches, and ability to work with various datatypes including JSON, XML, etc.
• Ability to build data pipelines (e.g. ETL, data preparation, data aggregation and analysis) using tools such as NiFi, Sqoop, Ab Initio familiarity with data lineage processes and schema management tools such as Avro
• Proficient in some or all of the following techniques: Linear and Logistic Regression, Decision Trees, Random Forests, K-Nearest Neighbors, Markov Chain, Monte Carlo, Gibbs Sampling, Evolutionary Algorithms (e.g. Genetic Algorithms, Genetic Programming), Support Vector Machines, Neural Networks, etc.
• Expert knowledge of advanced data mining and statistical modeling techniques, including Predictive modeling (e.g., binomial and multinomial regression, ANOVA) Classification techniques (e.g., Clustering, Principal Component Analysis, factor analysis) Decision Tree techniques (e.g., CART, CHAID)
• Deliver results within committed scope, timeline and budget
• Very strong people and project management skills and experience
• Ability to travel within MENA on short notice

Business Experience
• Results-oriented with strong problem-solving skills and demonstrated intellectual and analytical rigor
• Good business acumen with a track record in solving business problems through data-driven quantitative methodologies.
• Experience in payment, retail banking, or retail merchant industries is preferred
• Very detailed oriented, is expected to ensure highest level of quality and rigor in reports and data analysis
• Proven skills in translating analytics output to actionable recommendations and delivery
• Experience in presenting ideas and analysis to stakeholders whilst tailoring data-driven results to various audience levels
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 30K - 56K *
570,"Director, Data Engineering",Publicis Groupe,"India, India",Executive-level / Director,"Company Description
We at Publicis Sapient, enable our clients to thrive in Next and to create business value through expert strategies, customer-centric experience design, and world-class product engineering. 
The future of business is disruptive, transformative and becoming digital to the core.
In our 20 + years in IT, never before have we seen such a dire need for transformation in every major industry - from financial services to automotive, consumer products, retail, energy, and travel.
To make this transformative journey a reality in these exciting times, we seek Rockstars who will:
brave it out to go do the next; “what will be” from “what is”
exhibit the optimism that says there is no limit to what we can achieve
deeply-skilled, bold, collaborative, flexible
Reimagine the way the world works to help businesses improve the daily lives of people and the world.
Our people thrive because of the belief that it is both our privilege and responsibility to usher our clients and the world into Next. 
Our work is fueled by
challenging boundaries,
multidisciplinary collaboration,
highly agile teams, and
the power of the newest technologies and platforms. 
If that’s you, come talk to us!
This is the world-class engineering team where you should build your career.
Job Description
As Director in Data Engineering, you are responsible for defining and executing data strategy for clients. Your role focused on high-quality strategy, definition, and delivery of solutions involving:
Data Integration, Governance & Wrangling
Data Storage and Computation Frameworks, Performance Optimizations
Analytics & Visualizations
Infrastructure & Cloud Computing
Data Management Platforms
The role requires a hands-on technologist with expertise in databases, Hadoop, MDM, and reporting to provide strategic and tactical direction to customers in the areas of marketing and technology. The person should have a strong programming background like Java.
As a data engineering practitioner, you should have a point of view and understanding of build vs. buy, performance considerations, hosting, business intelligence, reporting & analytics. Ideally, you have experience in integrating data with marketing scenarios like segmentation, targeting, consumer 360 view, etc.
Provide inputs to define and execute strategic roadmap for enterprise data architecture by identifying the current landscape and future business goals
Provide technical leadership and hands-on implementation role in the areas of data techniques including data access, integration, modeling, visualization, mining, design and implementation
Lead a globally distributed team to deliver high quality solutions. Manage functional & non-functional scope and quality
Help establish standard data practices like governance and address other non-functional issues like data security, privacy and quality
Help establish best practice like standards and guidelines for design & development, deployment, support and analytics and mining
Help establish best practice in acquiring, storing and analyzing structured, semi-structured and un-structured data from the enterprise and outside like social
Come up with analytics solutions based on the business goals and appropriate data visualization to support the goals
Manage and provide technical leadership to large data programs or multiple programs implementation based on the requirement using agile technologies
Define and drive key transformational programs like customer 360 degree view for the clients
Functional understanding related to digital marketing & customer experience solution blocks, Master data Management (MDM), Customer Relationship Management (CRM), Campaign Management, Tag Management, Media Buying, Optimizations, Recommendations & Targeting, DMP, and DSP.
Understanding Digital data sources such as Open source data (ex: Facebook, Twitter, LinkedIn etc.), Web log Data (SiteCatalyst, Google Analytics), 3rd party paid data (ex: Acxiom, ACNielsen etc.) and business application data (CRM, Ecommerce etc.)
Run workshops with clients and align client stakeholders to optimal solutions
  Qualifications
Excellent understanding of data technologies landscape
Well versed with pros and cons of various database technologies like Relational, NO SQL, MPP, Columnar databases
Well versed with Software as a service, Platform as a service and Infrastructure as a service concepts and can drive clients to a decision
Expert in programming languages like Java, Scala and / or JavaScript
Expert in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models
Expert in one or more ETL, BI, Analytics and advanced visualization technologies
Expert in in Hadoop eco-system with one or more distribution like Cloudera and HortonWorks
Expert in agile development with CI / CD pipeline with data projects
Knowledge in computation frameworks like Storm and Spark
Knowledge in cloud and social media technologies and integrations
Expert in master data management and building customer 360 degree views
Strong analytical and problem solving skills
Strong communication skills verbal, written and visual presentations
Strong coordination and negotiation skills
Multi geo experience and distributed delivery experience in large programs
Business Knowledge:  Data driven marketing experience would be a plus
Additional Information
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com",USD 130K - 225K *
571,Staff Data Engineer,Wayfair Inc.,"Bengaluru, IND",Senior-level / Expert,"Who we are: 
Wayfair Data Engineering is the engine that powers our data-obsessed eCommerce enterprise. We move fast, iterating quickly on big business problems. We work smart, applying technology to unlock insights and provide outsized value to our customers. We swing big, knowing our customers won't benefit from micro optimizations. Leveraging the largest data set for products sold in the Home space, this team treats data as an asset and determines how to maximize its business value and extend our competitive advantage. 
You will be instrumental in designing and delivering Data Warehouses, Data Lake, Self-Service Tooling, Real-time Streaming and Big Data Solutions for multiple functional areas using modern cloud technologies. You will have the chance to combine a deep knowledge of business and technical mastery to own and deliver the right solution for the right business problem. Most importantly, you will have the opportunity to move fast, adapt quickly, and leave a lasting mark through the new solutions you deliver! 
What you'll do: 
Own the technical architecture, design, and implementation of big data platforms and self-service solutions 
Collaborate with stakeholders and other engineering leaders to define and develop the data architecture roadmap. 
Act as a subject matter expert to leadership for technical guidance around solution design and best practices. 
Be a technical mentor to junior engineers and expose the team to new opportunities, while still being able to dependably deliver on ongoing goals. 
Keep current on big data and data visualization technology trends, evaluate, work on proof-of-concepts and make merit-based recommendations on technologies 
Who you are: 
An expert at SQL-based ETL development, and experienced with Python, Java, or equivalent scripting language. 
Experienced developing in cloud platforms such as Google Cloud Platform (preferred), AWS, Azure, or Snowflake at scale. 
Comfortable designing and implementing DW Architecture, OLAP technologies, and star/snowflake-schemas to enable self-service tooling. 
Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm or any similar tools. 
Experience with big data technologies like Hadoop, Spark, Cassandra, MongoDB or other open source big data tools. 
Experience architecting data solutions utilizing Bl tools like Looker, Tableau, AtScale, PowerBI, or any similar tools.
Excellent communication and presentation skills, strong business acumen, critical thinking, and ability to work cross functionally through collaboration with engineering and business partners. Previous e-commerce experience is a plus. 
5+ years of Data Architecture experience working in partnership with large data sets (5+TB highly desired) 
4+ years of experience leading or mentoring technical teams. 
Bachelor's or Masters in Computer Science, Computer Engineering, Statistics, or another quantitative discipline
Assistance for Individuals with Disabilities
Wayfair is fully committed to providing equal opportunities for all individuals, including individuals with disabilities. As part of this commitment, Wayfair will make reasonable accommodations to the known physical or mental limitations of qualified individuals with disabilities, unless doing so would impose an undue hardship on business operations. If you require a reasonable accommodation to participate in the job application or interview process, please let us know by completing our Accomodations for Applicants form.
Need Assistance?
For more information about applying for a career at Wayfair, visit our FAQ page here. 
About Wayfair Inc.
Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.
No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.
We are interested in retaining your data for a period of 12 months to consider you for suitable positions within Wayfair. Your personal data is processed in accordance with our Candidate Privacy Notice (which can found here: https://www.wayfair.com/careers/privacy). If you have any questions regarding our processing of your personal data, please contact us at dataprotectionofficer@wayfair.com. If you would rather not have us retain your data please contact us anytime at dataprotectionofficer@wayfair.com. ",USD 45K - 84K *
572,Sr. Data Scientist,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Serve as an analytics expert in designing, developing and implementing best in analytic solutions
Create and deliver powerful insights from data through better visualization and storyboarding
Collaborate with internal and external partners to fully understand business requirements and desired business outcomes
Demonstrate execution proficiency in handing multiple medium-to-large analytics projects in a team environment that includes the rest of the Data Science team
Draft detailed scope for assigned projects, addressing suggested methodology and analytics plan
Execute on the analytics plan with appropriate data mining and analytical techniques
Perform quality assurance of data and deliverables for work performed by other Data Scientists and self
Ensure all project documentation is up to date and all projects are reviewed per analytics plan
Ensure project delivery within timelines and budget requirements
Build on team’s analytical skills and business knowledge
Enhance existing analytics techniques by promoting new methodologies and best practices in the Data Science field
Provide subject matter expertise and quality assurance of complex data-driven analytic projects
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
• Post-graduate degree (Masters or PhD) in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent
• Minimum of 5-7 years of analytics expertise in applying statistical solutions to business problems
• Experience working in one or more of the Card Payments markets around the globe
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Good knowledge of data, market intelligence, business intelligence, and AI-driven tools and technologies
• Experience planning, organizing, and managing multiple large projects with diverse cross-functional teams
• Demonstrated ability to incorporate new techniques to solve business problems
• Demonstrated resource planning and delivery skills
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 136K - 205K *
573,AI Machine Learning Engineer,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Education and Work Experience Requirements:· 6 to 8 years of experience as Machine Learning Engineer· Leverage proficiency in AWS and Azure to architect, create, and deploy machine learning solutions on cloud platforms, implementing scalable and efficient pipelines through the utilization of cloud-based services.· Ability to train models with multi-GPU frameworks; eg: mxnet· Strong oops and python clean code practices· Work closely with data scientists and software engineers to streamline the deployment and integration of machine learning models.
Expertise with ML frameworks TensorFlow, Keras, PyTorch, Scikit Learn.· Hands-on experience in deploying model in AWS SageMaker or Azure ML Studio· Containerize machine learning applications using technologies such as Docker and orchestrate deployments with tools like Kubernetes.· Optimize models for distributed computing environments.
Implement security best practices for machine learning models deployed on cloud platforms.
Ensure compliance with relevant data protection and privacy regulations.· Monitor and optimize the performance of machine learning models on cloud platforms.· Implement and manage end-to-end CI/CD pipelines for machine learning models, enabling seamless integration, testing, and deployment.
Good to have skills :
Knowledge on Responsible AI concepts
 Qualifications
BE,BTEch, MCA
Additional Information
6 to 8 years of experience as Machine Learning Engineer",USD 150K - 230K *
574,Manager-Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Follow Tesco's Business Code of Conduct and always act with integrity and due diligence
- Accountable for engaging with markets to understand their key outcomes; identifying and implementing analytics projects that will result in disproportionate returns
- Drive value realization through delivery of high impact projects and efficiency gain by automating repeatable tasks
- Track and measure return on investment for Analytical Investments
- Accountable for achieving teams objectives; partner management and issue management
- Institutionalize robust ways of working through reusable frameworks; code and knowledge management
- Develop analytical assets that are deployed in production and will deliver value on sustained periods of time
- Collaborate with colleagues to craft; implement and measure analytical solution
- Develop and lead an impactful team; crafting an environment for success by setting direction and mentoring them to succeed through inspiring conversations every day
- Hands-on problem solving. You will be required to get hands dirty with data and applied math
- Initiates and crafts continuous improvements initiatives to drive performance within their teams
- Diagnose and recommends solutions to operational challenges; using specialist knowledge and operational expertise.
Qualifications
- Understanding of machine learning techniques - Linear & Logistics regression; Decision Trees; Random Forest; XgBoost and Neural Network
- Knowledge of Python; SQL; Hive and one of the visualization tools (Tableau)
- Stakeholder management; Operations Delivery; Analysis and Judgment; People Policies and Processes; Foundational Statistics & Math
7-10 yrs of experience in Leading analytics engagements in any one of domains like retail; cpg; telecom or hospitality and for one of the following functional areas - marketing; supply chain; customer; merchandising; operations; finance or digital
Additional Information
Last Date of Application-14th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
575,Data Scientist,GetMyUni,"New Delhi, India",Mid-level / Intermediate,"Company Description
GetMyUni is a CollegeDekho group company. 
GetMyUni is one of India’s largest college decision-making platforms in India, disrupting the college admissions space. We serve over 50M+ users annually.
For more visit: www.getmyuni.com
GetMyUni and IELTSMaterial are a part of the CollegeDekho Group, which is one of India’s leading Higher Education Ed Tech companies and has raised ~$50M USD from investors like Winter Capital, ETS Strategic Capital, Calega, Man Capital, and ADQ.
 Job Description
Responsibilities for Data Scientist 
● Collaborate with stakeholders across the organization to explore ways to use company data to 
create business solutions. 
● To optimize and improve product development, marketing approaches, and commercial strategies, 
data from company databases are mined and analyzed. 
● Examine the efficacy and precision of new data sources and data collection procedures. 
● To apply to data sets, create bespoke data models and algorithms. 
● 
Increase and optimize customer experiences, revenue creation, ad targeting, and other company 
results via predictive modeling. 
● Develop an A/B testing framework for the organization and evaluate model quality. 
● To implement models and track outcomes, collaborate with various functional teams. 
● Develop monitoring and analysis methods and tools for model performance and data accuracy. 
 Qualifications
Qualifications for Data Scientist 
● Strong problem-solving abilities, focusing on product creation. 
● Experience manipulating data and extracting insights from huge data sets using statistical computer 
languages (R, Python, SLQ, etc.). 
● Working with and designing data architectures is a plus. 
● Understanding of a variety of machine learning approaches (clustering, decision tree learning, 
artificial neural networks, and so on) as well as their real-world benefits and limitations. 
● Advanced statistical techniques and ideas (regression, characteristics of distributions, statistical 
tests, suitable application, etc.), as well as application experience, are required. 
 ",USD 86K - 160K *
576,"Associate, Data Engineer",Micron Technology,"Hyderabad - Skyview, India",Mid-level / Intermediate,"Our vision is to transform how the world uses information to enrich life for all.
Micron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever.
JR40427 Associate, Data Engineer
As a Business Intelligence Data Analyst in the Digital Supply Chain Business Intelligence Analytics Team, we will be part of an Agile project team focused on driving data analytic initiatives in the automation of a digital supply chain using visualizations and stories. We will be responsible for creating and delivering data reporting solutions and visualizations that are consumed by a wide audience including business leaders, business analysts & planners, suppliers and customers. You will work with business partners to define system requirements (such as requirements for interface design to support a global user base) and coordinating with the Information Technology (IT) department as needed. 
 As a team, we craft and build specialized business intelligence solutions that answer key business questions on semiconductor industry. We strive to deliver value to the organization through the visibility of data through metrics, dashboards, analytics, and reporting. We seek to deliver high-quality data, support, and availability of our information assets. 
Successful applicants will work on 
Analyze and define Functional requirements of the user story (requirements) and acceptance criteria. 
Design, Develop and deliver Reporting and Analytic solutions using Microsoft SQL Server Business Intelligence tools, Snowflake, SAP Hana/Business Objects and Power BI or Tableau 
Develop Coding in Advanced SQL and Python,Complete unit testing, participate in code review, document solution delivery, and coordinate deployment. 
Support Operational reporting requirements coming from Singapore team and US Teams, quickly deliver them. 
Support the development team in functional requirement and understanding of User stories. 
Collaborate with Global user base and BI Analysts to ensure that the solution is meeting the business needs. 
Drive effective agile project management through active engagement in the scrum development process. 
Provide hands on demonstration of the solution. 
Provide Functional support to business team members during testing and deployment phase. 
Work with teams to deliver effective, high-value reporting solutions by using an established delivery methodology. 
Qualified candidates must possess: 
Outstanding SQL and Python skills 
Decent Knowledge on DBMS
Basic Knowledge on Data visualization and Reporting software like Tableau/Power BI 
Nice to have knowledge on UiPath/Blue Prism in Automating the Manual Work by developing Standard Bots standardized for Business purposes.
Bachelor’s Degree or Master's Degree (Year of Completion -2023) or equivalent experience in relevant Management Information Systems (MIS), Computer Information Systems, Computer Science, Statistics, Engineering or related field of study.
About Micron Technology, Inc.
We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.

To learn more, please visit micron.com/careers

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_in@micron.com
Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.
Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.",USD 110K - 181K *
577,Business Intelligence Professional,BT Group,"Building No 14 Sector 24 & 25A, Gurugram, India",Mid-level / Intermediate,"Why this job matters
The Data Analytics Professional supports the collection, analysis, interpretation and presentation of data to support the BT Group's strategic decision making.
What you’ll be doing
1.Supports the acquisition, processing, integration, and cleaning of data from multiple sources.
2.Uses a variety of tools to automate data collection and build reports guided by procedures.
3.Undertakes initial data investigation and data analysis in order to identify trends in data.
4.Supports the development and refinement of data dashboards and reports.
5.Supports the presentation of data insights to relevant stakeholders for planning and decision support.
6.Supports in the implementation of ways to improve working processes within the area of data analytics.
The skills you’ll need
Database Design/Development
Requirements Analysis
Requirements Gathering
Data Storytelling
Business Intelligence Reporting
Programming/Scripting
Data Quality
Data Decision Support
Business Analysis
Data Analysis
Agile Methodologies
Data Dashboards
Decision Making
Growth Mindset
Inclusive Leadership
Our leadership standards
Looking in:
Leading inclusively and Safely
I inspire and build trust through self-awareness, honesty and integrity.
Owning outcomes
I take the right decisions that benefit the broader organisation.
Looking out:
Delivering for the customer
I execute brilliantly on clear priorities that add value to our customers and the wider business.
Commercially savvy
I demonstrate strong commercial focus, bringing an external perspective to decision-making.
Looking to the future:
Growth mindset
I experiment and identify opportunities for growth for both myself and the organisation.
Building for the future
I build diverse future-ready teams where all individuals can be at their best.",USD 30K - 56K *
578,Lead-Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Following Tesco's Business Code of Conduct and always act with integrity and due diligence
- Engaging with business & functional partners to understand business priorities; ask relevant questions and scope same into a analytical solution document calling out how application of data science will improve decision making
- In depth understanding of techniques to prepare the analytical data set leveraging multiple complex data set sources
- Building Statistical models and ML algorithms with practitioner level competency
- Writing structured; modularized & codified algorithms using Continuous Improvement principles (development of knowledge assets and reusable modules on GitHub; Wiki; etc) with expert competency
- Building easy visualization layer on top of the algorithms in order to empower end-users to take decisions - this could be on a visualization platform (Tableau / Python) or through a recommendation set through PPTs
- Proactively driving consumption of solutions developed by the team and owning the initiative to identify and address areas of improvement in the larger Tesco business
- Keeping up-to-date with the latest in data science and retail analytics and disseminating the knowledge among colleagues
- Mentoring and leading a small team of Applied Data Scientists to deliver high impact analytics projects
Qualifications
- Applied Math: Applied Statistics; Design of Experiments; Regression; Decision Trees; Forecasting; Optimization algorithms; Clustering; NLP
- Tech: SQL; Hadoop; Spark; Python; Tableau; MS Excel; MS Powerpoint; GitHub
- Business: Basic understanding of Retail domain
- Soft Skill: Analytical Thinking & Problem solving; Storyboarding; Stakeholder engagement; Leading team
Additional Information
Last Date of Application- 14th Nov 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
579,Engineer - DocData Management,Shell,SHELL CENTRE – CHENNAI,Mid-level / Intermediate,", India

Job Family Group:
Information Technology (IT)

Worker Type:
Regular

Posting Start Date:
October 11, 2023

Business unit:
Projects and Technology

Experience Level:
Early Careers

Job Description:
Competencies and Job Requirements (Data and/or Document Controller):
Minimum of 3-4 years industry experience as Data and Document Controller with knowledge of data control processes and systems on Major Capital Projects, and of EPC interface management.
Prior experience in writing and manipulating databases (like SQL, Oracle, NoSQL).
Knowledge of cross-discipline engineering data (requirements and use) including business data model of engineering, spare parts processes, Maintenance Management System build processes.
Knowledge of SharePoint and document management systems.
Experience of working with Engineering Data Warehouse (EDW) systems (or similar) e.g. Bentley, AVEVA, SPF.
Experience working with document management systems (EDMS). Experience in Bentley ALIM preferred.
Preferably knowledge of Engineering IM Scope of Work and Information Specification in a major contract, CFIHOS/DEP, Engineering Information Specification (EIS) and the related document.
Working in a highly virtualized environment in a geographically diverse and multicultural team.      
Good written and oral communications.
The Document controller scope of services and work are detailed below.
Processing Asset/Project internally generated documents (document numbering, review workflows, quality assurance)
Manual processing of Maintenance Contractors’ deliverables (by exception, when not covered by automated process)
Support and manage and where needed update of automated DDMs in Assai Cloud
Support in the mapping of Tier 1 and Tier 2 Asset documents in Assai
Quality Assurance (spot checks) on Maintenance Contractors’ deliverables submitted through the Assai Portal
Check-out and Check-in of Asset documents to and from Capital projects & Minor Mods projects for Concurrent Engineering
Mapping of RDL discipline and doc-types to legacy documents in support of migration activities
Migration of LMS/BMS documents into Assai (as per MIDS Health Check recommendation)
Review the Doc-Tag relations in Assai received from AVEVA IMS
Maintain the PSV Certification data updates in Assai
Highlight to the IM lead shortcomings in the document PBI performance reports (status, progress and forecast).
Document metadata mapping in support of specific work processes and reporting dashboards (e.g. DCAF Control Point mapping and P2A requirements mapping)
Ensure all DCC transactional actions in the Project and Asset functional mailboxes are completed in a timely manner.
Behavioral Competences:
Excellent communication skills and a quick learner. Be a good team player. Ability to prioritize and ensure delivery of priorities for the area of responsibility. Flexible and adaptable to change, with a track record of demonstrating initiative, analytical capabilities and problem-solving.
Ability to apply engineering best practices, codes, and standards to identify issues, recommend improvements, and implement solutions.
Excellent stakeholder management with business interface exposure
Strong interpersonal leadership skills are critical due to the requirement for effective communication of complex issues across multiple offices and teams.
Expertise in pipe modeling and facility layouts.
Flexibility to move quickly across changing priorities and manage multiple Projects/Programme
Ability to independently, resourcefully, and creatively research and implement new solutions
A good understanding of the Upstream/DS/IG business and how it works.
Ability to engage and effectively communicate at all levels inside and outside Shell and within different cultural settings.
Strong interpersonal skills, ability to challenge and ability to build internal and external relationships based on trust and to integrate across multiple functions.
Strong understanding of Continuous Improvement process in TAO
Competitive applicants will have a proven track record of delivery in Asset and/or Project.
While the hubs will remain the core locations for SEAM, we will continue to use a distributed working model. This means that our preference is to appoint the best candidate for the job on local terms working virtually from their base country.
We may make appointments on expatriate terms where it is justified in accordance with the International Mobility criteria for expatriation, but our clear preference is to appoint on local terms and build the local talent pipeline.
Positions in SEAM will require global travel and flexibility in working hours to manage communications across time zones in order to influence and support stakeholders and enable business performance. However, flexibility in recognition of diverse family situations will be conside
-

DISCLAIMER:
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Shell/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell is an Equal Opportunity Employer.",USD 30K - 56K *
580,"HR Data Analyst(HR Data Reporting, Service Now, Workday)",SNC-Lavalin,SNC-Lavalin Atkins Bengaluru Office,Entry-level / Junior,"Job Description
We’re AtkinsRéalis, a world-leading Design, Engineering and Project Management organization. Created by the integration of long-standing organizations dating back to 1911, we are a world-leading professional services and project management company dedicated to engineering a better future for our planet and its people. We create sustainable solutions that connect people, data and technology to transform the world's infrastructure and energy systems. We deploy global capabilities locally to our clients and deliver unique end-to-end services across the whole life cycle of an asset including consulting, advisory & environmental services, intelligent networks & cybersecurity, design & engineering, procurement, project & construction management, operations & maintenance, decommissioning and capital. The breadth and depth of our capabilities are delivered to clients in key strategic sectors such as Engineering Services, Nuclear, Operations & Maintenance and Capital.
News and information are available at www.atkinsrealis.com or follow us on LinkedIn.  
Our teams are proud to deliver on some of the most prestigious projects across the world. It's thanks to our talented people and their diverse thinking, expertise, and knowledge. Join us and you'll be part of our genuinely collaborative environment, where everyone is supported to make the most of their talents and expertise.
When it comes to work-life balance, AtkinsRéalis is a great place to be. So, let's discuss how our flexible and remote working policies can support your priorities. We're passionate about are work while valuing each other equally. So, ask us about some of our recent pledges for Women's Equality and being a 'Disability Confident' and 'Inclusive Employer’.
Job Description
As HR Data Analyst in our Bangalore-based HR Shared Services Centre, you’ll be an integral part of delivering an exceptional HR customer experience. You will be part of HR Operational Excellence team that is responsible for HR Data Reporting & Analytics, Ops Excellent deliveries, and automations to improve business processes by designing, developing, implementing new processes, and ensuring that changes are well managed as well as well communicated. The team ensure to create a culture of continuous improvement within the organization and strive to increase efficiency and reduce costs.
Key Responsibilities:
Data Analysis:
Collect, clean, and pre-process data from various sources.
Perform data analysis to identify trends, patterns, and insights.
Conduct quantitative and qualitative data analysis to support business objectives.
Collaborate with cross-functional teams to understand data requirements.
Reporting and Visualization:
Create and maintain reports, dashboards, and visualizations using tools like Tableau, Power BI, or custom solutions.
Develop interactive and user-friendly reports for stakeholders.
Ensure data accuracy and consistency in reports.
Customize reports to address specific business needs.
Data Interpretation and Communication:
Translate data findings into actionable insights and recommendations.
Present data analysis results to non-technical stakeholders.
Collaborate with teams to help them understand the implications of data findings.
Assist in making data-driven decisions.
Data Governance and Security:
Ensure data integrity and adherence to data governance and security policies.
Maintain data documentation and metadata for traceability.
Monitor data quality and take corrective actions as needed.
Tools and Technology:
Stay up to date with data analytics, reporting, and automation tools and technologies.
Continuously improve technical skills and knowledge.
Qualifications and Skills:
Bachelor's degree in a relevant field (e.g., Data Science, Computer Science, Business Analytics).
Strong analytical and problem-solving skills.
Proficiency in data analysis tools and languages (e.g., Python, R, SQL).
Experience with reporting and visualization tools (e.g., Power BI, Excel).
Strong communication and presentation skills.
Ability to work in a collaborative team environment.
Attention to detail and a commitment to data accuracy.
Understanding of data security and governance best practices.
Experience:
Relevant work experience in data analysis, reporting, and process automation is typically preferred.
Entry-level positions may require internship experience or academic projects demonstrating relevant skills.
This job description provides an overview of the key responsibilities and qualifications for a Data Analytics, Reporting, and Automation Analyst. However, the specific requirements and expectations may vary depending on the organization and industry.
What We Can Offer You
Varied, interesting and meaningful work.
A hybrid working environment with flexibility and great opportunities.
Opportunities for training and, as the team grows, career progression or sideways moves.
An opportunity to work within a large global multi-disciplinary consultancy on a mission to change the ways we approach business as usual.
Why work for AtkinsRéalis?
We at AtkinsRéalis are committed to developing its people both personally and professionally. Our colleagues have the advantage of access to a high ranging training portfolio and development activities designed to help make the best of individual’s abilities and talents. We also actively support staff in achieving corporate membership of relevant institutions.
Meeting Your Needs
To help you get the most out of life in and outside of work, we offer employees ‘Total Reward’.
Making sure you're supported is important to us. So, if you identify as having a disability, tell us ahead of your interview, and we’ll discuss any adjustments you might need.
Additional Information
We are an equal opportunity, drug-free employer committed to promoting a diverse and inclusive community - a place where we can all be ourselves, thrive and develop. To help embed inclusion for all, from day one, we offer a range of family friendly, inclusive employment policies, flexible working arrangements and employee networks to support staff from different backgrounds. As an Equal Opportunities Employer, we value applications from all backgrounds, cultures and ability.
We care about your privacy and are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data.
Link: Equality, diversity & inclusion | Atkins India (atkinsrealis.com)
Worker Type
Employee
Job Type
Regular
At AtkinsRéalis, we seek to hire individuals with diverse characteristics, backgrounds and perspectives. We strongly believe that world-class talent makes no distinctions based on gender, ethnic or national origin, sexual identity and orientation, age, religion or disability, but enriches itself through these differences.  ",USD 60K - 94K *
581,BI Developer,Ramboll,"Chennai, India",Senior-level / Expert,"Company Description
Ramboll in India
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Job Description
Inviting bright minds
Do you want to push the boundaries of your profession and develop your excellence in an open, collaborative, and empowering culture? We work to create a sustainable future and our inspiring projects and innovative solutions aim to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies, and people around the world.
You will join our Data & Analytics department
As our new experienced Senior BI Developer, you will be part of a Global team, which is responsible for developing global data driven analytical solutions by both using classic and advanced disciplines supporting Ramboll’s business units globally. With an increased strategic focus on the area in Ramboll, we are currently expanding. The purpose of our department is among others to support the business with excellent data driven solutions. Make sure all solutions in production runs smoothly, train users in the new solutions, handle change request and support incidents etc.
Your key tasks and responsibilities will be:
Understand user requirements
Present your BI solutions to users, stakeholders, and the BI Team
Monitor, improve and constantly optimize existing structures, data flows and processes
Take part in the daily task in our data warehouse and BI solutions
Plan and manage your own BI projects from A to Z
Background in data warehouse design (e.g., dimensional modeling) and data mining
In-depth understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework
Teach users how to create value in Power BI with Ramboll data
Create good customer experiences
Your starting point for constant growth
From the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this role, we believe your starting point is:
Several years of experience with Data Analytics
Hold a relevant educational degree
Have expert knowledge in SQL, SQL Server Integration Services and Power BI.
Strong knowledge in Data Visualization, Data Modelling, Query Performance Tuning.
Strong knowledge on writing Stored Procedure, Complex queries, and DAX
Have hands on in Tools like: Power BI, SSMS, Visual Studio
Have Knowledge on SQL Server Analysis Server, Power Query
Good to have knowledge on TFS /GIT
Fluent in English – written and orally
 Additional Information
Personal qualities that will help you succeed in this role include self-driven and analytical in your work approach thriving with transformation and building new BI solutions by challenging status quo. In addition, you are also highly structured and well organized enabling you to maintain the full overview.
Welcome to our Support Organization
In Ramboll’s Support Organization we take pride in keeping Ramboll running smoothly, enabling bright minds throughout the organization to focus on their areas of expertise as we tie together all parts of the business. We provide support within areas like Finance, HR, IT, Legal, Communication, Facility Management and more, coordinating efforts and securing common ground for the development and servicing of clients and markets.
Ramboll in Denmark
Ramboll is the leading engineering, design and consultancy company in Denmark and has more than 3,500 experts working across 13 offices applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health, Energy and Management Consulting. We invite you to contribute to a sustainable future working in an open, collaborative, and empowering culture.
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 106K - 140K *
582,Lead Engineer CS(Data Management),Antolin,"Pune, IN",Senior-level / Expert,"Lead Engineer - Data management
Pune, India

Who are we:
  Antolin is a leading global automotive supplier, we are experts in designing, manufacturing, and supplying innovative solutions for vehicles around the world. Our product portfolio includes trim, headliners, and acoustic systems, as well as lighting and other interior systems. We offer comprehensive solutions with a focus on quality, safety, and sustainability. Our products are used in many of the world’s leading car brands, including JLR, BMW, Toyota, Volkswagen, Audi, Mercedes-Benz, and Ford.
   What we offer:
  You will be part of a highly engaged multinational with international career opportunities.
We offer you a learning journey adapted to your professional experience.
You will work on international projects for world- renowned companies in Automotive sector.
You can find an Open Environment to learn new technologies.
We can offer you a competitive salary, benefits and valuable OEM discounts.
   Responsibilities:
  7-9 years experience in Design and PLM sytems like Enovia, Teamcenter for customers like Ford , VW , Skoda.
Should be able to lead a small team of 2 to 3 people with the abilty to get the workdone from the team
Excellent communication skills and customer handling experience Able to work on full release procedure on VW group, Daimler and or FIAT CHRYSLER GROUP and speak with Client if any open issues.
Be an excellent coordinator with internal teams in GA .
Must able to produce the required documentation for releases and knowledge building.
Attend the key meetings between customer and BU if necesary.
Should be technically sound to check the clashes and advise internal CAD teams to correct the data. In some cases should be proactive to himslef fix the CAD and release to customer.
  Here at Antolin, we are an equal opportunity employer and value diversity in our workplace. We do not discriminate based on race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status. All qualified applicants will receive consideration for employment without regard to any of these protected characteristics. We encourage applications from all individuals and strongly support diversity in our workplace. We strive to create an inclusive environment for everyone, and we are committed to treating everyone in a fair and equitable manner. We are proud to be an equal opportunity employer and are committed to fostering a diverse and inclusive work environment.
    DREAM. DARE. DO",USD 45K - 84K *
583,BI Developer,Autodesk,APAC - India - Bengaluru - Sunriver,Senior-level / Expert,"Job Requisition ID #
23WD74242
We are seeking an experienced Business Intelligence Developer with a strong background in Microsoft Fabric, SQL, Power BI, and other BI technologies. The ideal candidate will possess expertise in UX design, data model design, DAX, and Data Flows and have hands- on experience working with Snowflake, Data Lake, SAP Hana, SharePoint, and REST APIs as data sources. Additionally, knowledge of Sales and Finance domains in a Product-based company is a valuable asset.
Learn More
About Autodesk
Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.
We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.
When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!
Salary transparency
Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package.
Diversity & Belonging
We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging
Are you an existing contractor or consultant with Autodesk?
Please search for open jobs and apply internally (not on this external site).",USD 85K - 135K *
584,BI Developer Specialist,LRN Corporation,"Goregaon, Maharashtra, India",Senior-level / Expert,"About LRN
LRN is a SaaS based e-Learning provider with a presence across US, EMEA, APAC, Japan and LatAm. More than 2,500 companies worldwide (including some of the world’s most recognizable brands) utilize LRN services and leverage LRN e-learning courses to help navigate complex regulatory environments and foster ethical, responsible, and inclusive cultures. In partnership with LRN, companies translate their values into concrete corporate practices, training materials, and leadership behaviours that create a sustainable competitive advantage. By acting upon shared values, companies and their people find the means to out behave and outperform. About the role: LRN is seeking a Business Intelligence Analyst to support our product team. You will work closely with team to develop new features and enhancements for our product. You will work alongside of project managers, Data engineer and quality assurance team to meet delivery expectations. Role requires
Requirements
 Person should have relevant work experience in analytics, reporting and business intelligence tools.
 Working experience with AWS Quicksight / Looker
 Proficient in using SQL, ETL, Data Warehouse solutions and databases in a business environment with medium to large-scale, disparate datasets.
 Analytical mind with a problem-solving aptitude
 Ability to work closely with stakeholders to get dashboards in place.
Understanding customer requirements and design solution in AWS Business Intelligence environment.
 Excellent communication skills and exposure dealing with customers.
Nice to Have:
Experience with similar visualization tools like Power BI, Tableau, Qlik, etc. is an added advantage.
Experience with AWS
Understanding AWS IAM policies, roles and administrator of AWS services.
Qualifications and work experience:
• 2 to 7 years of experience in Data visualization
• Proven experience with AWS Quick sight
• Data enthusiast
Benefits
Competitive compensation
Excellent medical cover
LRN is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",USD 106K - 140K *
585,Data Manager,Corning,"Gurgaon, HR, IN, 122002",Mid-level / Intermediate,"Requisition Number: 61919
  Corning is vital to progress – in the industries we help shape and in the world we share.
We invent life-changing technologies using materials science. Our scientific and manufacturing expertise, boundless curiosity, and commitment to purposeful invention place us at the center of the way the world interacts, works, learns, and lives.
Our sustained investment in research, development, and invention means we’re always ready to solve the toughest challenges alongside our customers. 


The Global Supply Management (GSM) Function is recognized as a critical function for business success.  It delivers the training, tools and opportunities needed to create innovative solutions for the function & the corporation.  GSM has leading edge, effective processes to anticipate and exceed customer requirements.
    What is the role?
Corning is consolidating 29 ERP platforms around the world to unite the organization under one common ERP solution, SAP S/4 HANA, with Master Data Governance (MDG). In this role, you will lead efforts to transform and improve data governance capabilities, and provide leadership for enterprise-data related activities, including data profiling, cleansing, rationalization, and validation. This role is accountable and responsible for creating the end-to-end vision, strategy, and roadmap execution spanning across people, process, systems, and risks. As an outcome, this leader will identify and recommend policy changes, technology enhancements, and governance architecture required to achieve future-state.
  What will you be doing?
Create, articulate, and execute supply chain data strategy, roadmap, and action plan with adherence to standardization and harmonization
Accountable for supply chain data, including governance, master data administration processes, and data-related activities within our SAP S/4HANA and supply chain transformation
Identify data management capabilities necessary to enable differentiation, and deliver long-term value, including best in class data stewardship
Identify opportunities to leverage new technologies, drive process automation, and deliver efficiencies
Ensure data management process consistency across functions and regions
Develop persuasive and impactful presentations conveying complex ideas in a simple manner leading to fast and informed decisions. Manage stakeholder expectations including global leadership audiences
Drives decisions regarding the data design for Global Template
Champions the Global Operations Transformation program guiding principles, including “enterprise over function”, “no customization without differentiation”, and “risk over value”
Monitor and manage project and operational milestones, deliverables, and budgeting; create visibility to program deliverables and escalate appropriately for efficient and effective proactive resolution of obstacles
Maximize the adoption of industry leading practices, with the adjustments necessary to accommodate Corning’s requirements
Supervise and mentor a global team of direct and matrix reports to deliver data management operational support excellence
Effectively manage diversity and inclusion in complex global initiatives where employees and partners work across geographies, time zones, and culture
  Who will you be interacting with?
Global Operations Transformation (ERP Program Management) 
IT solution architects
Business leads
GSM and Shared Services process owners
Power Users & Super Users
  What education and experience you will bring?
Bachelor’s Degree required, ideally in Business, Engineering, Supply Chain Management
Master’s degree preferred
Minimum of 10 years in leading data-related activities with direct continuous and process improvement experience
Minimum of 5 years of manufacturing/operations experience in Supply Chain areas – Plan, Make, Source, Deliver
Minimum of 3 years with SAP S4HANA and/or SAP ECC
Minimum of 3 years with SAP MDG or MDM
Minimum of 3 years of experience in leading resources within a global business environment.
  What skills you need to demonstrate?
Demonstrated track record in project management abilities
Bias for action – ability to simplify complex situations guiding teams to deliver results
Knowledge of technologies, techniques and best practices in data governance, master data administration and systems implementations data-related activities
Coach, mentor and develop team members, encourages, and recognizes performance for both results achieved and key learnings throughout the journey
Strong verbal and written communication skills to share project progress, scope, and risks
Agile, flexible, and a change champion – effectively coach and mentor teams through transformational change
Ability to define and drive global standards across a portfolio of cross-functional teams, leading to consistency of operation and execution, maximizing efficiency and business performance 
Problem solving, analytical, and exceptional follow through skills
Comfortable influencing without authority
  Travel Requirements (domestic and/or international)
Ability to work remotely and ability to travel to international locations for duration of up to 2 weeks at a time.
Travel will constitute 15% of the role
  We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. To request an accommodation, please contact us at accommodations@corning.com.",USD 73K - 115K *
586,QA Engineer – ETL,Syniverse,India (Bengaluru),Senior-level / Expert,"Syniverse is the world’s most connected company. Whether we’re developing the technology that enables intelligent cars to safely react to traffic changes or freeing travelers to explore by keeping their devices online wherever they go, we believe in leading the world forward.  Which is why we work with some of the world’s most recognized brands. Eight of the top 10 banks. Four of the top 5 global technology companies. Over 900 communications providers. And how we’re able to provide our incredible talent with an innovative culture and great benefits.
Who We're Looking For
-
Some of What You'll Do
Duties and responsibilities:
Provide assistance and consulting to Development and Product Support teams on project activities.
Develop and create work plans and schedules for Test Project activities. 
Coach and train Testing employees to assist in fulfillment of job responsibilities.
Ability to work from functional specifications to write test plans.
Perform team lead responsibilities in managing test plans and schedules.
Assign tasks and track Project deliverables.
Identify resource needs and acquire resources.
Consult with Development and Production Support to identify test data.
Accurately diagnose test results and document product defects.
Setup test environment and follow release notes to install product releases and fixes.
Execute test scripts and cases and initiate modifications if necessary.
Provide daily test statuses on testing progress and issues.
Actively participate in product and project team meetings. 
Provide input on training requirements and available classes for the Test team.
Keep abreast of business needs and stay current with technology trends. 
ETL Testing
Design and execute comprehensive test plans and test cases to validate ETL processes.
Ensure data extraction, transformation, and loading operations meet business requirements and data quality standards.
Identify and report data anomalies, discrepancies, and inconsistencies.
Data Validation
Develop and maintain data validation scripts and procedures to verify data integrity.
Perform data reconciliation between source and target systems.
Validate data transformations, aggregations, and calculations.
Performance Testing
Conduct performance and scalability testing of ETL processes to ensure optimal data flow.
Identify bottlenecks and optimize ETL workflows for efficiency.
Regression Testing
Establish and maintain regression test suites to prevent regressions in ETL pipelines.
Automate regression testing where possible to streamline validation processes.
Documentation
Document test cases, test results, and testing procedures.
Maintain documentation for ETL processes and data mappings.
Error and Defects are created in Jira and fully documented including description, steps to recreate, and attached failed test collateral.
Collaboration
Collaborate with data engineers, data analysts, and business stakeholders to understand data requirements and business logic.
Work closely with the development team to ensure ETL code changes are tested thoroughly.
Issue Resolution
 Investigate and troubleshoot data-related issues and defects.
 Work with the development team to resolve identified problems.
Requirements:
 7+ years Software Engineering experience, including 6+ years' experience working in a
Quality Assurance testing environment.
Team lead experience.
Expertise in formal software testing methodologies.
Integration testing.
Conformance testing.
Scripting and automated software testing tools.
6+ years' experience working with industry standard testing tools like JMeter, Zephyr, Cucumber, Postman, and others.
Strong understanding of platforms (UNIX experience preferred).
Strong programming knowledge.
Jira knowledge preferred.
Required Interpersonal Skills:
Strong leadership skills.
Strong understanding of software processes.
Strong documentation skills.
Strong analytical and problem resolution skills.
Strong technical writing skills for creating test related documents.
Strong control and follow-up skills.
Strong organizational skills.
Strong attention to detail.
Strong negotiating skills.
Strong conflict resolution skills.
Support Project Management Process.
Thorough understanding of Agile/Scrum development methodology.
#LI-hybrid
-
Why You Should Join Us
Join us as we write a new chapter, guided by world-class leadership. Come be a part of an exciting and growing organization where we offer a competitive total compensation, flexible/remote work and with a leadership team committed to fostering an inclusive, collaborative, and transparent organizational culture.
At Syniverse connectedness is at the core of our business. We believe diversity, equity, and inclusion among our employees is crucial to our success as a global company as we seek to recruit, develop, and retain the most talented people who want to help us connect the world.
Know someone at Syniverse?
Be sure to have them submit you as a referral prior to applying for this position.",USD 45K - 84K *
587,"Senior Analyst, Data Analysis",TransUnion,Pune,Senior-level / Expert,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
This role requires that you perform an array of data analysis and other advanced statistical analysis techniques to understand client business environments to advise clients to consider changing processes or updating implemented solutions to maximize business strategies. You will construct, analyze and interpret various data pipelines , reports and present outputs to clients in order to give them a clear understanding of their credit book over a period of time.
Explores new statistical analysis and related research techniques and software and presents findings to peers within TransUnion. Manages the integration of data analysis, with statistical models to make sound strategic recommendations
What You'll Bring:
Preferably 2-4 years’ experience with handling and analyzing data, preferably within the credit risk industry.
A degree in Statistics, Mathematics, Actuarial science, Business Mathematics or Informatics degree.
Sound understanding of statistical software. R, SQL, Tableau, Advanced Excel Business Object and Dashboard creation experience would be preferred. 
Impact You'll Make:
Conduct data analysis to understand internal and client data, process flows, policies and procedures.
Provides ongoing customer and sales support; uncovering opportunities and resolving problems.
Constructs, analyses and interprets various BI monitoring reports.
Analyses and interprets trends encountered and makes logical conclusions from monitoring output.
Utilizes communication and reporting methods to ensure the output and recommendations are presented to clients in an understandable manner.
Read and import raw data from various formats into R environment. Use R to analyse data in detail as well as the utilization of macros.
Generate tables and graphs using SAS, R and Excel.
Managing the analysis of data files in various layouts and performing data auditing and validation.
General and detailed data interrogation, transformation and manipulation.
Identification of data trends or patterns, data mining and warehousing.
Ability to present outputs and recommendations to clients in an understandable manner.
Attachments
TransUnion Job Title
Sr Analyst, Data Analysis",USD 45K - 84K *
588,Data Strategy Manager,Salesforce,India - Bengaluru,Mid-level / Intermediate,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Operations
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good– you’ve come to the right place.
Roles & Responsibilities:
Own the Account Data Strategy for the OU
Work with the Global Data Strategy Team and Global Counterparts to ensure the Data is sourced, cleaned, and maintained in compliance with Global Data Guidelines
Own vendor relationships for Data Sourcing and Management
Act as the team lead for a team of Data Analysts, focusing on the below
 Account Data Cleanup & Enrichment at an Industry/ Sub-industry level
Net New Account Discovery through external data sources
Top Focus Industries: Market Research, Account Discovery, Deduplication, Tiering; Identify Top accounts to go after+Add into the org6
Providing Live Data Intelligence Support Example (Social Insights, PR activity & Persona Movement)
Customer Lookalike Mapping to understand whitespaces & greenfield accounts
Provide support to SPMs and Sales Programs at a segment-level
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 30K - 56K *
589,Product Data Analyst (L3),Twilio,"Bengaluru, India",Mid-level / Intermediate,"See yourself at Twilio
Join the team as our next Product Data Analyst (L3)
Who we are & why we’re hiring
Twilio powers real-time business communications and data solutions that help companies and developers worldwide build better applications and customer experiences.
  Although we're headquartered in San Francisco, we have presence throughout South America, Europe, Asia and Australia. We're on a journey to becoming a globally anti-racist, anti-oppressive, anti-bias company that actively opposes racism and all forms of oppression and bias. At Twilio, we support diversity, equity & inclusion wherever we do business. We employ thousands of Twilions worldwide, and we're looking for more builders, creators, and visionaries to help fuel our growth momentum.
About the job
This position is needed to help uncover and deliver product data, analysis, and insights that empower stakeholders at all levels to maximize the impact of data in decision making. Our team is expanding to provide meaningful, data-backed insights from which to develop and grow our industry leading communications products.
Responsibilities
In this role, you’ll:
Work with product managers to inject data into decision making and planning to increase confidence in strategic business outcomes via defining OKRs, designing and building insight generating reports and dashboards, and partnering cross functionally to source and process product data.
Leverage SQL programming skills and data visualization tools to communicate product insights and recommendations to stakeholders at all levels. Standardize, maintain, and document metrics, models, datasets, and dashboards leveraging tools such as Looker, Tableau, Confluence, Acryl, and code.
Source, identify, and leverage data and insights for time-critical and strategic decision making.
Own and foster stakeholder partnerships by acting as a trusted advisor. 
Collaborate with data producers and consumers during the product development lifecycle to ensure consistent data quality and availability for reporting post launch. 
Qualifications 
Not all applicants will have skills that match a job description exactly. Twilio values diverse experiences in other industries, and we encourage everyone who meets the required qualifications to apply. While having “desired” qualifications make for a strong candidate, we encourage applicants with alternative experiences to also apply. If your career is just starting or hasn't followed a traditional path, don't let that stop you from considering Twilio. We are always looking for people who will bring something new to the table!
  Required:
4-5 years of professional experience performing quantitative analysis, building dashboards and reports, working with business partners to convert ambiguous, messy data into tangible and actionable results that influence product and business impacting decisions in a fast paced industry. 
Intermediate level experience writing, developing, and performing QA in SQL and SQL-like relational data languages (2+ years on a regular basis). 
Demonstrated ability in building reports, metrics, dashboards, etc. for analytics projects that often require data preparation processes such as data extraction, cleansing, mapping, loading and operationalizing workflows in production.
Ability to think strategically and initiate, refine, and complete projects with minimal guidance in an often ambiguous environment.
Experience with modern data visualization tools. Tableau and Looker (LookML) is preferred.
Desired:
Experience or familiarity with data warehousing and/or ETL processes, and distributed computing technologies (Hive/Presto/Spark/Zeppelin) is a plus.
Experience in python (e.g. pandas, numpy, scikit-learn) or R for data manipulation and analysis, including predictive analytics, regression, hypothesis testing, and causal analysis is a plus.
  Location 
This role will be remote, and based in India.
What We Offer
There are many benefits to working at Twilio, including, in addition to competitive pay, things like generous time-off, ample parental and wellness leave, healthcare, a retirement savings program, and much more. Offerings vary by location.
Twilio thinks big. Do you?
We like to solve problems, take initiative, pitch in when needed, and are always up for trying new things. That's why we seek out colleagues who embody our values — something we call Twilio Magic. Additionally, we empower employees to build positive change in their communities by supporting their volunteering and donation efforts.
  So, if you're ready to unleash your full potential, do your best work, and be the best version of yourself, apply now!
  If this role isn't what you're looking for, please consider other open positions.
Twilio is proud to be an equal opportunity employer. Twilio is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Additionally, Twilio participates in the E-Verify program in certain locations, as required by law.
Twilio is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at accommodation@twilio.com.",USD 68K - 111K *
590,Sr. Manager Customer Data Analytics,AGCO,"Bengaluru, KA, IN",Senior-level / Expert,"Do you want to help solve the world's most pressing challenges? Feeding the world's growing population and slowing climate change are two of the world's greatest challenges. AGCO is a part of the solution! Join us to make your contribution.
  Join one of the world leaders in global agriculture engineering Technology. AGCO's consistent efforts to deliver smart farming solutions leveraging technology and engineering prowess has helped create innovative global platforms like Precision AG Technologies.
In Support of AGCO's Farmer First purpose and clear intent of developing innovative technological solutions, we are opening a new digital capability centre located in Bengaluru, India,
The centre would focus on augmenting AGCO's global IT and Digital capability and investment in high-quality technology, innovation, and R&D talent.
The teams will be an integral part of AGCO's global ecosystem. They will work as part of a global cross-function and cross-cultural team, working together to deliver AGCO's purpose to provide Farmer-focused solutions to sustainably feed our world and our vision to be the Trusted partner for industry-leading, smart farming solutions.
""So if you are interested in working for a diverse organization that provides global opportunities, has a vision and purpose to help solve one of the biggest problems of our time and who is on the forefront of innovation, please apply today!""’
  AGCO is looking to hire candidates for the position of Director, Customer Data & Analytics.
The Customer Data & Analytics Lead will drive customer centricity across AGCO’s global customer data analytics through highly impactful, innovative visualizations of CX data, analytics and metrics. This role will define and own the critically important customer data strategy in conjunction with AGCO Strategy & Transformation Data & Analytics Strategy, establishing business data requirements and determining with the brands how that data is acquired and shared across AGCO for marketing purposes in a region. This data will then be used for the creation of insights in customer and NPS analytics which will better help AGCO understand and serve our customers.
Enabling the quality and volume of AGCO’s customer data and insights for analytics and the execution of customer focused analytics as managed by this role will determine the effectiveness of AGCO’s Strategy and differentiation from competition.
This position will be responsible for building a robust process for capturing customer data and defining use cases and growing analytics maturity in the customer data area as well as the ongoing management of this data & analytics focus globally including management of a team who provide data services and analytics insights. The Customer Data & Analytics Lead will work closely with cross-functional business groups, IT, legal and the AGCO analytics hub to ensure an improved customer experience, relevant personal and timely insights, and a more efficient AGCO business by leveraging data and analytics while remaining within the parameters set by GDPR and other legal requirements. The Incumbent will directly supervise, develop and architect go-forward AGCO customer data & analytics use case development and execution under the direction of the Customer Experience Director to continually raise the standards of AGCO customer care resulting in a customer and dealer experience that significantly differentiates AGCO from its competitors. This role will also help use in our data and analytics maturity as we increasingly leverage big data and AI capabilities to execute prescriptive and predictive use cases.
The incumbent is typically a candidate with a background in data science or a related field with proven leadership skills understanding business needs and able to recommend and initiate analytics of customer / market behavior from the integration of multiple sources of data and information to yield improved CX and business growth.
    Your Impact
Define and own the global customer data strategy and key analytics use cases in conjunction with S&T.
Determines data acquisition strategy and drives a compliant approach by region.
Build dealer data integration strategy in conjunction with S&T and align with other data domains.
Determine together with the brands how data is shared across brands for marketing purposes in a region and how analytics insights are implemented for making better customer and business decisions.
Install data quality process and standards metrics.
Determine data quality improvement areas and action.
Identify, prioritize and execute customer analytics use cases.
Work across the P&L teams, IT, and other business functions and build a set of data and analytics requirements from internal digital, marketing, sales, IT and external partners, such as dealers to yield improved CX and business growth.
Build global customer analytics strategy and approach to manage a onetime customer needs segmentation and ongoing review of this segmentation plus proactively drive cx and growth improvements.  Present insights to senior staff in various functions.
Build and manage a process to collect and prioritize CX use case requests for analytics.
Build a sound communication and change management approach to implement use case outcomes and insights to deliver the value of customer data and analytics insights globally.
Develop a highly impactful, innovative way to visualize and communicate CX data, metrics and analytics insights in all AGCO sites easily understood by all levels – including CEO and execute management CX analytics requirements.
Ensure a fast-moving challenging environment for team members to retain and attract the best talent.
Change agent to drive data and analytics driven decision making.
    Your Experience and Qualifications
Years of experience relevant to this position – 9-12 years.
Minimum level of education – Master’s Degree.
Understanding and/or Proficiency in two or more languages/programs: Python and/or R, SQL (Preferred), SAS, Spark, etc.
Understanding of data science and data governance principles and proficiency level in leading data and reporting output.
Industry background are required in relevant field.
Strong cross-functional thinking and communication skills are the other key attributes needed.
Proficiency level in managing and translating analytics requirements and collaborative work style.
Competencies - Strong leadership skills (9 direct reports in different locations), business acumen, good communication at all levels of the organization, Customer first culture, Team player, problem solving, strategic thinker, drives change, structured, process oriented.
Coaching and Developing, Compelling Communication, Driving Execution, Strategic Influence and Planning, Facilitating Change, Business Data and Analytics, Data Science
All CX related KPI’s such as NPS in brands, regions and global, MOT improvements, AGCO Business growth, Market share improvement, data quality metrics.
    Your Benefits
GLOBAL DIVERSITY – Diversity means many things to us, different brands, cultures, nationalities, genders, generations – even variety in our roles. You make us unique!
ENTERPRISING SPIRIT- Every role adds value. We're committed to helping you develop and grow to realize your potential.
POSITIVE IMPACT – Make it personal and help us feed the world.
INNOVATIVE TECHNOLOGIES - You can combine your love for technology with manufacturing excellence – and work alongside teams of people worldwide who share your enthusiasm.
MAKE THE MOST OF YOU – Benefits include health care and wellness plans and flexible and virtual work option……….
    We value inclusion and recognize the innovation a diverse workforce delivers to our farmers. Through our recruitment efforts, we are committed to building a team that includes a variety of experiences, backgrounds, cultures and perspectives.
  Join us as we bring agriculture into the future and apply now!
  Please note that this job posting is not designed to cover or contain a comprehensive listing of all required activities, duties, responsibilities, or benefits and may change at any time with or without notice.
  AGCO is proud to be an Equal Opportunity Employer",USD 45K - 84K *
591,Business Intelligence Engineer II,SIXT,"Bengaluru, India",Mid-level / Intermediate,"Job Description
Responsibilities:
Should be self-sufficient to complete e2e ETL task.
Should be self-sufficient in Technical Documentation and version controlling.
Should be self-sufficient in completing Complicated BI reporting requirement.
Take ownership of different BI requirements coming from certain Line of Business.
Grow in-depth Data Knowledge very quickly.
Produce Business In-sights and produce value added suggestions.
Understand Data Gaps and take initiative to full fill the same.
Work closely with Business and should be able to complete Ad-hoc business analysis.
Should be self-sufficient to complete User story decomposition and logical grouping of task.
Should be self-sufficient in Bug Fixing and subsequent stakeholder communication.
Should be self-sufficient in multiple stakeholder handling.
Qualifications
Must have :- 
Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.
4+ years of relevant experience in Data Engineering
Excellent SQL knowledge
Working Experience with ETL tools (preferable Matillion)
Good knowledge about python
Good knowledge about:
AWS GLUE
Athena
Redshift
AWS IAM
S3
EC2 
Hands on experience with Version controlling (Git)
Good Understanding about BI work flow and reporting. (some idea about how reporting tools works)
Good knowledge about Data warehousing concept, data modelling etc.
Additional Information
Why Choose Sixt?
SIXT is the company with legacy of more than a century offering healthy work environment, friendly work culture and continuous learning. The leadership here believes in team empowerment and challenging opportunities are offered to solve real world problems.
#LI-India
About the department:
Engineers take note: cutting edge technology is waiting for you! We don't buy, we primarily do it all ourselves: all core systems, whether in the area of car sharing, car rental, ride hailing and much more, are developed and operated by SIXT itself. Our technical scope ranges from cloud and on-site operations through agile software development. We rely on state-of-the-art frameworks and architectures and strive for a long-term technical approach. Exciting? Then apply now!
About us:
We are a leading global mobility service provider with sales of €3.07 billion and around 7,500 employees worldwide. Our mobility platform ONE combines our products SIXT rent (car rental), SIXT share (car sharing), SIXT ride (cab, driver and chauffeur services), SIXT+ (car subscription) and gives our customers access to our fleet of 270,894 vehicles, the services of 1,500 cooperation partners and around 1.5 million drivers worldwide. Together with our franchise partners, we are present in more than 110 countries at 2,098 rental stations. At SIXT, a first-class customer experience and outstanding customer service are our top priorities. We focus on true entrepreneurship and long-term stability and align our corporate strategy with foresight. Want to take off with us and revolutionize the world of mobility? Apply now!",USD 65K - 165K *
592,PowerBi Developer,Gainwell Technologies,"Bengaluru, KA, IN, 560100",Mid-level / Intermediate,"Summary
  As a PowerBi Developer at Gainwell, you can contribute your skills as we harness the power of technology to help our clients improve the health and well-being of the members they serve — a community’s most vulnerable. Connect your passion with purpose, teaming with people who thrive on finding innovative solutions to some of healthcare’s biggest challenges. Here are the details on this position.
Your role in our mission
  Make your mark as Gainwell develops innovative, purpose-built technologies and solutions to deliver better health and human services outcomes. 
Support the full life cycle of development activities to assist us in delivering new services and technical products to clients 
Perform as an advisor and individual contributor for product systems, processes, software configuration, network architecture and interface capabilities
Assist in preparing and addressing product requirements by determining usability and implementing change requests to meet business needs
Deploy specific product configurations and bring your skills to overall system design and integration
Participate in user acceptance testing and coordinate product launches into new and existing markets
Get involved in helping define and outline business cases to ensure that our proposed solutions can deliver significant business benefits to clients
What we're looking for
  3 years of experience working with technical products, product configurations, product design and integration
Knowledge of relevant software packages or classes of packages and products within area of technical expertise
Strong analytical and communication skills (written and verbal) to work with other developers, business analysts, project managers and leadership
Ability to understand your role on a team and step up into additional stretch assignments as needed
Ability to work with and influence others to achieve Gainwell’s goals 
What you should expect in this role
  Hybrid Office Environment",USD 76K - 128K *
593,Data Analyst,BharatX,"Bengaluru, Karnataka, India",Mid-level / Intermediate,"Data Analysis & Reporting: Analyze large datasets to extract meaningful insights. Prepare reports and dashboards to present findings to stakeholders.
Credit Risk Modeling: Assist in developing models to assess credit risk and predict financial outcomes.
Market Research: Conduct research to understand market trends and customer needs.
Collaboration with Teams: Work with sales, marketing, and product teams to implement data-driven strategies.
Process Improvement: Identify and recommend improvements in data collection and processing techniques.
Requirements
A minimum of 1-2 years of experience in a data analysis role, preferably in the financial services or B2B sector.
Proficient in data analysis tools (e.g., SQL, Python, R) and visualization software (e.g., Tableau, Power BI).
Experience in credit risk analysis or financial services is a plus.
Strong analytical and problem-solving skills.
Excellent communication and collaboration abilities.
Benefits
Best-in-Class ESOP Policy: You get either equal or better terms than founders for your ESOP Policy
Unlimited Paid-Time-Off: Next time you need time for a loved one's birthday or a trip to Goa with friends, just go. PS: do invite us too.
Bi-Annual Appraisals: When startups grow so fast, why should your financial growth be slow
Insurance for all: You and your family (Spouse, Parents/In-Laws and Children) are all covered with the best insurance policy out there
Maternity and paternity Leave: Because Hey! You both deserve to spend time with the little one",USD 68K - 111K *
594,"Business Intelligence Engineer, LMAQ",Amazon.com,"Hyderabad, Telangana, IND",Mid-level / Intermediate,"When you attract people who have the DNA of pioneers and the DNA of explorers, you build a company of like-minded people who want to invent. And that’s what they think about when they get up in the morning: how are we going to work backwards from customers and build a great service or a great product” – Jeff Bezos
Amazon.com’s success is built on a foundation of customer obsession. Have you ever thought about what it takes to successfully deliver millions of packages to Amazon customers seamlessly every day like a clock work? In order to make that happen, behind those millions of packages, billions of decision gets made by machines and humans. What is the accuracy of customer provided address? Do we know exact location of the address on Map? Is there a safe place? Can we make unattended delivery? Would signature be required? If the address is commercial property? Do we know open business hours of the address? What if customer is not home? Is there an alternate delivery address? Does customer have any special preference? What are other addresses that also have packages to be delivered on the same day? Are we optimizing delivery associate’s route? Does delivery associate know locality well enough? Is there an access code to get inside building? And the list simply goes on. At the core of all of it lies quality of underlying data that can help make those decisions in time. The person in this role will be a strong influencer who will ensure goal alignment with Technology, Operations, and Finance teams. This role will serve as the face of the organization to global stakeholders. This position requires a results-oriented, high-energy, dynamic individual with both stamina and mental quickness to be able to work and thrive in a fast-paced, high-growth global organization. Excellent communication skills and executive presence to get in front of VPs and SVPs across Amazon will be imperative.

Key Strategic Objectives: Amazon is seeking an experienced leader to own the vision for quality improvement through global address management programs. As a Business Intelligence Engineer of Amazon last mile quality team, you will be responsible for shaping the strategy and direction of customer-facing products that are core to the customer experience. As a key member of the last mile leadership team, you will continually raise the bar on both quality and performance. You will bring innovation, a strategic perspective, a passionate voice, and an ability to prioritize and execute on a fast-moving set of priorities, competitive pressures, and operational initiatives. You will partner closely with product and technology teams to define and build innovative and delightful experiences for customers. You must be highly analytical, able to work extremely effectively in a matrix organization, and have the ability to break complex problems down into steps that drive product development at Amazon speed. You will set the tempo for defect reduction through continuous improvement and drive accountability across multiple business units in order to deliver large scale high visibility/ high impact projects. You will lead by example to be just as passionate about operational performance and predictability as you will be about all other aspects of customer experience.

The successful candidate will be able to:
- Effectively manage customer expectations and resolve conflicts that balance client and company needs.
- Develop process to effectively maintain and disseminate project information to stakeholders.


- Be successful in a delivery focused environment and determining the right processes to make the team successful.


- This opportunity requires excellent technical, problem solving, and communication skills. The candidate is not just a policy maker/spokesperson but drives to get things done.


- Possess superior analytical abilities and judgment. Use quantitative and qualitative data to prioritize and influence, show creativity, experimentation and innovation, and drive projects with urgency in this fast-paced environment.

- Partner with key stakeholders to develop the vision and strategy for customer experience on our platforms. Influence product roadmaps based on this strategy along with your teams.

- Support the scalable growth of the company by developing and enabling the success of the Operations leadership team.


- Serve as a role model for Amazon Leadership Principles inside and outside the organization


- Actively seek to implement and distribute best practices across the operation

We are open to hiring candidates to work out of one of the following locations:

Hyderabad, TS, IND
Basic Qualifications

- 2+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
- Experience with data visualization using Tableau, Quicksight, or similar tools
- Experience with scripting language (e.g., Python, Java, or R)
- Experience with descriptive and inferential statistics such as data distribution, measures of central tendencies, Hypothesis testing, correlation analysis etc.
Preferred Qualifications
- Knowledge of data modeling and data pipeline design
- Experience with advanced analytics techniques such as regression, classification, text analytics etc.",USD 65K - 165K *
595,Sr.Associate - Data Scientist,Visa,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Position Summary
We are seeking an innovative and analytical thinker to support our Data Science team in the Middle East and North Africa (MENA) region based in Bangalore, India. As a Data Scientist, you are expected to generate data and business insights, develop predictive and prescriptive models, context-based prototypes, and high impact storyboards to promote a data-driven strategy and solutions approach for the company.

Principal Responsibilities
Serve as an analytics expert in designing, developing and implementing best in analytic solutions
Create and deliver powerful insights from data through better visualization and storyboarding
Collaborate with internal and external partners to fully understand business requirements and desired business outcomes
Demonstrate execution proficiency in handing multiple medium-to-large analytics projects in a team environment that includes the rest of the Data Science team
Draft detailed scope for assigned projects, addressing suggested methodology and analytics plan
Execute on the analytics plan with appropriate data mining and analytical techniques
Perform quality assurance of data and deliverables for work performed by other Data Scientists and self
Ensure all project documentation is up to date and all projects are reviewed per analytics plan
Ensure project delivery within timelines and budget requirements
Build on team’s analytical skills and business knowledge
Enhance existing analytics techniques by promoting new methodologies and best practices in the Data Science field
Provide subject matter expertise and quality assurance of complex data-driven analytic projects
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Professional Experience
• Minimum of 4 plus years of analytics expertise in applying statistical solutions to business problems
• Experience working in one or more of the Card Payments markets around the globe
• Post-graduate degree or phd in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Good knowledge of data, market intelligence, business intelligence, and AI-driven tools and technologies
• Experience planning, organizing, and managing multiple large projects with diverse cross-functional teams
• Demonstrated ability to incorporate new techniques to solve business problems
• Demonstrated resource planning and delivery skills

Technical Expertise
• Experience in distributed computing environments and big data platforms (Hadoop, Elasticsearch, etc.) as well as common database systems and value stores (SQL, Hive, HBase, etc.)
• Ability to write scratch MapReduce jobs and fluency with Spark frameworks
• Familiarity with both common computing environments (e.g. Linux, Shell Scripting) and commonly-used IDEs (Jupyter Notebooks) proficiency in SAS technologies and techniques
• Strong programming ability in different programming languages such as Python, R, Scala, Java, Matlab, C, and SQL
• Experience in drafting solution architecture frameworks that rely on APIs and micro-services
• Familiarity with common data modeling approaches, and ability to work with various datatypes including JSON, XML, etc.
• Ability to build data pipelines (e.g. ETL, data preparation, data aggregation and analysis) using tools such as NiFi, Sqoop, Ab Initio familiarity with data lineage processes and schema management tools such as Avro
• Proficient in some or all of the following techniques Linear and Logistic Regression, Decision Trees, Random Forests, K-Nearest Neighbors, Markov Chain, Monte Carlo, Gibbs Sampling, Evolutionary Algorithms (e.g. Genetic Algorithms, Genetic Programming), Support Vector Machines, Neural Networks, etc.
• Expert knowledge of advanced data mining and statistical modeling techniques, including Predictive modeling (e.g., binomial and multinomial regression, ANOVA) Classification techniques (e.g., Clustering, Principal Component Analysis, factor analysis) Decision Tree techniques (e.g., CART, CHAID)
• Deliver results within committed scope, timeline and budget
• Very strong people/project management skills and experience
• Ability to travel within MENA on short notice
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 86K - 160K *
596,Senior Data Analyst,Ubisoft,"Pune, India",Senior-level / Expert,"Company Description
Ubisoft is a leading developer and publisher of video games worldwide whose brand portfolio covers blockbusters such as Assassin’s Creed, Watch Dogs, The Division, Prince of Persia and Splinter Cell, Ghost Recon, Rainbow Six, Rayman, Just Dance as well as games for the whole family, from Imagine and Petz to Raving Rabbids. To continue building on its achievements for the future, Ubisoft is looking for new talent for its growing Indian studios! 
We have challenging and exciting opportunities for creative minds to develop their expertise and capabilities to grow. At Ubisoft we favor diversity, creativity, and team spirit, and, together, we build success.
If you are excited about solving game-changing challenges, cutting-edge technologies, and pushing the boundaries of entertainment, we invite you to join our journey and help us create the unknown.
Job Description
Job Summary:
Collaborate with QC stakeholders to provide analytical solutions based on a variety of data sources.
Handle and analyze complex game test data and visualize it in a simple manner using various visualization tools.
Using data analytics expertise to provide innovative solutions to various problem statements
Job Responsibilities:
Core Responsibilities
Interprets raw data to provide analytics on QC team performance for a variety of AAA and mobile games.
Creating dashboards for the QC teams internally and the WWQC teams externally
Working with the Project Managers and QC Leads to defining relevant KPIs for measuring game performance.
Working with the team in data collection and identifying the right data source to refer
Analyze QC team coverage using gameplay data
Ensuring continuous communication of KPIs to the QC teams, and maintaining an updated summary of the current view
Maintain and constantly enhance tools, bring new ideas, and employ best practices that define industry standards.
Implementation of analytics tools, best practices, and novel ideas
Query databases to extract relevant data for reporting and analytics
Constantly improving the KPIs to ensure they are relevant and useable in everyday work
Implementation of analytics tools, best practices, and novel ideas
Identify the tools that should be used to analyze data and ensure that they are installed and available to the team
Determine best practices and areas for improvements and automation.
Core Competencies:
Proven ability to determine the best method to place products in the market & experience with metrics-driven decision making
4+ years of experience doing quantitative analysis or comparable (manipulation and analysis of large data sets)
Solid understanding of fundamental statistical approaches for developing intelligent tools
Excellent SQL Skills (experience with MySQL is preferred!)
Good experience with visualization and reporting tools such as Tableau, Power BI, MicroStrategy, and others.
Experience of developing and implementing predictive models
A good quantitative background (mathematics, statistics, computer science, etc...) is highly desired.
Technical Competencies:
Excellent quantitative and analytical abilities with attention to detail
Ability to balance technical and business views
Analytical thinking
Think outside the box to create unique solutions
Good Knowledge of R software / Python.
Knowledge of statistical techniques and data science
Behavioral Competencies:
Highly driven, with a passion for social media and video games
Open for feedback and enjoys working in a fast-paced environment
Excellent organizational skills, self-starter, and autonomy
Excellent verbal and written communication abilities
Ability to work alone on a project or in a collaborative environment
Good interpersonal skills",USD 92K - 145K *
597,Data Scientist,HARMAN International,IN Bengaluru EOIZ Indust Area Campus HCS,Senior-level / Expert,"HARMAN’s engineers and designers are creative, purposeful and agile. As part of this team, you’ll combine your technical expertise with innovative ideas to help drive cutting-edge solutions in the car, enterprise and connected ecosystem. Every day, you will push the boundaries of creative design, and HARMAN is committed to providing you with the opportunities, innovative technologies and resources to build a successful career.
A Career at HARMAN
As a technology leader that is rapidly on the move, HARMAN is filled with people who are focused on making life better. Innovation, inclusivity and teamwork are a part of our DNA. When you add that to the challenges we take on and solve together, you’ll discover that at HARMAN you can grow, make a difference and be proud of the work you do everyday.


Education & Training
• Masters/Bachelors in Computer Science or Electronics and Communication Engineering or related field

Mandatory Skills
• C++ programming experience
• Experience with development on embedded Linux platforms
• Experience in using IPC mechanism like DBus, Thrift etc.,
• Experience in working with Linux embedded platform (Development, Build and Deployment)
• Experience in build tools cmake, make/gmake and cross compilation
• Excellent Communication and Team work skills

Desired Skills
• Experience in working with Automotive Infotainment Head Unit Hardware
• Good knowledge of UML Modelling tools like EA, Rhapsody.
• Good knowledge of Test driven development (Unit and Module testing)
• Good knowledge of SW-Version-Tools like SVN, GIT Knowledge of systems software design, operating systems and architectures
• Proven ability working in Agile Scrum environment using Atlassian tools

Job Responsibilities
• Software Development and Unit Testing
• Optimizing computational applications (such as computer vision, image processing, graphics, machine learning) for architectures such as x86, ARM, NEON, or CUDA
• Conceptualize, architect and prototype software solutions on high performance embedded systems
• Development of SW frameworks and modules for Head Unit
• System requirements analysis and clarification internal in Daimler and with suppliers
• Define and Analyse SW requirements and SW interfaces
• Integration, Build and Release Management of application
• Documentation of High Level, Low Level design, Source code and Unit Tests
• Develop, flash and test the application in Embedded Hardware
• Communication with partners, suppliers and within the team
HARMAN is an Equal Opportunity /Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race,color, religion, sex, sexual orientation, gender identity, national origin,disability or Protected Veterans status. HARMAN offers a great work environment, challenging career opportunities, professional training and competitive compensation. (www.harman.com)",USD 136K - 205K *
598,Data Engineer,Alter Domus,"Hyderabad, IN",Senior-level / Expert,"We are Alter Domus. Our name means “The Other House” and we’re a world leading provider of integrated solutions for the alternative investment industry. We believe in being different. Here, you progress on merit, not who you know. You speak openly, whoever you’re speaking to. And it’s your freedom to decide which cutting-edge kind of finance professional you want to be. Join more than 5,000 fund administration, accounting, tax, loan administration and legal experts worldwide and take pride in being alternative. 
  Alter Domus clients include the world’s leading asset managers, lenders, and asset owners. We’re specialists who use the most innovative technologies to create unparalleled solutions for the private equity, real assets, and debt capital markets sectors. This is where standout talent advances what’s possible in fund administration, corporate services, depositary services, transfer pricing, domiciliation, management company services, loan administration, agency services, trade settlement and CLO manager services.
  As a Senior Data Engineer at AtlerDomus Data and Analytics, you will play a crucial role in shaping our data infrastructure, ensuring data reliability, and driving innovation through the development of data products. You will work closely with cross-functional teams to collect, process, and deliver data to provide insights for our verity of data products. If you are passionate about building scalable data solutions in a cloud environment, have experience with data lake house architectures, and can implement CI/CD practices for data pipelines, this is the role for you.
  Key Responsibilities:
  Cloud Expertise: Design, implement, and maintain data solutions on cloud platforms, such as AWS, Azure, or GCP, ensuring scalability, reliability, and cost-effectiveness.
Data Lake House Architecture: Lead the design and implementation of data lake house architecture, combining the benefits of data lakes and data warehouses for improved data management and analytics.
Data Pipeline Development: Develop and maintain production-grade data pipelines to ingest, process, and transform data from various sources, ensuring data quality and reliability.
Data Pipelines CI/CD: Implement continuous integration and continuous delivery (CI/CD) practices for data pipelines, automating deployment, testing, and monitoring.
Data Product Development: Collaborate with data scientists and analysts to turn data into actionable insights by creating data products, dashboards, and reporting tools.
Data Governance: Establish and enforce data governance best practices, ensuring data security, privacy, and compliance with relevant regulations.
Optimization and Monitoring: Continuously monitor and optimize data pipelines, infrastructure, and CI/CD processes for performance, cost, and scalability.
Documentation and Knowledge Sharing: Document data engineering processes, CI/CD pipelines, and best practices, and actively share knowledge with the team.
Team Collaboration: Work closely with data scientists, analysts, software engineers, and other stakeholders to understand data requirements and deliver data solutions that meet business needs.

Qualifications:
  Bachelor's or master’s degree in computer science, Information Technology, or a related field.
Proven experience (5+ years) as a Data Engineer with a strong focus on cloud-based data solutions.
Extensive hands-on experience with cloud platforms (e.g., AWS, Azure, GCP).
Proficiency in building and maintaining data pipelines using tools like Apache Spark, Apache Airflow, or similar.
Strong programming skills in languages like Python, Java, or Scala.
In-depth knowledge of data lake house architecture principles and best practices.
Experience with big data technologies (e.g., Hadoop, Hive, HBase) is a plus.
Familiarity with data warehousing and SQL-based databases.
Strong experience in implementing CI/CD practices for data pipelines using tools like Github, GitLab CI/CD, or similar.
Excellent problem-solving skills and the ability to work in a fast-paced, dynamic environment.
Strong communication and collaboration skills.
Certifications in relevant cloud technologies and CI/CD practices are a plus.
  #LI-DH1",USD 121K - 188K *
599,Associate Data Engineer,Boeing,"IND - Bengaluru, India",Mid-level / Intermediate,"Associate Data Engineer
Company:
Boeing India Private Limited
Job ID:
00000405038
Date Posted:
2023-12-12
Location:
IND - Bangalore, India
Job Description Qualifications:
Boeing is the world’s largest (Per Boeing LinkedIn page) aerospace company and a leading provider of commercial airplanes, defense, space, and security systems, and global services. Building on a legacy of over a century of innovation and leadership, Boeing continues to lead the way in technology and innovation, customer delivery, and investment in its people and future growth of aerospace. 

In India, Boeing has been a strong partner to the Indian aerospace and defense sectors for more than 75 years. People at Boeing have been supporting mission readiness and modernization of India’s defense forces, and enabling connected, safer, and smarter flying experiences, in the sky, in the seas, and in space. 
Technology for today and tomorrow

The Boeing India Engineering & Technology Center (BIETC) is a 3000+ diverse engineering workforce that contributes to global aerospace growth. Our engineers deliver cutting-edge R&D, innovation, and high-quality engineering work in global markets, and leverage new-age technologies such as AI/ML, IoT, Cloud, Model-Based Engineering, and Additive Manufacturing, shaping the future of aerospace
. 
People-driven culture
At Boeing, we believe creativity and innovation thrives when every employee is trusted, empowered, and has the flexibility to choose, grow, learn, and explore. We offer variable arrangements depending upon business and customer needs, and professional pursuits that offer greater flexibility in the way our people work. We also believe that collaboration, frequent team engagements, and face-to-face meetings bring diverse perspectives and thoughts – enabling every voice to be heard and every perspective to be respected.  No matter where or how our teammates work, we are committed to positively shaping people’s careers and being thoughtful about employee wellbeing. 

At Boeing, we are inclusive, diverse, and transformative.  
With us, you can create and contribute to what matters most in your career, community, country, and world. Join us in powering the progress of global aerospace.

Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.

Boeing India is currently seeking an Associate Data Engineer to join the product development team. The development team provides comprehensive software solutions to rapidly access and visually transform complex engineering and manufacturing product data. Responsibilities include development and maintenance of in-house software applications supporting our business lines.
Good communication skills are needed both verbally and written, to interact with peers and customers. Job requires working within a diverse team of skilled and motivated co-workers to collaborate on results. Other qualities for this candidate are a positive attitude, self-motivated, the ability to work in a fast-paced, demanding environment, and the ability to adapt to changing priorities.

Position Responsibilities: 
Support: With Solution Architects / Data Architecture support solution design for the service layer for APIs and Data Services for Analytics
Lead:  API Development, Data migration using ETL/ADF or other means.
Lead: Develop business logic as needed for developing and consuming API services
Lead: Stakeholder requirements / design for taking the project from scratch to completion.
Lead: SQL query creation for complex business functionalities
Support / Lead: With Domain Data Architect for data pipeline methods / service in support of additional data types from the Data Strategy
Basic Qualifications (Required Skills/Experience): 
Experience with data engineering using Apache Spark [2.4+, 3.1+] & Scala [2.11+] (or Java 11+), Spark SQL, Tuning Spark ETL jobs etc.
Bachelors’ Degree or higher is required as a basic qualification 
Should be proficient with Databases like SQLServer: MS-SQL/T-SQL; Teradata[16.10+]; 
General awareness of other Databases like  ANSI SQL with advanced SQL skills
Experience working with Data Warehouses AND/OR Data Lakes
Working with *nix VMs OR working with containers [docker/podman/lxc etc.], container orchestration platforms [CF/Kubernetes/GKE/AKS]
Shell scripting [sh/bash], knowlege of *nix VM operation and management [Fedora 28+/RHEL 8+/OL 8+]
Source control systems to manage code and repositories [Git/Mercurial]
Experience using continuous integration/deployment tools to continually tweak and deploy code [GitLab-CI other distributed, stateless CI systems]
Preferred Qualifications (Desired Skills/Experience): 
Expertise in using advanced Excel features and functionality, VBA programming with macros
Data modelling – ER mapping, should be able to represent business problems using optimized data structures & schemas 
Data intensive, cloud native application development using the Java/Spring [Boot/Cloud/Data/Security] stack
Experience with task & operation sequencing [manual/using a DAG runner like Airflow]
Typical Education & Experience: 
Typically, 4-8 years related work experience 
Relocation:
This position offers relocation within India based on candidate’s eligibility 
Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.
Relocation:
Relocation is available for eligible candidates, if authorized
Export Control Requirement:
Not an export control position
Safety Sensitive:
This is not a safety sensitive position
Contingent Upon Award Program
This position is not contingent upon program award
Experience Level:
Individual Contributor - 2
Job Type:
Regular
Job Code:
BAUVI2 (B41)",USD 90K - 150K *
600,Senior Data Scientist,BharatX,"Bengaluru, Karnataka, India",Senior-level / Expert,"Collecting and cleansing data from diverse sources for analysis, ensuring high-quality and relevant datasets for effective decision-making.
Exploring and visualising data to uncover insights and trends, using advanced tools and techniques for meaningful data interpretation.
Applying statistical and mathematical techniques to analyze data, providing robust analytical foundations for predictive modeling and inference.
Developing and implementing machine learning and deep learning models, including the adaptation of foundation models to address specific business challenges.
Managing big data infrastructure and carrying out data engineering tasks, ensuring efficient data storage, processing, and retrieval.
Utilising version control for maintaining codebase integrity and collaboration, fostering a collaborative and error-free development environment.
Designing, creating, and supporting AI-driven products, focusing on delivering scalable and impactful AI solutions that meet user needs and business objectives.
Requirements
Minimum 3+ years of experience in a data science role
Proficiency in Python, R, SQL, and Scala and experience using AI Frameworks
Knowledge of SQL and NoSQL database management.
Experience in developing and designing ETLs, Big data pipelines and corresponding infrastructure.
Strong background in data science, statistics, mathematics, and analytical techniques.
Expertise in machine learning and deep learning methodologies, including an understanding of foundation models.
Familiarity with big data technologies and data engineering practices.
Benefits
Best-in-Class ESOP Policy: You get either equal or better terms than founders for your ESOP Policy
Unlimited Paid-Time-Off: Next time you need time for a loved one's birthday or a trip to Goa with friends, just go. PS: do invite us too.
Bi-Annual Appraisals: When startups grow so fast, why should your financial growth be slow
Insurance for all: You and your family (Spouse, Parents/In-Laws and Children) are all covered with the best insurance policy out there
Maternity and paternity Leave: Because Hey! You both deserve to spend time with the little one ",USD 136K - 205K *
601,Sr Data Engineer,Syniverse,India (Bengaluru),Senior-level / Expert,"Syniverse is the world’s most connected company. Whether we’re developing the technology that enables intelligent cars to safely react to traffic changes or freeing travelers to explore by keeping their devices online wherever they go, we believe in leading the world forward.  Which is why we work with some of the world’s most recognized brands. Eight of the top 10 banks. Four of the top 5 global technology companies. Over 900 communications providers. And how we’re able to provide our incredible talent with an innovative culture and great benefits.
Who We're Looking For
The Sr Data Engineer is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems or building new
solutions from ground up. This role will work with developers, architects, product managers and data analysts on data initiatives and ensure
optimal data delivery with good performance and uptime metrics.
-
Some of What You'll Do
Scope of the Role: • Direct Reports: This is an individual contributor role.
Implements enhancements for projects assigned to Common Data Engineering • Create, enhance, and maintain optimal data pipeline architecture and implementations.
• Analyze data sets to meet functional / non-functional business requirements. • Identify, design, and implement data process: automating processes, optimizing data delivery, etc.
• Build infrastructure and tools to increase data ETL velocity.
• Work with data and analytics experts to implement and enhance analytic product features. Provide life cycle support the Operations team for existing products, services, and functionality assigned to the Data Engineering team.
Bachelor’s degree in Computer Science, Statistics, Informatics or related field or equivalent work experience. • 5+ years of Software Development experience, including 3+ years of experience in Data Engineer fields.
• Familiar with Agile software design processes and methodologies. Experience in building and optimizing big data pipelines, architectures, and data sets:
○ Experience with big data tools: Hadoop, Spark, Kafka, etc.
○ Experience with relational SQL databases, such as PostgreSQL, MySQL, etc.
○ Experience with stream-processing systems: Flink, KSQL, Spark-Streaming, etc.
○ Experience with programming languages, such as Java, Scala, Python, etc.
○ Experience with cloud data engineering and development, such as AWS, etc. • • Good analytic skills related to working with structured and unstructured datasets.
• Knowledge of message queuing, stream processing and scalable big data stores.
• Ownership/accountability for tasks/projects with on time and quality deliveries.
• Good verbal and written communication skills.
• Teamwork with independent design and development habits. • Work with a sense of urgency and positive attitude.
#LI-hybrid
-
Why You Should Join Us
Join us as we write a new chapter, guided by world-class leadership. Come be a part of an exciting and growing organization where we offer a competitive total compensation, flexible/remote work and with a leadership team committed to fostering an inclusive, collaborative, and transparent organizational culture.
At Syniverse connectedness is at the core of our business. We believe diversity, equity, and inclusion among our employees is crucial to our success as a global company as we seek to recruit, develop, and retain the most talented people who want to help us connect the world.
Know someone at Syniverse?
Be sure to have them submit you as a referral prior to applying for this position.",USD 121K - 188K *
602,Senior Analyst - Business Intelligence,Marsh McLennan,Mumbai - Hiranandani,Senior-level / Expert,"Company:
Guy Carpenter
Description:
MMGS India Pvt. Ltd. is a part of Marsh McLennan companies which is a global leader in risk, strategy and people. With roots dating back to 1871, MMC today is formed of 4 large global organizations – namely Marsh, Mercer, Guy Carpenter and Oliver Wyman.
Guy Carpenter India Knowledge Services team is seeking candidates for the following position based in the Mumbai office:

Graduate Trainee
What can you expect?
A data-intensive position, the role requires (re)insurance risk identification based on broader financial analysis through the lens of capital, growth and volatility, to enable informed business decision for Property & Casualty (re)insurance industry.
What is in it for you?
The trainee will deliver support for Guy Carpenter’s Business Intelligence team
Work closely with senior colleagues in Business Intelligence team, part of the Global Strategic Advisory (GSA) arm of Guy Carpenter
Build specialized understanding of (re)insurance markets globally
We will count on you to:
Apply deeper understanding of macro economic, financial/ statutory accounting (GAAP/ IFRS) and sector (re)insurance information for output generation
Retrieve and comprehend (re)insurance financial data to build outputs/ dashboards (Power Bi, other)
Synthesize varied financial information quickly and look for high level patterns/themes
To prod at facts - starts with asking/framing questions; use judgement and subsequently attempt to develop logical answers
Document, produce and communicate analysis
What you need to have: 
Excellent analytical and problem solving skills
Attention to details. Ability to understand financial data quickly and creatively.
A positive mind-set to question analytical output, challenge, identify and to develop creative outputs.
MS in Economics or MBA Finance from a well accredited university. CFA/FRM an added advantage.
What makes you stand out?
Enthusiastic, Energetic & love for working with data & numbers in a quest to solve business problems
Guy Carpenter & Company, LLC is a leading global risk and reinsurance specialist with more than 3,100 professionals in over 60 offices around the world. Guy Carpenter delivers a powerful combination of broking expertise, trusted strategic advisory services and industry-leading analytics to help clients adapt to emerging opportunities and achieve profitable growth. Guy Carpenter is a business of Marsh McLennan (NYSE: MMC), the world’s leading professional services firm in the areas of risk, strategy and people. The company’s 85,000 colleagues advise clients in over 130 countries. With annualized revenue of over $20 billion, Marsh McLennan helps clients navigate an increasingly dynamic and complex environment through four market-leading companies including Marsh, Mercer and Oliver Wyman. For more information, visit www.guycarp.com and follow Guy Carpenter on LinkedIn and Twitter @GuyCarpenter
Marsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people regardless of their sex/gender, marital or parental status, ethnic origin, nationality, age, background, disability, sexual orientation, caste, gender identity or any other characteristic protected by applicable law.",USD 45K - 84K *
603,Senior Data Engineer,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
1. Design, build, test, and maintain highly scalable data platforms, ensuring that these systems meet business requirements and industry best practices.
2. Incorporate new data engineering technologies into existing systems, to help move data across systems.
3. Create custom data pipelines and solution components that extract, cleanse, transform, move, and aggregate data across various enterprise systems
4. Identify potential opportunities for data acquisition and explore new uses for existing data.
5. Develop processes and standards for common data models, and data mapping across systems.
6. Use a range of ETL tools, Data integration platforms, and underlying languages and tools to integrate disparate data systems effectively.
7. Leverage data virtualization technologies for data aggregation and unification from multiple, disparate data sources, without the use of any ETL.
8. Recommend ways to improve data reliability, efficiency, and quality.
9. Foster collaboration with data architects, modelers, and IT team members on project goals.
10. Provide technical leadership and consultation on complex projects involving data management, data virtualization, and unification. Qualifications:
11. Bachelor’s/Master’s degree in Computer Science, Data Science, Information Systems, or a related field.
12. Minimum of 5 years of experience in a data engineering role, with a focus on data management and data pipeline construction.
13. Demonstrable experience with data engineering solutions, including data aggregation, data transformation, data movement, and data unification strategies.
14. Proficiency with Data Lakes built on Cloud Services such as Azure and AWS – e.g., ADLS (Azure Data Lake Storage Gen2),
15. Proficiency with cloud platforms, and cloud services, on at least 1 major enterprise cloud (Azure or AWS Cloud)
16. Solid exposure to and experience with data virtualization technologies and platforms, particularly the Denodo platform, is highly preferred.
17. Proficiency with data orchestration services and data workflow platforms – e.g., Apache Airflow, highly preferred.
18. Proficiency in scripting and data intensive languages like SQL, Python, etc.
19. Experience with big data frameworks and associated languages / toolsets is nice-to-have",USD 121K - 188K *
604,Data Engineer,Novo Nordisk,"Bengaluru, Karnataka, IN",Senior-level / Expert,"    Department: Global Security Operations (GSO)
  At Novo Nordisk, we strive to be at the forefront of digital healthcare and to succeed with this, we need many bright minds. Working directly or indirectly with all parts of Novo Nordisk Globally, you will play a significant part in leading Novo Nordisk towards the future of digital healthcare securely. Do you have what it takes to succeed in this role? Then, join a growing team, working in an international environment. Apply now!
  About the department
Global Information Security, GBS is an area within Digital Data and IT GBS. Global Information Security, GBS is an integral part of Global Information Security Organisation of Novo Nordisk which is headed by the CISO (Chief Information Security Officer) and consists of two main areas: Global Security Operations (GSO) and Global Information Security Advisory (GISA). In GIS (Global Information Security) GBS (Global Business service), we work closely with Global Information Security organisation in defining and executing on strategy to support the digital journey of Novo Nordisk by ensuring smooth operations of SOC, Service Management, advisory support, Security Mailbox, and various other Information Security functions.
  The Position
As a Security Specialist you will be anchored to  and support the Global Security Operations mission with Global Information Security.  It includes,
Building and maintaining interfaces between enterprise applications, infrastructure, and security systems.  Examples include ServiceNow, Splunk, Sentinel, Qlik, PowerBI, AWS, Azure, Anomali, Cribl, Trellix, and Tenable products and delivering Data analytics, detections, and automation through SIEM/SOAR content development (Alerts and Signatures) and maintenance.
Gathering and tracking stakeholder requirements and applying fundamental knowledge of Cloud IAAS/SAAS/PAAS platforms to deliver solutions for data collection and analysis and record, track, and maintain their work items within a work management system such as Azure DevOps.
Quickly learning the basics of new security platforms and discovering how to integrate with new data sources to configure, gather, and tune security alerts and events from diverse services and softwar and documenting their work and commenting code sufficiently to communicate critical details for others to pick up the work and develop further if required.
Metrics and reporting through maintenance of data connections, data warehousing, and reporting within BI Platforms.
Working independently with minimal guidance and oversight and is adept and finding solutions that often arise through the course of development and operations.
  Qualification
Bachelor’s degree in computer science, cyber security, engineering, or other relevant fields.
6-8 years’ experience within IT and relevant 4+years development experience as a primary responsibility. 
Preference will be given to individuals experienced with JavaScript and Python.
Experience on SIEM/SOAR platforms is preferred
Fundamental knowledge of and experience working with Information Security is preferred.
Foundational Knowledge of Major operating systems in general, and experience developing and operating in Linux operating systems is a must.
Experience in Qlik Sense or Power BI and Azure or AWS is preferred.
Experience with source code version control systems and API integrations is required.
Experience with common platforms such as Office 365, ServiceNow, Azure DevOps is highly preferred.
Experience administering and building complex queries and working in an enterprise scale IT operations environment highly preferred.
Excellent communication in English and stakeholder management skills.
  Working at Novo Nordisk
We are a proud life-science company, and life is our reason to exist. We’re inspired by life in all its forms and shapes, ups and downs, opportunities, and challenges. For employees at Novo Nordisk, life means many things – from the building blocks of life that form the basis of ground-breaking scientific research, to our rich personal lives that motivate and energies us to perform our best at work. Ultimately, life is why we’re all here - to ensure that people can lead a life independent of chronic disease.
  Contact
To submit your application, please upload your CV online (click on Apply and follow the instructions).
  Deadline
11- December- 2023
We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 121K - 188K *
605,Data Scientist 2,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
The Automotive practice within Epsilon accelerates and drives growth for major players of the automotive industry, from Original Equipment Manufacturers (OEM) to Dealers big and small in the US and Canada. Part of a 1,600-member global team, the practice offers the automotive world’s largest service reminder platform along with agency services and digital media solutions. A leader in the automotive space, the team supports over 50% dealers in the US and manages 280M+ customer vehicle relations.
The Automotive Data Science team within Epsilon partner with both internal and external clients and data providers, leverage predictive analytics and advanced modeling techniques to drive strategic thought and effective decision making. The core work charter includes supporting Retail and After Sales Service businesses for all the OEMs by developing solutions across the Customer Journey to drive Acquisition, Engagement, Retention using Advanced Analytics, Machine Learning, Deep Learning Capabilities and Data Platforms.
The Data Scientist, II would support stakeholders by deploying projects from inception to insights and enable business strategy and impact for the clients. Contributes towards automation, process improvement and efficiency. Demonstrates innovative thinking, passion, and cross team collaboration. Establish strong working relationship with stakeholders.
Roles and Responsibilities
Deliver end to end Data Science projects including understanding of business requirements, exploratory data analysis, data processing, aggregating data, feature engineering, building, and validating predictive models, explaining model results and insights.
Use AI, ML, DL techniques such as regression, classification, clustering, tree-based algorithms, support vector machine, and neural networks, recommender system, attribution modeling to address business problems.
Improve upon existing methodologies by developing new data sources/features, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytical capabilities, platforms, and pipelines.
Present insights and recommendations to audiences of varying levels of technical sophistication
Automate processes to ensure scalability of solutions by collaborating with cross-functional teams.
Perform the extraction, transformations, and loading from the source systems and the data lake to the analytics products using independently developed logic.
Enhance data maturity and integration for Epsilon projects by interacting with operations to standardize the core value-add functionality, enabling a multiplier effect experience working within a collaborative team.
Challenge the status quo with entrepreneurial innovation in curating new data sources, elevating analytics beyond data reporting and dashboarding to delivering actionable insights.
Qualifications
Master’s or Bachelor’s Degree in a quantitative discipline (Statistics, Economics, Mathematics, Data Science, Business Analytics).
2-4 years of experience as a Data Scientist deploying Data Science projects.
2+ years of coding skills in Python, SAS, SQL, and YAML.
Deep understanding and hands-on experience with ML and DL Algorithms.
Experience of working with large data sets and developing scalable solutions.
Knowledge of Automotive, Marketing Business, E-Commerce, Digital transformation is preferred.
Ability to work independently and deal with ambiguity.
Strong analytical and problem-solving skills.
Excellent presentation and communication skills.
Strong written and verbal communication skills.
Highly motivated and collaborative team player with strong interpersonal skills.",USD 128K - 199K *
606,Senior AI/ML Engineer,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems.
Thorough understanding of software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.
Strong programming skills in Python, Scala, Go, Rust or other languages.
Excellent written and verbal communication skills and interpersonal skills.
Experience with MLOps platforms, such as Kubeflow or MLFlow.
Experience with ML frameworks, such as scikit-learn, Tensorflow, PyTorch.
Experience with Big Data tools – Spark, S3, Athena/Trino.
Experience with GenAI tools, such as Langchain, LlamaIndex, and open source Vector DBs.
Advanced degree in Computer Science, Machine Learning or related field.
A minimum of 5 years experience in AI/ML engineering, with a track record of handling increasingly complex projects.
Qualifications
B.E/B.Tech
Additional Information
5-9 Years",USD 174K - 276K *
607,Senior Manager Data Engineering,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value.
Job Description
As Senior Manager in Data Engineering, you would be responsible for defining and executing data strategy for clients. Your role would be focused on high-quality strategy, definition, and delivery of solutions involving:
Data Integration, Governance & Wrangling
Data Storage and Computation Frameworks, Performance Optimizations
Analytics & Visualizations
Infrastructure & Cloud Computing
Data Management Platforms
The role requires a hands-on technologist with expertise in databases, Hadoop, MDM and reporting to provide strategic and tactical direction to customers in the areas of marketing and technology. The person should have a strong programming background like Java.
As a data engineering practitioner, you should have a point of view and understanding of build vs. buy, performance considerations, hosting, business intelligence, reporting & analytics. Ideally, you have experience in integrating data with marketing scenarios like segmentation, targeting, consumer 360 view, etc.
Responsibilities:
Provide inputs to define and execute strategic roadmap for enterprise data architecture by identifying the current landscape and future business goals
Provide technical leadership and hands-on implementation role in the areas of data techniques including data access, integration, modeling, visualization, mining, design and implementation
Lead a globally distributed team to deliver high quality solutions. Manage functional & non-functional scope and quality
Help establish standard data practices like governance and address other non-functional issues like data security, privacy and quality
Help establish best practice like standards and guidelines for design & development, deployment, support and analytics and mining
Help establish best practice in acquiring, storing and analyzing structured, semi-structured and un-structured data from the enterprise and outside like social
Come up with analytics solutions based on the business goals and appropriate data visualization to support the goals
Manage and provide technical leadership to large data programs or multiple programs implementation based on the requirement using agile technologies
Define and drive key transformational programs like customer 360 degree view for the clients
Functional understanding related to digital marketing & customer experience solution blocks, Master data Management (MDM), Customer Relationship Management (CRM), Campaign Management, Tag Management, Media Buying, Optimizations, Recommendations & Targeting, DMP, and DSP.
Understanding Digital data sources such as Open source data (ex: Facebook, Twitter, LinkedIn etc.), Web log Data (SiteCatalyst, Google Analytics), 3rd party paid data (ex: Acxiom, ACNielsen etc.) and business application data (CRM, Ecommerce etc.)
Run workshops with clients and align client stakeholders to optimal solutions
 Qualifications
12+ years of experience within the field of data engineering
Excellent understanding of data technologies landscape
Well versed with pros and cons of various database technologies like Relational, NO SQL, MPP, Columnar databases
Well versed with Software as a service, Platform as a service and Infrastructure as a service concepts and can drive clients to a decision
Expert in programming languages like Java, Scala and / or JavaScript
Expert in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models
Expert in one or more ETL, BI, Analytics and advanced visualization technologies
Expert in in Hadoop eco-system with one or more distribution like Cloudera and HortonWorks
Expert in agile development with CI / CD pipeline with data projects
Knowledge in computation frameworks like Storm and Spark
Knowledge in cloud and social media technologies and integrations
Expert in master data management and building customer 360 degree views
Strong analytical and problem solving skills
Strong communication skills verbal, written and visual presentations
Strong coordination and negotiation skills
Multi geo experience and distributed delivery experience in large programs
Business Knowledge:  Data driven marketing experience would be a plus
Additional Information
Benefits of Working Here:
Gender-Neutral Policy.
18 paid holidays throughout the year for NCR/BLR (22 For Mumbai).
Generous parental leave and new parent transition program.
Flexible work arrangements.
Employee Assistance Programs to help you in wellness and well being.",USD 121K - 188K *
608,Lead Data Scientist,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
The Automotive practice within Epsilon accelerates and drives growth for major players of the automotive industry, from Original Equipment Manufacturers (OEM) to Dealers big and small in the US and Canada. Part of a 1,600-member global team, the practice offers the automotive world’s largest service reminder platform along with agency services and digital media solutions. A leader in the automotive space, the team supports over 50% dealers in the US and manages 280M+ customer vehicle relations.
The Automotive Data Science team within Epsilon partner with both internal and external clients and data providers, leverage predictive analytics and advanced modeling techniques to drive strategic thought and effective decision making. The core work charter includes supporting Retail and After Sales Service businesses for all the OEMs by developing solutions across the Customer Journey to drive Acquisition, Engagement, Retention using Advanced Analytics, Machine Learning, Deep Learning Capabilities and Data Platforms.
The Lead Data Scientist would support stakeholders by deploying projects from inception to insights and enable business strategy and impact for the clients. Contributes towards driving efficiency through process improvement and automations. Demonstrates subject matter expertise, innovative thinking, passion, and cross team collaboration. Establish strong working relationship with stakeholders, coach and develop junior data scientists in the team.
Roles and Responsibilities
Deliver end to end Data Science projects including understanding of business requirements, exploratory data analysis, data processing, aggregating data, feature engineering, building, and validating predictive models, explaining model results and insights.
Use AI, ML, DL techniques such as regression, classification, clustering, tree-based algorithms, support vector machine, and neural networks, recommender system, attribution modeling to address business problems.
Improve upon existing methodologies by developing new data sources/features, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytical capabilities, platforms, and pipelines.
Present insights and recommendations to audiences of varying levels of technical sophistication
Automate processes to ensure scalability of solutions by collaborating with cross-functional teams.
Coach junior data scientists and support delivering projects.
Qualifications
Master’s or Bachelor’s Degree in a quantitative discipline (Statistics, Economics, Mathematics, Data Science, Business Analytics).
8-10 years of experience as a Data Scientist deploying Data Science projects.
7+ years of coding skills in Python, SAS, and SQL.
Deep understanding and hands-on experience with ML and DL Algorithms.
Experience of working with large data sets and developing scalable solutions.
Knowledge of Automotive, Marketing Business, E-Commerce, Digital transformation is preferred.
Ability to work independently and deal with ambiguity.
Strong analytical and problem-solving skills.
Excellent presentation and communication skills.
Strong written and verbal communication skills.
Highly motivated and collaborative team player with strong interpersonal skills.",USD 56K - 172K *
609,Senior Data Science Analyst (R-15489),Dun & Bradstreet,Hyderabad - India,Senior-level / Expert,"Why We Work at Dun & Bradstreet
Dun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!

Key Responsibilities:
*Work across range of Analytical Solutions that includes Design, Development, Validation, Calibration, Documentation, Implementation, Monitoring, and Reporting
*Generate Analytical Insights on various customer portfolios
*Develop Predictive Solutions using advanced statistical techniques to enable better decision making
*Utilize latest data science techniques across both supervised and unsupervised machine learning methodologies, NLP and development of new capabilities
*Serve as a Subject Matter Expert on using Machine Learning techniques
*Collaborate with Technology teams to implement analytical solutions and models
*Work with stakeholders in providing additional analysis based on specific needs

Key Requirements:
*5 to 8 years of relevant experience in Data Analytics / Data Science roles
*Strong programming skills in tools such as Pyspark, Python, R, SQL to manipulate data and conduct statistical analysis
*Knowledge of Python packages and tools
*Sound Knowledge and proven experience on application of Statistical / Machine Learning Techniques
*Experience in BFSI domain / Statistical Modelling & Validation is an added advantage
*Ability to interpret and translate data into meaningful business insights
*Excellent verbal, written communication and presentation skills
All Dun & Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html. Official communication from Dun & Bradstreet will come from an email address ending in @dnb.com.

Notice to Applicants: Please be advised that this job posting page is hosted and powered by Lever. Your use of this page is subject to Lever's Privacy Notice and Cookie Policy, which governs the processing of visitor data on this platform.",USD 45K - 84K *
610,Senior Data Engineer,Aptos,India - Bengaluru,Senior-level / Expert,"Making a job change is a big decision. Why consider Aptos?
You will join a team of remarkable colleagues who are committed and passionate about creating and delivering leading-edge solutions to the retail market. You will be part of an exciting growth journey where we will do everything possible to help you reach and exceed your career dreams. Our colleagues have access to industry-leading training and development opportunities, and the chance to work in a global, diverse culture with offices in 13 countries. You will be part of an inclusive culture that is grounded in our Company's purpose: to make a difference for every colleague, every client, every day.
With years of deep retail DNA, Aptos has been a market-leading platform that drives the world’s largest retailers’ product, promotion, commerce and merchandising decisions across online and brick-and-mortar operations. The opportunity at Aptos has never been greater, as we transition our solutions to cloud-native, microservices architecture. More than 135,000 retail locations impact nearly $2 trillion in annual revenue across fashion, grocery, drug, convenience, general merchandise, discount and sporting goods stores optimized with Aptos’ solutions. We hope you’ll be a part of taking innovative solutions to market with the leader in Unified Commerce.
Aptos develops highly advanced solutions on the forefront of retailing for more than 500 of the world’s most iconic brands. Over 33,000 retail locations and $200B+ in annual revenue across grocery, drug, convenience, general merchandise, discount, sporting goods, fashion, and eCommerce sites optimize with Aptos’ solutions.
Aptos acquired Revionics in September 2020. Revionics software powers some of the largest and best-known retailers in the world, delivering AI/ML-driven retail pricing and promotions across all products and every store.
Revionics is investing in their Data Platform and is growing the team in India. The engineering team is hiring a Senior Data Engineer in the Bengaluru office. You don’t need to know anything about AI/ML to be successful, but if you find the domain interesting, you will love being in this environment!  
About the role:
Senior Data Engineer role in the DPE team is responsible for building end-end data pipelines using cloud-native architecture
Who You Are
Bachelor's degree in computer science or equivalent STEM field, or equivalent work experience
You have 3+ years of experience in building scalable data pipelines
Experience with big data technologies likes Spark and demonstrated experience in languages like Python/Scala (or similar) 
Experience with different non-relational (MongoDB or similar) and relational technologies (SQL)
Exposure to orchestration tools (e.g. Luigi, Airflow, Kubeflow etc.) 
You display ownership, team-spirit, are a clear communicator, can lead cross-functionally and with empathy
  What You'll Do
In this role, you will be defining and developing modular data pipelining solutions to feed the AI/ML systems that power Revionics’ pricing products
Work with Product and Science teams to build data products that enable some of the largest retailers in the world to consume and build upon Revionics’ AI/ML platform.
Collaborate with data operations to build native observability services that meet the high bar in terms of visibility and precision for AI/ML software.
Continually improve our technical stack and processes
We also look for
Passion
Initiative and a Pioneering Spirit
Quality orientation
Resourcefulness and application
We offer a competitive total rewards package including a base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. 
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. By submitting an application for this job, you acknowledge that any personal data or personally identifiable information that you provide to us will be processed in accordance with our Candidate Privacy Notice.",USD 121K - 188K *
611,"Analyst, Provider data management",Evolent,Pune,Entry-level / Junior,"Your Future Evolves Here
Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference working in everything from scrubs to jeans.
Are we growing? Absolutely and Globally. In 2021 we grew our teams by almost 50% and continue to grow even more in 2022. Are we recognized as a company you are supported by for your career and growth, and a great place to work? Definitely. Evolent Health International (Pune, India) has been certified as “Great Places to Work” in 2021. In 2020 and 2021 Evolent in the U.S. was both named Best Company for Women to Advance list by Parity.org and earned a perfect score on the Human Rights Campaign (HRC) Foundation’s Corporate Equality Index (CEI). This index is the nation's foremost benchmarking survey and report measuring corporate policies and practices related to LGBTQ+ workplace equality.
We recognize employees that live our values, give back to our communities each year, and are champions for bringing our whole selves to work each day. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.
What You’ll Be Doing:
Job Description
Evolent Health is looking for a Provider Data Analyst to be a key member of the PDM Shared Services team. This Provider Data Analyst will work with both internal and external business partners to implement ongoing operational monitoring, resolve service barriers, develop solutions to improve effectiveness and identify continuous improvement initiatives to increase service levels.
Essential functions
Serve as a liaison between TPA/BPO partner, internal team members and partner organization providing support for Provider Data Management activities; acts as liaison with fellow Analyst/Technology team and business product team members.
Defines analysis methodology and provides analytic support.
Analyzes existing systems to recommend enhancements and creates new systems to reduce manual processes and maximize the business efficiencies.
Analyzes data from conceptualization through presentation and requires proficiency with analytical tools, knowledge of data analysis methodology, use of presentation software, and strong communication skills
Identifies, evaluates, and implements new data-driven strategies and processes for the department.
Develops tools and reports that lend valuable insights that capitalize on a combination of internal and external data.
Recommends enhancements to existing systems in accordance to business needs by creating ad hoc and standard reports as well as information delivery technologies.
Prepare reports in an accurate, concise and timely fashion.
Performs data collection, analysis, reporting.
Provide guidance and support to all claims and operations personnel towards resolution of provider data and claims problems with an emphasis on root cause analysis and resolution of problems
Compile, review and analyze management reports and take appropriate action
Identify and advise Claims, Provider Network Management, Medicare Operations and other operational areas of trends, problems, and issues as well as recommended course of action; ensure timely communication; participate in the development and implementation of solutions.
Monitor adherence to the efficiency and service level goals including volume, processing, timeliness, accuracy and other metrics.
Compose, submit and track claim system questions and configuration requests to correct identified systemic issues.
Prioritize issues identified by TPA/BPO, internal team members and/or partner representatives and monitors progress in the resolution of the issues.
Develop deep understanding of processing capabilities and limitations of claims and benefits with TPA/BPO systems, tools and resources; provide recommendations to meet plan requirements.
Confirm that all provider data elements have been set up within the claims payment system and are aligned with the requirements as specified by the plan materials.
Create and report operational tracking metrics and dashboards for monitoring claims, provider disputes and benefits performance.
Coordinate corrective action plans with partner/client and TPA/BPO operations services administrator to resolve issues.
Support internal team members and Lead Analyst with the resolution of daily issues.
Work with other departments to identify and resolve problems leading to incorrect provider data and issues regarding payment of claims.
Serve on various committees and attends required meetings.
Able to commute up to 15% to Evolent offices.
Perform other duties and projects as assigned
Key competencies/skill/success factors:
Hands-on experience is creating python scripts and must have knowledge on Python Libraries NumPy and Pandas.
Experience working within a health plan, managed care organization, provider operated healthcare environment or third party administrator.
Extensive knowledge of PCs and related software applications, such as Word, PowerPoint, Excel, Project.
Demonstrated exceptional active listening and communications skills
Experience in systems and languages related to database lifecycle management such as MS Access, SQL Server, Visual Basic, etc.

Qualification and Experience:
Required
Associates Degree or equivalent
2-4 years of experience in collecting, analyzing, and presenting data and recommendations to management
Big plus
Bachelor’s degree in Computer Science, Statistics, Mathematics or related field.
1-3 years data analysis and business intelligence experience working with BI suites such as Qlikview, SSRS, Tableau, Power BI or other enterprise class tools
Experience with Medicare Advantage plan
Mandatory Requirements:
We require that all employees have the following technical capability at their home: High speed internet over 10 Mbps, the ability to plug in directly to the home internet router. These at-home technical requirements are subject to change with any scheduled re-opening of our office locations.
Evolent Health is an equal opportunity employer and considers all qualified applicants equally without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, or disability status.",USD 22K - 42K *
612,"Vice President, NLP Engineer, Gen AI- Portfolio Management Group",BlackRock,HA3-Gurgaon - DLF Cyber City,Executive-level / Director,"About this role
Business overview:
Data Strategy & Solutions is a Global Research & Data team within BlackRock Portfolio Management Group (PMG) focused on developing AI powered products and generating actionable insights using alternative, primary and big data. We are seeking an experienced Data Scientist, with experience in Large Language Models, Natural Language Processing, (NLP), and Transformer Models, to spearhead the build-out of AI powered capabilities within Investment Research, Product Strategy, and Process Optimization.
There are four groups within Data Strategy & Solutions – Investment AI, Insights & Data Products, Solutions, and Platform. All these groups work towards various aspects of Alpha Generation using Alternative data for a host of portfolio management functions.
As a member of Investment AI, you will be working with Investment Researchers, and Portfolio Managers to build capabilities that enable alpha generation and streamlining research processes using Generative AI and Natural Language understanding techniques.
Job Purpose/Background:
Data Strategy & Solutions is looking for a dynamic individual to join their Investment AI team. The primary job responsibilities include research and development of language models including large language model to capture and extract unstructured data from varied sources & reports and build out of quantitative/ML based components for generating alpha.
Familiarity with following areas is essential:
Natural language processing solutions on any domain
Language models like transformers, BERT, LSTM, RNN etc.
Large language models and underlying transformer/attention architecture
Key Responsibilities:
Lead the design and development of Products and capabilities powered by multimodal generative AI models
Conduct research and execute Generative AI and Machine Learning models revolutionizing towards Alpha generation, client experience, and productivity.
Work with cross-functional teams to understand and scope requirements and implement innovative solutions.
Lead the technical build and evaluation of Proof of Concepts and MVP towards Production Product
Act as an expert on large language models/ Natural language processing of large amounts of unstructured data
Building estimation approaches for missing data and application of statistical techniques for generating curated analytics using data & model outputs
Support internal validation process through benchmarking analysis / research, user engagement and comprehensive documentation of models
Additional responsibilities include working on techniques for synthetic data generation, accuracy, etc.
Skills & Qualifications:
Master’s level education with a focus on statistics, mathematics, engineering, computer science, computational physics, or economics
4+ years of experience in building natural language processing and natural language understanding solutions for challenging real world problems
Project experience with the modern Transformer/Attention architecture for text summarization, vectorization, entity extraction and reasoning
Experience with emerging Large Language Model offerings from Open AI, Google, Anthropic, and other industry leaders
Experience in python & related framework/libraries needed for NLP/LLM’s, knowledge of algebraic modelling languages
Experience with advanced statistical modeling for outlier detection, estimation of missing data, generation of synthetic data
Understanding of investment strategies and asset classes is a plus.
Experience in various modelling techniques such as balance sheet modeling, econometrics / statistical analysis, mathematical optimization, is desirable
Strong analytical skills, attention to detail, and the ability to work as part of a team in a fast-paced environment
Excellent interpersonal, oral, and written communication skills
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 71K - 200K *
613,"Analyst/Associate, Data Engineering- Gen AI",BlackRock,HA3-Gurgaon - DLF Cyber City,Entry-level / Junior,"About this role
Business Overview:
Data Strategy & Solutions team is a Global Research & Data team within BlackRock Portfolio Management Group (PMG) focused on developing AI powered products and generating actionable insights using alternative, primary and big data. We are seeking an experienced Data Scientist, with experience in Large Language Models, Natural Language Processing, (NLP), and Transformer Models, to spearhead the build-out of AI powered capabilities within Investment Research, Product Strategy, and Process Optimization.
There are four groups within Data Strategy & Solutions – Investment AI, Insights & Data Products, Solutions, and Platform. All these groups work towards various aspects of Alpha Generation using Alternative data for a host of portfolio management functions.
As a member of Investment AI, you will be working with Investment Researchers, and Portfolio Managers to build capabilities that enable alpha generation and streamlining research processes using Generative AI and Natural Language understanding techniques.
Job Purpose/Background:
Data Strategy & Solutions is looking for a dynamic individual to join their Investment AI team. The primary job responsibilities include research and development of language models including large language models to capture and extract unstructured data from varied sources & reports and build out of quantitative/ML based components for generating alpha.
As a Data Engineer in the Investment AI team you will: -
Work alongside Data Scientists, Investors, and other Data Engineers in partner teams to design and build scalable, automated platforms for rapid experimentation and build-out of Generative AI applications.
Scope out and productionize infrastructure and tooling to support scalable cloud-based applications
Specific Responsibilities:
Ensuring the required data is available for product development, testing, rapid experimentation
Experience in integrating data from varied sources both on-prem and cloud
Understanding of on-prem data landscape as well as external unstructured data
Develop, deploy, and maintain optimized and automated data pipelines at scale
Working as part of a multi-disciplinary squad to establish our next generation of data pipelines and tools for large structured and unstructured data
Be involved from inception of projects, understanding requirements, designing & developing solutions, and incorporating them into the designs of our platforms
Mentor team members on technology and best practices
Build and maintain strong relationships between Investments and Platform teams
Contribute to the open source community and be a student of technology, data & cloud concepts
Assist in troubleshooting issues, support the operation of production software
Write comprehensive technical documentation, design plans, and user flows to support PoC, MVPs, and Products
Communicate with partner teams and stakeholders on project progress and potential bottlenecks
Desirable Skills
Passion for engineering data centric performant systems
Experience with Cloud Native platforms
Experience working in a multi-disciplinary environment
Working knowledge of building and deploying distributed systems and scaling algorithms for ETL on structured and unstructured data
Experience with building data pipelines in Python
Good understanding/experience with languages such as Python/Go/Scala
Experience in building resilient data pipelines on large amounts of unstructured data.
Experience in messaging and streaming platforms such as NATS or Kafka is a plus
Experience in networking, coordination and service discovery
Curiosity to design, evaluate and implement data architecture for AI applications
2+ years of hands-on experience in Data Engineering or related Engineering practices.
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 60K - 125K *
614,Director - Data Management & Centralized Data Review,Novo Nordisk,"Bengaluru, Karnataka, IN",Executive-level / Director,"    Job Title: Director - Data Management & Centralized Data Review
   Department – CDS GBS
 Are you passionate about quality and simplification? Do you want to build quality within processes in the most efficient way? Do you have an innovative mindset to drive change in a future-ready environment and support your colleagues and stakeholders by challenging the status-quo in a friendly and open-minded way? If so, there is a job opportunity waiting for you as our new Director. At Novo Nordisk, we will challenge you to do the best work of your life. Apply Now.
   The Position
As the Director of Data Management and Centralized Data Review at Novo Nordisk, you will be a pivotal leader responsible for driving the strategy and implementation of a dynamic new team dedicated to enhancing focused, next generation clinical data review practices across our diverse portfolio. This role involves overseeing multiple specialized teams, fostering process optimization, technical capability development, innovation, and delivery of projects. The Director is – in collaboration with the leaders of Data Management in Sobor and Bangalore - responsible for coordination of the 60+ people situated worldwide working on these projects. In addition, the Director for Data Management & Centralized Data Review will have full project responsibility for large innovation and transformation projects.
  Manage the Centralized Data Review team according to the Novo Nordisk Way, developing employees and the team to meet business needs.
Ensure resource allocation to supply trials with Data Managers and report developers in a timely manner.
Establish and lead a team focused on implementing a Risk – Based Data Management Framework.
Lead a Centre of Excellence to create clinical data review reports, dashboards, and interactive visualizations on behalf of the overall Data Management Functional area.
Establish a team dedicated to developing and maintaining an interactive clinical data lineage mapping system/too.
Foster a continuous improvement mindset by participating in quality activities and sharing best practices.
Collaborate with the department to challenge and improve existing processes.
Embrace new methods and working styles to enhance efficiency and effectiveness.
Follow-up and maintain team line budget.
Qualifications:
  Bachelor’s or Master’s degree within data sciences, life sciences, computer science, or economics.
Experience working with clinical development (10+ years)
Profound knowledge of drug development, thorough understanding of the pharmaceutical business
Leadership competencies and experience (5+ years)
Proven track record in managing cross-functional and international teams
In-depth knowledge of computer systems and IT, the data structures in CTMS, EDC, CDMS and/or data warehouse systems
In-depth understanding of clinical data review and visualizations
Regular experience with communication and presentations
Experience in working in metrics organization
In-depth knowledge of GxP and guidelines within drug development and experience working under quality requirements such as GCP experience required in the job.
    About the Department: 
Our Data Management group is 350+ professionals spanning across India, Denmark and North America. Data Management sits in Development where we manage clinical drug development worldwide, ensuring that the process lives up to uniform global standards, regulations and business ethics while delivering viable products that make a difference to patients and ultimately benefit society. Our newly formed Data Review and Cleaning group sits within the Data Management & Centralised Data Review Department led from our Bengaluru site. The Data Review and Cleaning group has been set up to centralise and modernize the data review and cleaning processes, implement new methodologies and to develop innovative toolkits supporting the transformation.
  Working at Novo Nordisk
  At Novo Nordisk, we are driving change to defeat diabetes and other serious chronic conditions. Our treatments today are benefiting millions of people living with diabetes, obesity, and rare blood and endocrine diseases. From our labs to our factory floors, we are discovering and developing innovative biological medicines and making them accessible to patients throughout the world. Since the company was founded in Denmark more than 100 years ago, we have been translating the unmet medical needs of people living with serious chronic diseases into innovative medicines and delivery. Our focus is on these diseases, which affect hundreds of millions of people and are among the most urgent global health challenges. By combining our innovation and commercial excellence, we draw upon insights from patients and partners to transform bold ideas into life-saving and preventive medicines. Our ambition is to take the lead in each of these areas, driving change with an unfailing belief that it can be done. 
  Contact
 To submit your application, please upload your CV online (click on Apply and follow the instructions)
 Deadline
 Apply before 15th Dec,  2023.
        We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 49K - 91K *
615,"Sr. Software Engineer- AWS, Big Data",NECSWS,"Mumbai, India",Senior-level / Expert,"Company Description
NEC Software Solutions (India) 
On 1st July 2021, Rave Technologies became NEC Software Solutions India. This change brought us under the global NEC Corporation brand. We are proud to be part of an organisation with 122 years of experience in evolution with technology and innovation.
We have more than 30 years of experience in providing end to end IT services across the globe and have earned a reputation for delighting our customers by consistently surpassing expectations and helping them deliver robust, market-ready software products that meet the highest standards of engineering and user experience. Supported by more than 1300 exceptionally talented manpower, we are a hub for offshore support and technology services.
We work with diverse industry verticals which include publishing, media, financial services, retail, healthcare and technology companies around the world. Our customers range from two-person startups to $bn listed companies.
For more information, visit at www.necsws.com/india.
About NEC Corporation 
NEC Corporation is a Japanese multinational information technology and electronics company, headquartered in Tokyo, Japan. It is recognised as a ‘Top 50 Innovative Company’ globally and the NEC Group globally provides “Solutions for Society” that promote the safety, security, fairness and equality of society. Their main goal is to help create a safer society with their innovations in technologies.
NEC Corporation has established itself as a leader in the integration of IT and network technologies while promoting the brand statement of “Orchestrating a brighter world.” NEC enables businesses and communities to adapt to rapid changes taking place in both society and the market as it provides for the social values of safety, security, fairness and efficiency to promote a more sustainable world where everyone has the chance to reach their full potential. 
For more information, visit NEC at https://www.nec.com.
Job Description
Role: Data Engineer
Experience: 10+yrs
Location: mumbai
 • Productive experience in the context of Big Data, ETL, Data Ingestion, Data Modeling & Pipelines, Data Architectures
• Work as a Product Owner for Data Engineering related modules / requirements
implementing the integration, preparation, enrichment, storage and sharing of data
Close participation in Product Owner meetings to together design the product roadmap
setup, monitoring and optimization of the data pipeline including the necessary hardware and software infrastructure
implement security and data protection aspects
• Knowledge and experience in:
batch processing frameworks & tools (e.g. Apache Spark, HDInsight, Hadoop, AWS)
real-time streaming (e.g. Apache Spark Structured Streaming, Kafka, AWS Kinesis, AWS Lambdas)
• Knowledge of NoSQL, relational database systems, data warehouses, data lakes, interface protocols (REST, MQTT, ODBC/JDBC, ...), Python, Java, Bash
• Design and development in the area of data management, data governance, data catalog
• Experience with enterprise application integration and encryption
• Design and implementation of data integration scenarios and use cases in cloud environments (AWS)
• Integration of (cloud) solutions / data platforms into enterprise application landscapes.
• DevOps and work on continuous improvement of software and processes
• unit and integration testing
• coder versioning in code repos and build pipelines
Additional Information
Good Communication Skills required.",USD 45K - 84K *
616,Lead/Senior Data Scientist,ZF Friedrichshafen AG,"Bengaluru, KA, IN, 560058",Senior-level / Expert," Req ID 52164 | Bangalore, India
Your Tasks:
Refine ambiguous questions and generate new hypotheses about the product and business through a deep understanding of the data, our customers, and our business
Design experiments and interpret the results to draw detailed and impactful conclusions.
Prototype, implement and iterate data driven solutions to core customer challenges 
Build algorithms and predictive models to solve business problems.
Collaborate with product managers, designers and engineers to build scalable data products
  Your Profile:
8+ years of data science experience.
Expertise in data analysis, statistical techniques, exploratory analysis and data visualization.
Deep expertise on working with very large data sets. Experience with Apache Spark is a plus.
Real world experience in applying machine learning and optimization techniques to solve business problems. 
SQL/Python skills along with one more more machine learning frameworks.
      Be part of our ZF team as Lead/Senior Data Scientist and apply now!
  Contact
Neha Sharma
ZF Jobs
  DIVERSITY COMMITMENT: 
Diversity, Equity and Inclusion are more than just words for us. They are at the core of the ZF Way that propels our team members towards their utmost success. We strive to build and nurture a culture where inclusiveness is a natural reflex. We actively seek ways to remove barriers so that every member of ZF can rise to their full potential. We aim to embed this in our legacy through how we operate and build our products as we shape next generation mobility, safety, sustainability and social justice. 
With four generations across 118 nationalities in 41 countries, ZF combines a unique variety of backgrounds, perspectives, and ideas. Together, we solve problems, drive innovation and shape next generation mobility. 
Our company is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with us and are in need of accommodation or special assistance to navigate our website or to complete your application, please contact us. Requests for reasonable accommodation will be considered on a case-by-case basis. ZF is an Equal Opportunity and Affirmative Action Employer and is committed to ensuring equal employment opportunities for all job applicants and employees. Employment decisions are based upon job-related reasons regardless of an applicant's race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, marital status, genetic information, protected veteran status, or any other status protected by law. Equal Employment Opportunity/Affirmative Action Employer M/F/Disability/Veteran.",USD 136K - 205K *
617,Data Science Senior Advisor,The Kraft Heinz Company,"Bengaluru, India",Senior-level / Expert,"Data Science Senior Advisor
Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.
Join us to do the best work of your career and make a profound social impact as a Data Science Senior Advisor on our Customer Data - Insights and Quality Team in Bangalore.

What you’ll achieve
As a Data Science Senior Advisor, you will be responsible for contributing to business strategy and influence decision making based on information gained from deep dive analysis. You will produce actionable and compelling recommendations by interpreting insights from complex data sets. You will design processes to consolidate and examine unstructured data to generate actionable insights. You will also partner with business leaders, engineers and industry experts to construct predictive models, algorithms and probability engines.

You will:
Work with large and complex data sets to solve business challenges using machine learning and statistical approaches
Apply technical expertise with data mining, analysis and presentation of data to understand our Customer Data Product Ecosystem
Demonstrate strong initiative to research and apply new methods to exceed
Apply broad knowledge of ML/AI capabilities to identify growth areas, new and emerging opportunities, identifying challenges, evaluating trends


Take the first step towards your dream career
Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

Essential Requirements
Advanced SQL (Postgres, MySQL),Proficiency with Applied ML, Core Supervised and Unsupervised Learning, e.g: Clustering, Classification, Data mining techniques.
Python for Data Exploration and Data Science
String working knowledge of MLOps (ML Pipelines, Design Patterns)
Tableau/PowerBI for Visualization.Experience with Applied Statistics
Familiarity with Data Structures i.e Binary Trees, Set Theory
 
Desirable Requirements
Bachelors + 6 years Business Analyst  experience or Masters + 2 years Business Analyst experience 
Here’s our story; now tell us yours
Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Application closing date: 30 Novemeber 2023

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.",USD 45K - 84K *
618,"Analyst/Associate, Data Engineering- Gen AI, Portfolio Management Group",BlackRock,HA3-Gurgaon - DLF Cyber City,Entry-level / Junior,"About this role
Business Overview:
Data Strategy & Solutions team is a Global Research & Data team within BlackRock Portfolio Management Group (PMG) focused on developing AI powered products and generating actionable insights using alternative, primary and big data. We are seeking an experienced Data Scientist, with experience in Large Language Models, Natural Language Processing, (NLP), and Transformer Models, to spearhead the build-out of AI powered capabilities within Investment Research, Product Strategy, and Process Optimization.
There are four groups within Data Strategy & Solutions – Investment AI, Insights & Data Products, Solutions, and Platform. All these groups work towards various aspects of Alpha Generation using Alternative data for a host of portfolio management functions.
As a member of Investment AI, you will be working with Investment Researchers, and Portfolio Managers to build capabilities that enable alpha generation and streamlining research processes using Generative AI and Natural Language understanding techniques.
Job Purpose/Background:
Data Strategy & Solutions is looking for a dynamic individual to join their Investment AI team. The primary job responsibilities include research and development of language models including large language models to capture and extract unstructured data from varied sources & reports and build out of quantitative/ML based components for generating alpha.
As a Data Engineer in the Investment AI team you will: -
Work alongside Data Scientists, Investors, and other Data Engineers in partner teams to design and build scalable, automated platforms for rapid experimentation and build-out of Generative AI applications.
Scope out and productionize infrastructure and tooling to support scalable cloud-based applications
Specific Responsibilities:
Ensuring the required data is available for product development, testing, rapid experimentation
Experience in integrating data from varied sources both on-prem and cloud
Understanding of on-prem data landscape as well as external unstructured data
Develop, deploy, and maintain optimized and automated data pipelines at scale
Working as part of a multi-disciplinary squad to establish our next generation of data pipelines and tools for large structured and unstructured data
Be involved from inception of projects, understanding requirements, designing & developing solutions, and incorporating them into the designs of our platforms
Mentor team members on technology and best practices
Build and maintain strong relationships between Investments and Platform teams
Contribute to the open source community and be a student of technology, data & cloud concepts
Assist in troubleshooting issues, support the operation of production software
Write comprehensive technical documentation, design plans, and user flows to support PoC, MVPs, and Products
Communicate with partner teams and stakeholders on project progress and potential bottlenecks
Desirable Skills
Passion for engineering data centric performant systems
Experience with Cloud Native platforms
Experience working in a multi-disciplinary environment
Working knowledge of building and deploying distributed systems and scaling algorithms for ETL on structured and unstructured data
Experience with building data pipelines in Python
Good understanding/experience with languages such as Python/Go/Scala
Experience in building resilient data pipelines on large amounts of unstructured data.
Experience in messaging and streaming platforms such as NATS or Kafka is a plus
Experience in networking, coordination and service discovery
Curiosity to design, evaluate and implement data architecture for AI applications
2+ years of hands-on experience in Data Engineering or related Engineering practices.
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 60K - 125K *
619,Machine Learning Engineer/SRE,Dew Software,"Mumbai, Maharashtra, India",Senior-level / Expert,"Dew Software is looking for a highly skilled and motivated Machine Learning Engineer/SRE to join their dynamic team. As a Machine Learning Engineer/SRE at Dew Software, you will have the unique opportunity to combine your expertise in machine learning and site reliability engineering to drive digital innovation and transformation for Fortune 500 clients. You will be responsible for managing Azure infrastructure, monitoring model performance, and responding to incidents related to model operations. This role requires a strong understanding of machine learning principles, as well as experience in managing cloud infrastructure and implementing CI/CD pipelines.

Responsibilities
Manage Azure infrastructure to support AI model development and deployment
Implement and maintain monitoring systems to track model performance
Collaborate with the SRE team to respond to and resolve incidents related to model operations
Optimize CI/CD pipelines for efficient deployment of machine learning models
Build and optimize machine learning models using Python and relevant libraries
Preprocess and engineer data for machine learning
Ensure clear documentation of models, infrastructure configurations, and incident responses
Stay up-to-date with the latest advancements in machine learning and cloud technologies
Requirements
Bachelor's degree in Computer Science, Engineering, or related field
3+ years of experience in machine learning engineering, SRE, or related roles
Proficiency in managing Azure infrastructure for AI model development and deployment
Experience in implementing and maintaining monitoring systems for model performance
Strong knowledge of CI/CD pipelines for efficient deployment of machine learning models
Expertise in machine learning principles, algorithms, and frameworks such as TensorFlow and PyTorch
Proficiency in Python programming for building and optimizing machine learning models
Experience in data preprocessing, feature engineering, and data pipeline development
Excellent communication and collaboration skills
Benefits
Azure Infrastructure Experience: Proficiency in managing Azure infrastructure components, including virtual machines, storage, and networking, to support AI model development and deployment.
CI/CD Pipeline Experience: Experience with Continuous Integration/Continuous Deployment (CI/CD) pipelines, including the automation of model deployment processes.
Containerization in the Cloud: Strong knowledge of containerization technologies in the cloud, such as Docker and Kubernetes, for efficient deployment and scaling of machine learning models.
Machine Learning Expertise: Proficient in building and optimizing machine learning models, with a deep understanding of various ML algorithms and frameworks.
Programming Skills: Proficiency in programming languages commonly used in machine learning, such as Python and libraries like TensorFlow and PyTorch.
Data Management: Experience in data preprocessing, feature engineering, and data pipeline development for machine learning.
Collaborative Team Player: Excellent communication skills and the ability to work collaboratively with cross-functional teams, including AI engineers and SREs.
Documentation: Effective documentation skills to maintain clear and organized records of models, infrastructure configurations, and incident responses.",USD 150K - 230K *
620,Senior Manager - Data Management & Centralized Data Review,Novo Nordisk,"Bengaluru, Karnataka, IN",Senior-level / Expert,"    Job Title: Senior Manager – Data Management & Centralized Data Review
  Department – Clinical Data Operations & Insights GBS
   Are you passionate about quality and simplification? Do you want to build quality within processes in the most efficient way? Do you have an innovative mindset to drive change in a future-ready environment and support your colleagues and stakeholders by challenging the status-quo in a friendly and open-minded way? If so, there is a job opportunity waiting for you as our new Senior Manager – Data Management & Centralized Data Review. At Novo Nordisk, we will challenge you to do the best work of your life. Apply Now.
   The Position
  As the Senior Manager of Data Management & Centralized Data Review at Novo Nordisk, the person will be a pivotal leader responsible for driving the strategy and implementation of a highly skilled team of programmers and developers. This team will focus on creating data review reports, data visualizations, and digitalizing Risk-Based Data Management practices across Novo Nordisk portfolio. The person in the role will play a vital role in evaluating and implementing new technology solutions for clinical data review and ensuring the effective use of data in collaboration with DD&IT and appropriate ART teams.  Lead the digitalization of Risk-Based Data Management practices, ensuring efficiency and accuracy in data review.
  The Key Responsibilities:
  Manage the Centralized Data Review development team according to the Novo Nordisk Way, developing employees and the team to meet business needs.
Responsible for resource allocation, ensuring that trials and relevant business functions are supplied with necessary data review reports, visualizations, and operational insights. 
Host and contribute to share best practice discussions in the department. Follow-up and maintain team line budget.  
Build and lead a team of programmers and developers responsible for creating data review reports and data visualizations for clinical data review and operational insights on behalf of the Data Management functional area.
Provide technical leadership, mentorship, and guidance to the team, fostering a culture of excellence and innovation.
Identify innovative solutions, including automation, AI/ML, and advanced data analytics, to enhance data quality and efficiency.
  Qualifications:
  Bachelor’s or Master’s degree within data sciences, life sciences, computer science, or economics.
Experience working with clinical development (8+ years).
Profound knowledge of drug development.
Thorough understanding of the pharmaceutical business.
Leadership competencies and experience (3+ years).
Proven track record in managing cross-functional and international teams.
In-depth knowledge of computer systems and IT.
Knowledge of the data structures in CTMS, EDC, CDMS and/or data warehouse systems.
In-depth understanding of clinical data review and visualizations.
Regular experience with communication and presentations.
Experience in working in metrics organization.
In-depth knowledge of GxP and guidelines within drug development.
Experience working under quality requirements such as GCP experience required.
  About the Department: 
Our Clinical Data Operations & Insights group is about 400 professionals spanning across India, Denmark and North America. Data Management sits in Development where we manage clinical drug development worldwide, ensuring that the process lives up to uniform global standards, regulations and business ethics while delivering viable products that make a difference to patients and ultimately benefit society. Our newly formed Data Review and Cleaning group sits within the Data Management & Centralised Data Review Department led from our Bengaluru site. The Data Review and Cleaning group has been set up to centralise and modernize the data review and cleaning processes, implement new methodologies and to develop innovative toolkits supporting the transformation.
  Working at Novo Nordisk
  At Novo Nordisk, we are driving change to defeat diabetes and other serious chronic conditions. Our treatments today are benefiting millions of people living with diabetes, obesity, and rare blood and endocrine diseases. From our labs to our factory floors, we are discovering and developing innovative biological medicines and making them accessible to patients throughout the world. Since the company was founded in Denmark more than 100 years ago, we have been translating the unmet medical needs of people living with serious chronic diseases into innovative medicines and delivery. Our focus is on these diseases, which affect hundreds of millions of people and are among the most urgent global health challenges. By combining our innovation and commercial excellence, we draw upon insights from patients and partners to transform bold ideas into life-saving and preventive medicines. Our ambition is to take the lead in each of these areas, driving change with an unfailing belief that it can be done. 
  Contact
 To submit your application, please upload your CV online (click on Apply and follow the instructions)
   Deadline
 Apply before 25 th Dec,  2023.
      We commit to an inclusive recruitment process and equality of opportunity for all our job applicants. 
  At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.
 ",USD 45K - 84K *
621,Vice President – AI/ML Engineering,Icertis,"Pune, Maharashtra",Executive-level / Director,"With unmatched technology and category-defining innovation, Icertis pushes the boundaries of what’s possible with contract lifecycle management (CLM). The AI-powered, analyst-validated Icertis Contract Intelligence (ICI) platform turns contracts from static documents into strategic advantage by structuring and connecting the critical contract information that defines how an organization runs. Today, the world’s most iconic brands and disruptive innovators trust Icertis to fully realize the intent of their combined 10 million contracts worth more than $1 trillion, in 40+ languages and 93 countries.

Who we are:  Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values—Fairness, Openness, Respect, Teamwork and Execution—which guide all our interactions with employees, customers, partners and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination

Position Overview:

As the Vice President of AI/ML Engineering, you will be a pivotal leader responsible for overseeing and driving the development and implementation of advanced AI/ML solutions. You will lead a highly skilled team of engineers and data scientists, guiding them to push the boundaries of technology and innovation to deliver industry leading contract-intelligence solutions.
  Key Responsibilities:
Leadership and Strategy: Develop and execute the strategic vision for the AI/ML engineering team towards contract intelligence initiatives aligned with the Icertis’ goals. Provide leadership and mentorship to foster a culture of innovation, collaboration, and excellence for providing outcome driven products to our customers.
Technical Oversight: Drive the design, development, and deployment of state-of-the-art AI/ML solutions. Ensure the team is utilizing cutting-edge technologies and methodologies to deliver scalable, efficient, and robust systems.
Cross-functional Collaboration: Collaborate closely with other departments such as Product Management, Marketing, Sales, Pre-sales and Research to align efforts, share insights, and drive cohesive strategies that leverage AI/ML capabilities for value driven contracting solutions.
Team Management: Recruit, build, and retain a top-tier team of AI/ML engineers and data scientists. Provide mentorship, guidance, and performance feedback to foster professional growth and ensure high team performance.
Innovation and Research: Stay abreast of industry trends, emerging technologies, and best practices in AI/ML. Encourage a culture of continuous learning and exploration to drive innovation within the team.
Quality Assurance and Compliance: Ensure adherence to industry standards, best practices, and regulatory requirements in the development and deployment of AI/ML solutions.
   Qualifications
Advanced degree (Ph.D. or Master's) in Computer Science, AI, Machine Learning, NLP or a related field, with 20+ years of experience in designing, developing and deploying SaaS products.
Expertise in NLP techniques, machine learning, and deep learning algorithms for text analysis and understanding.
Strategic thinker with the ability to align technical initiatives with business objectives.
Strong track record of defining and delivering successful AI powered innovations with data-driven and customer-centric approach.
Extensive experience in developing and deploying AI/ML solutions at scale, with a strong understanding of various algorithms, frameworks, and tools.
Exceptional leadership and communication skills with the ability to inspire and motivate cross-functional teams.
Proficiency in constructing, articulating, and advocating for business proposals.
Icertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to careers@icertis.com or get in touch with your recruiter.
 By submitting your application you acknowledge that you have read Icertis’s Privacy Policy (https://www.icertis.com/privacy-statement/)

Icertis is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary. ",USD 151K - 260K *
622,Data Architect,MoEngage,"Bengaluru, Karnataka, India",Senior-level / Expert,"Location: Bengaluru,Karnataka,India
MoEngage is an insights-led customer engagement platform, trusted by 1,200+ global consumer brands. As a Great Place to Work Company we are a young, fast-paced and intelligent customer engagement platform that fosters a culture of innovation, ownership, freedom, and fun while building future-ready technology products. Sitting at a conflux of diverse technologies like Artificial Intelligence, Big Data, Web & Mobile platforms, MoEngage technology analyzes billions of data points generated by customers and their devices in order to predict their behavior and engage them at every touchpoint throughout their lifecycle with personalized communication.
 In just eight years since our inception, we have worked with leading Fortune 500 brands such as Deutsche Telekom, Samsung, Ally Financial, Vodafone, and McAfee along with internet-first brands such as Flipkart, Ola, OYO, Bigbasket, and Sharechat, with a global presence that encompasses 35 countries. We currently have offices in San Francisco, Boston, London, Dubai, Ho Chi Minh city, Bangkok, Kuala Lumpur, Singapore, Sydney, Vietnam, Berlin, Jakarta, and Bengaluru.
The care we give to our customers is quite high! Our achievement of top service and support ratings in Gartner's Magic Quadrant, Gartner Peer Insights, and G2 Summer Reports is a testament to that. Another commendable quality is our people-centric culture, as we have recently been included in Battery Ventures' top 25 private cloud computing companies. As recognized by the DivHERsity Awards, we are one of the top 20 diversity companies in the world, while the Economics Times names us as one of the Top Organizations for Women.
 Will you be able to thrive in a fast-paced environment where innovation, speed, and customer-centric thinking are the norm? Is it your passion to uncover opportunities others are unaware of and to champion them? Do you crave ownership and a chance to be a part of something that matters? If so, this may be a worthwhile opportunity for you!
 As part of the Engineering team at MoEngage, here are some things you can expect:
Take ownership and be responsible for what you build - no micro management
Work with A players (some of the best talent in the country), and expedite your learning curve and career growth
Make in India and build for the world at scale of 900M active users, which no other internet company in the country has seen
Learn together from different teams on how they scale to millions of users and billions of messages. 
Explore the latest in topics like Data Pipeline, MongoDB, ElasticSearch, Kafka, Spark, Samza and share with the team and more importantly have fun while you work on scaling MoEngage.
We are looking for Technical Architect to help achieve organizational goals by defining, integrating, and upgrading a comprehensive architecture to support Java / Python based applications.
 Responsibilities:
Lead/Guide a team of developers to build the next gen marketing automation platform
Hands on with Modular Software Architecture, Software Design and Implementation
Institute and Lead the adoption of best practices, coding standards and development practices to improve the quality of the deliverables
Own Reliability, Quality and Costs agendas for the assigned teams.
Define layered architecture and lead technical teams – presentation layer, data layer, business layer, etc.
Define & drive implementation of long term technology vision for your product & team
Drive a culture of curiosity and active debate around technology at MoEngage
Experiment with new & relevant technologies and tools, and drive adoption while measuring yourself on the impact you are able to create
 Must Haves:
10+ years of relevant industry experience
Worked at the scale where the organisation had at least 20Mn MAU
Very Strong System design and OO skills with a nifty ability to craft clean interfaces and operate at the right levels of abstraction.
Solid coding skills with ability to drive teams through massive refactoring exercise & improve coding standards across large code bases
Experience in Python or Java
Excellent Problem Solving skills for complex & large scale Systems
Experience & expertise in a variety of large scale persistent systems and databases
Deep understanding of cloud based distributed systems. Must have in-depth knowledge on one of the cloud platforms viz. AWS/GCP/Azure
 At MoEngage, we are passionate about our team and technology - see below to know more about us and technology.
Tech @MoEngage | Scale @MoEngage | Life @MoEngage
We handle more than a billion messages every day. Rest assured, you will be surrounded by really smart and passionate people as we scale much more to build a world-class technology team.
Apply to this job",USD 115K - 193K *
623,IND Senior Data Engineer,Walmart,IN TN CHENNAI Home Office RMZ Millenia Biz Park,Senior-level / Expert,"Position Summary...
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales. Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities. Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.
What you'll do...

About Team:
Our organization focuses on managing and delivering world-class data assets, including creating and maintaining data standards, driving policy compliance, creating partnerships, and developing pipelines and self-service tools. We empower our business to leverage data to fuel growth, driving revenue in our core and building new business model opportunities. 
At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our customers.  
Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on.  You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives. 
What you'll do:
Data Strategy: Understands, articulates and applies principles of the defined strategy to routine business problems that involve a single function.
Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends.
Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.
Data Modelling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions.
Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.
Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.
Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working.
Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines.
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales.
What you'll bring: 
·      You have consistently high standards, your passion for quality is inherent in everything 
Well versed with Hadoop, Hive, Spark using Scala, Kubernetes, Cloud, API and Data Lake concepts .
·      You evangelize an extremely high standard of code quality, system reliability, and performance 
·      You have a proven track record coding with at least one programming language (e.g., Java, Python) 
You’re experienced in computing platforms (e.g., GCP, Azure) 
You’re skilled in data modelling & data migration protocols 
Experience with Kafka connect, Druid, Big Query and Looker is added advantage.
Experience with the integration tools like Automic, Airflow
About Walmart Global Tech:
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people.  That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. 
We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
Flexible, hybrid work:
We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives.
Benefits:
Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more.
Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.
Minimum Qualifications...
Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.
Minimum Qualifications:Option 1: Bachelor's degree in Computer Science and 3 years' experience in software engineering or related field. Option 2: 5 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 1 year's experience in software engineering or related field. 2 years' experience in data engineering, database engineering, business intelligence, or business analytics.
Preferred Qualifications...
Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.
Primary Location...
RMZ Millenia Business Park, No 143, Campus 1B (1st -6th floor), Dr. MGR Road, (North Veeranam Salai) Perungudi , India",USD 121K - 188K *
624,Senior Data Engineer,Swiss Re,"Hyderabad, TG, IN",Senior-level / Expert,"  About the Role:
As a Data Engineer, you will be responsible for leading the design and implementation of complex data pipelines and analytics solutions to support key decision-making business processes in our Reinsurance Client Solutions business domain. You will lead the development of strategic use cases within our Data Integration and Analytics platform. You will gain exposure to projects that are leveraging cutting edge technology that applies Big Data and Machine Learning to solve new and emerging problems for Swiss Re Reinsurance Client Solutions.
  You will be expected to work with business experts to understand client requirements and design and develop solutions to meet those needs. You will have end-to-end ownership of deliverables, gaining a full understanding of the Reinsurance data, Client data, and the business logic required to deliver analytics solutions.
  Key responsibilities include:         
Work closely with Product Owners, Business Analysts and Architects to understand requirements, formulate solutions and evaluate the implementation effort.
Design, develop and maintain scalable data transformation pipelines.
Design and implement analytics models and visualizations to provide actionable data insights.
Evaluate new capabilities of the analytics platform, develop prototypes and assist in drawing conclusions about the applicability to our solution landscape.
Collaborate within a global development team to design and deliver solutions.
Assist colleagues and clients with data-related functional and technical issues.
  About the Team:
This position is part of the Swiss Re Solutions Data & Technology organization. We are enabling our Clients to make data driven decisions at all stages of their value chain with the help of Swiss Re data and expertise.
  About You:
You enjoy the challenge of solving complex big data analytics problems using state-of-the-art technologies as part of a growing global team of data engineering professionals. You are a self-starter with strong problem-solving skills and capable of owning, designing and implementing solutions from start to finish. Key qualifications include:
  Experience designing and implementing data analytics solutions on enterprise data platforms and distributed computing (Spark/Hive/Hadoop preferred).
Proven track record of understanding and transforming customer requirements into a best-fit design and architecture.
Demonstrated experience in end-to-end data management, data modelling, and data transformation for analytical use cases.
Working experience in Palantir Foundry platform is preferred.
Proficient in Python/PySpark.
Proficient in SQL (Spark SQL preferred).
Experience with JavaScript/HTML/CSS a plus.
Experience working in a Cloud environment such as Azure or AWS is a plus.
Experience with Scrum/Agile development methodologies.
At least 5 years of experience working with large scale software systems.
Bachelor's degree level or equivalent in Computer Science, Data Science or similar discipline.
Knowledge of Insurance Domain or Financial Industry is a strong plus.
Experienced working in multicultural globally distributed teams.
Self-starter with a positive attitude and a willingness to learn, who can manage their own workload.
Strong analytical and problem-solving skills.
Strong interpersonal and communication skills, demonstrating a clear and articulate standard of written and verbal communication in complex environments.
  About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127741 
   ",USD 121K - 188K *
625,EDH Data Engineer,Equifax,IND-Pune-Equifax Analytics-PTEC,Senior-level / Expert,"Equifax is seeking creative, high-energy, diverse and driven software engineers with hands-on development skills to work on a variety of meaningful projects.
Our software engineering positions provide you the opportunity to join a team of talented engineers working with leading-edge technology. You are ideal for this position if you are a forward-thinking, committed, and enthusiastic software engineer who is passionate about technology.
What You’ll Do
Lead and guide a team of Data Engineers with new and existing data pipeline design patterns 
You will design, develop, improve data ingestion processes and code in the public cloud like GCP and AWS
You will coordinate with the business and technical partners on test strategy and testing process of data and data pipeline balance & controls 
You will manage individual project priorities, deadlines and work you're doing
You have the ability to translate functional and technical requirements into detailed architecture and design
You will orchestrate data applications Go-Lives with business and technical product owners 
You have good knowledge of Data Governance, Data Catalog and Data Observability 
You are part of a community and participate in code and design reviews to maintain our high development standards
You enjoy working with other data engineers, having a voice in defining our challenging technical culture
What experience you need
BS or equivalent job experience required
5+ years’ of experience working in Data or equivalent experience
What could set you apart 
Experience preferably in Google cloud (GCP) or AWS data areas like Spark and Python  or equivalent experience
Knowledge of modern software development lifecycles including CI / CD or equivalent experience
Source code control management systems (e.g. SVN/Git, Subversion) and build tools like Maven
Big Data, Postgres, Oracle, MySQL, NoSQL databases (e.g. Cassandra, Hadoop, MongoDB, Neo4J)
Cloud engineering and architecture computing, SaaS (Software as a Service)
You have the ability to operate across a broad and complex business unit with multiple stakeholders
You possess excellent written and verbal communication skills with the ability to communicate with team members at various levels, including business leaders
We offer a hybrid work setting, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Equifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran
Primary Location:
IND-Pune-Equifax Analytics-PEC
IND-Trivandrum-Equifax Analytics-PEC
Function:
Function - Tech Dev and Client Services
Schedule:
Full time",USD 121K - 188K *
626,Data Science Consultant,Blue Yonder,Bengaluru,Senior-level / Expert,"Overview:
Leading AI-driven Global Supply Chain Solutions Software Product Company and one of Glassdoor’s “Best
Places to Work”
Seeking an astute individual who has a strong statistical/analytical foundation with the additional ability to
be hands-on with the broader team as part of the deploy/operate cycle. Knowledge of industry best practices,
with the ability to implement them would be a bonus.
Scope:
Core responsibilities to include participation in onboarding of clients with BY’s Luminate Planning suite of
solutions and their continued support during the BAU phase.
The team currently comprises of ~30 associates in India, part of a larger global team spread across US,
Germany and is expected to grow rapidly. The incumbent will need to have leadership qualities to also mentor
junior and mid-level associates in our team
What you’ll do:
• Selecting features, building and optimizing classifiers using machine learning techniques
• Data mining using state-of-the-art methods & tools
• Extending company’s data with third party sources of information when needed
• Enhancing data collection procedures to include information that is relevant for building analytic systems
• Processing, cleansing, and verifying the integrity of data used for analysis
• Performing ad-hoc analysis and presenting results in a clear manner
What we are looking for:
• Excellent understanding of machine learning techniques and algorithms, such as K means clustering, Naive Bayes
• Experience with common data science toolkits, such as Python, R, Weka, NumPy, MatLab, etc. Excellence in at
least one of these is required
• Experience in Supply Chain concepts
• Experience in Statistical Analysis, Operations Research concepts – Integer/Linear/Stochastic programming
• Experience with data visualization tools, such as D3.js
• Proficiency in using query languages such as SQL, Hive, Pig
• Experience with NoSQL databases, such as MongoDB, Cassandra
• Good applied statistics skills, such as distributions, statistical testing, regression, etc.
• Good scripting and programming skills
• Data-oriented personality
• Bachelors or Masters in Computer Science w/Data Science specialty
• Experience preferred: 3-10 yrs
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Diversity, Inclusion, Value & Equality (DIVE) is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural Diversity Report which outlines our commitment to change, and our video celebrating the differences in all of us in the words of some of our associates from around the world.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",USD 116K - 137K *
627,Data Scientist 1,IQVIA,"Bengaluru, India",Senior-level / Expert,"Principal Accountabilities:
Work across projects such as promotional return (ROI analysis), Resource and price optimization analysis, Physician / patient profiling
Develop a good understanding of consumer offerings, proprietary databases, and analytical approaches to effectively guide and support client-facing stakeholders across globe mainly in Europe and US
Handle small and large datasets on projects efficiently and figure out the right technology for processing the data (e.g. Excel, R, Python etc.,). Be a champion on analytics technologies within the team
Present findings and recommendations to stakeholders in business point of view
Education, Specialized Skills Required & Experience:
Education:
An academic background in quantitative sciences (Master’s in Economics / Econometrics / Statistics
/Computer Science/ Operations Research / Mathematics / Data Mining / Agricultural Economics etc.) from a well-known institution
Specialized Skills Required:
Strong organizational skills with the ability to multitask and work independently and efficiently to meet scheduled deadlines
Ability to work in a team and coordinate with team members in performing QC for the delivery of projects with tight turnaround time
Self-motivated with the ability to make decisions in the absence of detailed instructions
Proficiency in MS office applications such as Excel and Power Point proficiency in SAS, R, Python are mandatory will be plus, if experience id data visualization platforms like Tableau, Power BI
Ability to perform advance analytics analyses such as Hierarchical model, Bayesian Hierarchical model, Linear & Non-Linear Optimization Techniques, RNN,CNN etc.
Experience:
3 – 6 years of experience in pharmaceutical / retail commercial analytics
Organization Reporting and Scope:
Reports to Manager – AA/CE CoE, CESE, IQVIA - GDC
Management scope: (number of full-time employees): Not Applicable
Annual revenue scope: Not applicable
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com",USD 136K - 205K *
628,"Business Intelligence Engineer III, LMAQ",Amazon.com,"Hyderabad, Telangana, IND",Senior-level / Expert,"When you attract people who have the DNA of pioneers and the DNA of explorers, you build a company of like-minded people who want to invent. And that’s what they think about when they get up in the morning: how are we going to work backwards from customers and build a great service or a great product” – Jeff Bezos
Amazon.com’s success is built on a foundation of customer obsession. Have you ever thought about what it takes to successfully deliver millions of packages to Amazon customers seamlessly every day like a clock work? In order to make that happen, behind those millions of packages, billions of decision gets made by machines and humans. What is the accuracy of customer provided address? Do we know exact location of the address on Map? Is there a safe place? Can we make unattended delivery? Would signature be required? If the address is commercial property? Do we know open business hours of the address? What if customer is not home? Is there an alternate delivery address? Does customer have any special preference? What are other addresses that also have packages to be delivered on the same day? Are we optimizing delivery associate’s route? Does delivery associate know locality well enough? Is there an access code to get inside building? And the list simply goes on. At the core of all of it lies quality of underlying data that can help make those decisions in time. The person in this role will be a strong influencer who will ensure goal alignment with Technology, Operations, and Finance teams. This role will serve as the face of the organization to global stakeholders. This position requires a results-oriented, high-energy, dynamic individual with both stamina and mental quickness to be able to work and thrive in a fast-paced, high-growth global organization. Excellent communication skills and executive presence to get in front of VPs and SVPs across Amazon will be imperative.

Key Strategic Objectives: Amazon is seeking an experienced leader to own the vision for quality improvement through global address management programs. As a Business Intelligence Engineer of Amazon last mile quality team, you will be responsible for shaping the strategy and direction of customer-facing products that are core to the customer experience. As a key member of the last mile leadership team, you will continually raise the bar on both quality and performance. You will bring innovation, a strategic perspective, a passionate voice, and an ability to prioritize and execute on a fast-moving set of priorities, competitive pressures, and operational initiatives. You will partner closely with product and technology teams to define and build innovative and delightful experiences for customers. You must be highly analytical, able to work extremely effectively in a matrix organization, and have the ability to break complex problems down into steps that drive product development at Amazon speed. You will set the tempo for defect reduction through continuous improvement and drive accountability across multiple business units in order to deliver large scale high visibility/ high impact projects. You will lead by example to be just as passionate about operational performance and predictability as you will be about all other aspects of customer experience.

The successful candidate will be able to:
- Effectively manage customer expectations and resolve conflicts that balance client and company needs.
- Develop process to effectively maintain and disseminate project information to stakeholders.


- Be successful in a delivery focused environment and determining the right processes to make the team successful.


- This opportunity requires excellent technical, problem solving, and communication skills. The candidate is not just a policy maker/spokesperson but drives to get things done.


- Possess superior analytical abilities and judgment. Use quantitative and qualitative data to prioritize and influence, show creativity, experimentation and innovation, and drive projects with urgency in this fast-paced environment.

- Partner with key stakeholders to develop the vision and strategy for customer experience on our platforms. Influence product roadmaps based on this strategy along with your teams.

- Support the scalable growth of the company by developing and enabling the success of the Operations leadership team.


- Serve as a role model for Amazon Leadership Principles inside and outside the organization


- Actively seek to implement and distribute best practices across the operation

We are open to hiring candidates to work out of one of the following locations:

Hyderabad, TS, IND
Basic Qualifications

- 10+ years of professional or military experience
- 5+ years of SQL experience
- Experience programming to extract, transform and clean large (multi-TB) data sets
- Experience with theory and practice of design of experiments and statistical analysis of results
- Experience with AWS technologies
- Experience in scripting for automation (e.g. Python) and advanced SQL skills.
- Experience with theory and practice of information retrieval, data science, machine learning and data mining
Preferred Qualifications
- Experience working directly with business stakeholders to translate between data and business needs
- Experience managing, analyzing and communicating results to senior leadership",USD 104K - 186K *
629,"Head of Data Quality, Ahmedabad",S&P Global,IN - AHMEDABAD,Executive-level / Director,"S&P Global Ratings  
 The Role: Head of Data Quality, Ahmedabad
The Team:    The Data Management team is responsible for the end-to-end operational management and continued improvement of our practices and strategy to deliver high quality, context rich data to our clients and colleagues.   
Key areas of focus for the team/function are Data Quality, Discoverability, Governance and Product development supporting our Clients and Colleagues to power Global Markets.
 The Impact:    We are looking for a senior leader to be the Head of Data Quality for the Ratings Business within S&P Global. This is a key role with a focus on transforming Data Quality approach, processes and practices partnering with Controls, Lines of Business and Technology.
As a senior member of our Data team, you lead the Data Quality function expected to solve problems in a fast-paced, collaborative, and iterative delivery environment. To meet these demands, candidates should be influential Data Management leaders with deep expertise, and a collaborative style that brings others into the decision-making process. You will devise quality metric definition processes, metric lifecycles and outcomes that deliver consistency, transparency, and utility of our data assets across organizational boundaries. 
What’s in it for you:     You will be responsible for helping to build our agile organization and align to a culture of continuous improvement, partnership, trust and sharing.  You will work with global staff of Data Content Managers in “value streams” and partner with your Product Management and Quality peers to support a large, global group of agile scrum teams.  In addition to the functional responsibilities the role will also act as the leader for the Ratings Technology function in Ahmedabad. Working with the wider Ratings technology leadership community to build our presence in the local market.
Fundamental to this position is a demonstrable ability to combine your strong problem-solving skills with deep data quality management delivery know how.  You have exceptional collaboration and communication skills, are highly motivated, creative, and engaged. 
 Responsibilities:     
Own the Data Quality KRI / OKR definition and realization process.
Create and manage the processes for identifying data quality metrics and their lifecycle with an emphasis on supporting ongoing application transformation projects.
Socialize and drive adoption of Data Quality programs and practices across the organization through building a comprehensive narrative of the value added and efficiencies delivered.
Partner very closely with various value stream engineering leaders and provide them with necessary process and technical guidance.
Augment data governance, content management and reference data management architecture and practices.
Be and active participant in cross-organization initiatives to drive consistency, re-use and value extraction from our Data Assets.
Define and shape data quality for AI / Generative AI.
Local leadership in the Ahmedabad region with a focus on building a talent pipeline and supporting the growth of Ratings Technology in the locale.
What We’re Looking For:    
Hold a bachelor’s degree, and ideally master’s degree or equivalent.
A S&P Global employee at this level would ordinarily have 15+ years’ of experience. For this position employees in this role would ordinarily have 8+ years’ of experience designing and delivering data quality transformation programs for a global audience within their 15+ years’ of experience.
Experience of a highly regulated industry or industries is desirable.
Experience of data quality automation and any experience of using AI for data quality will be a highly desirable.
Possess a quality first mindset with a strong background and experience with developing products for a global audience at scale.
Excellent analytical thinking, interpersonal, oral, and written communication skills with strong ability to influence both IT and business partners.
Financial services industry experience would be desirable but is not essential.
Grade Level: Grade 13 (for internal purposes)      
 Location:   Ahmedabad, India   
 Benefits:    Here at S&P Global we believe in offering a competitive transparent benefits package. In India this includes a Wellbeing Support Program, Recharge (S&P Global’s flexible time-off approach under which there is no prescribed maximum amount of time off you can take), our hybrid working model, our Parental Leave, and Give Back Days (five days of paid leave per calendar year to spend volunteering in your community). We encourage you to ask about our benefits during our screening process with our talent acquisition team.   
 S&P Global delivers essential intelligence that powers decision making. We provide the world’s leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you’ll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.      
 S&P Global Ratings is the world’s leading provider of independent credit ratings. Our ratings are essential to driving growth, providing transparency, and helping educate market participants so they can make decisions with confidence. We have more than 1 million credit ratings outstanding on government, corporate, financial sector and structured finance entities and securities. We offer an independent view of the market built on a unique combination of broad perspective and local insight. We provide our opinions and research about relative credit risk; market participants gain independent information to help support the growth of transparent, liquid debt markets worldwide.      
 S&P Global has a Securities Disclosure and Trading Policy (“the Policy”) that seeks to mitigate conflicts of interest by monitoring and placing restrictions on personal securities holding and trading. The Policy is designed to promote compliance with global regulations. In some Divisions, pursuant to the Policy’s requirements, candidates at S&P Global may be asked to disclose securities holdings. Some roles may include a trading prohibition and remediation of positions when there is an effective or potential conflict of interest. Employment at S&P Global is contingent upon compliance with the Policy.      
#LI-KM1
-----------------------------------------------------------
Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law.  Only electronic job submissions will be considered for employment.  
 If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.  
 
US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. 
-----------------------------------------------------------
10 - Officials or Managers (EEO-2 Job Categories-United States of America), DTMGOP103.2 - Middle Management Tier II (EEO Job Group), SWP Priority – Ratings - (Strategic Workforce Planning)",USD 172K - 270K *
630,Senior Analyst-Data Analysis,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardizing processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardization and build centralized capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimizing processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
 Job Description
Analyse complex data sets using Business Intelligence tools; data modelling techniques and Commercial Retail analytics expertise. Work across all functions irrespective of geography to support to define and solve business problems using Big data analytics. Make it consumable using visual storytelling and visualization tools such as reports and dashboards built using approved tools (Tableau; PyDash)
- Understands business needs and in depth understanding of Tesco processes
- Builds on Tesco processes and knowledge by applying CI tools and techniques.
- Responsible for completing tasks and transactions within agreed KPI's
- Solves problems by analyzing solution alternatives
-Engage with market leaders to understand problems to be solved; translate the business problems to analytical problems; taking ownership of specified analysis and translate the answers back to decision makers in business
- Manipulating; analyzing and synthesizing large complex data sets using different sources and ensuring data quality and integrity
- Think beyond the ask and develop analysis and reports that will contribute beyond basic asks
- Accountable for high quality and timely completion of specified work deliverables and ad-hocs business asks
- Write codes that are well detailed; structured; and compute efficient
- Drive value delivery through efficiency gain by automating repeatable tasks; report creation or dashboard refresh
- Collaborate with colleagues to craft; implement and measure consumption of analysis; reports and dashboards
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Understands business needs and in depth understanding of Tesco processes
- Responsible for completing tasks and transactions within agreed metrics
- Experience in handling high volume; time pressured business asks and ad-hocs requests
- Draw Entity Relationship diagrams by exploring & mining data required for Solution building & analysis
- Continuously analyse the data from different sources and use analytics to detect leakages & flaws in the Engines; Investigate tables; data and processes for inaccuracies and missing data to ensure accuracy and Perform accurate promotion funding calculations and analysis
Qualifications
Strong understanding of Business Decisions; Skills to develop visualizations; self-service dashboards and reports using Tableau & Basic Statistical Concepts (Correlation Analysis and Hyp. Testing); Good Skills to analyze data using Adv Excel; Adv SQL; Hive; Phython; Data Warehousing concepts (Hadoop; Teradata); Automation using alteryx; python
Additional Information
Last Date of Application- 12th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
631,Lead Data Scientist,Boeing,"IND - Bengaluru, India",Senior-level / Expert,"Lead Data Scientist
Company:
Boeing India Private Limited
Job ID:
00000405921
Date Posted:
2023-12-11
Location:
IND - Bangalore, India
Job Description Qualifications:
Overview
Boeing is the world’s largest aerospace company and a leading provider of commercial airplanes, defense, space, and security systems, and global services. Building on a legacy of over a century of innovation and leadership, Boeing continues to lead the way in technology and innovation, customer delivery, and investment in its people and future growth of aerospace.
In India, Boeing has been a strong partner to the Indian aerospace and defense sectors for more than 75 years. People at Boeing have been supporting mission readiness and modernization of India’s defense forces, and enabling connected, safer, and smarter flying experiences, in the sky, in the seas, and in space.
Technology for today and tomorrow
The Boeing India Engineering & Technology Center (BIETC) is a 3000+ diverse engineering workforce that contributes to global aerospace growth. Our engineers deliver cutting-edge R&D, innovation, and high-quality engineering work in global markets, and leverage new-age technologies such as AI/ML, IIoT, Cloud, Model-Based Engineering, and Additive Manufacturing, shaping the future of aerospace.
People-driven culture
At Boeing, we believe creativity and innovation thrives when every employee is trusted, empowered, and has the flexibility to choose, grow, learn, and explore. We offer variable arrangements depending upon business and customer needs, and professional pursuits that offer greater flexibility in the way our people work. We also believe that collaboration, frequent team engagements, and face-to-face meetings bring diverse perspectives and thoughts – enabling every voice to be heard and every perspective to be respected.  No matter where or how our teammates work, we are committed to positively shaping people’s careers and being thoughtful about employee wellbeing.
At Boeing, we are inclusive, diverse, and transformative.  
With us, you can create and contribute to what matters most in your career, community, country, and world. Join us in powering the progress of global aerospace.
Boeing Global Services Digital Solutions team is currently looking for one Lead Data Scientist to join their team in Bengaluru, KA.
As a Lead Technical Product Owner - Simulation, you will be part of the BDAS-India team, which develops software applications and products that create direct value to its customers. We provide re-vamped work environments focused on delivering data-driven solutions at a rapidly increased pace over traditional development. Be a part of our passionate and motivated team who are excited to use the latest in software technologies for modern web and mobile application development. Through our products, we deliver innovative solutions to our global customer base at an accelerated pace.
.
Position Responsibilities:
As a Lead Data Scientist, the selected individual will engage in architecting Industry first – Airline Disruption Management system employing AI/ML and engineering data analytics methods for aerospace applications.
The Select candidate shall engage in development of innovative, nonstandard approaches for knowledge discovery and parametric trending of structured and unstructured data and analysis to provide concrete information that improves aircraft and fleet efficiency and performance and helps increase productivity of Boeing engineers.
The Select candidate shall engage in developing data visualization technique and implement data dashboards to enable interpretable representation of raw data as well as results of analysis. Programming in languages such Python and R as well as developing applications using tools such as Tableau, Power BI.
The select candidate will work with cross-functional teams spread across multiple products and locations within Boeing and external partners.
The select candidate will work in an Agile Scrum team following the best practices on Software Craftsmanship such as Test-driven development and Pair Programming/Peer Reviews.
The selected individual will be a skilled, highly professional engineer, work collaboratively with an international team comprising software development, product management, and business analysis.
The selected individual will also be supporting any training plans to help upskill the capability of teams across BDAS
The selected individual is highly passionate and innovative in solving problems for airline, airspace and airport operations.
The selected individual may require to provides periodic updates to Boeing management in the form of progress reports, project summaries, and other related documents. This position will also be responsible for coordinating and communicating regularly with experts in Boeing organizations around the world.
The selected individual may require to travel domestically and internationally, as required.
Employer will not sponsor applicants for employment visa status.
Basic Qualifications (Required Skills/Experience):
A Bachelor’s degree or higher is required as a BASIC QUALIFICATION
7 to 12 years of overall work experience in data analytics and machine learning algorithm development and testing.
Bachelor’s degree or higher in computer science or other closely related fields.
Must have some degree of knowledge of a variety of mathematical modeling and simulation techniques including Discrete Event Simulation, Agent Based Modeling and Simulation, algorithm development, and numerical techniques.
Strong interpersonal and communications skills.
The candidate must be a self-starter with a positive attitude, high ethics, and strong analytical and creative problem-solving skills and, a track record of working successfully under pressure in a time-constrained environment.
Must be an excellent team player.
Preferred Qualifications (Desired Skills/Experience ) :
Candidates with Aviation related application development background will be preferred
Expertise in building and productizing Machine Learning/Deep Learning models.
Expertise in working with one or more deep learning frameworks like TensorFlow, PyTorch
Must have programming experience in Python, C++, MATLAB
Demonstrated capability to apply sophisticated visualization tools like Tableau, Power BI.
Typical Education & Experience:
Education/experience typically acquired through advanced education (e.g. Bachelor) and typically 11 Plus years' related work experience or Master’s Degree with 12+ years of experience with
 an equivalent combination of education and experience.
Relocation:
This position does offer relocation within INDIA.
Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.
Relocation:
Relocation is available for eligible candidates, if authorized
Export Control Requirement:
Not an export control position
Safety Sensitive:
This is not a safety sensitive position
Contingent Upon Award Program
This position is not contingent upon program award
Experience Level:
Individual Contributor - 4
Job Type:
Regular
Job Code:
BEH7I4 (B71)",USD 56K - 172K *
632,Expert Data Engineer,Swiss Re,"Hyderabad, TG, IN",Senior-level / Expert,"  About the Role:
As an Senior Data Engineer, you will be responsible for leading the design and implementation of complex data pipelines and analytics solutions to support key decision-making business processes in our Reinsurance Client Solutions business domain. You will lead the development of strategic use cases within our Data Integration and Analytics platform. You will gain exposure to projects that are leveraging cutting edge technology that applies Big Data and Machine Learning to solve new and emerging problems for Swiss Re Reinsurance Client Solutions.
  You will be expected to work with business experts to understand client requirements and design and develop solutions to meet those needs. You will have end-to-end ownership of deliverables, gaining a full understanding of the Reinsurance data, Client data, and the business logic required to deliver analytics solutions.
  Key responsibilities include:         
Work closely with Product Owners, Business Analysts and Architects to understand requirements, formulate solutions and evaluate the implementation effort.
Design, develop and maintain scalable data transformation pipelines.
Design and implement analytics models and visualizations to provide actionable data insights.
Evaluate new capabilities of the analytics platform, develop prototypes and assist in drawing conclusions about the applicability to our solution landscape.
Collaborate within a global development team to design and deliver solutions.
Assist colleagues and clients with data-related functional and technical issues.
  About the Team:
This position is part of the Swiss Re Solutions Data & Technology organization. We are enabling our Clients to make data driven decisions at all stages of their value chain with the help of Swiss Re data and expertise.
  About You:
You enjoy the challenge of solving complex big data analytics problems using state-of-the-art technologies as part of a growing global team of data engineering professionals. You are a self-starter with strong problem-solving skills and capable of owning, designing and implementing solutions from start to finish. Key qualifications include:
  Experience designing and implementing data analytics solutions on enterprise data platforms and distributed computing (Spark/Hive/Hadoop preferred).
Proven track record of understanding and transforming customer requirements into a best-fit design and architecture.
Demonstrated experience in end-to-end data management, data modelling, and data transformation for analytical use cases.
Working experience in Palantir Foundry platform is preferred.
Proficient in Python/PySpark.
Proficient in SQL (Spark SQL preferred).
Experience with JavaScript/HTML/CSS a plus.
Experience working in a Cloud environment such as Azure or AWS is a plus.
Experience with Scrum/Agile development methodologies.
At least 10 years of experience working with large scale software systems.
Bachelor's degree level or equivalent in Computer Science, Data Science or similar discipline.
Knowledge of Insurance Domain or Financial Industry is a strong plus.
Experienced working in multicultural globally distributed teams.
Self-starter with a positive attitude and a willingness to learn, who can manage their own workload.
Strong analytical and problem-solving skills.
Strong interpersonal and communication skills, demonstrating a clear and articulate standard of written and verbal communication in complex environments.
  About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127740 
   ",USD 121K - 188K *
633,Data Engineer - Intern,Philips,Chennai - Cambridge Tower,Entry-level / Junior,"Job Title
Data Engineer - Intern
Job Description
About the Organization
Royal Philips (NYSE: PHG, AEX: PHIA) is a leading health technology company focused on improving people's health and enabling better outcomes across the health continuum from healthy living and prevention, to diagnosis, treatment and home care. Philips leverages advanced technology and deep clinical and consumer insights to deliver integrated solutions. Headquartered in the Netherlands, the company is a leader in diagnostic imaging, image-guided therapy, patient monitoring and health informatics, as well as in consumer health. Philips' health technology portfolio generated 2021 sales of EUR 17.2 billion and employs approximately 78,000 employees with sales and services in more than 100 countries.
Philips Global Business Services delivers excellence in the execution of business services, enabling an agile repeatable framework to leverage market opportunities that contribute to extending our leadership as a Health Technology company. Our people are a key part of the transformation program in Philips and at GBS, you become part of a global team of professionals that form the backbone of this journey.
Responsibilities:
Perform proof-of-concept projects, engage in product design, and build prototypes and production models.
Consider the full impact of your work. This means considering privacy, ethics, and regulation, as well as the performance of your code and the accuracy of your models.
Creates methods of obtaining data that can be used for data sciences and Data Visualization; Identifies ways to improve current data pipelines for future recommendations to reduce manual manipulation of data.
Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses & insights, and present these insights to the different stakeholders
A strong passion for empirical research and for answering hard questions with data
Good understanding of data warehousing concepts.
Strong with SQL and R / Python /Spark / Pandas programming or any other open-source programming language.
Contribute independently  to implement & deliver complex End to End project assignments simultaneously and support live applications
Able to work as an independent contributor in building an end-to-end implementation of Data Solutions
Develop, maintain, track and identify fine-tuning opportunities for existing data solutions for different business problems.
Design and develop Pipelines using Azure Databricks, Azure Data factory and other Azure data services
Should support the Production live application by maintaining 100% Data accuracy and data availability in all 24*7.
Experience with operational support and Governance
Working closely with Business Stakeholders, Technology Stakeholders, IT Teams and Advanced Analytics experts
Supporting Data Scientists with some background in AI/ML with data skills
Supporting Data Visualization team with some background in Qlik view/Power BI/Tableau reports with data skills
Be a champion of Standard software practices, high- & low-level architecture
Confidence training and guiding colleagues through complex technical challenges and best practice
Offer support by responding to system problems on time.
Essential Qualifications and Skills
Good undergraduate or Master's degree in a mathematical or technical discipline, such as Mathematics, Economics, Computer Science, Engineering, or MBA.
Your passion is focused on the design of algorithms and products to solve real, pressing problems using data
Obsessed with data, very strong quantitative and analytical muscle
Have 1+ years of experience with predictive modelling and statistical analysis techniques in a business environment. Exceptional recent graduates will also be considered.
Any Cloud certification and/or relevant Data experience is a plus
Excellent communication and presentation skills, good to have prior stakeholder management experience
Domain or process knowledge on various functions such as supply chain, procurement, finance etc.
Soft Skills Required
Good  communication and presentation skills
Highly driven, energetic, flexible, resourceful & able to multitask
Clarity of thoughts and vision
Ability to ideate and bring solutions to the table
Adherence to timelines, without sacrificing the quality of output
Hands-on and detail-oriented, with a strong ability to coordinate across different Geographies and with different stakeholders at Exec and Director levels
In return, we offer you
A challenging, innovative environment with great opportunities to explore. Our benefits are very competitive and designed around your preferences:
A rewarding career in Philips with an attractive package. `
A variable bonus based on both Philips results and personal performance
An extensive set of tools to drive your career, such as a personal development budget, free training and coaching
Attractive collective health insurance package
Opportunity to buy Philips shares and products with discount
How we work at Philips
Our newly-adopted hybrid work concept fuses flexibility with collaboration to deliver great outcomes for our people and our customers. We are embracing an approach wherein we spend more time together than apart – which for full-time employees translates to an average of at least 3 days working from the office and up to 2 days from home – for our hybrid roles.
Hybrid work flexibility means people can meet the changing demands of work and home in the most balanced, productive, and healthy way.
Our hybrid working model is defined in 3 ways:
We believe in the importance of impactful collaboration: There's a certain energy when everyone’s in the same room that can heighten idea generation and creative friction needed for problem-solving.
We embrace flexibility: Choosing where, when and how to work can vary according to task and team schedules. Flexibility isn’t office or online, it means choosing the space that works best for you, your teams and our customers on a case-by-case basis.
We want to be at our best: The way we work and our workspaces are designed to support our well-being, offer career advancement opportunities, and enable us to be at our best.
Why should you join Philips?
Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on innovative, customer-first health technology solutions. Help us improve the health and well-being of billions of people, every year. Ultimately creating a career that no one could have planned for. Even you.",None
634,ServiceNow Platform Senior AI Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
Join the team that's revolutionizing the industry, only at ServiceNow!!
Do you want to work on the latest offerings of Gen AI from ServiceNow and leverage the large language models (LLMs) for different use cases across the DT organization?
Do you want to configure, finetune the Now LLM for internal use cases?
Do you want to work on the latest and cutting egde GenAI solutions that teams within DT (Digital Technology) can use? Then this is the role for you!!
At ServiceNow, we are looking for a skilled & motivated Now Platform AI Engineer to join our team who is focussed on implementing, enhancing, integrating and optimizing GenAI solutions. You will closely work with the ServiceNow Platform Team to understand, validate and deploy the Gen AI solutions internally. You will collaborate cross-organization and partner with key stakeholders including GTM (Go to Market), Digital Employee Experience, Digital Customer Experience in DT Organization
You will Accelerate the value realization of Gen AI-powered solutions for DT organization at scale.
Responsibilities include but are not limited to:
As Customer Zero, Partner and collaborate with the product team for GenAI solutions
Create Alignment with all the Business Units within DT on GenAI use cases
Act as the bridge between Product team and the BU’s of DT to identify, evaluate and test GenAI solutions
Create POCs for the Use cases of DT organization, work with the product team to identify gaps and work towards solving them
Customize and enhance NowAssist to leverage AI capabilities for DT use cases
Be the enablement team in DT for the GenAI use cases.
Collaborate with Platform to refine the models based on feedback from stakeholders
Develop and Implement monitoring and alerting systems to track model performance and address issues proactively
Share knowledge with team members and contribute to a collaborative and innovative work culture
Qualifications
To be successful in this role, you should have:
4+ years of deep development experience in AI, ML or Analytics
Servicenow Platform Experience delivering AI-powered products/solutions like Predictive Intelligene and GenAI Solution
A desire to be an enablement subject matter expert (SME) on the AI & GenAI capabilities within the ServiceNow platform
Demonstrated experience in gathering and transforming product requirements into an actionable product roadmap
Exceptional problem-solving skills
Enjoys working in a highly collaborative environment
Experience delivering AI-powered products/solutions that leverage LLM and Search
 FD21
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 106K - 223K *
635,Senior Analyst Business Intelligence,NVIDIA,"India, Pune",Senior-level / Expert,"NVIDIA has continuously reinvented itself over two decades. Our invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI — the next era of computing. NVIDIA is a “learning machine” that constantly evolves by adapting to new opportunities that are hard to tackle, that only we can pursue, and that matter to the world. This is our life’s work, to amplify human creativity and intelligence. Make the choice to join us today .We are looking for a SAP BW HANA Analyst to design, develop business intelligence and analytics solutions at NVIDIA.

What you'll be doing:
Develop, and deploy BI solutions using multiple tools and technologies including but not limited to SAP Hana.
Developing data pipelines using ERP and other enterprise systems as source.
Work on the assigned development tasks and activities.
Understand the technical specifications and work on the BI development and unit testing
Develop analytics/reporting, dashboards.
Pursue problems and resolve technical issues. Participate in debugging and performance optimization.

What we need to see:
MBA or MS or BS degree or equivalent experience
10+ years of extensive development experience in BI and analytics space using SAP BI tools and other modern BI tools like data bricks/snowflake.
Hands on experience on at least one of the reporting and visualization tools like Tableau, pwoerBI
Hands on experience extracting data using ETL/ELT tools like SAP BODS, Alteryx or cloud tools like Amazon glue or programming languages like Python.
Expert level competency in SQL and performance optimization of SQL.
Exposure on cloud platforms preferably on AWS, using different AWS tools like Athena, Glue, S3, red shift etc.
Familiar with AI/ML algorithms for automating data loads and/or automating monitoring and data quality rules.
Demonstrable ability to handle efficient collection and migration of Transport Requests through the landscape and have hands on experience with version control tools.
Ways to stand out from the crowd:
Semiconductor industry experience, including the “fabless” business model
Experience with more than one modules of SAP systems and/or other enterprise applications like SFDC
Experience writing complex SQL for business questions.
Hands on experience with Snowflake/Databricks
NVIDIA is widely considered to be one of the technology world’s most desirable employers; we have some of the most forward-thinking and hardworking people in the world working for us and, due to unparalleled growth, best-in-class teams are rapidly growing. If you’re creative and autonomous with a real passion for your work, we want to hear from you! NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",USD 45K - 84K *
636,Data Analyst - Senior Associate,PwC,Bengaluru (SDC) - Bagmane Tech Park,Senior-level / Expert,"Line of Service
Advisory
Industry/Sector
Not Applicable
Specialism
Oracle
Management Level
Senior Associate
Job Description & Summary
A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities, coaching them to deliver results.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Use a broad range of tools and techniques to extract insights from current industry or sector trends.
Review your work and that of others for quality, accuracy and relevance.
Know how and when to use tools available for a given situation and can explain the reasons for this choice.
Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Data Analyst Role
●      Responsible for creating, evaluating and modifying prototypes to support evolving hardware and software application development.
●      Experience in Data analysis with multi domain datasets, Data sovereignty and data governance with network and cloud technologies. Able to deliver data mapping specifications for large reporting applications.
●      Deliver useful insights to decision-makers to influence experience design strategy
●      Produce datasets and reports for analysis using analytics and various reporting tools.
●      Will be responsible in developing design concept and implementation, providing input on user design considerations, producing specifications describing user needs and internal structures for product in development.
●      Document detailed user stories in Agile Product Development methodology; Groom the user stories with cross functional teams.
●      Hands-on experience with one or more language(s) used for querying (e.g., SQL, HQL)
●      Familiarity with big-data/analytics platforms/languages like Hadoop, Snowflake, Oracle with user access management and security.
●      Work with multiple sophisticated data sets to accelerate operational and strategic data-oriented decision-making. Understand the opportunities and business drivers building insight and solutions for those through data
●      Knowledge of designing, implementing, deploying, and maintaining the ETL/ELT process and data flow, including data quality using various data integration tools.
●      Identify, analyze, and interpret trends or patterns in complex data sets using statistical techniques and provide ongoing reports and dashboards including but not limited to Tableau
●      Able to assess the effectiveness and accuracy of new data sources and data gathering techniques
●      Should have experience with database design, from requirements analysis to conceptual, logical and physical data model designs for transactional applications.
●      Able to be technically adept at learning new technologies, architectural methodologies and adapting our practices to support frequent changes in the data environment.
●      Collaborate with team members, DBAs, architects and subject area owners to create scalable data models ensuring that database designs and modeling standards are in alignment with Enterprise Modeling best practices
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Data Analytics
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
Not Specified
Available for Work Visa Sponsorship?
No
Government Clearance Required?
No
Job Posting End Date",USD 92K - 145K *
637,"Research Scientist, Alexa Sensitive Content Intelligence (ASCI)",Amazon.com,"Bengaluru, Karnataka, IND",Senior-level / Expert,"Alexa is the voice activated digital assistant powering devices like Amazon Echo, Echo Dot, Echo Show, and Fire TV, which are at the forefront of this latest technology wave. To preserve our customers’ experience and trust, the Alexa Sensitive Content Intelligence (ASCI) team creates policies and builds services and tools through Machine Learning techniques to detect and mitigate sensitive content across Alexa. We are looking for an experienced Senior Applied Scientist to build industry-leading technologies in attribute extraction and sensitive content detection across all languages and countries.
A Senior Applied Scientist will be a tech lead for a team of exceptional scientists to develop novel algorithms and modeling techniques to advance the state of the art in NLP or CV related tasks. You will work in a hybrid, fast-paced organization where scientists, engineers, and product managers work together to build customer facing experiences. You will collaborate with and mentor other scientists to raise the bar of scientific research in Amazon. Your work will directly impact our customers in the form of products and services that make use of speech, language, and computer vision technologies.

We are looking for a leader with strong technical experiences a passion for building scientific driven solutions in a fast-paced environment. You should have good understanding of NLP models (e.g. LSTM, transformer based models) or CV models (e.g. CNN, AlexNet, ResNet) and where to apply them in different business cases. You leverage your exceptional technical expertise, a sound understanding of the fundamentals of Computer Science, and practical experience of building large-scale distributed systems to creating reliable, scalable, and high-performance products. In addition to technical depth, you must possess exceptional communication skills and understand how to influence key stakeholders.

You will be joining a select group of people making history producing one of the most highly rated products in Amazon's history, so if you are looking for a challenging and innovative role where you can solve important problems while growing as a leader, this may be the place for you.



Key job responsibilities
You'll lead the science solution design, run experiments, research new algorithms, and find new ways of optimizing customer experience. You set examples for the team on good science practice and standards. Besides theoretical analysis and innovation, you will work closely with talented engineers and ML scientists to put your algorithms and models into practice. Your work will directly impact the trust customers place in Alexa, globally. You contribute directly to our growth by hiring smart and motivated Scientists to establish teams that can deliver swiftly and predictably, adjusting in an agile fashion to deliver what our customers need.

A day in the life
You will be working with a group of talented scientists on researching algorithm and running experiments to test scientific proposal/solutions to improve our sensitive contents detection and mitigation. This will involve collaboration with partner teams including engineering, PMs, data annotators, and other scientists to discuss data quality, policy, and model development. You will mentor other scientists, review and guide their work, help develop roadmaps for the team. You work closely with partner teams across Alexa to deliver platform features that require cross-team leadership.
About the hiring group


About the team
The mission of the Alexa Sensitive Content Intelligence (ASCI) team is to (1) minimize negative surprises to customers caused by sensitive content, (2) detect and prevent potential brand-damaging interactions, and (3) build customer trust through appropriate interactions on sensitive topics.
The term “sensitive content” includes within its scope a wide range of categories of content such as offensive content (e.g., hate speech, racist speech), profanity, content that is suitable only for certain age groups, politically polarizing content, and religiously polarizing content. The term “content” refers to any material that is exposed to customers by Alexa (including both 1P and 3P experiences) and includes text, speech, audio, and video.

We are open to hiring candidates to work out of one of the following locations:

Bangalore, KA, IND
Basic Qualifications

- PhD, or Master's degree and 4+ years of quantitative field research experience
- Experience investigating the feasibility of applying scientific principles and concepts to business problems and products
- Experience analyzing both experimental and observational data sets
Preferred Qualifications
- Knowledge of R, MATLAB, Python or similar scripting language
- Experience with agile development
- Experience building web based dashboards using common frameworks",USD 150K - 240K *
638,"Manager, Data Science",Western Digital,"Bengaluru, India",Senior-level / Expert,"Company Description
We are seeking an innovative and accomplished Data Scientist to join our team. As a Data Scientist, you will collaborate with Analytics Business Partners (ABP)/AI-product managers to understand the problem statement, data, and analytics insights needed to solve a given business problem. You will be responsible for developing and implementing cutting-edge analytics solutions that generate new insights and drive business value.
Job Description
Lead, mentor and manage a team of data scientists, machine learning engineers, and researchers
Define OKRs and roadmaps for the team aligned with business goals
Oversee the end-to-end development of machine learning models and data products, ensuring high quality standards
Stay up-to-date on advances in AI/ML and lead integration of appropriate new technologies
Implement processes for rigorous testing, validation and monitoring of machine learning models
Identify and facilitate professional growth and skill development within the team
Provide technical guidance to the team and set standards for innovation
Balance delivery of rapid value with investment in innovative but high-impact solutions
Collaborate cross-functionally with business, product, and engineering teams to identify and execute on AI/ML opportunities
Manage workloads and provide prioritization guidance to optimize efficiency
Establish success metrics and regularly report progress to executives
Qualifications
PhD/Master’s in Computer Science, Data Science or related field preferred
8+ years relevant data science experience with at least 3 years in a team lead role
Extensive experience developing, deploying, and managing machine learning models in production
Deep knowledge of machine learning algorithms, model development, and deployment. You should be well-versed in various ML frameworks and libraries. Understanding of LLMs is a plus.
Demonstrated ability to lead and machine learning teams, fostering a collaborative and innovative work culture.
Strong track record of delivering business value via applied AI/ML
Proficiency in Python and frameworks like TensorFlow/PyTorch
Superb communication, strategic thinking and problem solving skills
Additional Information
Preference will be given to:
Experience in rigorous experimentation with large language models.
Experience in publishing research papers and patents to establish thought leadership in the industry. 
Proven experience in applying reinforcement learning techniques to solve real-world problems.
Penchant for self-learning, literature research, and participation in relevant conferences to stay up-to-date with the latest technological advancements in the AI/ML space. ",USD 45K - 84K *
639,Power BI/Power Apps Expert,Gainwell Technologies,"Bengaluru, KA, IN, 560100",Senior-level / Expert,"Summary
As a Power BI/Power Apps Expert at Gainwell, you can contribute your skills as we harness the power of technology to help our clients improve the health and well-being of the members they serve — a community’s most vulnerable. Connect your passion with purpose, teaming with people who thrive on finding innovative solutions to some of healthcare’s biggest challenges. Here are the details on this position.
  Your role in our mission
Apply healthcare domain knowledge to understand the data from various source systems and align the data to platform’s integration model.
Work with Business, Architects and System Analysts to fully understand the business requirements and translate them into Conceptual, Logical and Physical models.
Deliver high quality normalized and/or star schema models that will address strategic vision and goals of the platform.
Partner with development and QA teams to communicate the business rules, data models and ensure test cases target the quality and integrity of the data model.
Participate in regular model reviews, provide constructive feedback that will lead to higher quality models. 
Maintain superior quality metadata across all models.
Assists in providing time estimates for project-related tasks.
What we're looking for
Bachelor's degree in data management, computer science, or related field preferred.
6-9 years of IT experience with 2-3 years of hands-on experience in Power platform as illustrate below
Ability to gather functional requirements and provide the design specifications.
Be flexibility when there is a change to our priorities when needed.
Must have excellent verbal communications and documentation skills.
Must have proven experience in the below 
  Power BI
  Power Apps
  Power Automate
It is desirable and good to have development, test and maintenance skills on the below listed tools
Knowledge on RDBMS/SQL
Power Platform Gateway
Power BI:
Data modelling in the Power BI layer for optimal performance.
Experience in intuitive UX design of dashboards
Good working knowledge on DAX functions and power query
Knowledge on Row Level Security
PowerApps:
Understanding of Delegation in canvas apps
Performance optimization and considerations
Working experience on Variables , collections and DAX (LOOKUP,FILTER,PATCH etc)
Connecting and accessing Power Automate
Experience on responsive UX design
Usage of Dataverse and dataflow in canvas apps
Good knowledge on Solution, security and environments in Powerapps
Knowledge on Model Driven apps and Power Portals
Power Automate:
Good working knowledge and experience in Automated, Instant and Scheduled flows.
Performance optimized design of flows
Integration of flow with other apps through REST API
Usage of child flow
Good analytical skills ,problem solving skills and communication
The candidate must be able to work independently
Able to grasp and understand new technological trends & concepts
What you should expect in this role
  Fast-paced,challenging and rewarding work environment.
Work life balance.    
Hybrid Office environment.
Will require late evening work to overlap US work hours.",USD 45K - 84K *
640,AI Architect,HARMAN International,IN Bengaluru Sattva Knowledge Court Bdg HII,Senior-level / Expert,"HARMAN’s engineers and designers are creative, purposeful and agile. As part of this team, you’ll combine your technical expertise with innovative ideas to help drive cutting-edge solutions in the car, enterprise and connected ecosystem. Every day, you will push the boundaries of creative design, and HARMAN is committed to providing you with the opportunities, innovative technologies and resources to build a successful career.
A Career at HARMAN
As a technology leader that is rapidly on the move, HARMAN is filled with people who are focused on making life better. Innovation, inclusivity and teamwork are a part of our DNA. When you add that to the challenges we take on and solve together, you’ll discover that at HARMAN you can grow, make a difference and be proud of the work you do everyday.
About the Job:
You are a passionate AI professional, who is enthusiastic about automotive electronics and wants to define the future in-cabin user experience.
Join our Automotive AI Lab as AI Architect. The AI Architect position is a high-impact role where you will work directly with Product Management, Automotive Domain Architects, and Engineering to shape product definition and identify AI technology fit to enhance our OTA (Over-the-Air update) products. Collaborating with global automotive and AI/ML expert teams, you will design and implement solutions for a compelling vehicle software update experience for OEM customers and end-consumers.
Responsibilities:
· Lead architect and technical leader of the AI Analytics team
· Conceptualize and design AI-based solutions that optimize OTA campaign success and delivery algorithms
· Coordinate requirements, roadmaps, and delivery schedules with product lines
· Collaborate with internal and external suppliers on solution design and technology selection
· Act as AI technology ambassador, continuously improving and innovating the AI value-add in our OTA product portfolio
· Keep pace with AI/ML technology advancements in automotive, adjacent areas, and academia; guide your team and peers; run feasibility studies and PoCs; support business analyses
Minimum Qualification:
· Master's degree in computer science or comparable practical experience
· 9 years of industry experience with 4 years of experience in applied machine learning, data science, and big data technologies
· 2 years technical leadership experience
· Experience in developing AI/ML analytics applications like OTA, predictive maintenance, recommendation systems
· Experience with MLOps and cloud machine-learning platforms like SageMaker, DataBricks
· Relevant practical experience with selected AI tech stacks, tool chains, data collection, synthetic data and simulators (e.g. PyTorch, Kafka, Apache Spark, Python, Java)
Preferred Qualification:
· Experience working with automotive services or products
· Proficient coding capability in Java
· Experience in production-grade ML workflows
· Project management experience in a production environment
What Makes You Eligible:
· Willingness to travel up to 10%, domestic and international travel
· Be willing to work in an office or home office in Bengaluru, India
HARMAN is an Equal Opportunity /Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race,color, religion, sex, sexual orientation, gender identity, national origin,disability or Protected Veterans status. HARMAN offers a great work environment, challenging career opportunities, professional training and competitive compensation. (www.harman.com)",USD 204K - 330K *
641,Data Engineer,Merck Group,"Bengaluru, Karnataka, IN, 560100",Senior-level / Expert,"Work Your Magic with us! 
  Ready to explore, break barriers, and discover more? We know you’ve got big plans – so do we! Our colleagues across the globe love innovating with science and technology to enrich people’s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That`s why we are always looking for curious minds that see themselves imagining the unimageable with us.
  Job Title: Data Engineer - Enterprise Big Data Platform
In this role, you will be part of a growing, global team of data engineers, who collaborate in DevOps mode, to enable Merck's Life Science business with state-of-the-art technology to leverage data as an asset and to take better informed decisions.
The Life Science Data Engineering Team is responsible for designing, developing, testing, and supporting automated end-to-end data pipelines and applications on Life Science’s data management and analytics platform (Palantir Foundry, Hadoop, and other components).
 
The Foundry platform comprises multiple different technology stacks, which are hosted on Amazon Web Services (AWS) infrastructure or on-premises Merck’s own data centers. Developing pipelines and applications on Foundry requires: 
•    Proficiency in SQL / Java / Python (Python required; all 3 not necessary)
•    Proficiency in PySpark for distributed computation
•    Familiarity with Postgres and ElasticSearch
•    Familiarity with HTML, CSS, and JavaScript and basic design/visual competency
•    Familiarity with common databases (e.g., JDBC, mySQL, Microsoft SQL). Not all types required
 
This position will be project based and may work across multiple smaller projects or a single large project utilizing an agile project methodology. 
 
Roles & Responsibilities: 
•    Develop data pipelines by ingesting various data sources – structured and un-structured – into Palantir Foundry
•    Participate in end-to-end project lifecycle, from requirements analysis to go-live and operations of an application
•    Acts as business analyst for developing requirements for Foundry pipelines
•    Review code developed by other data engineers and check against platform-specific standards, cross-cutting concerns, coding and configuration standards and functional specification of the pipeline
•    Document technical work in a professional and transparent way. Create high quality technical documentation
•    Work out the best possible balance between technical feasibility and business requirements (the latter can be quite strict)
•    Deploy applications on Foundry platform infrastructure with clearly defined checks
•    Implementation of changes and bug fixes via Merck's change management framework and according to system engineering practices (additional training will be provided)
•    DevOps project setup following Agile principles (e.g., Scrum)
•    Besides working on projects, act as third level support for critical applications; analyze and resolve complex incidents/problems. Debug problems across a full stack of Foundry and code based on Python, Pyspark, and Java
•    Work closely with business users, data scientists/analysts to design physical data models
 
Education 
•    Bachelor (or higher) degree in Computer Science, Engineering, Mathematics, Physical Sciences, or related fields 
 
Professional Experience  
•    5+ years of experience in system engineering or software development
•    3+ years of experience in engineering with experience in ETL type work with databases and Hadoop platforms.
 
Skills
Hadoop General    Deep knowledge of distributed file system concepts, map-reduce principles, and distributed computing.  Knowledge of Spark and differences between Spark and Map-Reduce.  Familiarity of encryption and security in a Hadoop cluster.
Data management / data structures    Must be proficient in technical data management tasks, i.e., writing code to read, transform and store data
XML/JSON knowledge
Experience working with REST APIs
Spark    Experience in launching spark jobs in client mode and cluster mode.  Familiarity with the property settings of spark jobs and their implications to performance.
Application Development    Familiarity with HTML, CSS, and JavaScript and basic design/visual competency
SCC/Git    Must be experienced in the use of source code control systems such as Git
ETL     Experience with developing ELT/ETL processes with experience in loading data from enterprise sized RDBMS systems such as Oracle, DB2, MySQL, etc.
Authorization    Basic understanding of user authorization (Apache Ranger preferred)
Programming     Must be at able to code in Python or expert in at least one high level language such as Java, C, Scala.
Must have experience in using REST APIs
SQL     Must be an expert in manipulating database data using SQL.  Familiarity with views, functions, stored procedures and exception handling.
AWS     General knowledge of AWS Stack (EC2, S3, EBS, …)
IT Process Compliance    SDLC experience and formalized change controls
Working in DevOps teams, based on Agile principles (e.g., Scrum)
ITIL knowledge (especially incident, problem and change management)
Languages     Fluent English skills
 
Specific information related to the position: 
•    Physical presence in primary work location (Bangalore)
•    Flexible to work CEST and US EST time zones (according to team rotation plan)
•    Willingness to travel to Germany, US, and potentially other locations (as per project demand)
  What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
Apply now and become a part of our diverse team!",USD 110K - 181K *
642,Senior Data Engineer,"Insight Enterprises, Inc.","Gurugram Gurgaon HR, IN",Senior-level / Expert,"Requisition Number: 95163 
Role – Senior Data Engineer
  Job Description
  Required Experience: 5 - 8 Years
  Skills: Databricks, ADF, SQL, Snowflake
  Responsibilities – Senior Data Engineer will be responsible for designing, developing, and maintaining complex ETL pipelines that extract, transform, and load data for building of Enterprise Data platform.
Minimum of 5 - 8 years of overall experience.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Strong hands-on experience in designing, developing, testing, and maintaining complex ETL pipelines using Databricks.
Experience in extracting, transforming, and loading data from a variety of data sources by adopting latest ETL technologies and best practices.
Experience in implementing Azure data services solutions, including Azure Data Factory, SQL Database, Stream Analytics and Data Lake.
Ability to troubleshoot and debug complex ETL pipelines.
Possess a deep understanding of data warehousing concepts, reporting, and analytical concepts.
Good to have experience in Snowflake, ML & Big Data stack.
Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
  Insight India Location:Level 16, Tower B, Building No 14, Dlf Cyber City In It/Ites Sez, Sector 24 &25 A Gurugram Gurgaon Hr 122002 India",USD 121K - 188K *
643,Principal Data Scientist,Western Digital,"Bengaluru, India",Senior-level / Expert,"Company Description
We are seeking an innovative and accomplished Data Scientist to join our team. As a Data Scientist, you will collaborate with Analytics Business Partners (ABP)/AI-product managers to understand the problem statement, data, and analytics insights needed to solve a given business problem. You will be responsible for developing and implementing cutting-edge analytics solutions that generate new insights and drive business value.
Job Description
Drive innovation by researching and implementing state-of-the-art AI/ML techniques, build POCs, and constantly exploring new ways to improve our analytics capabilities.
Work with SMEs to establish data understanding and address data quality issues.
Perform data cleansing, feature engineering, and exploratory data analysis to prepare data required for modelling.
Partner with other data scientists in AAO and Asia factories to build advanced statistical, AI, and ML models that are congruent with the problem being solved and optimize for performance.
Seamlessly operationalize models developed from notebooks to customer pilot to production with the help of ML Engineers and Solution Architects in AAO.
Present findings and recommendations to project stakeholders in a compelling manner that communicates complex data and analytics insights effectively.
Lead and manage two or more ML projects with diverse cross-functional teams.
Qualifications
BE/BS/MS/PhD in a quantitative discipline (e.g., Computer Science, Data Science, Applied Sciences or Engineering).
BE/BS & 8+ years or MS & 4+ years or PhD & 3+ year of experience in data science and machine learning.
Strong theoretical understanding & hands-on experience in statistical data analysis, AI & ML techniques (e.g., generative text techniques, NLP/NLU/NLG, supervised and unsupervised modelling, Deep Learning, CNN, NLP, Time-series analysis) and common data analytics tools (e.g., Python, R, Tensorflow etc).
Experience with Database Technologies (SQL, NoSQL), Big Data Technologies (Hadoop, Hive, Spark) and Cloud Technologies (AWS, GCP).
Strong problem solving and critical thinking skills.
Positive attitude towards learning on-the-job and thriving in a rapidly changing environment.
Additional Information
Preference will be given to:
Experience in rigorous experimentation with large language models.
Experience in publishing research papers and patents to establish thought leadership in the industry. 
Proven experience in applying reinforcement learning techniques to solve real-world problems.
Penchant for self-learning, literature research, and participation in relevant conferences to stay up-to-date with the latest technological advancements in the AI/ML space. ",USD 173K - 235K *
644,Hadoop Developer (Hadoop/Nifi/Spark),Gainwell Technologies,"Chennai, TN, IN, 600032",Senior-level / Expert,"Summary
  Establishes and enforces data warehousing standards, determines data warehousing strategy, and selects data tools and techniques to devise solutions to complex integrated warehousing projects. Focuses on a specific product or family of technologies in multiple platforms; functions independently within a business area and assists at the enterprise level to influence the technical decisions during various phases of the project.
Essential Job Functions
  Experience working in large-scale on Hadoop development & implementations.
Proven knowledge and experience with core Hadoop ecosystem including Nifi, HIVE, Spark etc.,
Experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, Hadoop, Spark.
Proficiency in scripting languages in python, pyspark/Scala spark.
Experience in Database design/data modelling.
Must have strong experience in data warehouse concepts.
Ability to work creatively and analytically in a problem-solving environment.
Knowledge of US healthcare will be an advantage.
Assists in outlining new product/service business case justification to ensure that the proposed solution can deliver articulated business benefits to the client.
Basic Qualifications
  Bachelor's degree in computer science, information systems, or related field preferred.
At least 5 years of experience in Hadoop Development.
Experience working with technical products, vendors, and families of technologies.
Experience working with product configurations.
Experience working with relevant software packages or classes of packages, and products within area of technical expertise.
What you should expect in this role
  Hybrid Office environment.
Fast-Paced, Challenging and rewarding work environment.
Work life balance.    
Will require late evening work to overlap US work hours.",USD 45K - 84K *
645,Data Scientist Engineer,GSK,Bengaluru,Senior-level / Expert,"GSK is one of the world’s foremost pharmaceutical and healthcare companies, and we are proud to be part of an industry that improves the lives of others. We embark on a significant transformation journey to support GSK in becoming a top-quartile data-enabled organization.
This is an exciting time to join GSK. We are embracing new data technologies to improve the development, manufacture, and distribution of GSK’s vital products to patients and consumers worldwide. You will be part of a team building a robust data and analytics ecosystem, allowing GSK to drive higher value by placing data at the core of its strategic and operational decisions.
This is an ideal role for a candidate with previous experience in applied data science, data analysis & insights generation and wishing to grow their career in healthcare analytics and towards finding critical solutions to drive patient outcomes.
This role will apply natural language processing and text analytics capabilities to translate unstructured data (human language / Medical voice of customer) into key topics, context summaries, and sentiment for additional insight discovery. This role will have two key responsibilities - solving business problem statements through execution of ad hoc analyses and building / maintaining data science solutions to be embedded as features into analytics product.
This role will provide YOU the opportunity to lead key activities to progress YOUR career. These responsibilities include some of the following:
Partner with Global Medical affairs to understand the business problem / need, define the analytical problem statement and scope out the deliverable and delivery plan.
Execute analysis to discover customer and patient findings/potential insights using domain understanding, business acumen and advanced analytics techniques such as natural language processing, text analytics, statistical analysis, machine learning; aligned with and guided by the Global Medical Affairs business priorities and strategies.
Partner with the Medical Insights leads to reveal findings that are potential insights for medical expert validation and pressure testing. Determine appropriate advanced analytic solutions for more efficient customer focus to support the insight leads.
Leverage NLP methodologies to build solutions that analyze unstructured data from multiple feedback.
Appropriately train and maintain ML models for accuracy and relevance with analytical findings. Pull through analytics and business acumen through appropriate selection of methods fit for purpose that reveal customer patterns in the data that may spark additional data analysis or research for deep customer insight.
Productize analytics solutions / Proof of concepts as features on Azure based analytics platform using systems understanding, engineering constraints and system performance needs.
Core and Technical Competencies, to be successful in this role, you should demonstrate
Must have
4+ years of experience of working in Data Science role.
2+ years of experience with unstructured data analysis/text analytics/natural language processing
Practical experience in applied ML and NLP (including language models).
Demonstrate proficiency in Python programming, SQL, Statistics, data pipelines and data story telling through visualization methods e.g., PowerBI, PowerPoint, Excel etc.
Working knowledge of cloud based and local data science frameworks and toolkits. Experience in Azure / Databricks is preferred but GCP / AWS would be considered.
Be curious and passionate about creative thinking and data innovation, enjoy problem solving and have empathy for the problems you are challenged to solve.
Be able to compile, integrate and analyze data from multiple sources to answer business questions and ad-hoc analysis requests.
Should be able to independently drive stakeholder discussions and project delivery.
Good To have
Knowledge of Deep learning models is preferred but not mandatory.
Exposure to building large scale machine learning systems or product development environment would be preferred but not mandatory.
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
 ",USD 136K - 205K *
646,Staff Engineer - Data scientist,Freshworks,"Bengaluru, India",Senior-level / Expert,"Company Description
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end user. Headquartered in San Mateo, California, Freshworks has a global team operating from 13 global locations to serve more than 65,000 companies -- from startups to public companies – that rely on Freshworks software-as-a-service to enable a better customer experience (CRM, CX) and employee experience (ITSM). 
Freshworks’ cloud-based software suite includes Freshdesk (omni-channel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshchat (AI-powered bots), supported by Neo, our underlying platform of shared services.
Freshworks is featured in global national press including CNBC, Forbes, Fortune, Bloomberg and has been a BuiltIn Best Place to work in San Francisco and Denver for the last 3 years. Our customer ratings have earned Freshworks products TrustRadius Top Rated Software ratings and G2 Best of Awards for Best Feature Set, Best Value for the Price and Best Relationship. 
Job Description
About the role:
As a Staff Engineer Data Scientist with a focus on GenAI (Generative Artificial Intelligence), you will be at the forefront of pioneering innovative applications of data science and machine learning in employee engagement. In this role, you will lead efforts to leverage GenAI techniques to address unique challenges within our company, including building a state of the art conversational servicebot that should scale across a million MAU, developing cutting edge production AI/ML solutions to complex Text2Action problems, time series data to look for anomalous behavior. Imagine the next generation of IT services being offered not via dashboards or clicks or filters but in an interactive, conversational manner, backed by real time analysis of the entire streaming data into an operating center. This vision is what you would make into a reality. You will build algorithms that analyze these millions of streaming data points, build a distributed, scalable, and high-performance system to serve the insights to the customer through a next-gen conversational UI/UX.  
Responsibilities:
Strategic Collaboration: Collaborate closely with product and business teams to gain a comprehensive understanding of the challenges and opportunities within the GenAI landscape, aligning data science initiatives with the organization's objectives.
Metric Definition: Define key performance metrics that accurately reflect the value delivered to end-users through GenAI solutions.
Intelligent System Design: Apply deep expertise in machine learning, statistics, and advanced mathematics to conceptualize, experiment, and design intelligent systems powered by GenAI.
Big Data Processing: Develop efficient systems capable of processing vast volumes of data, demonstrating proficiency in distributed programming frameworks like Hadoop and Spark.
ML/AI Architecture: Collaborate closely with ML Engineers to design scalable systems and model architectures that enable real-time ML/AI services.
End-to-End ML Pipelines: Take ownership of ML pipelines from end to end, encompassing data pre-processing, model generation, cross-validation, and feedback sharing.
Qualifications
A Bachelor’s degree or higher in Computer Science, Statistics, Mathematics, or a related field, with a minimum of 10 years of relevant work experience.
Strong problem-solving and programming skills, coupled with a profound understanding of the mathematical foundations underpinning machine learning algorithms, including probability, statistics, linear algebra, calculus, and optimization.
Proven track record of successfully deploying ML projects in production systems with substantial individual contributions.
Experience with natural language processing tasks utilizing prompt engineering, LLMs, transformers, and knowledge graphs is highly advantageous. 
Proficiency in time series analysis, NLP, Distributed Systems, large-scale computing, and Big Data technologies such as and Spark is a plus.
A solid background in at least 3 of the following areas: Natural language processing, statistical ML techniques, graph algorithms, constraint optimization, signal processing (speech or vision), deep learning, and distributed systems.
Proficiency with database systems and schema design, encompassing both SQL and NoSQL databases.
If you are a forward-thinking data scientist with a passion for pushing the boundaries of GenAI and envision yourself driving the transformation of IT services through interactive, conversational experiences, we encourage you to apply and join our dynamic team. Your expertise will play a pivotal role in turning our GenAI vision into a reality.
Additional Information
All your information will be kept confidential according to EEO guidelines.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 136K - 205K *
647,Data Architect,KONE,Chennai ITEC/KBS,Senior-level / Expert,"As Data Architect your main responsibilities will be:
Managing the data product backlog: Analyzing data requirements and forming information requirements specifications for data products. Translating business requirements into clear data requirements for end-to-end data pipeline creation and business optimized data consumption.
Designing data architecture and data products on the platform: Data architecture design, data modelling and data quality assurance activities.
Driving data related innovation creation, such as developing new data products, and providing guidance to data consumers about existing data products and data consumption capabilities.
Translating the KONE level strategic objectives to data requirements on the platform. Bringing data architecture perspective to decision making and planning activities helping to deal with complex implementations.
Identifying data architecture improvement needs and opportunities and ensure that the improvements are incorporated to data & analytics platform roadmap, and also to source systems or data consuming systems roadmaps, when required.
Supporting in incident process when the incident is related to in data issues on the platform. Helping in identifying data flow and data quality flaws causing these incidents, and to preparing change proposals to permanently fix them.
Data asset and data product cataloguing to Data Catalog to improve availability of data documentation, and usability of data by the data consumers.
The desired candidate will have:
Master’s degree in engineering, computer science, management information systems, or a related field
Data architecture professional experience
Passion for data and ability to quickly master complex data enterprise landscapes. Proven professional experience in data architecture development, data product development and data modelling.
Data subject matter experience in multiple processes areas (e.g. sales, finance, logistics, procurement, engineering) and genuine passion to understand data produced in the business processes.
Previous working experience working with enterprise systems data covering multiple functional areas in e.g. SAP ERP and Salesforce, or other major enterprise systems.
Data platform and analytics professional experience
Hands-on professional experience in data engineering and analytical data processing (data lake, lake house, data warehouse and analytics), and working with raw, semi structured, and unstructured data.
Ability to provide data architecture leadership on hands-on level to data engineering teams. Working knowledge in data integrations/ETL/ELT, data quality, data compliancy, AWS data analytics services and Databricks.
Ways of working professional experience
Working proficiency in agile and lean development methods and ceremonies.
Ability to work in global multi-cultural team and effectively manage collaboration with all stakeholder groups including global business functions.
Ability to self-organize and be proactive, seek feedback, be courageous and resilient, and have excellent problem-solving skills.
Proficiency in spoken and written English language, and strong facilitation and communication skills.
At KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.
Read more on www.kone.com/careers",USD 115K - 193K *
648,Sr Data Engineer - Remote (Mumbai),Aryng,"Mumbai, Maharashtra, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a cloud data engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 188K *
649,Sr. Data Engineer,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Are you passionate about Data Engineering? Do you like to solve the most complex and large-scale data challenges? Do you want to have an impact on the development and use of new Analytics technologies? Come join us.
Our HR and Learning systems landscape are comprised of home-grown and vendor applications such as Workday, ADP, Smart Recruiters, Degreed, Absorb, and many others.  We have embarked on a major transformation journey to leverage a variety of vendor applications and custom software, to build a connected systems architecture, that is reliable, trusted, responsive, and always available. We are creating the next generation of employee experiences and journeys via self-service portals, embedding HR capabilities within commonly used applications, applying Artificial Intelligence & Machine Learning, mastering Data management and insights, and applying Automation. 
We are looking for a Senior Data Engineer to build next generation analytics and reporting platform. The successful candidate will be a well-rounded data engineer with a strong expertise and experience in building large scale applications with Big Data technologies like Hadoop, Spark, Hive, Map Reduce etc.
 Job Responsibilities:
Work with business partners and team members to fully understand business requirements and desired business outcomes.
Assist in scoping and designing analytic data assets, implementing modelled attributes, and contributing to brainstorming sessions.
Build and maintain a robust data engineering process to develop and implement self-serve data and tools for Visa’s data scientists.
Perform other tasks on data governance, system infrastructure, analytics tool evaluation, and other cross team functions, on an as-needed basis.
Find opportunities to create, automate and scale repeatable analyses or build self-service tools for business users.
Implement data engineering projects ranging from small to large either individually or as part of a project team.
Ensure project delivery within timelines and budget requirements.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Qualifications
Bachelor’s degree in a technical field such as computer science or equivalent required.
Minimum of 5 years of software development experience (with a concentration in data centric initiatives), with demonstrated expertise in using standard development best practice methodologies.
Experience in building large-scale applications using open-source technologies. Design and coding skills with Big Data technologies like Hadoop, Spark, Hive, and Map Reduce
Experience with highly distributed, scalable, concurrent, and low latency systems working with one or more of the following database technologies: MS SQL server, DB2, MySQL and NoSQL data warehouses such as Mongo DB.
Experience working with Microsoft technologies like MSBI, Power BI, .Net, SQL Server preferred.
Experience working in an Agile Development environment.
Experience with Continuous Integration and Automated Test tools such as Jenkins, Artifactory, Git, Selenium, Chef desirable
Familiarity or experience with GenAI tools and methodologies, data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.) is preferred.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 188K *
650,Sr Data Engineer - Remote (Hyderabad),Aryng,"Hyderabad, Telangana, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a cloud data engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 188K *
651,"Professional 3, Information Technology - ETL. Apache Spark applications",Western Digital,"Bengaluru, India",Entry-level / Junior,"Company Description
At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.
At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that. Our technology helped people put a man on the moon.
We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world’s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.
Binge-watch any shows, use social media or shop online lately? You’ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That’s us, too.
We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital®, G-Technology™, SanDisk® and WD® brands.
Today’s exceptional challenges require your unique skills. It’s You & Western Digital. Together, we’re the next BIG thing in data.
Job Description
Minimum of 6+ years of experience in developing ETL jobs using any industry leading ETL tool.
Ability to design, develop, and optimize Apache Spark applications for large-scale data processing.
Ability to implement efficient data transformation and manipulation logic using Spark RDDs and Data Frames.
Ability to design, implement, and maintain Apache Kafka pipelines for real-time data streaming and event-driven architectures.
Development and deep technical skill in Python, Scala, and SQL/Procedure.
Working knowledge and understanding on Unix/Linux operating system like awk, ssh, crontab, etc.,
Ability to write transact SQL, develop and debug stored procedures and user defined functions in python.
Working experience on Postgres and/or Redshift database is required.
Exposure to CI/CD tools like bit bucket, Jenkins, ansible, docker, Kubernetes etc. is preferred.
Ability to understand relational database systems and its concepts.
Ability to handle large table/dataset of 2+TB in a columnar database environment.
Ability to integrate data pipelines with Splunk/Grafana for real-time monitoring, analysis, and visualization.
Ability to create and schedule the Airflow Jobs.
Qualifications
Minimum of a bachelor’s degree in computer science or engineering.  Master’s degree preferred.
AWS developer certification will be preferred.
Any certification on SDLC (Software Development Life Cycle) methodology,  integrated source control system, continuous development and continuous integration will be preferred.
Additional Information
Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.
Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at staffingsupport@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.",USD 22K - 42K *
652,Senior Principal Data Engineer,Merck Group,"Bengaluru, Karnataka, IN, 560100",Senior-level / Expert,"  Work Your Magic with us!  
  Ready to explore, break barriers, and discover more? We know you’ve got big plans – so do we! Our colleagues across the globe love innovating with science and technology to enrich people’s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.
  Everything we do in Electronics is to help us deliver on our purpose of being the company behind the companies, advancing digital living. We are dedicated to being the trusted supplier of high-tech materials, services and specialty chemicals for the electronics, automotive and cosmetics industries. We foster a global collaborative organization made up of individuals who have the passion to win, obsess about the customer, are relentlessly curious and act with urgency. Together, we push the boundaries of science to make more possible for our customers.
  Company Healthcare R&D Data Sciences seeks biological data engineering support for data analysis activities, to build our FAIR data environment, and to streamline our data handling.  Omics Data Engineering will play a pioneering role in establishing this new group and a leading role in building tools and setting standards for biological data.  Our Data Engineers will work in Company's X-Omics Platform, which won the 2022 BioIT Innovative Practices Award.
‘Omics Data Engineers will work on clinical and pre-clinical datasets but their focus is biological data types (e.g., DNA sequencing, proteomics, gene expression, collectively “omics data”).  While the group will be responsible for routine data engineering tasks, its success will be measured by the extent to which activities can be automated, problems anticipated, and attention focused on our data strategy.  Data engineers will collaborate daily with scientists at Company's other R&D hubs and across departments.  Ideal candidates will have a background with biological data, perhaps through bioinformatics or data management experience. 
  Specific responsibilities for data engineers include
building tools to automate data transfers and QC
working with other Data Sciences functions on an R&D-wide data catalog
developing and implementing standards for data formats, processing, and documentation
training internal users on data standards, data formats, and data assets
running pipelines for raw data analysis
arranging and managing data transfers with CROs and data providers
Core qualifications for ‘Omics Data Engineers
experience with data engineering, data management, and cleaning in biology or healthcare
attention to detail and ability to lead work with multiple parties (analyst, data type subject matter expert, external lab, etc.) to accomplish data transfers efficiently
experience with R and Python programming, as well as other tools/technologies such as RShiny and SQL
experience with Linux command line, shell scripting, and AWS S3
experience with controlled vocabularies and ontologies
Preferred qualifications include:
RNASeq and DNASeq data processing
Familiarity with ADaM or SDTM data standards

What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
 
Apply now and become a part of our diverse team!
 ",USD 121K - 188K *
653,GSSO - Data Engineering - Specialist / Sr. Specialist,Colgate-Palmolive,"Mumbai, MH, IN",Senior-level / Expert,"Relocation Assistance Offered Within Country
# 156966 - Mumbai, Maharashtra, India

Who We Are
Colgate-Palmolive Company is a caring, innovative growth company that is reimagining a healthier future for all people, their pets and our planet. Focused on Oral Care, Personal Care, Home Care and Pet Nutrition, we sell our products in more than 200 countries and territories under brands such as Colgate, Palmolive, elmex, hello, meridol, Sorriso, Tom’s of Maine, EltaMD, Filorga, Irish Spring, PCA SKIN, Protex, Sanex, Softsoap, Speed Stick, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Pet Nutrition.

We are recognized for our leadership and innovation in promoting sustainability and community wellbeing, including our achievements in decreasing plastic waste and promoting recyclability, saving water, conserving natural resources and improving children’s oral health.

If you want to work for a company that lives by their values, then give your career a reason to smile and join our global team!
  Job Summary
The candidate is an individual contributor and responsible for design, development and implementation of various applications in the area of large scale worldwide Colgate e-Commerce Operation and provides support.
The person will be required to collaborate with business teams / functional teams and IT counterparts for daily support incidents and project activities in different business areas across all geographies.
The person should have the ability to understand the requirements related to business problems and transform that into a solution design.
Main Responsibilities
Understand and apply information technology standards to daily support and project implementation activities
Involve in planning, design, development and maintenance of our data repositories, pipeline, and analytical solutions
Build and maintain optimal data pipeline architecture
Assemble large, sophisticated data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for efficient extraction, transformation, and loading of data from a wide variety of data sources
Assist with data-related technical issues and support their data infrastructure needs.
Build data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics specialists to strive for greater functionality in our data systems
Apply conceptual knowledge of business processes and technology to design solutions and tackle high complexity issues
Work closely with internal team and external partners to ensure new developments align with roadmap and integrate seamlessly with other platform components
Ensuring that systems are safe and secure against cybersecurity threats
Maintain production systems reliability through correct utilization of GIT standard support and governance processes
Support day to day business requirements according to global SLA
Deliver solutions to solve business requirements considering priorities and resources availability
Ensure the proper use of information technology project management methodology to comply of information technology governance practices
Collaborate with business and functional teams, develop detailed plans and accurate estimates for completion of build, system testing and implementation phases of project
Ensure proper documentation of processes, knowledge acquisitions and transfers
Manage / guide members to implement cross functional projects / initiatives leveraging project management standards
Conduct performance tuning to improve system performance over multiple business processes
Mentor and share knowledge to grow and develop the skills of the eCommerce team members
Eager to learn new technologies, extract insights and value from data and how to leverage technology to deliver those insights while protecting user data through compliance with privacy standards & regulations and implementation of appropriate security safeguards
Required Qualifications
Over all 5+ years of IT experience and min 4 years of experience in a Data Engineer role
SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with multi-functional teams in a multifaceted environment
Preferred Qualifications
Bachelor’s degree or higher degree in Computer Science, Statistics, Informatics, Information Systems or related work experience
Certification in Data Engineer is preferable
Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc
Experience with cloud services: Snowflake, GCP, DBT, etc
Experience with object-oriented/object function scripting languages: Python, JS, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.

Our Commitment to Sustainability
With the Colgate brand in more homes than any other, we are presented with great opportunities and new challenges as we work to integrate sustainability into all aspects of our business and create positive social impact. We are determined to position ourselves for further growth as we act on our 2025 Sustainability & Social Impact Strategy.

Our Commitment to Diversity, Equity & Inclusion
Achieving our purpose starts with our people — ensuring our workforce represents the people and communities we serve —and creating an environment where our people feel they belong; where we can be our authentic selves, feel treated with respect and have the support of leadership to impact the business in a meaningful way.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.

#LI-Hybrid",USD 121K - 188K *
654,Sr Data Engineer - Remote (Gurgaon),Aryng,"Gurugram, Haryana, India - Remote",Senior-level / Expert,"Welcome! You made it to the job description page!
Aryng is looking for a cloud data engineer with experience in developing enterprise-class distributed data engineering solutions on the cloud. We are seeking an entrepreneurial and technology-proficient Data Engineer who is an expert in the
implementation of a large-scale, highly efficient data platform, batch, and real-time pipelines and tools for Aryng clients. This role is based out of India. You will work closely with a team of highly qualified data scientists, business analysts, and
engineers to ensure we build effective solutions for our clients. Your biggest strength is creative and effective problem-solving.
Key Responsibilities:
Should have implement asynchronous data ingestion, high volume stream data processing, and real-time data analytics using various Data Engineering Techniques.
Implement application components using Cloud technologies and infrastructure.
Assist in defining the data pipelines and able to identify bottlenecks to enable the adoption of data management methodologies.
Implementing cutting edge cloud platform solutions using the latest tools and platforms offered by GCP, AWS, and Azure.
Functional capabilities: Requirement gathering, Client Mgt, team handling, Program delivery, Project Management (Project Estimation, Scope of Project, Agile methodology).
Requirements
5+ years of data engineering experience is a must.
2+ years implementing and managing data engineering solutions using Cloud solutions GCP/AWS/Azure or on-premise distributed servers
2+ years’ experience in Python.
Must be strong in SQL and its concepts.
Experience in Big Query, Snowflake, Redshift, DBT.
Strong understanding of data warehousing, data lake, and cloud concepts.
Excellent communication and presentation skills
Excellent problem-solving skills, highly proactive and self-driven
Consulting background is a big plus.
Must have a B.S. in computer science, software engineering, computer engineering, electrical engineering, or a related area of study
Good to have:
Experience in some of the following: Apache Beam, Hadoop, Airflow, Kafka,Spark
Experience in Tableau, Looker, or other BI tools is preferred
This role requires mandatory overlap hours with clients in the US from 8 am to 1 pm PST.
Benefits
Direct Client Access
Flexible work hours
Rapidly Growing Company
Awesome work culture
Learn From Experts
Work-life Balance
Competitive Salary
Executive Presence
End to End Problem Solving
50%+ Tax Benefit
100% Remote company
Flat Hierarchy
Opportunity to become a thought leader

Why Join Aryng: Click on the Youtube link",USD 121K - 188K *
655,"Data Engineering - Senior Consultant (Pyhon, SQL, PySpark)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Summary:
Data Engineering Senior Consultant role for Asia Pacific Region is based out of Bangalore. The role will work with both internal VISA Consulting/Market data science organizations and with external clients of VISA. This position requires strong technical background in modern data architecture, evaluating and recommending suitable technology stack, building scalable, reliable, and secured data ecosystem and good appreciation of data governance and data management practices. 
 With external clients, the position is responsible for data engineering advisory, design and implementation of comprehensive data platforms and solutions that meets the need of aspiring data organizations. The role is expected to work and collaborate with cross-functional teams within Visa, external clients, and vendors to develop and implement data solutions that support the organization's data-driven initiatives and improve business outcomes while maintaining robust data solutions that align with industry best practices and compliance standards.
 Internally, the role will support design, development, and delivery of data engineering solutions for the client facing market data science teams. The role will take responsibility for building and running data pipelines, designing our local data warehouse, data marts and data frameworks, and catering to different data presentation techniques based on client requirements.
 Principal Responsibilities
•    Act as Data technology SME for both VISA’s external clients and internal market teams for design and implementation of scalable, secure, robust, and interoperable data solutions that support advanced analytics, reporting, and decision-making processes. 
•    Lead Development and implementation of data solutions, data integration, data warehousing, data lakes, data governance and quality, analytics platforms, and reporting tools for both internal and external clients. 
•    Create and maintain optimal data pipelines and data exchange channels (Such as APIs, Secured File Transfer, other custom data exchange capabilities provided by VISA) between VISA and clients.
•    Evaluate and select appropriate technologies, tools, and frameworks to support data solution development and ensure data security, privacy, and compliance alignment with market regulations. 
•    Explore new technology trends leveraging them to modernize our client data ecosystem. Our clients are Banks, Fintechs and Merchant in the region that we operate.
•    Collaborate with partners & stakeholders at varying levels both internally and externally to provide best in class solutions to VISA’s clients. 
•    Strong execution skills in a fast-paced environment using agile methodologies.
•    Experience in Event Driven Architecture, Massive Parallel and Stream processing, Microservices, ELT and micro-batches.
•    Advanced experience in Hadoop, Python, Spark, PySpark and cloud-based data technologies.  
•    Hands on experience with public cloud like Azure, GCP, AWS
•    Driving Innovation and guiding the teams to implement solutions with future thinking.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
•    Bachelor’s or Master’s degree in engineering, Computer Science, Software Engineering, Information Technology, or technical field required.
• 11+ years of experience in data architecture, data engineering, design, development and delivery of large-scale data solutions with 2+ years of experience in AWS/MA/GCP.

Technical Expertise
•    11+ years of experience in data architecture, data engineering, design, development and delivery of large-scale data solutions with 2+ years of experience in AWS/MA/GCP.
•    Demonstrated technology and personal leadership in architecting, designing, and building highly scalable data ecosystems. 
•    Deep knowledge and experience in architecting modern data extraction and ingestion frameworks using open source and emerging data architecture designs/patterns.
•    Certification in Hadoop, Apache Spark and cloud technologies preferred. 
•    Hands-on experience of Hadoop ecosystem and associated technologies such as Hive, Apache Spark, PySpark, MLlib, GraphX. 
•    Advanced experience in writing and optimizing efficient SQL queries and Python/PySpark scripts.
•    Good appreciation of ML engineering and Operationalization.
•    Experience with APIs, container-based software deployments.
•    Experience with DevOps, Continuous Integration and Continuous Delivery technologies.
•    Experience in data governance (process & standards for Metadata Management, Data Lineage, Master/Reference Data Management, Data Quality Management and associated tools/platforms) will be an added advantage. 
•    Experience in Data Visualization (platforms such as power BI and tableau) and data security practices will be an added advantage. 
•    Good appreciation of NoSQL and in-memory data stores
•    Good appreciation of machine learning algorithms, feature engineering, validation, prediction, recommendation, and measurement. 
•    Understanding of Payments, Banking and Financial services domain will be a plus.

Leadership Competencies
•    Demonstrates integrity, maturity, and a constructive approach to business challenges. 
•    Serves as a role model for the organization by implementing core Visa Values 
•    Shows respect for individuals at all levels in the workplace. 
•    Strives for excellence and extraordinary results. 
•    Uses sound insights and judgments to make informed decisions in line with business strategy and needs. 
•    Able to allocate tasks and resources across multiple lines of businesses and geographies. 
•    Able to influence senior management both within and outside Data Science 
•    Successfully persuading internal stakeholders to commit to best-in-class solutions, when required. 
•    Leverages change management leadership as required.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 121K - 188K *
656,Sr Business Intelligence Analyst (Power BI),Gartner,Gurgaon - Cyber Park,Senior-level / Expert,"Senior BI Analyst – Consulting
Gurgaon
 About this role:
Consulting, Strategy & Operations is a division within Gartner which encompasses Consulting Technology and other core functions to support Gartner’s Consulting teams. This role will partner with key business stakeholders across the company to support a Consulting organization of more than 1,000 associates. Consulting Technology is on the forefront of innovation helping Consulting Associates to sell and deliver high quality engagements.
We are seeking a highly skilled Senior Business Intelligence Analyst to join a group of professionals who are participating in the exciting phase of revolutionizing Analytics for Consulting Business Unit. Partnering with the key business stakeholders, you will be responsible for requirements gathering and for modernizing our analytics and generating actionable insights. If you are excited about delivering impact within a fast-moving environment and passionate about delivering customer-center solutions, this is the role for you.
What you will do:
Develop actionable insights that can be used to make business decisions by building reports and dashboards
Understand business stakeholders’ objectives, metrics that are most important to them, and how they measure performance
Translate data into highly leveraged and effective visualizations for Gartner Consulting
Share knowledge and skills with your teammates to grow analytics impact on Gartner Consulting
Willingness to question the validity, accuracy of data and assumptions, make recommendations to improve our analytics
Ability to come up with an overall design strategy for all analytics that improves the user experience
Influence and educate stakeholders on the appropriate data, tools, and visualizations.
Review all analytics for quality before final artifacts are delivered to customers
Responsibly for version control and creating technical documentation
Partner with IT to provide different ways of improving on existing processes
Successful contribution to the delivery of Gartner Analytics through the development and implementation of best-in-class data visualization and insights
Strong relationship with the business stakeholders to ensure understanding of business needs
Improvement in performance for all visualizations due to optimized code
Ensure that all assigned Consulting Analytics demonstrate business value and satisfy all defined business requirements gathered through consistent customer feedback
What you will need:
Graduate or equivalent level qualification, preferably in a related discipline; Master’s degree preferred
5+ years of analytical experience in Data and Analytics: Building reports and dashboards
5+ years of experience with visualization tools such as Power BI, Tableau etc
3+ years of experience with requirements gathering
Experience working with and creating analytics to enable stakeholders for data driven decision making
Strong business intuition and ability to understand complex business processes and translate them to efficient & scalable technical solutions
Experience using analytic techniques to contribute to Gartner’s growth efforts, increasing revenue and other key business outcomes
Strong problem solving, quantitative and analytical abilities
Solid written and verbal communication skills and knowledge to build strong relationships and influence across Consulting
Knowledge in data warehousing architecture, and dimensional data modeling is a plus.
Strong knowledge of Agile principles and process; experience driving requirements and delivery with SCRUM teams
Ability to solve complex problems and successfully manage ambiguity and unexpected change
Ability to thrive in a fast-paced, technical, and mission-focused environment.
Who you are:
Motivated, high-potential performer, with demonstrated ability to influence and lead.
Strong communicator with excellent interpersonal skills.
Forward thinking, highly influential, and can walk people through the rationale behind a decision and convince them
Teachable, embraces best practices, and leverages feedback as a means of continuous improvement.
Consistently high achiever marked by perseverance, humility and a positive outlook in the face of challenges
#LI-SS10
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:83308
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 110K - 171K *
657,Data Integration Architect,Alstom,"Bengaluru, KA, IN",Senior-level / Expert,"As a promoter of sustainable mobility, Alstom develops and markets systems, equipment and services for the transport sector. Alstom offers a complete range of solutions (from high-speed trains to metros, tramways and e-buses), passenger solutions, customised services (maintenance, modernisation), infrastructure, signalling and digital mobility solutions. Alstom is a world leader in integrated transport systems. The company recorded sales of €7.3 billion and booked €10.0 billion of orders in the 2016/17 fiscal year. Headquartered in France, Alstom is present in over 60 countries and employs 32,800 people. UNIFE report forecasts India's accessible market at 4B€ over 2016-18, with growth of 6.6%. Alstom has established a strong presence in India and is currently executing metro projects in several Indian cities including Chennai, Kochi and Lucknow where it is supplying Rolling Stock manufactured out its state of the art facility at SriCity in Andhra Pradesh. In the Mainline space, Alstom is executing Signaling & Power Supply Systems for the 343 Km. section on World Bank funded Eastern Dedicated Freight Corridor. Construction of the new electric locomotive factory for manufacturing and supply of 800 units of high horse power locomotives is also in full swing at Madhepura in Bihar. Alstom has set up an Engineering Centre of Excellence in Bengaluru, and this coupled with a strong manufacturing base as well as localized supply chains, is uniquely positioned to serve customers across the globe. Today, Alstom in India employs close to 3000 people and in line with Government of India’s ‘Make in India’ policy initiative, Alstom has been investing heavily in the country in producing world class rolling stock, components, design, research and development to not only serve the domestic market, but also rest of the world. 
OVERALL PURPOSE OF THE ROLE:
The purpose of this role to build inhouse technical expertise for data integration area and delivery of data integration services for the platform.
  Primary Goals and Objectives-
This role should be responsible for delivery model for Data Integration services. Person should be responsible for building technical expertise on data integration solutions and providing data integration services. The role is viewed as an expert in solution design, development, performance tuning and troubleshooting for data integration.
  RESPONSIBILITIES:
Technical -
Hands-on-experience architecting and delivering solutions related to enterprise integration, APIs, service-oriented architecture, and technology modernizations
3-4 years hands-on experience with the design, and implementation of integrations in the area of Dell Boomi
Understanding the Business requirements and Functional requirement Documents and Design a Technical Solution as per the needs
Person should be good with Master Data Management, Migration and Governance best practices
Extensive data quality and data migration experience including proficiency in data warehousing, data analysis and conversion planning for data migration activities
Lead and build data migration objects as needed for conversions of data from different sources
Should have architected integration solutions using Dell Boomi for cloud, hybrid and on-premise integration landscapes
Ability to build and architect a high performing, highly available, highly scale Boomi Molecule Infrastructure
In depth understanding of enterprise integration patterns and prowess to apply them in the customers IT landscape
Assists project teams during system design to promote the efficient re-use of IT assets Advises project team during system development to assure compliance with architectural principles, guidelines and standards
Adept in building the Boomi processes with Error handling and email alerts logging best practices
Should be proficient in using Enterprise level and Database connectors
Extensive data quality and data migration experience including proficiency in data warehousing, data analysis and conversion planning for data migration activities
Excellent understanding on REST with in-depth understanding on how Boomi processes can expose consume services using the different http methods, URI and Media type
Understand Atom, Molecule, Atmosphere Configuration and Management, Platform Monitoring, Performance Optimization Suggestions, Platform Extension, User Permissions Control Skills.
Knowledge on API governance and skills like caching, DB management and data warehousing
Should have hands on experience in configuring AS2, https, SFTP involving different authentication methods
Thorough knowledge on process deployment, applying extensions, setting up schedules, Web Services user management process filtering and process reporting
Should be expert with XML and JSON activities like creation, mapping and migrations
Person should have worked on integration on SAP, SuccessFactors, Sharepoint, cloud-based apps, Web applications and engineering application
Support and resolve issues related to data integration deliveries or platform
Project Management –
Person should deliver Data Integration projects using data integration platform
Manage partner deliveries by setting up governance of their deliveries
Understand project priorities, timelines, budget, and deliverables and the need to proactively push yourself and others to achieve project goals
Managerial:
Person is individual contributor and operationally managing small technical team
  Qualifications & Skills:
10+ years of experience in the area of enterprise integrations
Minimum 3-4 years of experience with Dell boomi
Should have working experience with database like sql server, Data warehousing
Hands on experience on REST, SOAP, XML, JSON, SFTP, EDI
Should have worked on integration of multiple technologies like SAP, Web, cloud based apps.
  EDUCATION: B.E.
  BEHAVIORAL COMPETENCIES:
Demonstrate excellent collaboration skills as person will be interacting with multiple business units, Solution managers and internal IT teams
Should have excellent analytical and problem solving skills
Coaches, supports and trains other team membres
You demonstrate excellent communication skills
  TECHNICAL COMPETENCIES & EXPERIENCE 
Technical expertise in Delll Boomi for data integration is MUST.
  Language Skills: English
IT Skills: Dell Boomi, SQL, REST APIs, EDI, JSON, XML
Location for the role? Travel? If yes, how much (%) - Bangalore. 5%.
Contract Type/ Bonus (OPTIONAL)
Alstom is committed to create a diverse & international working environment,  that reflects the future of our industry, our clients and end-users.  As an employee, you will have a unique opportunity to continue to build your career and directly contribute to the expanding growth of the global transport industry
Job Type: Experienced",USD 45K - 84K *
658,Associate-Business Intelligence&Data Warehousing,Tesco Bengaluru,"Bengaluru, India",Mid-level / Intermediate,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
Following our Business Code of Conduct and always acting with integrity and due diligence and have these specific risk responsibilities:
- Identifying operational improvements and finding solutions by applying CI tools and techniques
- Responsible for completing tasks and transactions within agreed KPI's
- Knows and applies fundamental work theories/concepts/processes in own areas of work
-Engage with market partners to understand problems to be solved; translate the business problems to analytical problems; taking ownership of specified analysis and translate the answers back to decision makers in business
- Manipulating; analyzing and synthesizing large complex data sets using different sources and ensuring data quality and integrity - Responsible for high quality and timely completion of specified work deliverables
- Support automation of repeatable tasks; report generation or dashboard refresh
- Think beyond the ask and develop analysis and reports that will contribute beyond basic asks
- Write codes that are well detailed; structured; and compute efficient
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Ability to generate practical insights that drive decisions in our business operations
- Understands business needs and in depth understanding of Tesco processes
- Responsible for completing tasks and transactions within agreed important metrics
Qualifications
Basic understanding of Business Decisions; Basic Skills to develop visualizations; self-service dashboards and reports using Tableau & Basic Statistical Concepts (Correlation Analysis and Hyp. Testing); Basic skills to analyze data using Adv Excel; SQL; Hive; Basic DW concepts on Hadoop and Teradata; Automation using alteryx/ python is good to have
Additional Information
Last Date of Application-12th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 56K *
659,Data Integration Architect,Alstom Transport,"Bengaluru, KA, IN",Senior-level / Expert,"As a promoter of sustainable mobility, Alstom develops and markets systems, equipment and services for the transport sector. Alstom offers a complete range of solutions (from high-speed trains to metros, tramways and e-buses), passenger solutions, customised services (maintenance, modernisation), infrastructure, signalling and digital mobility solutions. Alstom is a world leader in integrated transport systems. The company recorded sales of €7.3 billion and booked €10.0 billion of orders in the 2016/17 fiscal year. Headquartered in France, Alstom is present in over 60 countries and employs 32,800 people. UNIFE report forecasts India's accessible market at 4B€ over 2016-18, with growth of 6.6%. Alstom has established a strong presence in India and is currently executing metro projects in several Indian cities including Chennai, Kochi and Lucknow where it is supplying Rolling Stock manufactured out its state of the art facility at SriCity in Andhra Pradesh. In the Mainline space, Alstom is executing Signaling & Power Supply Systems for the 343 Km. section on World Bank funded Eastern Dedicated Freight Corridor. Construction of the new electric locomotive factory for manufacturing and supply of 800 units of high horse power locomotives is also in full swing at Madhepura in Bihar. Alstom has set up an Engineering Centre of Excellence in Bengaluru, and this coupled with a strong manufacturing base as well as localized supply chains, is uniquely positioned to serve customers across the globe. Today, Alstom in India employs close to 3000 people and in line with Government of India’s ‘Make in India’ policy initiative, Alstom has been investing heavily in the country in producing world class rolling stock, components, design, research and development to not only serve the domestic market, but also rest of the world. 
OVERALL PURPOSE OF THE ROLE:
The purpose of this role to build inhouse technical expertise for data integration area and delivery of data integration services for the platform.
  Primary Goals and Objectives-
This role should be responsible for delivery model for Data Integration services. Person should be responsible for building technical expertise on data integration solutions and providing data integration services. The role is viewed as an expert in solution design, development, performance tuning and troubleshooting for data integration.
  RESPONSIBILITIES:
Technical -
Hands-on-experience architecting and delivering solutions related to enterprise integration, APIs, service-oriented architecture, and technology modernizations
3-4 years hands-on experience with the design, and implementation of integrations in the area of Dell Boomi
Understanding the Business requirements and Functional requirement Documents and Design a Technical Solution as per the needs
Person should be good with Master Data Management, Migration and Governance best practices
Extensive data quality and data migration experience including proficiency in data warehousing, data analysis and conversion planning for data migration activities
Lead and build data migration objects as needed for conversions of data from different sources
Should have architected integration solutions using Dell Boomi for cloud, hybrid and on-premise integration landscapes
Ability to build and architect a high performing, highly available, highly scale Boomi Molecule Infrastructure
In depth understanding of enterprise integration patterns and prowess to apply them in the customers IT landscape
Assists project teams during system design to promote the efficient re-use of IT assets Advises project team during system development to assure compliance with architectural principles, guidelines and standards
Adept in building the Boomi processes with Error handling and email alerts logging best practices
Should be proficient in using Enterprise level and Database connectors
Extensive data quality and data migration experience including proficiency in data warehousing, data analysis and conversion planning for data migration activities
Excellent understanding on REST with in-depth understanding on how Boomi processes can expose consume services using the different http methods, URI and Media type
Understand Atom, Molecule, Atmosphere Configuration and Management, Platform Monitoring, Performance Optimization Suggestions, Platform Extension, User Permissions Control Skills.
Knowledge on API governance and skills like caching, DB management and data warehousing
Should have hands on experience in configuring AS2, https, SFTP involving different authentication methods
Thorough knowledge on process deployment, applying extensions, setting up schedules, Web Services user management process filtering and process reporting
Should be expert with XML and JSON activities like creation, mapping and migrations
Person should have worked on integration on SAP, SuccessFactors, Sharepoint, cloud-based apps, Web applications and engineering application
Support and resolve issues related to data integration deliveries or platform
Project Management –
Person should deliver Data Integration projects using data integration platform
Manage partner deliveries by setting up governance of their deliveries
Understand project priorities, timelines, budget, and deliverables and the need to proactively push yourself and others to achieve project goals
Managerial:
Person is individual contributor and operationally managing small technical team
  Qualifications & Skills:
10+ years of experience in the area of enterprise integrations
Minimum 3-4 years of experience with Dell boomi
Should have working experience with database like sql server, Data warehousing
Hands on experience on REST, SOAP, XML, JSON, SFTP, EDI
Should have worked on integration of multiple technologies like SAP, Web, cloud based apps.
  EDUCATION: B.E.
  BEHAVIORAL COMPETENCIES:
Demonstrate excellent collaboration skills as person will be interacting with multiple business units, Solution managers and internal IT teams
Should have excellent analytical and problem solving skills
Coaches, supports and trains other team membres
You demonstrate excellent communication skills
  TECHNICAL COMPETENCIES & EXPERIENCE 
Technical expertise in Delll Boomi for data integration is MUST.
  Language Skills: English
IT Skills: Dell Boomi, SQL, REST APIs, EDI, JSON, XML
Location for the role? Travel? If yes, how much (%) - Bangalore. 5%.
Contract Type/ Bonus (OPTIONAL)
Alstom is committed to create a diverse & international working environment,  that reflects the future of our industry, our clients and end-users.  As an employee, you will have a unique opportunity to continue to build your career and directly contribute to the expanding growth of the global transport industry
Job Type: Experienced",USD 45K - 84K *
660,Data Engineer Lead,Alstom,"Bengaluru, KA, IN",Senior-level / Expert,"  Leading societies to a low carbon future, Alstom develops and markets mobility solutions that provide the sustainable foundations for the future of transportation. Our product portfolio ranges from high-speed trains, metros, monorail, and trams to integrated systems, customised services, infrastructure, signalling and digital mobility solutions. Joining us means joining a caring, responsible, and innovative company where more than 70,000 people lead the way to greener and smarter mobility, worldwide 
Purpose of the Job
As part of RSC data analytics team, the primary responsibility of this post is to review, analyse and report on data from the relevant Databases in order to support the business.The lead position is to cooridnate for collecting the requiremnet, guideiing the team technically and process adherance.
Organisational Reporting: M&T Manager
Network & Links
Internal: Planning, Project team, Human Resources, IS&T, Competency, etc.
Responsibilities
Manage the team for technical and process adherance. 
Define, develop, manage & sustain the data solution including storage, processing units and UI defined as the industrial solutionfor the program, such as:
Design technical solution for production-grade and cyber-secure data solutions
Build multi-tenant data collector and storage
Build multi-tenant streaming and data processing in batch and near-real time flows
Design scalable data model, including SQL and NoSQL modeling
Assess and enhance the data quality of incoming data flows
Apply Data management and security components
Build customizable Analytical Dashboards
Evaluate the opportunities from new technologies
Apply a strong testing and quality assurance practices
Educational Requirements
Engineering Graduate 
Technical Knowledge / Experience
Mandatory:
7 years in IT and/or digital companies or software or startups
Extensive practice of data processing and software development, PowerApps, Power BI, or Java/Scala environment.
 Experience in developing solution with Apache Spark, Apache
Kafka and/or Nifi for production.
Experience of data modelling
Deep knowledge of SQL database configuration, eg. Postgres,
MariaDB, MySQL
Knowledge with devops including docker and ansible
 Experience with git and release management
Desirable:
Knowledge of Microsoft Azure or AWS or GCP.
Knowledge of QlikSense
Knowledge of network and security : SSL, certifcates, IPSEC, Active Directory, LDAP. 
Knowledge about Machine Learning with scikit-learn, R, Tensorflow or another AI framework or toolkit
Good understanding of the Apache open source ecosystem
Behavioural Competencies
  Proven track record for designing stable solution, testing and debugging.
Demonstrated teamwork and collaboration in a professional setting
Proven capabilities with worldwide teams
Fluent English. French is a plus.
  Alstom is the leading company in the mobility sector, solving the most interesting challenges for tomorrow’s mobility. That’s why we value inquisitive and innovative people who are passionate about working together to reinvent mobility, making it smarter and more sustainable. Day after day, we are building an agile, inclusive and responsible culture, where a diverse group of people are offered opportunities to learn, grow and advance in their careers, with options across functions and geographic locations. Are you ready to join a truly international community of great people on a challenging journey with a tangible impact and purpose?  
  Equal opportunity statement:
Alstom is an equal opportunity employer committed to creating an inclusive working environment where all our employees are encouraged to reach their full potential, and individual differences are valued and respected.  All qualified applicants are considered for employment without regard to race, colour, religion, gender, sexual orientation, gender identity, age, national origin, disability status, or any other characteristic protected by local law. 
        Job Type:Experienced",USD 45K - 84K *
661,Data Engineer Lead,Alstom Transport,"Bengaluru, KA, IN",Senior-level / Expert,"  Leading societies to a low carbon future, Alstom develops and markets mobility solutions that provide the sustainable foundations for the future of transportation. Our product portfolio ranges from high-speed trains, metros, monorail, and trams to integrated systems, customised services, infrastructure, signalling and digital mobility solutions. Joining us means joining a caring, responsible, and innovative company where more than 70,000 people lead the way to greener and smarter mobility, worldwide 
Purpose of the Job
As part of RSC data analytics team, the primary responsibility of this post is to review, analyse and report on data from the relevant Databases in order to support the business.The lead position is to cooridnate for collecting the requiremnet, guideiing the team technically and process adherance.
Organisational Reporting: M&T Manager
Network & Links
Internal: Planning, Project team, Human Resources, IS&T, Competency, etc.
Responsibilities
Manage the team for technical and process adherance. 
Define, develop, manage & sustain the data solution including storage, processing units and UI defined as the industrial solutionfor the program, such as:
Design technical solution for production-grade and cyber-secure data solutions
Build multi-tenant data collector and storage
Build multi-tenant streaming and data processing in batch and near-real time flows
Design scalable data model, including SQL and NoSQL modeling
Assess and enhance the data quality of incoming data flows
Apply Data management and security components
Build customizable Analytical Dashboards
Evaluate the opportunities from new technologies
Apply a strong testing and quality assurance practices
Educational Requirements
Engineering Graduate 
Technical Knowledge / Experience
Mandatory:
7 years in IT and/or digital companies or software or startups
Extensive practice of data processing and software development, PowerApps, Power BI, or Java/Scala environment.
 Experience in developing solution with Apache Spark, Apache
Kafka and/or Nifi for production.
Experience of data modelling
Deep knowledge of SQL database configuration, eg. Postgres,
MariaDB, MySQL
Knowledge with devops including docker and ansible
 Experience with git and release management
Desirable:
Knowledge of Microsoft Azure or AWS or GCP.
Knowledge of QlikSense
Knowledge of network and security : SSL, certifcates, IPSEC, Active Directory, LDAP. 
Knowledge about Machine Learning with scikit-learn, R, Tensorflow or another AI framework or toolkit
Good understanding of the Apache open source ecosystem
Behavioural Competencies
  Proven track record for designing stable solution, testing and debugging.
Demonstrated teamwork and collaboration in a professional setting
Proven capabilities with worldwide teams
Fluent English. French is a plus.
  Alstom is the leading company in the mobility sector, solving the most interesting challenges for tomorrow’s mobility. That’s why we value inquisitive and innovative people who are passionate about working together to reinvent mobility, making it smarter and more sustainable. Day after day, we are building an agile, inclusive and responsible culture, where a diverse group of people are offered opportunities to learn, grow and advance in their careers, with options across functions and geographic locations. Are you ready to join a truly international community of great people on a challenging journey with a tangible impact and purpose?  
  Equal opportunity statement:
Alstom is an equal opportunity employer committed to creating an inclusive working environment where all our employees are encouraged to reach their full potential, and individual differences are valued and respected.  All qualified applicants are considered for employment without regard to race, colour, religion, gender, sexual orientation, gender identity, age, national origin, disability status, or any other characteristic protected by local law. 
        Job Type:Experienced",USD 45K - 84K *
662,Power BI/Power Apps Expert,Gainwell Technologies LLC,"Bengaluru, KA, IN, 560100",Senior-level / Expert,"Summary
As a Power BI/Power Apps Expert at Gainwell, you can contribute your skills as we harness the power of technology to help our clients improve the health and well-being of the members they serve — a community’s most vulnerable. Connect your passion with purpose, teaming with people who thrive on finding innovative solutions to some of healthcare’s biggest challenges. Here are the details on this position.
  Your role in our mission
Apply healthcare domain knowledge to understand the data from various source systems and align the data to platform’s integration model.
Work with Business, Architects and System Analysts to fully understand the business requirements and translate them into Conceptual, Logical and Physical models.
Deliver high quality normalized and/or star schema models that will address strategic vision and goals of the platform.
Partner with development and QA teams to communicate the business rules, data models and ensure test cases target the quality and integrity of the data model.
Participate in regular model reviews, provide constructive feedback that will lead to higher quality models. 
Maintain superior quality metadata across all models.
Assists in providing time estimates for project-related tasks.
What we're looking for
Bachelor's degree in data management, computer science, or related field preferred.
6-9 years of IT experience with 2-3 years of hands-on experience in Power platform as illustrate below
Ability to gather functional requirements and provide the design specifications.
Be flexibility when there is a change to our priorities when needed.
Must have excellent verbal communications and documentation skills.
Must have proven experience in the below 
  Power BI
  Power Apps
  Power Automate
It is desirable and good to have development, test and maintenance skills on the below listed tools
Knowledge on RDBMS/SQL
Power Platform Gateway
Power BI:
Data modelling in the Power BI layer for optimal performance.
Experience in intuitive UX design of dashboards
Good working knowledge on DAX functions and power query
Knowledge on Row Level Security
PowerApps:
Understanding of Delegation in canvas apps
Performance optimization and considerations
Working experience on Variables , collections and DAX (LOOKUP,FILTER,PATCH etc)
Connecting and accessing Power Automate
Experience on responsive UX design
Usage of Dataverse and dataflow in canvas apps
Good knowledge on Solution, security and environments in Powerapps
Knowledge on Model Driven apps and Power Portals
Power Automate:
Good working knowledge and experience in Automated, Instant and Scheduled flows.
Performance optimized design of flows
Integration of flow with other apps through REST API
Usage of child flow
Good analytical skills ,problem solving skills and communication
The candidate must be able to work independently
Able to grasp and understand new technological trends & concepts
What you should expect in this role
  Fast-paced,challenging and rewarding work environment.
Work life balance.    
Hybrid Office environment.
Will require late evening work to overlap US work hours.",USD 45K - 84K *
663,"Sr. Systems Engineer - ETL, Python, SQL, Shell, Production Support",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Duties and Responsibilities: 
Monitor and manage Windows/Linux Servers and operations across environments
Resolve ETL & Data Warehouse job related issues 
Work with development team on production defects fixes 
Building CI/CD pipelines and managing them
Maintain/improve production operations SLA 
 This position will be based in Bangalore, India and will be reporting to Senior Engineering Manager. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
 Qualifications
Basic Qualification

2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experience

Preferred Qualifications

Skills, Experience and Requirements: 

2+ years of experience in production operations on large Enterprise Data Warehouse
Hands on working knowledge in Data Warehouse Environment and proficient in SQL Queries & Python
Good hands on experience in Unix operating system and shell scripting 
Troubleshooting of ETL jobs and addressing production issue 
Experience in Talend Admin, Jenkins(CI/CD) and Hadoop ecosystem 
Good Communication skills – written and verbal with the ability to understand and interact with the diverse range of stakeholders 
Candidate should be able to work without much supervision
The ability to tackle challenges and address problems head-on
Stay on top of the open source technology and be ready to learn/adopt new technology continuously
Highly driven, resourceful and results oriented
Good team player and excellent interpersonal skills
Good analytical and problem-solving skills
Demonstrated ability to lead and navigate through ambiguity
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
664,Sr Power BI Developer,Marlabs,"Pune, IN",Senior-level / Expert,"Organization
Marlabs is a digital innovation company helping enterprises innovate & capture digital opportunities to enable swifter solutions. Our focus is to help each of our clients find and capture their unique opportunities and empower them with digital technologies so that they can run a purposeful business. Visit and know more about us – www.marlabs.com
Role
Sr. Power BI Developer
Technology Area
Power BI
Domain
BI
Experience
8-10 Years
Responsibilities
Power BI Job Profile
A Power BI developer takes responsibility of creating and managing BI dashboards and has a thorough understanding of the BI system.
A Power BI developer's primary responsibility is to transform raw data into relevant insights via interactive and simple-to-understand dashboards and reports. Because of his strategic, executive, and management roles and duties, a Power BI developer is critical to the firm.
Roles and Responsibilities:
Recognize business requirements in the context of BI and create data models to transform raw data into relevant insights.
Using Power BI, create dashboards and interactive visual reports.
Define key performance indicators (KPIs) with specific objectives and track them regularly.
Analyze data and display it in reports to aid decision-making.
Convert business needs into technical specifications and establish a timetable for job completion.
Create, test, and deploy Power BI scripts, as well as execute efficient deep analysis.
Use Power BI to run DAX queries and functions.
Create charts and data documentation with explanations of algorithms, parameters, models, and relationships.
Construct a data warehouse.
Use SQL queries to get the best results.
Make technological adjustments to current BI systems to improve their performance.
For a better understanding of the data, use filters and visualizations.
  Skills Required:
Background with BI tools and systems such as Power BI
Prior experience in data-related tasks
Understanding of the Microsoft BI Stack
Mastery in data analytics
Should be proficient in software development.
Be familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, PowerBI, and DAX
Analytical thinking for converting data into relevant reports and graphics.
Capable of enabling row-level data security
Knowledge of Power BI application security layer models
Ability to run DAX queries on Power BI desktop.
Proficient in doing advanced-level computations on the data set.
Excellent communication skills are required to communicate needs with client and internal teams successfully.
    USP
Marlabs provides challenging and rewarding career opportunities as well as avenues for continuous learning to all our employees. Accelerated learning, amazing colleagues, and a chance to solve some of the biggest problems in the enterprise world - this is life at Marlabs!
 ",USD 106K - 140K *
665,Hadoop Developer (Hadoop/Nifi/Spark),Gainwell Technologies LLC,"Chennai, TN, IN, 600032",Senior-level / Expert,"Summary
  Establishes and enforces data warehousing standards, determines data warehousing strategy, and selects data tools and techniques to devise solutions to complex integrated warehousing projects. Focuses on a specific product or family of technologies in multiple platforms; functions independently within a business area and assists at the enterprise level to influence the technical decisions during various phases of the project.
Essential Job Functions
  Experience working in large-scale on Hadoop development & implementations.
Proven knowledge and experience with core Hadoop ecosystem including Nifi, HIVE, Spark etc.,
Experience working with varied forms of data infrastructure inclusive of relational databases such as SQL, Hadoop, Spark.
Proficiency in scripting languages in python, pyspark/Scala spark.
Experience in Database design/data modelling.
Must have strong experience in data warehouse concepts.
Ability to work creatively and analytically in a problem-solving environment.
Knowledge of US healthcare will be an advantage.
Assists in outlining new product/service business case justification to ensure that the proposed solution can deliver articulated business benefits to the client.
Basic Qualifications
  Bachelor's degree in computer science, information systems, or related field preferred.
At least 5 years of experience in Hadoop Development.
Experience working with technical products, vendors, and families of technologies.
Experience working with product configurations.
Experience working with relevant software packages or classes of packages, and products within area of technical expertise.
What you should expect in this role
  Hybrid Office environment.
Fast-Paced, Challenging and rewarding work environment.
Work life balance.    
Will require late evening work to overlap US work hours.",USD 45K - 84K *
666,"Data Analyst,IND,Blr , Grp 5.1",ANZ Banking Group Limited,"Bengaluru, IN",Entry-level / Junior,"About the role
At ANZ our purpose is to shape a world where people and communities thrive. We’re making this happen by improving the financial wellbeing and sustainability of our customers so they can achieve incredible things– whether they’re buying a home, building a business or saving for things big or small.
  This Data Analyst role is part of Trusted Operational Data –.
** DATA POWER ** Helping to uplift the data that matters the most for Group Technology, whilst building out your data skills and experience.
Seeking those graduates with a growth ""data"" mindset, whom are great at problem solving and have an analytical brain.
We don't wait for an opportunity; we create it together - collaborating with other domains and visions, and we succeed together!
What will your day look like
The following outlines the primary responsibilities undertaken by the squad:
Implement and maintain robust data quality management processes to ensure the accuracy, consistency, and completeness of data across various systems and databases.
Work closely with cross-functional teams to ensure alignment of data governance initiatives with overall business objectives.
Monitor and assess the effectiveness of data governance initiatives, identify areas for improvement, and implement continuous improvement measures to enhance the overall data governance framework.
Establish key performance indicators (KPIs) and metrics to measure the effectiveness of data governance initiatives, and regularly report on progress and compliance to relevant stakeholders.
Collaborating with the product owner, data analysts and other people in your squad
Data Wrangling (prep, collection and analysis) to assist with automation initiatives.
Identifying opportunities for continuous improvement and implement solutions to deliver actionable data insights.
Understanding customer needs and ensuring data solutions are designed to meet acceptance criteria.
In every interaction you’ll be looking for opportunities, and you’ll bring a positive growth mindset.
In this role, you will have the opportunity to contribute to the overall delivery of the team's goals and priorities.
You will manage pieces of work, develop data driven insights and reports that will enhance and support the desired objectives.
What will you bring?
To grow and be successful in the role, you will ideally bring the following:
Strong attention to detail to ensure accuracy and completeness in data governance processes.
Analytical and inquisitive mindset to continuously improve the level of insight surfaced
Ability to translate data insights into practical business recommendations
Strong communication and presentation skills
Proficiency in SQL for handling large complex datasets of varying types
Strong problem-solving skills to address data quality, security, and compliance challenges in a proactive manner.
Proficiency in Microsoft tools such as Excel and PowerPoint is considered beneficial for this role.
Strong understanding of the data and analytics lifecycle i.e. exploratory data analysis, data modelling and design, data wrangling, data quality, hypothesis testing, data visualisation and dashboard design.
Clear and effective communication skills to convey data governance policies, procedures, and insights to both technical and non-technical stakeholders.   
Ability to effectively communicate to stakeholders (technical and non-technical)
Experience with tools/systems such as GitHub, JIRA, Confluence, QlikSense and SQL databases.
So, why join us?
At ANZ, everything we do is focused on supporting our customers with their financial wellbeing. When they are thriving, our communities are thriving too.
We are just as committed to supporting our people and giving them the opportunity to develop a career. As one of Australia’s biggest banks, we have many opportunities in many locations. Joining ANZ is about starting a career, not starting a job and we encourage people to look for opportunities across our bank.
Supporting the wellbeing of our people is also core at ANZ which is why we cherish the people-first culture we are famous for and why the Australian Financial Review rated us the number 1 place to work in the banking and finance industry for 2021.
Being part of ANZ means working in a diverse and inclusive workplace where the different backgrounds, perspectives and life experiences of our people are celebrated, creating a great place to belong. We encourage you to talk to us about any adjustments you may require to our recruitment process or the role itself. If you are a candidate with a disability, let us know how we can provide you with additional support.
Ready to build the career in banking you didn’t realise was for you? Click Apply now, or visit www.anz.com/careers to find out more or view other opportunities.
Job Posting End Date
 15/12/2023, 11.59pm, (Melbourne Australia)",USD 60K - 94K *
667,Lead Data Analyst,Clarivate,R131-Bengaluru,Senior-level / Expert,"We are looking for a Lead Data Analyst to join our Technology Consulting team in Bengaluru. This is an amazing opportunity to work on data analytics & work with various stakeholders from different departments. The team consists of 20+ members and is reporting to the Senior Director. We have a great skill set in Data Management & Visualization and we would love to speak with you if you have skills in Business Intelligence tools and data query languages & you’re willing to learn more about LS&H business in general.
 About You – experience, education, skills, and accomplishments  
  ·         Bachelor's degree in computer science, computer engineering, information technology, or relevant field.
·         7+ years of experience working in business intelligence, data analytics, product management or corporate strategy.
·         5+ years of experience in cloud-based data warehouses and tools such as Snowflake, BigQuery, Jupyter Notebook, and Databricks.
·         5+ years of experience with BI tools (Tableau, Power BI).
·         5+ years of experience with SQL, PostgreSQL, Python & Data warehousing.
·         7+ years of experience with Excel and PowerPoint. 
·         Possess strong ability to create compelling narratives and connect data analysis to audience storytelling.
 It would be great if you also had
 ·         Knowledge of or prior experience with Healthcare or Lifesciences domain.
·         Strong communication & analytical skills 
 What will you be doing in this role? 
 ·         Leveraging expertise in data analysis, visualization, and business intelligence to provide valuable insights and support data-driven decision-making within the organization.
·         Leverage modern Power BI to extract and manipulate data from a variety of diverse sources.
·         Understand business questions/pain points and alleviate with supporting data.
·         Ensure data accuracy, consistency, and adherence to data governance policies. Conduct data quality checks and implement measures to maintain data integrity.
·         Research advanced analytic/visualization capabilities to improve customer understanding of data insights.
·         Collaborate cross-functionally at various levels and diplomatically influence stakeholders.
 About the Team   
Technology Consulting team operates on a global scale, working seamlessly with stakeholders from different corners of the world to provide custom solutions to diversified client base. We believe in the power of collaboration and diversity to drive success. As a part of our team, you'll have the opportunity to contribute to impactful projects, exchange ideas with talented individuals, and be at the forefront of exciting challenges.
 Hours of Work  
40 hours per week, full-time employment, Hybrid (2 days in the office week). Although duties are typically performed during normal business hours, occasional off-hours may be required with flexibility to adjust to various global time zones as needed.
At Clarivate, we are committed to providing equal employment opportunities for all persons with respect to hiring, compensation, promotion, training, and other terms, conditions, and privileges of employment. We comply with applicable laws and regulations governing non-discrimination in all locations.",USD 45K - 84K *
668,Senior Specialist - Data Engineer,adidas,"Chennai, TN, IN",Senior-level / Expert,"  Senior Data Engineer
  Area:                                                                                       GBS
Department:                                                                           Enabling Functions
Direct Reporting Line:                                                           Manager GBS
Indirect/secondary reporting line:                                        --
Subsidiary/Country:                                                               India
Location:                                                                                Chennai
GSMS Grade:                                                                                         P1
Number of Personnel Managed:                                           0
Cost Center/Budget and/or Revenue Responsibility:           0
    Purpose & Overall Relevance for the Organization:
Global Business Services (GBS) has been created to provide globally unified services based on standardized and automated solutions across different functions and markets. This will enable us to drive operational efficiency, quality services, improved agility and better decision-making whilst reducing complexity and workload. In adidas GBS we leverage state-of-the-art technology and cultivate a human-centric and innovative mindset to continually raise the bar of the user experience.
  As a Senior Data Engineer, you will collect, aggregate, store, and reconcile data in support of adidas (GBS) business decisions. You will design and build data pipelines, data streams, data service APIs, data generators, and other end-user information portals and insight tools.  
  Key Responsibilities:
Plan, build, and implement data solutions based on DataBricks.
Design and build Modern Data Pipelines and Data Streams
Develop and Maintain Data Warehouse 
Design and create ETL processes supplying Data Warehouse
Implement effective metrics and monitoring processes.
Preprocess of structured and unstructured data, create queries in databases.
  Key Relationships:
Operations Teams in different Hubs
Global Operational Excellence Team
IT Platform Engineering team
IT Tech Consultants
  Knowledge, Skills and Abilities:
Experience working with Databricks and familiarity with PySpark
Mastery of SQL (T-SQL or PL SQL preferred)
Experience with SQL, T-SQL, and any one of the data engineering programming languages like Python, Scala, R, Java, etc 
Ability to conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows
Hands-on experience in performance tuning and optimizing code running in the Databricks environment
Demonstrated analytical and problem-solving skills particularly those that apply to a big data environment
Fluent in English (written and spoken)
  Requisite Education and Experience / Minimum Qualifications:
5+ years of experience in the GBS organization, experience in any of the Excellence functions (automation, continuous improvement, reporting) is preferable.
The Databricks Certified Data Engineer Associate
University degree or equivalent experience.",USD 121K - 188K *
669,Data Strategy | 6-13 Years | PAN India,Capgemini,"Mumbai, MH, IN",Mid-level / Intermediate,"Job Description
  Conduct comprehensive current state analysis of existing data systems, processes, and frameworks of an organization.
Provide strategic recommendations and design target state for optimizing data-related processes, structures, and systems.
Participate in Data Maturity assessments. Drive CXO conversations effectively.
Lead and facilitate engagements in data governance, establishing policies, procedures, and frameworks to ensure metadata, master data, data quality, security, and compliance.
Develop and define future state data architectures aligned with industry best practices and organizational needs.
Collaborate closely with cross-functional teams and stakeholders to ensure seamless integration of data strategies with business objectives.
Utilize expertise in cloud technologies e.g., GCP, Azure, and AWS, to guide and implement data strategies in cloud-based environments.
Help in providing tools/technology advisory to customers by creating market scan reports, technology comparison frameworks and selection, creating technology architecture.
Drive RFI/RFP and presales engagements. Lead and contribute to offerings development, provide thought leadership.
Leverage industry knowledge to drive business discussions, identify industry wise data strategy challenges and provide industry specific best practices. Following industry experience is preferred – Retail/CPG and Automobile/ Healthcare/Pharma
Ability to understand data and derive key performance indicators (KPI’s)
Good SQL experience for data analysis and reporting
Exposure to business intelligence tools such as Tableau, Qlik Sense and Power BI
Good understanding of data science and machine learning/AI concepts
Primary Skills
  Bachelor’s degree in computer science, Information Technology, or any related field. MBA from a tier 1 and tier 2 college preferred.
Proven experience in advisory and consultancy roles focused on data strategy and architecture. At least 1 end to end consulting engagement experience.
Proficiency in cloud technologies, particularly GCP, Azure, and AWS, with relevant certifications preferred.
Experience in leading and managing data governance, data modeling, and operating model initiatives.
Strong knowledge of DAMA and TOGAF frameworks and principles. Certifications preferred.
Secondary Skills
  Excellent communication and interpersonal skills, with the ability to articulate complex ideas and strategies effectively.
Exceptional analytical and problem-solving abilities.
Should be aware of latest tech trends in data and applications of advanced AI technologies across Industry sectors.
Should be a good storyteller, presenter and capable of steering leadership communication.
A self-motivated individual with a strong sense of ownership and drive to deliver high-quality results.",USD 30K - 56K *
670,Data Engineer,Springer Nature Group,"Pune, IN",Mid-level / Intermediate,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow. 
Visit: group.springernature.com and follow @SpringerNature
  Job Title:     Data Engineer
Location(s):   Pune
  About Springer Nature Group
Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 180 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.
  About Springer Nature
  Springer Nature Technology and Publishing Solutions, is the technology and publishing solutions arm of the Springer Nature Group. We leverage our insight in the publishing domain and acquire, produce and deliver content across media and markets using our Technology and Publishing Solutions. With a focus on technology driven solutions and deep insight in the publishing domain, Springer Nature Technology and Publishing Solutions offers a range of services that help our Group brand acquire, produce and deliver content in the most efficient ways possible. We are driven by over 1000 professionals in Technology, Research & Analysis and Marketing shared services.
  We are proud to be an equal-opportunity employer. All applicants will be considered for employment on the basis of merit alone, without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status
  About the Role:
  Springer Nature seeks a Data Engineer for its highly-regarded Nature Research Intelligence, group. The group meets the needs of Springer Nature’s Research division which includes Nature, Springer, BioMedCentral and Scientific American, as well as developing new data products for the research community. This is an exciting opportunity as Data Engineering is expanding from strong foundations into new solutions, and we are looking for someone who can deliver solutions and work independently, with support from the wider team where necessary.
As a Data Engineer, you will be responsible for ensuring a continuous flow of data with minimum latency between data sources, you will be developing, testing and deploying data pipelines into the production environment. You will be a part of the team which delivers ML/AI solutions at scale.
You will be working in close partnership with data analysts, data scientists, and data engineers, as well as other colleagues from Springer Nature and our technology partners, including Google. You will have opportunities to work with the latest data and analytics technologies, including graph databases, Google BigQuery, Tensorflow, and Plotly Dash, and preview new technologies from Google and other partners.
  Role Responsibilities:
  Build streaming/batch Data pipelines for extraction/loading/transforming data between various data sources at scale in different formats.
Work closely with Data Scientists /Analysts/Product Managers to understand the requirements and develop data solutions in line with the business requirements.
Explore various best practices to Deliver/Deploy/Maintain the in-house ML/AI solutions at scale.
Automate/orchestrate various template solutions to ensure continuous delivery.
Maintain the current cloud infrastructure and help onboard the new applications.
Use creative ideas to ensure ease of Data Use within the organization.
  Experience, Skills & Qualifications:
Experience: 2-4 years
Qualification: University degree with a strong analytical/quantitative background or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.
  Essential
  SQL and Python
problem-solving capabilities
at least one of the distributive frameworks such as Apache Beam or Spark
Well organized and accurate with good time management
  Desirable
  Machine Learning concepts are beneficial but not essential as training will be provided
schema designing data modeling
Google Cloud products (BigQuery, Dataform, Colab) or other cloud data platforms beneficial
  #LI-DP1
At Springer Nature, we value the diversity of our teams and work to build an inclusive culture, where people are treated fairly and can bring their differences to work and thrive. We empower our colleagues and value their diverse perspectives as we strive to attract, nurture and develop the very best talent.
Springer Nature was awarded Diversity Team of the Year at the 2022 British Diversity Awards. Find out more about our DEI work here.
  If you have any access needs related to disability, neurodivergence or a chronic condition, please contact us so we can make all necessary accommodation.",USD 110K - 181K *
671,Data Engineer,Springer Science+Business,"Pune, IN",Mid-level / Intermediate,"Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 175 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow. 
Visit: group.springernature.com and follow @SpringerNature
  Job Title:     Data Engineer
Location(s):   Pune
  About Springer Nature Group
Springer Nature opens the doors to discovery for researchers, educators, clinicians and other professionals. Every day, around the globe, our imprints, books, journals, platforms and technology solutions reach millions of people. For over 180 years our brands and imprints have been a trusted source of knowledge to these communities and today, more than ever, we see it as our responsibility to ensure that fundamental knowledge can be found, verified, understood and used by our communities – enabling them to improve outcomes, make progress, and benefit the generations that follow.
  About Springer Nature
  Springer Nature Technology and Publishing Solutions, is the technology and publishing solutions arm of the Springer Nature Group. We leverage our insight in the publishing domain and acquire, produce and deliver content across media and markets using our Technology and Publishing Solutions. With a focus on technology driven solutions and deep insight in the publishing domain, Springer Nature Technology and Publishing Solutions offers a range of services that help our Group brand acquire, produce and deliver content in the most efficient ways possible. We are driven by over 1000 professionals in Technology, Research & Analysis and Marketing shared services.
  We are proud to be an equal-opportunity employer. All applicants will be considered for employment on the basis of merit alone, without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status
  About the Role:
  Springer Nature seeks a Data Engineer for its highly-regarded Nature Research Intelligence, group. The group meets the needs of Springer Nature’s Research division which includes Nature, Springer, BioMedCentral and Scientific American, as well as developing new data products for the research community. This is an exciting opportunity as Data Engineering is expanding from strong foundations into new solutions, and we are looking for someone who can deliver solutions and work independently, with support from the wider team where necessary.
As a Data Engineer, you will be responsible for ensuring a continuous flow of data with minimum latency between data sources, you will be developing, testing and deploying data pipelines into the production environment. You will be a part of the team which delivers ML/AI solutions at scale.
You will be working in close partnership with data analysts, data scientists, and data engineers, as well as other colleagues from Springer Nature and our technology partners, including Google. You will have opportunities to work with the latest data and analytics technologies, including graph databases, Google BigQuery, Tensorflow, and Plotly Dash, and preview new technologies from Google and other partners.
  Role Responsibilities:
  Build streaming/batch Data pipelines for extraction/loading/transforming data between various data sources at scale in different formats.
Work closely with Data Scientists /Analysts/Product Managers to understand the requirements and develop data solutions in line with the business requirements.
Explore various best practices to Deliver/Deploy/Maintain the in-house ML/AI solutions at scale.
Automate/orchestrate various template solutions to ensure continuous delivery.
Maintain the current cloud infrastructure and help onboard the new applications.
Use creative ideas to ensure ease of Data Use within the organization.
  Experience, Skills & Qualifications:
Experience: 2-4 years
Qualification: University degree with a strong analytical/quantitative background or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.
  Essential
  SQL and Python
problem-solving capabilities
at least one of the distributive frameworks such as Apache Beam or Spark
Well organized and accurate with good time management
  Desirable
  Machine Learning concepts are beneficial but not essential as training will be provided
schema designing data modeling
Google Cloud products (BigQuery, Dataform, Colab) or other cloud data platforms beneficial
  #LI-DP1
At Springer Nature, we value the diversity of our teams and work to build an inclusive culture, where people are treated fairly and can bring their differences to work and thrive. We empower our colleagues and value their diverse perspectives as we strive to attract, nurture and develop the very best talent.
Springer Nature was awarded Diversity Team of the Year at the 2022 British Diversity Awards. Find out more about our DEI work here.
  If you have any access needs related to disability, neurodivergence or a chronic condition, please contact us so we can make all necessary accommodation.",USD 110K - 182K *
672,Data Engineering Specialist,BT Group,"Outer Ring Road, Bellandur, Bengaluru, India",Mid-level / Intermediate,"Why this job matters
BT recognises that data is absolutely critical to everything we do in the future. Right across BT there is a momentum to build world class teams that capture and use data to provide our customers with better experience, improve the working environment for our support staff, make world class products, and realise operational cost savings that can be reinvested in innovation. 
In Mobile System Development, we want to deliver on the potential of Data Analytics that identifies issues when they are still emerging and before they impact customer experience. We want to provide controlled self-healing of our networks and services when things do go wrong. We want to distil our data to make qualified decisions about where to direct our resources and investments for the future. This role will be at the centre of the Mobile System Development data strategy. It will be at the forefront of growing our existing capabilities, providing new tooling and creating new ways of working. It will deliver thought leadership and innovation that will change how we support our product portfolio and how that portfolio develops in the future.
What you’ll be doing
Working with stakeholders at all levels of the business to understand BT’s data needs and how that data can be exploited to provide tangible benefits and value to the business.
Researching new technologies in the fields of data engineering, data science, and AIOps, evaluating their applicability to our needs through trials and PoCs.
Creating and maintaining  road-maps (aligned with supplier road-maps) for the introduction of viable technologies.
Working with vendors to resolve immediate challenges and looking at tooling to enable data delivery and efficient data management 

  The skills you’ll need to succeed
Is likely to be a strategic thinker and will have a commercial acumen.
Leadership – Able to drive complex data lake projects by motivating stakeholders and breaking down barriers to progress.
Communication – can communicate complex issues, approaches and visions with both technical and non-technical stakeholders in a clear, understandable manner.
Able to navigate large corporate organisations, adopting a consultative and collaborative approach.
Is curious about technology trends and has the instinct to filter which are mature enough to be valuable and could be exploited to meet business needs.
Works with the team to improve the way we work, the tools we use and how we share experience.
Experience you’d be expected to have
Must have technical skills (at least 3 of below):
Knowledge of Big Data and Cloud Data Platforms (Hadoop , GCP ,AWS)
Experience with Apache Spark
Direct or indirect experience of data modelling (physical, logical, conceptual) – including analytic classic star / snowflake schemas
Experience of Data Engineering and Data Movement (ETL,ELT,CDC,Kafka)
Experience with programming languages like Python, Scala, Java, etc
Understanding and experience of working in an Agile Development team.
The skills you’ll need
Data Security
Database Design/Development
DevOps
Data Storage
Data Engineering
Data Integration
Programming/Scripting
Data Quality
Big Data Processing
Cloud Computing
Agile Methodologies
Data Management
Data Acquisition
Data Model Management
Decision Making
Growth Mindset
Inclusive Leadership
Our leadership standards
Looking in:
Leading inclusively
I inspire and build trust through self-awareness, honesty and integrity.
Owning outcomes
I take the right decisions that benefit the broader organisation.
Looking out:
Delivering for the customer
I execute brilliantly on clear priorities that add value to our customers and the wider business.
Commercially savvy
I demonstrate strong commercial focus, bringing an external perspective to decision-making.
Looking to the future:
Growth mindset
I experiment and identify opportunities for growth for both myself and the organisation.
Building for the future
I build diverse future-ready teams where all individuals can be at their best.
About us
BT is part of BT Group, along with EE, Openreach, and Plusnet.
Millions of people rely on us every day to help them live their lives, power their businesses, and keep their public services running. We connect friends to family, clients to colleagues, people to possibilities. We keep the wheels of business spinning, and the emergency services responding. 
We value diversity and celebrate difference. As Philip Jansen, our CEO, says ‘We embed diversity and inclusion into everything that we do. It’s fundamental to our purpose: we connect for good.’
We all stick to the same values: Personal, Simple, and Brilliant. From day one, you’ll get stuck in to tough challenges, pitch in with ideas, make things happen. But you won’t be alone: we’ll be there with help and support, learning and development.  
This is your chance to make a real difference to the world: to be part of the digital transformation of countless lives and businesses. Grab it.
  A FEW POINTS TO NOTE:
Although these roles are listed as full-time, if you’re a job share partnership, work reduced hours, or any other way of working flexibly, please still get in touch.
DON'T MEET EVERY SINGLE REQUIREMENT?
Studies have shown that women and people who are disabled, LGBTQ+, neurodiverse or from ethnic minority backgrounds are less likely to apply for jobs unless they meet every single qualification and criteria. We're committed to building a diverse, inclusive, and authentic workplace where everyone can be their best, so if you're excited about this role but your past experience doesn't align perfectly with every requirement on the Job Description, please apply anyway - you may just be the right candidate for this or other roles in our wider team.",USD 110K - 181K *
673,"Lead, Decision Scientist",London Stock Exchange Group,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Data
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
As a Decision Scientist, you will deliver key insights and analyses that help Salesforce leaders and teams make key decisions that shape strategy, operations, the way we develop products, sell and interact with customers. You will acquire deep knowledge and understanding of Salesforce products and business goals, build and manage cross-functional relationships, and communicate through digestible, relevant, and actionable storytelling. You will manage data and insights as a product, partnering with data product managers, data engineers, data scientists, ML engineers, visualization engineers, and many other DNA teammates to deliver data products, such as dashboards, ML apps, automation, and much more. You will use business thinking, engineering skills, statistical techniques, and data science practices - such as experimentation, forecasting, clustering, etc. - to wrangle data and deliver relevant and trustworthy insights.
Success in the Role: What would it look like?
A hands-on analyst - You will generate insights (e.g., performance drivers, retention analysis, behavioral personas and much more) to accelerate business growth. This requires acquiring and cleaning data from multiple sources, structuring and building data models, analyzing to generate insights, and distributing those insights to business leaders.
You have an experimentation demeanour. You are passionate about understanding the business problem and your internal users, focusing on outcome not output, and iterating to achieve the business outcome through an experimental approach.
A strategic problem solver - You understand the “big picture” context of your business and analyze data with business a mentality
You translate business challenges into an analytical plan; you think practically and creatively to craft quick, effective solutions to problems
A relationship builder - You will develop relationships and collaborate with teams to understand business problems and build and implement an analytical plan
You are comfortable delivering insights to an executive audience
A cross-functional partner - You will partner with data engineers and product managers to instrument, acquire, develop, and structure data assets that are essential to measuring the success of our products
Identify internal and external collaborators to curate data assets and produce actionable data insights and products
A data champion/A data-lover at heart/data evangelist - You will support the expansion of Salesforce data culture by growing new relationships, hosting learning sessions, integrating or crafting new tools, and improving team processes
Your Experiences
2-10 years of experience in data analytics or data science or a master’s degree in data science, statistics, applied mathematics, analytics or a related field, or equivalent alternative education, skills, and/or practical equivalent experience
You are proficient in common analytical programming languages (e.g. Python or R) and SQL
Experience with Spark and Airflow preferred
You have a strong understanding of statistical and machine learning methods such as A/B testing, experiment design, causal inference, quasi-experimental methods, common ML models, recommendation systems etc.
You are familiar with end-to-end data development, including data model design, quality review, deployment, and maintenance
You are proficient in telling data stories in a wide range of formats, including slides, charts, and dashboards (e.g. Tableau), and can coherently articulate the business impact of your insights product
You are able to plan projects in detail, set schedules, coordinate supplies across product, data, and engineering teams, complete projects end-to-end, and make sure timelines and quality expectations are met
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 129K - 204K *
674,Sr Power BI Developer,Marlabs Innovations Private Limited,"Pune, IN",Senior-level / Expert,"Organization
Marlabs is a digital innovation company helping enterprises innovate & capture digital opportunities to enable swifter solutions. Our focus is to help each of our clients find and capture their unique opportunities and empower them with digital technologies so that they can run a purposeful business. Visit and know more about us – www.marlabs.com
Role
Sr. Power BI Developer
Technology Area
Power BI
Domain
BI
Experience
8-10 Years
Responsibilities
Power BI Job Profile
A Power BI developer takes responsibility of creating and managing BI dashboards and has a thorough understanding of the BI system.
A Power BI developer's primary responsibility is to transform raw data into relevant insights via interactive and simple-to-understand dashboards and reports. Because of his strategic, executive, and management roles and duties, a Power BI developer is critical to the firm.
Roles and Responsibilities:
Recognize business requirements in the context of BI and create data models to transform raw data into relevant insights.
Using Power BI, create dashboards and interactive visual reports.
Define key performance indicators (KPIs) with specific objectives and track them regularly.
Analyze data and display it in reports to aid decision-making.
Convert business needs into technical specifications and establish a timetable for job completion.
Create, test, and deploy Power BI scripts, as well as execute efficient deep analysis.
Use Power BI to run DAX queries and functions.
Create charts and data documentation with explanations of algorithms, parameters, models, and relationships.
Construct a data warehouse.
Use SQL queries to get the best results.
Make technological adjustments to current BI systems to improve their performance.
For a better understanding of the data, use filters and visualizations.
  Skills Required:
Background with BI tools and systems such as Power BI
Prior experience in data-related tasks
Understanding of the Microsoft BI Stack
Mastery in data analytics
Should be proficient in software development.
Be familiar with MS SQL Server BI Stack tools and technologies, such as SSRS and TSQL, Power Query, MDX, PowerBI, and DAX
Analytical thinking for converting data into relevant reports and graphics.
Capable of enabling row-level data security
Knowledge of Power BI application security layer models
Ability to run DAX queries on Power BI desktop.
Proficient in doing advanced-level computations on the data set.
Excellent communication skills are required to communicate needs with client and internal teams successfully.
    USP
Marlabs provides challenging and rewarding career opportunities as well as avenues for continuous learning to all our employees. Accelerated learning, amazing colleagues, and a chance to solve some of the biggest problems in the enterprise world - this is life at Marlabs!
 ",USD 106K - 140K *
675,Snowflake Data Engineer | 4 TO 10 YEARS | PAN INDIA,Capgemini,"Chennai, TN, IN",Mid-level / Intermediate,"Job Description
Minimum 3 years experience in Snowflake.
In-depth understanding of Data Warehouse/ODS, ETL concept, and modelling structure principles
Experience gathering and analysing system requirements.
Snowflake SQL Writing SQL queries against Snowflake Developing scripts Unix, Python, etc to do Extract, Load and Transform data 3+ years of experience in Data management (e.g. DW/BI) solutions.
Proven analytical skills and Problem-solving attitude
Ability to effectively function in a cross teams environment
Primary Skills
Snowflake SQL Writing SQL queries 
Snowflake Developing scripts Unix, Python.
Extract, Load and Transform data. 
Secondary Skill
Good to have exposure to the Cloud Data ecosystem
Must have good knowledge of architecting and implementing very large scale data intelligence solutions around Snowflake Data Warehouse.
 ",USD 90K - 150K *
676,Lead Data Engineer (m/f/d),HRS,"Chandigarh, Associate, IN, 160001",Senior-level / Expert,"HRS AS A COMPANY
HRS, a pioneer in business travel, aims to elevate every stay through innovative technology. With over 50 years of experience, their digital platform, driven by ProcureTech, TravelTech, and FinTech, transforms how companies and travelers Stay, Work, and Pay.

ProcureTech digitally revolutionizes lodging procurement, connecting corporations and suppliers in a cutting-edge ecosystem. This enables seamless efficiency and automation, surpassing travelers' expectations.

TravelTech redefines the online lodging experience, offering personalized content from selection to check-in, ensuring an unparalleled journey for corporate travelers.

In FinTech, HRS introduces advancements like mobile banking and digital payments, turning corporate back offices into touchless lodging enablers, eliminating legacy cost barriers. The innovative 2-click book-to-pay feature streamlines interactions for travelers and hoteliers.

Combining these technology propositions, HRS unlocks exponential catalyst effects. Their data-driven focus delivers value-added services and high-return network effects, creating substantial customer value.

HRS's exponential growth since 1972 serves over 35% of the global Fortune 500 and leading hotel chains.

Join HRS to shape the future of business travel, empowered by a culture of growth and setting new industry standards worldwide.
BUSINESS UNIT
Data & Analytics Platform
The HRS Data & Analytics Platform is one of the key enablers of HRS GROUP's tech- and data driven business travel solutions. State of the art services and solutions like strategic consulting & hotel procurement, travel payment and expense solutions or efficient tools to manage corporate meetings and group booking facilitate the travel processes and guarantee savings along the value chain.
Around 50 Data Specialists (Analysts, Scientists and Engineers) work together in our Data Community to create analytics solutions that serve our corporate customers, hotel partners, internal stakeholders, and ultimately millions of business travelers worldwide.
HRS Data & Analytics leverage a rich data landscape (spend data, booking data, rate data, web analytics data, etc.) turning raw data into actionable insights to provide (semi-) automated decision support to customers and business stakeholders with advanced analytical solutions. We bring state-of-the-art algorithms in production, to enhance Search & Booking experience (with personalized recommendations), or optimize the corporate hotel portfolio to the objectives of customers and the needs of the travelers.
Your mission is to help reinventing how business work, stay, and pay, powered by Data & Analytics solutions and make it the next innovation of the HRS Group together with a great international team of passionate and result-driven entrepreneurial minds.
POSITION
We are looking for an experienced Senior AWS Data Engineer (all genders) supporting our teams from our Chandigarh/ Mohali office and reporting to HRS HQ. The candidate will be responsible for coordinating with stakeholders, business teams, and data teams, converting business requirements into pipeline- & data model designs, and implement data engineering solutions supporting different areas of the business. In doing so, the candidate knows and loves working with AWS resources and -capabilities, can model multidimensional datasets, and can implement and maintain data pipelines sponsoring ""lakehouse"" architectures. This is a role with high visibility to senior leadership and with high opportunity for impact for those willing to roll up their sleeves and dive deep to achieve results.
CHALLENGE
Develop an innovative data landscape for driving the business with analytics solutions up to real-time with state-of-the- art data & analytics technologies on AWS and RDBMS.
Design & Build pipelines with Continuous Delivery practices, to collect, normalize, index, integrate and publish data coming from multiple sources to our AWS-based data platform and in-memory data warehouse Exasol / Oracle.
Orchestrate our cloud (AWS) resources, automatic scheduling (Airflow), pipelining (Spark, DBT), monitoring and performance reporting.
Continuously improve Analytics & Data Pipelines workflow from experiment to release stage.
Build data platform tooling and capabilities that enable data analysts, scientists and engineers build and operate analytic workloads through self-service
FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
Understanding what it takes to design, build and maintain successful data platforms, services and products.
Hands-on experience in data extraction & integration and environment & deployment automation.
Experience in cloud engineering services using private and public cloud resources.
Expertise in Data Warehousing, ETL, Analytics, and reporting. Skill preferred SQL, Python, AWS, Spark, Microstrategy, Oracle/Exasol and Superset.
Excellent communication skills to collaborate with business stakeholders, technical engineers and management.
Fluency in English is a must
PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.
Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 121K - 190K *
677,IT Architecture Specialist-Data quality and Asset management,SAP,"Bengaluru, IN, 560066",Senior-level / Expert,"We help the world run better
Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.Apply now! 
  What you`ll do:
You are part of the Data Quality Management team (DQM) which is responsible of maintaining the meta data of all customer systems in various tool systems and the synchronization between them. The meta data is then used by automated procedures or reporting and is key for scalable and smoothly running operations.
In your role as an IT Architecture Specialist, you will have touchpoints with several technical aspects of Data Quality and will be responsible for:
Data quality along the Asset Management process
Feature requests and bug reporting to the development teams
Master Data standards definition and design in our internal tools
(CCIR, TIC, DED, Cloud Landscape Directory, …)
The definition of KPIs and Reporting
DQM Continuous Improvement
  In your day-to-day you will:
  Alignment with various asset management streams
Drive necessary process adjustments in case of data quality issues
Technical enablement of new asset management requirements
Pattern analysis of data issues (errors, missing data, …)
3rd Level Support for Asset Management & DQM issues
Interaction with various development teams & Process/Procedure Owners
The creation and tracking of development requirements until final implementation
The creation of development bug reports 
The harmonization of KPIs along the Asset Management & Data Quality Management process
Simplify management reporting
    What you bring:
Dou you have IT Architecture background? Are you pro-active, the ability to inspire others and convince them to see opportunities instead of problems? You have strong problem analysis and resolution skills as well as excellent English skills?
If this sounds like you, do you also bring:
Knowledge of SAP basis technologies, Network/Web technologies, LINUX based infrastructures, High Availability and Disaster Recovery
Background in Asset Management & Data Quality Management is a plus
Knowledge in ITIL and Project Management methodology is a plus
TOGAF certification is a plus
    Meet your team:
SAP Enterprise Cloud Services (ECS) is building the bridge for SAP on premise customers towards SAP cloud. ECS Delivery is the operational organization and our XDU Delivery unit, of which you will be part, is responsible for, among other topics, application monitoring.
Your team members and main stakeholders are in India and Germany.
  #SAPCloudReq  #SAPECSCareers
  We build breakthroughs together
SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together.
We win with inclusion
SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.
SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com
For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.
EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.
Successful candidates might be required to undergo a background verification with an external vendor.
Requisition ID: 380986  | Work Area: Information Technology  | Expected Travel: 0 - 10%  | Career Status: Professional  | Employment Type: Regular Full Time   | Additional Locations: #LI-Hybrid.
 ",USD 45K - 84K *
678,Machine Learning Engineer,ExxonMobil,"Bengaluru, KA, IN",Mid-level / Intermediate,"  About us
  At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.
  The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies. 
  We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.
What role you will play in our team
  We are looking to hire candidates to work on challenging technology and engineering problems that span oil and gas exploration & production, chemicals/fuels/lubricants products and low carbon solutions. A successful candidate would understand a business problem (both commercially and technically), translate it into a computational, data science or machine learning problem and apply engineering, numerical, data science and programming skills to tackle it. The Machine Learning Engineer will work as part of a team to design, develop, deploy and sustain data science solutions that are scalable, reproducible and with commercial-grade quality.
What you will do
  Applies software development practices, DevOps skills and Machine Learning (ML) techniques to orchestrate an end-to-end machine learning workflow that effectively brings ML models to production.
Participates in scoping of deployment of new data science solutions and implements the appropriate solution design.
Sustain data science solutions by enabling continuous ML model and/or service performance monitoring, training, and re-training of models, including the implementation of proactive alerting methods.
Works effectively with computational scientists, data scientists, engineers, software developers, and domain experts across the globe to develop and apply computational and data science solutions in support of our business.
  About You
  Skills and Qualifications
  Bachelor’s degree from a recognized university in Computer Science, IT, Applied Mathematics, Engineering or related disciplines with minimum 7.0 CGPA or equivalent.
Minimum 3 years of experience in Data Science and Machine Learning or related computational domain.
Competent to expert level programming experience in C/C++/Python.
Strong foundation in application design.
Experience with refactoring legacy code and leveraging third-party libraries/APIs during software development.
Experience with Source code version control (Git), Azure Cloud platform and containers, Databricks and MLflow.
Continuous Integration and Continuous Deployment.
Familiarity with statistical analysis, regression and classification.
Preferred Qualifications / Experience
  Experience with time series analysis, computer vision, natural language processing.
Knowledge or hands on experience on Matlab & SQL.
Strong written and verbal communication skills.
Prior knowledge of commercial software development and/or experience in commercial software teams.
Familiarity with Oil and Gas Industry.
Your benefits
  An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you: 
  Competitive compensation 
Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits 
Retirement benefits 
Global networking & cross-functional opportunities
Annual vacations & holidays
Day care assistance program
Training and development program
Tuition assistance program
Workplace flexibility policy
Relocation program
Transportation facility
  Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company’s eligibility guidelines.
Stay connected with us
  Learn more about ExxonMobil in India, visit ExxonMobil India  and Energy Factor India.
Follow us on LinkedIn and ExxonMobil (@exxonmobil) • Instagram photos and videos
Like us on Facebook
Subscribe our channel at YouTube
  EEO Statement
  ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.
  Business solicitation and recruiting scams
  ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.
 
  Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship. 
  Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",USD 110K - 200K *
679,Advanced Data Scientist,ExxonMobil,"Bengaluru, KA, IN",Senior-level / Expert,"  About us
  At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.
  The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies. 
  We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.
What role you will play in our team
We are seeking an advanced data scientist at the Bangalore Technology Center (BTC) who can provide technical expertise, strategic and cross-functional leadership to generate maximum business value from data science by working with computational and data scientists as well as business domain experts across engineering, geoscience, and commercial domains. 
You will be able to scope new opportunities, develop, and deploy data-driven models, automate workflows, and generate insights that lead to significant business value for ExxonMobil's multiple value chains. 
Opportunity scope ranges from accurately predicting subsurface properties using machine learning; predicting failure of machinery using historical data, and using advanced analytics to increase revenue from commercial sale of fuels and lubricants. 
You will have access to massive data sets, immense compute power and challenging, previously unsolved problems in the oil and gas domain
What you will do
Be a part of a growing organization comprising computational, data scientists and optimization experts working to solve challenging business problems by developing and applying state-of-the-art machine learning techniques.
Partner with domain experts across the corporation to identify, scope, and develop machine learning solutions and provide insights to our business partners to reduce costs and/or increase revenue. Primary scope of application will be in the engineering domain, which will require you understand the underlying physical processes that generate the data, for example solid or fluid mechanics.
Communicate recommendations and solutions from data science applications to business partners and influence and drive business uptake of the proposed solutions
Help screen and prioritize ideas based on technical feasibility and value maximization
Advise senior business line management on challenges and opportunities in the data science space in the various domains; identify and champion new opportunities
Provide technical leadership, consulting, and mentorship to early-career engineers, computational and data scientists
Work with software and data architecture experts to understand and influence architectural decisions to drive effective development of data-driven solutions for the business
About You
Skills and Qualifications
Master's or PhD from a recognized university in engineering, mathematical sciences, physics or related quantitative discipline with GPA 7.0 (out of 10.0) and above
10+ years of experience in developing and building data science solutions to solve business problems in an engineering or related field
In-depth knowledge and practical experience in applying statistical analysis techniques, such as classification, regression, time-series, Bayesian techniques, etc. and machine learning techniques, such as decision-trees, ensemble methods, neural networks, validation methods etc.
Experience in developing, applying, and analyzing physics-based and/or data driven computational models and simulations is an advantage
Practical experience in the full machine learning life cycle from problem formulation, data acquisition, modeling building, and deployment at enterprise scale.
Experience in Python & R and related packages such as numpy, pandas, sklearn, Keras, Tensorflow, PyTorch
Experience with software engineering practices, agile methodologies, DevOps, version control 
Demonstrated experience of identifying and scoping data science opportunities based on business needs
Demonstrated leadership experience in influencing business partners on uptake of data science solutions and facilitating change management
Strong communication and interpersonal skills
Ability to deal with business and technical uncertainty
Demonstrated experience mentoring early career data scientists 
Preferred Qualifications / Experience
Prior experience leading data science teams is an advantage
Experience with optimization techniques, such as linear and nonlinear programming or experience with commercial solvers such as CPLEX is an advantage
Your benefits
An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you: 
  Competitive compensation 
Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits 
Retirement benefits 
Global networking & cross-functional opportunities
Annual vacations & holidays
Day care assistance program
Training and development program
Tuition assistance program
Workplace flexibility policy
Relocation program
Transportation facility
  Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company’s eligibility guidelines.
Stay connected with us
Learn more about ExxonMobil in India, visit ExxonMobil India  and Energy Factor India.
Follow us on LinkedIn and ExxonMobil (@exxonmobil) • Instagram photos and videos
Like us on Facebook
Subscribe our channel at YouTube
  EEO Statement
ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.
  Business solicitation and recruiting scams
ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.
 
  Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship. 
  Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",USD 136K - 205K *
680,Mts Software Engineer (Python Programming and Machine Learning),NetApp,"Bengaluru, Karnataka, IN, 560071",Senior-level / Expert,"About NetApp
We’re forward-thinking technology people with heart. We make our own rules, drive our own opportunities, and try to approach every challenge with fresh eyes. Of course, we can’t do it alone. We know when to ask for help, collaborate with others, and partner with smart people. We embrace diversity and openness because it’s in our DNA. We push limits and reward great ideas. What is your great idea?
""At NetApp, we fully embrace and advance a diverse, inclusive global workforce with a culture of belonging that leverages the backgrounds and perspectives of all employees, customers, partners, and communities to foster a higher performing organization."" -George Kurian, CEO
Job Summary
We are seeking an experienced Software Engineer with a strong background in Python programming and expertise in machine learning. Candidate will be responsible for the development, design, and architecture of various modules within our organization. This is a hands-on role that requires excellent problem-solving skills and the ability to troubleshoot complex issues.
Job Requirements
  Utilize your 8+ years of hands-on development experience to design and implement robust solutions using Python programming language.
Apply your solid Python programming and machine learning skills to develop and enhance machine learning models (both supervised and unsupervised) for our organization.
Leverage your 4+ years of experience in Django and the Python ecosystem to build scalable and efficient applications.
3+ years of experience in building machine learning models, both supervised and unsupervised.
2+ years of experience in building data pipelines for processing and transforming large volumes of data.
Architect, design, and take ownership of modules within our system, ensuring their reliability, scalability, and maintainability.
Utilize your experience in building data pipelines to efficiently process and transform large volumes of data.
Collaborate with cross-functional teams to develop and integrate RESTful web services and microservices into our architecture.
Apply object-oriented design methodology to ensure code reusability, maintainability, and extensibility.
Demonstrate your expertise in building scalable architectures to support our growing user base and data volumes.
Utilize your proficiency in Angular, JavaScript, HTML, and CSS frameworks to develop user-friendly interfaces and front-end components.
Communicate effectively with team members and stakeholders, both verbally and in writing, to provide updates, gather requirements, and present solutions
Strong knowledge and experience in machine learning techniques and algorithms.
Proven experience in architecting, designing, and owning modules within a complex system.
Education
Bachelor's degree in Computer Science or a related field.
8-12 years of hands-on development experience in Python programming and Machine Learning
Did you know…
Statistics show women apply to jobs only when they’re 100% qualified. But no one is 100% qualified. We encourage you to shift the trend and apply anyway! We look forward to hearing from you.
Why NetApp?
In a world full of generalists, NetApp is a specialist. No one knows how to elevate the world’s biggest clouds like NetApp. We are data-driven and empowered to innovate. Trust, integrity, and teamwork all combine to make a difference for our customers, partners, and communities. 
 
We expect a healthy work-life balance. Our volunteer time off program is best in class, offering employees 40 hours of paid time off per year to volunteer with their favorite organizations.  We provide comprehensive medical, dental, wellness, and vision plans for you and your family.  We offer educational assistance, legal services, and access to discounts. We also offer financial savings programs to help you plan for your future.  
 
If you run toward knowledge and problem-solving, join us. ",USD 45K - 84K *
681,Cloud Technical Lead - AI & ML,"Insight Enterprises, Inc.","Gurugram Gurgaon HR, IN",Senior-level / Expert,"Requisition Number: 94942 
  Job Overview:
We are on the lookout for a seasoned Cloud Engineer with a deep expertise in Artificial Intelligence (AI) and Machine Learning (ML). The ideal candidate will possess robust communication abilities and a knack for resolving complex problems. If you are passionate about pioneering innovative AI/ML models and collaborating with a dynamic team, we would love to hear from you.
  Key Qualifications:
Proficiency in programming languages: C# and Python.
Hands-on experience with Azure Cognitive Services, including Azure Custom Vision and Azure Cognitive Search.
Strong command over OpenAI, custom modelling, and model fine-tuning.
Familiarity with Natural Language Processing (NLP), Linguistic Language Processing (LLP), and advanced Data Science algorithms.
  Primary Responsibilities:
Research, design, and develop cutting-edge AI/ML models tailored to business needs.
Collaborate closely with cross-functional teams to gather, analyze, and interpret data.
Oversee the entire model lifecycle: training, validation, and deployment.
Provide compelling demonstrations of AI/ML capabilities to stakeholders.
Maintain clear and effective communication with team members, stakeholders, and external partners.
Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
  Insight India Location:Level 16, Tower B, Building No 14, Dlf Cyber City In It/Ites Sez, Sector 24 &25 A Gurugram Gurgaon Hr 122002 India",USD 45K - 84K *
682,Sr Machine Learning Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
5+ years of experience with Python, Java or a similar OO language
Experience of core AI/ML techniques and algorithms
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
Passion for JavaScript and the Web as a platform, reusability, and componentization
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 150K - 230K *
683,"Chatbot|7-9yrs|Hyderabad,Kolkata,Noida",Capgemini,"Kolkata, KA, IN",Mid-level / Intermediate,"Job Description
Deliver chat & voice solutions according to requirements (GCP + Dialogflow, GCP + AWS, GCP + Cisco CVP)
integrate chat and voice solutions with Google services (gChat, Cloud Storage, gDrive, gMail, gSheet, ect.)
integrate chat and voice solutions with business applications (SAP, Service Now, Salesforce, etc.)
discover capabilities of available APIs and consume them to meet solution requirements
write micro applications in TypeScript  & Node.js to achieve desired functionalities & automations
discover best ways to deliver requirements within GCP using available technology stack
Primary Skills
  Very good TypeScript skills (optionally Node.js)
 Knowledge on kore.ai is Must and hands-on
very good understanding of authorisations concepts (API key, OAuth)
broad experience in exploring and consuming APIs through various methods
good understanding of Pub/Sub concept in messaging systems
technical / informatics background with coding mindset
skilled to discover ways of meeting solution requirements with available technology stack
enthusiasm to learn new things and discover new technologies
Secondary Skills
Basic front end skills (React)
experience in working in Google environment (GCP, Dialogflow)
experience in voice solutions (AWS, Cisco)
experience in using integration platforms (SEND, Mulesoft)",USD 30K - 56K *
684,Data Science Lead Technologist,Lloyd's Register,"Mumbai, MH, IN, 400093",Senior-level / Expert,"Job ID:38720
        Data Science Lead Technologist
    Lloyd’s Register
  Location: - Mumbai/Chennai, India
  What we’re looking for 
We are seeking an individual to lead and develop LR's capability in data and digital development activities across research and technology portfolios. Work with LR's domain experts on challenging problems that matter for safety and sustainability. The role will shape the understanding and development of LR's approach  to the data driven assurance, aligning with our strategy and client needs. Key to this will be supporting knowledge and capability development across our technical communities as we transition to Digital assurance of ships and Offshore installations. 
  Specific areas of expertise we are seeking for advancing data and digital initiatives within our portfolio include:
Proficiency in handling statistical process control data within a manufacturing environment.
Experience in utilizing data for making quality assurance decisions within manufacturing operations.
The ability to effectively analyze extensive manufacturing data to identify trends while ensuring compliance requirements are met.
Competence in data analytics to demonstrate safety, performance, and compliance.
  While it is advantageous for the aforementioned expertise to be in the realm of materials, equipment, or components used in the marine industry, we also consider other operational experiences. Furthermore, having prior experience in maritime or offshore industry manufacturing, such as in steel production, engines, machinery, or related sectors, is a desirable attribute.
   What we offer you 
  Competitive Salary
The opportunity to work for an organization that has a strong sense of purpose, is values driven and helps colleagues to develop professionally and personally through our range of people development programmes. 
  The role 
Apply technical expertise to advance LR's data and digital assurance capabilities in the realms of maritime safety and environmental compliance.
Assume a leadership role as a key stakeholder in the development of LR's data and digital assurance capabilities across LR's technical communities.
Evaluate and select appropriate data sources, including real-time data streams and discrete data sets, and employ effective data-gathering techniques to enhance data collection methods and architecture.
Conduct testing of data mining models to identify the most suitable ones for project implementation.
Apply statistical learning methodologies to predict the probabilities of extreme events and anomalies.
Define applications of algorithms in the design patterns of analytical tools to provide valuable insights to stakeholders.
Collaborate with the team to offer data and digital expertise required to support client and LR stakeholder projects.
Collaborate closely with technical domain specialists, especially in materials and manufacturing, to comprehend current data sources and outline future data requirements while establishing technical governance.
Lead LR's research and technology development efforts in assigned projects and keep a vigilant eye on developments within the LR client community. Engage in liaisons and collaborations with industry and academic stakeholders, continually identifying new opportunities.
Interface with and support the commercial and marketing team as needed, providing technical input into the development of our commercial offerings in the field of data and digital capability.
Contribute to the evolution of the technical content of LR procedures, rules, and industry guidance.
Share data and digital knowledge and expertise through participation in internal and external events, including representing LR on committees and research panels.
Identify and consistently seek enhancements to data and digital technical governance activities, ensuring their effective integration into operations.
Provide training and mentorship to team members to facilitate effective knowledge transfer and application.
Maintain strict compliance with all health and safety rules, instructions, and systems, and refrain from undertaking work that may jeopardize safety or health, either yours or that of others.
Actively pursue Continuing Professional Development and maintain a broad spectrum of discipline knowledge and awareness.
Undertake project management responsibilities when applicable, including monitoring project progress and expenditure against budget and contract requirements.
  What you bring 
  A minimum of a master's degree or post-graduate qualification in data science or an equivalent qualification recognized by Lloyd’s Register.
Demonstrated knowledge gained through coursework, projects, and prior professional experience in areas such as machine learning, fault diagnosis, formal methods, optimization theory, artificial intelligence, and system safety theory. Proficiency in imbalanced learning is also advantageous.
Proven experience, documented through coursework, projects, and professional roles, in setting up and executing experimental work.
Expertise in developing end-to-end machine learning projects, encompassing MLops (Machine Learning Operations) and distributed computing.
Proficiency in scientific computing within development environments such as Python and/or Matlab, R, extending beyond basic scripting capabilities.
The ability to showcase technical qualifications through diverse documentation, which may include scientific publications, personal webpages, or links to GitHub repositories.
Strong written and verbal communication skills, recognizing the importance of people and relationships alongside technical proficiency. Familiarity with technical authoring of engineering procedures, specifications, and standards is an advantageous asset.
A track record of leading by example in delivering exceptional customer service, both individually and as part of a team.
Confidence and competence in reviewing processes and procedures, and the ability to implement necessary changes.
Proficiency in MS 365 packages and relevant database software to efficiently manage data, generate reports, track KPIs, and provide valuable recommendations.
    About us 
We are a leading international technical professional service provider and a leader in classification, compliance, and consultancy services to the marine and offshore industry, a trusted advisor to our customers helping to design, construct and operate their assets to the highest levels of safety and performance. We are shaping the industry’s future through the development of novel and innovative technology for the next generation of assets, while continuing to deliver solutions for our customers every day.
  Be a part of 
Lloyd’s Register is wholly owned by the Lloyd’s Register Foundation, a politically and financially independent global charity that aims to engineer a safer world through promoting safety and education. For a thriving ocean economy, Lloyd’s Register colleagues and Lloyd’s Register Foundation work together to fund research, foster industry collaboration and develop action-oriented solutions to make the world a safer place. 
  Want to apply 
  We hire people with a wide variety of skills, experience, and backgrounds. This includes people with disability, women, people identifying as LGBTIQIA+, culturally and linguistically diverse people, careers, and other varied groups. 
  We are committed to making all stages of our recruitment process accessible to all candidates. Please let us know if you need any assistance or reasonable adjustments throughout your application and we will do everything we possibly can to support you. 
    If you don't tick every box in these ads, please don't rule yourself out. We focus on hiring people who share our goal of working together for a safer, sustainable, thriving ocean economy. 
  We care, we share, we do the right thing.
  If you have further questions about this role, please contact us at careers@lr.org and we will respond to you as soon as possible.
      Diversity and Inclusion at Lloyd's Register:
Together we are one Lloyd’s Register, committed to developing an inclusive and safe workplace that embraces and celebrates diversity. We strive to ensure that all applicants to LR experience equality of opportunity and fair treatment because we believe it is the right thing to do. We hope you do too.
Copyright © Lloyd's Register 2023. All rights reserved. Terms of use. Privacy policy.
The Lloyd's Register Group comprises charities and non-charitable companies, with the latter supporting the charities in their main goal of enhancing the safety of life and property, at sea, on land and in the air - for the benefit of the public and the environment. (Group entities)
 ",USD 45K - 84K *
685,Power BI Developer | 6 to 9 years | PAN India,Capgemini,"Mumbai, MH, IN",Executive-level / Director,"Job Description
Extensive experience in Power BI Visualization.
Experience in implementing Tabular model implementation and row level data security.  
Experience in Client interactions and requirement analysis.     
Good communication and comprehension skills.       
Experience in requirement documentation.       
Good presentation and coordination skills
  Primary Skills
Experience in Power BI Development using SSAS Tabular model.
Experience in writing and optimizing DAX queries.
Good understanding of Data warehouse concepts.
Secondary Skills
Good communication and comprehension skills
Knowledge of Microsoft Azure analytics is a plus.",USD 85K - 135K *
686,Data Engineer,Visa,"Bengaluru, India",Executive-level / Director,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Position Summary
We are looking for an individual contributor with deep expertise in building large-scale data processing systems by using the latest database and data processing technologies. This position plays a critical role in enabling the data platforms through which Data Scientists, Analysts, and BI Users drive solutions for our Visa clients.  Also, the role provides a bridge between our local end-users and our Visa Technology colleagues in San Francisco, influencing the development of our global data platforms whilst provisioning local tools and technologies as required.  The Data Engineer takes responsibility for building and running data pipelines, designing our data warehouses and data frameworks
The Global Data Science team is the engine of analytics at Visa: this is a high-performing team of data scientists, data analysts, statisticians, and business analysts from a variety of countries – serving the Asia Pacific, Central Europe, Middle East and Africa geographies.
Visa DS is looking for a hands-on manager, a person that earns trust and respect of the team. The Manager must be results oriented, highly organized, and must, must be focused on delivering innovative analytics work. As Data Engineer you will be responsible for designing, developing and delivering data solutions through best in class architected solutions.

Principal Responsibilities
Design local modifications to our global data architecture, including new tools and technologies where necessary to meet local requirements
Create and maintain optimal data pipeline architecture(s), based on our Global Technology Stack
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Executing medium to large analytic projects along with rest of the stakeholders in the Visa data science team and Client team
Performing QA on data and deliverables by analysts and own deliverables
Ensuring all project documentation is up to date and all projects are reviewed per analytic plan
Building on team’s analytical skills and business knowledge
Develop custom-built packages to support the needs of Data Scientists
Work with broader business stakeholders to assist clients and consultants with their data and infrastructure needs
 Business Experience
• Results-oriented with strong problem solving skills and demonstrated intellectual and analytical rigor
• Good business acumen with a track record in solving business problems through data-driven quantitative methodologies. Experience in payment, retail banking, or retail merchant industries is preferred 
• Team oriented, collaborative, diplomatic, and flexible style, with the ability to tailor data driven results to various audience levels 
• Very detailed oriented, is expected to ensure highest level of quality/rigor in reports and data analysis 
• Exhibits intellectual curiosity and a desire for continuous learning
Leadership Competencies
• Exhibits intellectual curiosity and a desire for continuous learning
• Demonstrates integrity, maturity and a constructive approach to business challenges
• Role model for the organization and implementing core Visa Values 
• Respect for the Individuals at all levels in the workplace
• Strive for Excellence and extraordinary results
• Use sound insights and judgments to make informed decisions in line with business strategy and needs
• Leadership skills include an ability to allocate tasks and resources across multiple lines of businesses and geographies. Leadership extends to ability to influence senior management within and outside Analytics groups
• Ability to successfully persuade/influence internal stakeholders for building best-in-class solutions.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Professional Experience
• 5 - 8 years' application development and support experience.
• Deep knowledge of distributed data architecture, commonly-used BI tools, and approaches/packages deployed for machine learning build
• Experience creating production software in Python and/or Scala, and a proven track record of identifying and resolving performance bottlenecks for production systems.
• Experience with complex, high volume, multi-dimensional data, as well as machine learning models based on unstructured, structured, and streaming datasets.
• Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
• Demonstrated ability to incorporate new techniques to solve business problems

Technical Expertise
• Qualification in Computer Science or Engineering ideal. 
• Certification in Hadoop (Cloudera or Hortonworks) and Apache Spark ideal. 
• Experience in developing production systems, with software engineering governance practices in place e.g, Object orientation, functional programming, unit testing frameworks, CI/CD and job scheduling technologies
• Data acquisition and provisioning through various modes and channels, e.g., Batch, real-time, event-driven architecture, APIs, etc. 
• Working knowledge of Hadoop ecosystem and associated technologies, e.g., Hadoop, Hive, Apache Spark, Kubernetes, Kafka, etc. 
• Advanced experience in writing and optimizing efficient SQL queries and scripts. Scala experience is ideal
• Deliver results within committed scope, timeline and budget 
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 110K - 182K *
687,Senior Applied Data Scientist,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru: We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
Tesco Business Services is a multi-disciplinary team that brings Tesco's Service Model to life. It aims to create a sustainable competitive advantage for Tesco by standardising processes, reducing cost to serve, enabling agility in the business and empowering colleagues to do even more for their customers. With cross-functional expertise, multi-locational teams supported by strong governance, Business Services reduces complexity and provides high quality services for its customers. The goal is to offer world-class service with real expertise delivering value for Tesco customers, and our shareholders. The organisation will create centres of excellence for improving economies of scale – freeing up our functional experts to deliver an enhanced customer experience. Learn more about Business Services and how we enhance customer experiences, provide cost leadership and indirect benefits for Tesco as we continue to serve enhances customer experiences.
Job Description
Understands business needs and in depth understanding of Tesco processes - Builds on Tesco processes and knowledge by applying CI tools and techniques. - Responsible for completing tasks and transactions within agreed KPI's - Solves problems by analyzing solution alternatives -Engaging with business & functional partners to understand business priorities, ask relevant questions and scope same into a analytical solution document calling out how application of data science will improve decision making - In depth understanding of techniques to prepare the analytical data set leveraging multiple complex data set sources - Building Statistical models and ML algorithms with practitioner level competency - Writing structured, modularized & codified algorithms using Continuous Improvement principles (development of knowledge assets and reusable modules on GitHub, Wiki, etc) with expert competency - Building easy visualization layer on top of the algorithms in order to empower end-users to take decisions - this could be on a visualization platform (Tableau / Python) or through a recommendation set through PPTs - Working with the line manager to ensure application / consumption and proactively identifying opportunities to help the larger Tesco business with areas of improvement - Keeping up-to-date with the latest in data science and retail analytics and disseminating the knowledge among colleagues
Qualifications
Skills Required: Operational skills relevant for this job: - Logical Reasoning; Adv Excel - Adv SQL; Hive; python; Tableau; Dash - Basic Statistical Concepts - Central measures of data; Linear & Logistics regression - Adv Statistical Concepts - ML - Regression; Classification; Clustering; Time Series - Gen AI - LLMs; RAG framework
- 2 - 4 years experience in data science application in Retail or CPG Preferred - Functional experience: Marketing, Supply Chain, Customer, Merchandising, Operations, Finance or Digital
Additional Information
Last Date of Application-9th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 30K - 67K *
688,Senior Cloud Data Engineer,NTT DATA,"Bengaluru, KA, IN",Senior-level / Expert,"Req ID: 259376 
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Senior Cloud Data Engineer to join our team in Bangalore, Karnātaka (IN-KA), India (IN).
Senior Cloud Data Engineer – II (Remote)
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Senior Cloud Data Engineerto join our team in Bangalore, Karnātaka (IN-KA), India (IN)
We are looking to hire Senior Cloud Data Engineers with experience in building data pipelines using cloud technologies. The ideal candidate should have demonstrated experience building large-scale solutions in one or more major cloud providers – AWS, Azure, or GCP.
Job Responsibilities Include:
•    As a senior member of the team, deliver production data pipelines, while working in collaboration with product and application teams
•    Mentor data engineering talent
•    Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art, next generation big data and machine learning applications
•    Leverage cloud-based architectures and technologies to move, transform, and secure data, at scale
•    Advocate for data engineering and software best practices
Basic Qualifications:
•    5+ years in building, scaling, and optimizing data pipeline
•    3+ years of experience developing and deploying solutions in one or more of the public clouds - AWS, Azure, GCP
•    5+ years of professional experience in data wrangling in rational databases using SQL
•    5+ years experience with object-oriented programming design best practices
•    5+ years of experience using source control (git)
•    Experience promoting data pipeline though development, testing, and production environments
Preferred Skills and Experience:
•    Professional services experience, a strong plus
•    Cloud provider certification, a strong plus
Technologies you will work with:
•    Data Engineering Technologies:
•    Spark / Hadoop / Databricks
•    Python (JavaScript, Java or Scala, a plus)
•    Advanced SQL
•    Petabyte-scale, cloud-native data stores (Redshift, Athena, BigQuery, Synapse, Snowflake)
•    Cloud storage (S3, GCS, Azure Blob Storage)
•    Modern warehousing and data lake patterns
•    Airflow or other orchestration tools
•    Kafka, queue/messaging paradigms
•    Flink, Beam, and other Apache data movement software
•    NoSQL and document store technologies
•    Cloud Technologies (One or More of AWS, Azure, GCP):
•    Security/networking basics
•    Cloud native tools for batch and streaming data processing
•    Cloud native query engines
•    Serverless cloud functions, a plus
•    Visualization/reporting experience, a plus
Must reside in the US
Where required by law, NTT DATA provides a reasonable range of compensation for specific roles. The starting pay range for this remote role is $82,900.00-$172,700.00. This range reflects the minimum and maximum target compensation for the position across all US locations. Actual compensation will depend on a number of factors, including the candidate’s actual work location, relevant experience, technical skills, and other qualifications. 
This position is eligible for company benefits including medical, dental, and vision insurance with an employer contribution, flexible spending or health savings account, life and AD&D insurance, short and long term disability coverage, paid time off, employee assistance, participation in a 401k program with company match, and additional voluntary or legally-required benefits.

About NTT DATA Services
NTT Data Services is a global business and IT services provider specializing in digital, cloud and automation across a comprehensive portfolio of consulting, applications, infrastructure and business process services. We are part of the NTT family of companies, a partner to 85% of the Fortune 100.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.
#Launch Jobs #LaunchEngineering
About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.",USD 82K - 172K
689,Open AI Developer | 4 to 10 years | PAN India,Capgemini,"Gurgaon, HR, IN",Senior-level / Expert,"Job Description
Develop, implement, and optimize OpenAI models for various applications, including chatbots and customer support.
Integrate OpenAI models with Power Automate for streamlined workflows and Power Virtual Agents for enhanced user interaction.
Design and develop backend services using Python or .NET to support OpenAI-powered solutions.
Work with custom datasets, utilizing techniques like chunking and embeddings, to train and fine-tune models.
Integrate Azure cognitive services to extend functionality and improve AI solutions.
Regularly review and fine-tune OpenAI models to ensure maximum accuracy and relevance for custom datasets.
Collaborate with cross-functional teams to ensure smooth deployment and integration of AI solutions.
Stay updated with the latest advancements in OpenAI and Azure services to bring innovation to our solutions.
Primary Skills
Bachelor's degree in Computer Science, Engineering, or a related field.
Proficient in Python and/or .NET for backend development.
Experience with OpenAI GPT models and their applications.
Hands-on experience with Microsoft Power Automate and Power Virtual Agents.
Familiarity with Azure cognitive services.
Strong understanding of machine learning concepts, including model training, fine-tuning, and evaluation.
Good knowledge of Natural Language Processing (NLP) techniques.
Ability to work in a team-oriented environment and deliver on tight deadlines.
Excellent problem-solving and analytical skills.
Experience with Google Cloud Build, Jenkins or other similar CI/CD tools
Secondary Skills
Master's degree or further education in AI, machine learning, or a related field.
Previous experience in customer support or chatbot development.
Certifications in Microsoft Azure or OpenAI technologies.",USD 74K - 192K *
690,Cloud Engineer- AI & ML,"Insight Enterprises, Inc.","Gurugram Gurgaon HR, IN",Senior-level / Expert,"Requisition Number: 94910 
AI & ML Specialist – 5-8 Years
Location: India (Hyd, Bangalore, Delhi/NCR)
Shift Timings: 07:00 PM -03:00 AM(Night)
    Job Overview:
We are on the lookout for a seasoned Cloud Engineer with a deep expertise in Artificial Intelligence (AI) and Machine Learning (ML). The ideal candidate will possess robust communication abilities and a knack for resolving complex problems. If you are passionate about pioneering innovative AI/ML models and collaborating with a dynamic team, we would love to hear from you.
  Key Qualifications:
Proficiency in programming languages: C# and Python.
Hands-on experience with Azure Cognitive Services, including Azure Custom Vision and Azure Cognitive Search.
Strong command over OpenAI, custom modeling, and model fine-tuning.
Familiarity with Natural Language Processing (NLP), Linguistic Language Processing (LLP), and advanced Data Science algorithms.
  Primary Responsibilities:
Research, design, and develop cutting-edge AI/ML models tailored to business needs.
Collaborate closely with cross-functional teams to gather, analyze, and interpret data.
Oversee the entire model lifecycle: training, validation, and deployment.
Provide compelling demonstrations of AI/ML capabilities to stakeholders.
Maintain clear and effective communication with team members, stakeholders, and external partners.
  Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.
  Insight India Location:Level 16, Tower B, Building No 14, Dlf Cyber City In It/Ites Sez, Sector 24 &25 A Gurugram Gurgaon Hr 122002 India",USD 45K - 84K *
691,Member of Technical Staff - (AI/ML Engineer - GenAI),Pure Storage,"Bengaluru, India",Senior-level / Expert,"BE PART OF BUILDING THE FUTURE.
What do NASA and emerging space companies have in common with COVID vaccine R&D teams or with Roblox and the Metaverse? 
The answer is data, -- all fast moving, fast growing industries rely on data for a competitive edge in their industries. And the most advanced companies are realizing the full data advantage by partnering with Pure Storage. Pure’s vision is to redefine the storage experience and empower innovators by simplifying how people consume and interact with data. With 11,000+ customers including 58% of the Fortune 500, we’ve only scratched the surface of our ambitions. 
Pure is blazing trails and setting records:
For ten straight years, Gartner has named Pure a leader in the Magic Quadrant 
Our customer-first culture and unwavering commitment to innovation have earned us a certified Net Promoter Score in the top 1% of B2B companies globally
Industry analysts and press applaud Pure’s leadership across these dimensions
And, our 5,000+ employees are emboldened to make Pure a faster, stronger, smarter company as we go
If you, like us, say “bring it on” to exciting challenges that change the world, we have endless opportunities where you can make your mark.
SHOULD YOU ACCEPT THIS CHALLENGE...
The MTS AI/ML Engineer will contribute to the development and implementation of generative AI applications. This position requires foundational skills in AI/ML technologies and software development, with an eagerness to grow in the field of generative AI.
Scope of work - The primary focus of the role is to contribute to the enterprise's transformation using generative AI technologies. Engage in advanced research and experimentation with cutting-edge technologies in the field of generative AI and develop custom applications using gen AI to solve complex business problems. Work on proprietary data formats, analyze data, and fine-tune models for specific use cases, such as code review and customer-facing sux`pport models.
Develop basic GenAI applications using libraries like TensorFlow, Keras, and PyTorch.
Implement AI algorithms, with a focus on models like GPT, BERT, or DALL-E.
Engage in scripting and automation using Python, and utilize software development tools such as Git, JIRA, and Jenkins.
Assist in data handling and processing using SQL, pandas, and NumPy.
Support AI application deployments in cloud environments using Docker and Kubernetes, and cloud platforms like AWS, Azure, or GCP.
Collaborate on API development for AI applications using Flask or Django.
WHAT YOU’LL NEED TO BRING TO THIS ROLE...
Familiarity with Python, and basic knowledge of software development tools (Git, JIRA).
Understanding of machine learning concepts and experience with frameworks like TensorFlow or PyTorch.
Introductory knowledge of cloud computing and containerization technologies.
Ability to work with data storage solutions (SQL, NoSQL, Hadoop).
Knowledge of software engineering practices, including version control and CI/CD.
BE YOU—CORPORATE CLONES NEED NOT APPLY.
Pure is where you ask big questions, think differently, and make an impact. This is not just a job, but a place where you have a voice and can accelerate your career. We value unique thoughts and celebrate individuality, and with ample opportunity to learn, develop yourself, and expand into different roles, joining Pure is an investment in your career journey.
Through our Pure Equality program, which supports a flourishing field of employee resource groups, we nourish the personal and professional lives of our team members. And our Pure Good Foundation gives back to local and global communities through volunteering and grants.
And because we understand the value of bringing your full and best self to work, we offer a variety of perks to manage a healthy balance, including flexible time off, wellness resources, and company-sponsored team events.
PURE IS COMMITTED TO EQUALITY.
Research shows that in order to apply for a job, women feel they need to meet 100% of the criteria while men usually apply after meeting about 60%. Regardless of how you identify, if you believe you can do the job and are a good match, we encourage you to apply.
Pure is proud to be an equal opportunity and affirmative action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or any other characteristic legally protected by the laws of the jurisdiction in which you are being considered for hire. 
If you need assistance or an accommodation due to a disability, you may contact us at TA-Ops@purestorage.com.
APPLICANT & CANDIDATE PERSONAL INFORMATION PRIVACY NOTICE.
If you're wondering how or why Pure collects or uses information you provide, we invite you to check out our Applicant & Candidate Personal Information Protection Notice.",USD 174K - 276K *
692,Data Architect,3Pillar Global,Noida,Senior-level / Expert,"We are 3PILLAR GLOBAL
We build breakthrough software products that power digital businesses. We are an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders in Software and SaaS, Media and Publishing, Information Services, and Retail. Our key differentiator is our Product Mindset. Our development teams focus on building for outcomes and all of our team members around the globe are trained on the Product Mindset’s core values – Minimize Time to Value, Solve For Need, and Excel at Change. Our teams apply this mindset to build digital products that are customer-facing and revenue-generating. Our business-minded approach to agile development ensures that we align to client goals from the earliest conceptual stages through market launch and beyond.

In 2023, 3Pillar Global India was named as a “Great Place to Work” for the fifth year in a row based on how our employees feel about our company, collaborative culture, and work/life balance - come join our growing team

Job Description:
 We are looking for a Data Architect with 13 to 18 years of experience to be part of the product engineering team.



Responsibilities
Designing large scale end-to-end Data Platforms by using best suited architecture patterns & practices
Assessments of exisiting data components, Performing POCs, Consulting to the clients
Define tools & technologies to develop automated data pipelines, write ETL processes, develop dashboard & report and ceate insights
Continually reassess current state for alignment with the architecture goals, best practices and the business needs - DB modeling, deciding best data storage, creating data flow diagrams, maintaining related documentation
Taking care of performance, reliability, reusability, resiliance, scalability, security, privacy & data govenrance while designing a data architecture
Apply or recommend best practices in architecture, coding, API integration, CI/CD pipelines
Coordinate with data scientists, analysts, engineers and other internal / client stakeholders for data-related needs - Contributing to Soltuions efforts for Data related prospects to win new oppornutities
Help the Data Science & Analytics Practice grow by mentoring, coaching junior Practice members, leading initiatives
Provide thought leadership to the Practice and the Organization, believes in leading by influance through Community of Practice

Requirements
Must have:
Strong interpersonal and consulting skills
Strong exposure to Client facing assignments
A thought leader, should believe in leading by influance
Exposure to different Data Architecture patterns & principles, ability to design secure & scalable data lakes, data warehouses, data hubs, and other event-driven architectures
Exposure to Strong Database & modelling concepts with exposure to SQL & NoSQL Database
Expertise in designing and writing ETL processes in Python / Java / Scala
Exposure to PySpark, Spark, Storm, Talend
Exposure to Redshift, DataBricks and Snowflake
Knowledge of Master Data management and related tools
Strong exposure to data security and privacy regulations (GDPR, HIPAA) and best practices
Skills in ensuring data accuracy, consistency, and quality
Proficiency in data visualization tools like Tableau, Power BI or similar to create meaningful insights from data""
AWS S3, Redshift, Lambda, DynamoDB, EMR, Glue, Lakeformation, Athena, Quicksight, RDS, Kinesis, Managed Kafka ElasticSearch and ElasticCache, API Gateway, CloudWatch - Understanding of Hadoop framework
Ability to implement data validation processes and establish data quality standards.

Nice to have
AWS IOT,
Apache NiFi, Talend, Informatica
Azure cloud & its data services, Data Factory, Data Catalog
Knowledge of GCP Data services - Exposure to AI / ML
Experience with Talend
Benefits
A competitive annual salary based on experience and market demands 
Flexi-timings 
Work From Anywhere
Medical insurance with the option to purchase a premium plan or HSA option for your entire family 
Regular Health check-up camps arranged by the company 
Recreational activities (Pool, TT, Wii, PS2) 
Business casual atmosphere
#LI-Remote
#LI-DV",USD 117K - 193K *
693,Senior Data Analyst,Vonage,"Bengaluru, India",Senior-level / Expert,"Fixed Working hours: 2pm - 10:30pm IST 
Vonage BI & Data Team Mission
We are a highly creative, energetic and results-oriented team that owns data and analytics delivery for the entire organization. This starts from data ingestion to corporate dashboards and includes data analytics to drive actions. The successful candidate is passionate about understanding customer needs, motivations, and behavior and enjoys discovering insights that help us deliver better outcomes like revenue growth, better customer experience, customer engagement and customer retention. 
Why this role matters
As a Senior Data Analyst, you will be helping us on a journey towards a modern, self-serve analytics organization. You will get autonomy and ownership around large parts of how we interface with users, how they’re trained and around defining the boundary between “let me show you how to do this yourself” and “let me do this for you”.
Over the last couple of years, we’ve made significant investments into our data infrastructure and our data processing platform. This has improved the internal team processes, however, there is still room for improvement on enabling self-serve and using advanced analytics techniques to predict what will happen rather than what happened.
What you will do
Work closely with constituents across the business (Sales, Marketing, Product, Customer Experience, Research and Finance)
Develop insights and strategy to drive revenue growth from customer base
Assist in annual budget planning and alignment 
Use data mining techniques and analyze core KPI's and generate insight to reach and improve on the target goals
Support scalable client engagement strategies that drive profitable growth, engagement and retention
Be our bridge and ambassador to the rest of the organization, championing for self-service data analytics and maintaining relationships with power users
Be responsible for coordinating our user facing “Data Academy” education initiative to make sure our users can make the most of the data and reporting that we have
Work closely with the rest of the BI & Data team to help make sure the data engineering work being done is well aligned to stakeholder needs
We’re specifically not looking for someone to churn out reports for other people all day long. 
Given the size of the team vs the hundreds of users we support, a large part of your work would be focused on finding ways to scale analytics via empowering our users so they are able to do what they are trying to do independently (while having support and training, if they need it).
Self-service analytics environment
We’re using a modern analytics stack with Tableau as the visualization front-end and Snowflake as the DWH, where the majority of report development is done by our users, we also use Python, SQL and Airflow
Rather than a report mill, the BI & Data team is there to empower and help users get their data and analytics work done themselves
What you will bring
  We’re looking for an experienced analytics professional with practical experience implementing and scaling self-service analytics in a mid-sized organization. 
What is required
Required: Bachelor’s Degree (preferably in Business, Economics, Statistics or Computer Science) and 5+ years of experience in data analytics role (preferably in a SaaS business)
Required: MBA or Master’s Degree (preferably in Marketing Analytics, Data Science, Operations Research, Industrial Engineering or Computer Science) 
Experience working independently with a wide range of stakeholders, from other analysts to senior management
Advanced knowledge of fundamental analytical, statistical techniques, attribution results, forecasting, simulation and data optimization
Strong technical capabilities with SQL, data warehouses, ETL processes, and data integration tools (Python, R coding/familiarity a plus)
Knowledge of Sales, Marketing, Customer Support and Financial (Billing and Accounting) systems
Skilled in Tableau or other BI Tools
Bonus points if you:
Have experience driving self-service analytics adoption in a scalable way
Worked in an agile environment and were able to bring structure where there was none before
What’s in it for you
In addition to providing exciting work, career advancement opportunities, and a collaborative work environment, Vonage provides competitive pay and benefits including unlimited discretionary time off. ",USD 92K - 145K *
694,MicroStrategy Development Analytics Engineer (all genders),HRS,"Chandigarh, Mid-Senior level, IN",Senior-level / Expert,"HRS AS A COMPANY
HRS, a pioneer in business travel, aims to elevate every stay through innovative technology. With over 50 years of experience, their digital platform, driven by ProcureTech, TravelTech, and FinTech, transforms how companies and travelers Stay, Work, and Pay.

ProcureTech digitally revolutionizes lodging procurement, connecting corporations and suppliers in a cutting-edge ecosystem. This enables seamless efficiency and automation, surpassing travelers' expectations.

TravelTech redefines the online lodging experience, offering personalized content from selection to check-in, ensuring an unparalleled journey for corporate travelers.

In FinTech, HRS introduces advancements like mobile banking and digital payments, turning corporate back offices into touchless lodging enablers, eliminating legacy cost barriers. The innovative 2-click book-to-pay feature streamlines interactions for travelers and hoteliers.

Combining these technology propositions, HRS unlocks exponential catalyst effects. Their data-driven focus delivers value-added services and high-return network effects, creating substantial customer value.

HRS's exponential growth since 1972 serves over 35% of the global Fortune 500 and leading hotel chains.

Join HRS to shape the future of business travel, empowered by a culture of growth and setting new industry standards worldwide.
BUSINESS UNIT
The HRS Data & Analytics Platform is one of the key enablers of HRS GROUP’s tech- and data driven business travel solutions. State of the art services and solutions like strategic consulting & hotel procurement, travel payment and expense solutions or efficient tools to manage corporate meetings and group booking facilitate the travel processes and guarantee savings along the value chain. Around 50 Data Specialists (Analysts, Scientists and Engineers) work together in our Data Community to create analytics solutions that serve our corporate customers, hotel partners, internal stakeholders, and ultimately millions of business travelers worldwide. HRS Data & Analytics leverage a rich data landscape (spend data, booking data, rate data, web analytics data, etc.) turning raw data into actionable insights to provide (semi-) automated decision support to customers and business stakeholders with advanced analytical solutions. We bring state-of-the-art algorithms in production, to enhance Search & Booking experience (with personalized recommendations), or optimize the corporate hotel portfolio to the objectives of customers and the needs of the travelers. Your mission is to help reinventing how business work, stay, and pay, powered by Data & Analytics solutions and make it the next innovation of the HRS Group together with a great international team of passionate and result-driven entrepreneurial minds.
POSITION
We are looking for an experienced MicroStrategy Developer (Analytics Engineer) (all genders) who can work from our Chandigarh office and can reports to HQ. The candidate will be responsible for coordinating with stakeholders, business teams, and data teams and provide reporting to different areas within the business functions. The candidate will be responsible for maintaining the current reporting system based on MicroStrategy and developing the reporting and analytics capabilities for present and upcoming projects. #LI-RK1
CHALLENGE
Collaborate closely with business stakeholders, peers, and other data teams to gain business insights and develop analytical solutions for enabling data-driven business operations.
At the interface between BI, Data Engineers, Analysts and their respective teams you translate business requirements into reporting and dossier/dashboard solutions.
Proactively identify areas for improvement in the enterprise reporting landscape (e.g. areas of repeated maintenance, data quality issues or recurring ad-hoc requests) and propose ideas to address them.
Ensure that data is modeled to the highest standards, is well documented and accessible to different end users through the appropriate platforms. Expert-level consulting on Exasol/Oracle (Datawarehouse) and MicroStrategy (BI Reporting Platform) to the business and tech teams.
FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
Several Years of Experience working with data exploration, modeling the schemas in Datawarehouse, and reporting in MicroStrategy. Understanding what it takes to design, build and maintain end-to-end stable reporting solutions.
Strong hands-on expertise on MicroStrategy (4-5 years) preferably 10.x onward.
Experience in understanding existing models, creating database views and designing MicroStrategy object layers like Schema Objects, Public Objects, Dossiers, Dashboards and Reporting.
Advanced SQL skills (4-5 years)- you can solve the problem with the most efficient SQL considering the data volumes of an underlying data warehouse is a prerequisite.
Good Knowledge on modeling techniques like Dimensional Modelling/Data Vault.
Fluency in English, spoken and written (German a plus)
PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.

Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 128K - 190K *
695,Data Engineer/Senior Data Engineer,London Stock Exchange Group,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
The Data and Analytics Organization (DnA) is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights.

Your Impact:
Be responsible for the technical solution design, lead the technical architecture and implementation of data acquisition and integration projects, both batch and real time
Define the overall solution architecture needed to implement a layered data stack that ensures a high level of data quality and timely insights
Communicate with product owners and analysts to clarify requirements
Craft technical solutions and assemble design artifacts (functional design documents, data flow diagrams, data models, etc.)
Build data pipelines data processing tools and technologies in open source and proprietary products
Serve the team as a domain expert & mentor for ETL design, and other related big data and programming technologies
Identify incomplete data, improve quality of data, and integrate data from several data sources
Proactively identify performance & data quality problems and drive the team to remediate them. Advocate architectural and code improvements to the team to improve execution speed and reliability
Design and develop tailored data structures
Reinvent prototypes to create production-ready data flows
Support Data Science research by designing, developing, and maintaining all parts of the Big Data pipeline for reporting, statistical and machine learning, and computational requirements
Perform data profiling, sophisticated sampling, statistical testing, and testing of reliability on data
Clearly articulate pros and cons of various technologies and platforms in open source and proprietary products Implement proof of concept on new technology and tools to help the organization pick the best tools and solutions
Strong SQL optimization and performance tuning experience in a high volume data environment that uses parallel processing
Teams are using the following: SQL, Python, Airflow, AWS, Spark, Tableau, AWS EMR, Snowflake
Participate in the team’s on-call rotation to address sophisticated problems in real-time and keep services operational and highly available
Required Skills:
4 - 12 years experience in data engineering
Build programmatic ETL pipelines with SQL based technologies and platforms
Solid understanding of databases, and working with sophisticated datasets
Data governance, verification and data documentation using current tools and future adopted tools and platform
Work with different technologies (Python, shell scripts) and translate logic into well-performing SQL
Perform tasks such as writing scripts, web scraping, getting data from APIs etc.
Automate data pipelines using scheduling tools like Airflow
Experience with CI/CD technologies and tools like Jenkins, Ant or Gradle, Github
Be prepared for changes in business direction and understand when to adjust designs
Experience writing production level SQL code and good understanding of Data Engineering pipelines
Experience with Hadoop ecosystem and similar frameworks
Previous projects should display technical leadership with an emphasis on data lake, data warehouse solutions, business intelligence, big data analytics, enterprise-scale custom data products
Knowledge of data modeling techniques and high-volume ETL/ELT design
Experience with version control systems (Github, Subversion) and deployment tools (e.g. continuous integration) required
Experience working with Public Cloud platforms like GPC, AWS, or Snowflake
Ability to work effectively in an unstructured and fast-paced environment both independently and in a team setting, with a high degree of self-management with clear communication and commitment to delivery timelines
A related technical degree required
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 121K - 190K *
696,Data Engineer,KONE,Chennai ITEC/KBS,Senior-level / Expert,"To succeed in this role, following professional experience will play a key role:
Master's degree in either software engineering, data engineering, data science, computer science, physics, statistics, mathematics, or a related field
Data engineering professional experience
Previous hands-on professional experience in developing and maintaining data pipelines on AWS and Databricks: Lake house architecture based on Databricks and Delta Lake, multi-hop medallion architecture to divide the data lake into bronze, silver and gold layers based on the quality and reusability of the data stored there, data product publishing in Unity catalog.
Ability to write compelling code, technical documentation and visualize your technical design.
Coding proficiency with multiple languages Python, Scala and DBT.
Fluent in industry-standard DevOps practices.
Practical experience in working with enterprise data landscapes and data structures: Structural data, non-structural data, metadata, master data, transactional data, batch/NRT.
Tech stack:  AWS, Gitlab, Databricks for ETL, Airflow, Python, Scala, and DBT for developing ETL, jobs, AWS CDK and Terraform for IaC.
Experience on enterprise data sources: Experience in woring with e.g. SAP ERP, Salesforce and product data management (PDM), manaufacturing execution system (MES) system data.
Way of working professional experience
Passion to utilize agile development methodologies and tools (Jira, Confluence, draw.io).
Inbuilt cybersecurity awareness. Understanding on data privacy and compliancy regulations.
Ability to work in global multi-cultural team and effectively collaborate within the team.
Ability to self-organize and be proactive, seek feedback, be courageous and resilient, and have excellent problem-solving skills.
Proficiency in spoken and written English language, and strong facilitation and communication skills.
At KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.
Read more on www.kone.com/careers",USD 121K - 190K *
697,Graduate Data Science & AI Engineer,Packt,India - Remote,Mid-level / Intermediate,"TeamEpic is committed to shaping the future of technology by nurturing and developing the next generation of Data Science and AI talent right here in India. Our vision is to create a powerful and globally competitive workforce. We specialize in hiring, training, and deploying fresh graduates into global projects and teams, focusing on innovative Data Science and Generative AI technologies. 
 Role overview 
We are seeking highly motivated graduate engineer trainees who are passionate about Data Science and AI. You will undergo a rigorous 4–6-month salary-led training program, gaining hands-on experience in the latest technologies and methodologies. Post-training, you will have the opportunity to work in multiple and diverse international teams, contributing to significant global projects. We offer a one-of-a-kind opportunity to not only build your portfolio, but also cultivate your soft skills while gaining invaluable real-world experience through our training academy. Our goal is to equip you with the skills necessary to meet the demands of global remote companies in the fields of Data Science and AI. For detailed information, visit https://www.teamepic.in/graduates 
Responsibilities 
Participate in an intensive training program covering Data Science, AI, MLOps (Machine Learning Operations), NLP (Natural Language Processing), and related technologies 
Collaborate on real-world projects and case studies to apply theoretical knowledge. 
Engage in continuous learning to stay abreast of industry trends and advancements 
Post-training, integrate into global teams to solve complex data problems and develop AI-driven solutions 
The Training Phase
This phase is designed to sharpen your skills, enhance your expertise, and empower you with the knowledge you need to excel in global work-ready environments. Immerse yourself in real-world projects to learn:
1) Foundational Skills:
Attain certifications in Data Science and Advanced Python proficiency 
Develop strong data literacy and effective prompt generation 
2) Project Management Mastery: 
Understand AI project stages, ethics, and communication strategies 
Learn documentation and reporting best practices 
Develop mindfulness for effective project execution 
3) Data Transformation Proficiency:
Gain fundamentals of data transformation 
Master structured data analysis and reporting 
Acquire goal alignment strategies for project success
4) AI Application Development: 
Explore AI-driven Image Recognition with OCR (Optical Character Recognition) 
Implement OCR algorithms, validate accuracy, and optimize core engines 
Develop automated data collection, preprocessing, and segregation skills 
5) Advanced AI Techniques:
Build a data science platform with real-time data synchronization. 
Develop AI applications for speech-text-actions and auto communication. 
Dive into advanced Gen-AI (Generative AI) prompt engineering, covering linguistic nuances and async IO 
Address NLG requirements, develop validation frameworks, and iteratively optimize NLG systems  
6) Python, AWS, Git, and GitHub challenges 
7) Master Generative AI for language, voice image models, develop GenAI (Generative AI) apps, and handle post-deployment challenges 
8) PowerBI, Tableau 
9) Interviewing techniques, business acumen, mindfulness practices, stakeholder management 
The Deployment Phase:
You will embark on an exciting journey of professional growth during the deployment phase. This phase is a critical part of your career progression, where you will: 
1) Work with multiple clients: Engage in trial projects with various clients, gaining exposure to diverse business needs and technological challenges in the field of Data Science and AI. 
2) Trial to full-term transition: Demonstrate your skills and expertise by successfully completing trial client projects, leading to full-term project engagements with our clients. This is when you will be promoted to an Associate Data Science & AI Engineer 
3) Twelve-Month client engagement: Upon completing 12 months of client deployment, you will reach a pivotal point in your career. At this juncture, based on client discretion and your performance, you will have two promising paths ahead:
Option to directly join a global client team: You may choose to move directly onto client payrolls, integrating into their teams and continuing to build your career in new environments. 
Continued growth with TeamEpic: Alternatively, you can opt to be absorbed within TeamEpic as a Data Science & AI Engineer where you will continue to advance your career, taking on more complex challenges and leadership roles within our dynamic team. 
4) This deployment phase is designed not only to enhance your professional skills but also to open multiple avenues for your career advancement in the global landscape of Data Science and AI 
Requirements
Bachelor's or Master’s Degree in Data Science/AI 
Internship experience in Data Science/AI is mandatory 
Solid foundation in programming languages such as Python, SQL, R, Java 
Data Analysis libraries like Pandas, NumPy and Matplotlib   
Hands-on experience of Machine Learning (ML) platforms like TensorFlow and PyTorch, AI concepts, and data analytics & solving ML techniques - Classification Models, Time-Series Data, Regression Models, Classification Problems, Recommender Systems 
Data visualization tools like Matplotlib, PowerBI, Tableau 
Innovative technical proficiency in Data Science/AI, encompassing advanced knowledge of state-of-the-art frameworks and solid fundamentals 
Excellent problem-solving and analytical skills 
Flexibility, adaptability, and strong teamwork/collaborative abilities 
Dedication to continuous personal and professional development 
Self-motivated individuals with pride in their work 
Effective communication and stakeholder management skills, with the ability to challenge status quo and give/receive constructive feedback 
Benefits
Comprehensive training in Data Science and AI by industry experts 
Exposure to global work culture and international projects 
Career advancement opportunities in innovative technology domains 
Competitive salary and benefits package",USD 50K - 225K *
698,Business Processes Consultant- Data Management (BTP),SAP,"Bengaluru, IN, 560103",Senior-level / Expert,"We help the world run better
Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.Apply now! 
  What you'll do 
  As Data Management Consultant @ Success Delivery Center, your role will be to support customer in their digital transformation journey by implementing across Data Management solutions covering Data Migrations and Master Data Governance. As a tech-no functional consultant, you will be part of project teams delivering SAP Implementations for customers.
You need to be hands on and well versed with solutions and good communication skills to participate in business discussions. Functional understanding of Data Management and prior development experience will be added advantage. While there may be travel based on customer needs, the focus will be delivering remote and offshore.
  What you bring 
  6-10 Years of stable professional experience in SAP with data management/MDG and good development experience in ABAP.
Experience in MDG, system landscape optimization scenarios using SAP DMLT tools will be an added advantage
Experience in Data Migration / Data Integration Solutions - SAP Data Services, Migration Cockpit, SDI, SLT, Data Intelligence
Good functional knowledge on SAP modules like MM, SD, PP
Good Written and Verbal Communication & Ability to Interact with diverse group of people.
Proven track record of performance with stable stint in the previous company.
  Meet your team
  Data Management Solution Area within BTP Delivery @ Scale is strong 100 plus team delivering engagements across wide range of Data Management Topics - Data Migration, Data Integration, Data Engineering, Data Governance and Data Quality.
  #CSPostings2023
  We build breakthroughs together
SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together.
We win with inclusion
SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.
SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com
For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.
EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.
Successful candidates might be required to undergo a background verification with an external vendor.
Requisition ID: 380306  | Work Area: Consulting and Professional Services  | Expected Travel: 0 - 10%  | Career Status: Professional  | Employment Type: Regular Full Time   | Additional Locations: #LI-Hybrid.
 ",USD 45K - 84K *
699,Data Scientist,ExxonMobil,"Bengaluru, KA, IN",Mid-level / Intermediate,"  About us
  At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.
  The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies. 
  We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.
What role you will play in our team
  We are looking to hire candidates to work on challenging engineering, geological and commercial problems that focus on exploration, development, production, marketing and transportation of hydrocarbons. A successful candidate would understand a problem in oil and gas space (both commercially/economically and technically), be able to formulate the problem in a solvable way, using application of engineering, numerical, data science and programming skills to tackle a range of problems in the oil and gas industry
What you will do
  Work with data scientists, computational scientists, engineers, software developers, and geoscientists across the globe to develop, deliver and apply computational tools, models, or software to support our business.
Use machine learning, pattern recognition, deep learning, statistical analysis and data visualizations – along with domain knowledge and subject-specific models (eg. physics-based) – to solve science, engineering, commercial problems and provide business insights.
Design, build, and execute studies using proprietary or commercial tools to provide insights including calibrating models to field data and providing field optimization recommendations.
  About You
  Skills and Qualifications
  Bachelor's degree from a recognized university in one of the following disciplines: Chemical Engineering, Mechanical Engineering or related disciplines with minimum GPA 7.0 (out of 10.0) and above
Minimum 3 years of work experience in developing, applying, and validating data-driven tools to model complex systems.
In-depth knowledge and practical experience in applying statistical analysis techniques, such as classification, regression, time-series, Bayesian techniques, etc. and machine learning techniques, such as decision-trees, ensemble methods, deep learning, neural networks, validation methods etc.
Practical experience in the full machine learning life cycle from problem formulation, data acquisition, modeling building, and deployment at enterprise scale.
Specialization in at least one of the sub-domains e.g. Natural Language Processing (NLP), Computer Vision, Time series forecasting, PINN’s, causality analysis.
Experience in Python & R and related packages such as numpy, pandas, sklearn, Keras, Tensorflow, PyTorch
Experience with software engineering practices, agile methodologies, DevOps, version control 
Experience working in Azure Databricks or any other data science frameworks
Software testing and development practices (Agile)
  Preferred Qualifications / Experience
  Experience in developing, applying, and analyzing physics-based or data driven computational models and simulations is an advantage
Prior knowledge of commercial software development and/or experience in commercial software teams
Experience of identifying and scoping data science opportunities based on business needs is an advantage
Strong communication and interpersonal skills
  Your benefits
  An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you: 
  Competitive compensation 
Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits 
Retirement benefits 
Global networking & cross-functional opportunities
Annual vacations & holidays
Day care assistance program
Training and development program
Tuition assistance program
Workplace flexibility policy
Relocation program
Transportation facility
  Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company’s eligibility guidelines.
Stay connected with us
  Learn more about ExxonMobil in India, visit ExxonMobil India  and Energy Factor India.
Follow us on LinkedIn and ExxonMobil (@exxonmobil) • Instagram photos and videos
Like us on Facebook
Subscribe our channel at YouTube
  EEO Statement
  ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.
  Business solicitation and recruiting scams
  ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.
 
  Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship. 
  Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",USD 86K - 156K *
700,Senior Account Manager-Business Intelligence,dentsu international,"Chennai, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
Dashboard Ownership:
Oversee the design, development, and enhancement of dashboards, ensuring they are effective, user-friendly, and aesthetically pleasing.
BI Strategy: Implement a BI vision that aligns with Scrum and Agile methodologies and Cybba’s strategic goals.
User Experience (UX) Improvement: Continually improve the UX for both internal and external users.
Independent Initiative: Demonstrate high levels of autonomy and accountability in enhancing BI capabilities.
Feedback Integration: Actively incorporate feedback to improve dashboard designs and analytics.
Data Integrity and Analysis: Manage data accuracy and consistency, employing strong SQL and Python skills for data analysis and management.
Feature Development: Utilize advanced BI functionalities using AWS technologies and other tools.
Performance Monitoring: Regularly evaluate and improve dashboard performance.
Scalable Systems Development: Construct and maintain scalable systems for efficient data handling.
Tool Implementation: Introduce new tools for effective management of client feedback. Product Vision Contribution: Actively contribute to the product vision and development. Training & Support: Offer expert training and support to enhance user skills in BI tools.
Qualifications

Qualifications:
Scrum and Agile certifications. Strong proficiency in SQL and Python for data analysis. Relevant AWS data analysis certifications.
Experience with AWS technologies (Quicksight, Athena, Glue), funnel.io, and ETL pipelines. Extensive experience in Jira Service Management and Jira Software.
Bachelor’s degree in Computer Science, Information Technology, or related field.
Proven ability to work independently with high accountability.
Demonstrated commitment to improving BI tools and processes for internal and external benefit.
Additional Information
Education & Training: Any Degree with Excellent communication skills",USD 45K - 84K *
701,Data Analytics Advisor,ExxonMobil,"Bengaluru, KA, IN",Mid-level / Intermediate,"  About us
  At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.
  The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies. 
  We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.
ExxonMobil’s affiliates in India
ExxonMobil’s affiliates have offices in India in Bengaluru, Mumbai and the National Capital Region. 
  ExxonMobil’s affiliates in India supporting the Product Solutions business engage in the marketing, sales and distribution of performance as well as specialty products across chemicals and lubricants businesses. The India planning teams are also embedded with global business units for business planning and analytics.
  ExxonMobil’s LNG affiliate in India supporting the upstream business provides consultant services for other ExxonMobil upstream affiliates and conducts LNG market-development activities.

The Global Business Center - Technology Center provides a range of technical and business support services for ExxonMobil’s operations around the globe.

ExxonMobil strives to make a positive contribution to the communities where we operate and its affiliates support a range of education, health and community-building programs in India. Read more about our Corporate Responsibility Framework.

To know more about ExxonMobil in India, visit ExxonMobil India and the Energy Factor India.
What role you will play in our team:
  Support the business on knowledge management and training on analytics toolsets
Facilitate awareness, development and implementation of Analytics
Align with business on improvement opportunities where analytics can bring value to the business
Provide guidance to users on available analytics products to work effective use of internal and external data sets and avoid non-sustainable local solutions
Monitor, support and enhance capability and effectiveness of Power User Network and create excitement and shape demand in the user community for the analytics practice
What you will do:
  Drive improvement opportunities via analytics and drive usage and value capture
Accountable for effective usability and availability of existing solutions
Interface with IT team as a product owner in an agile environment
About you:
  Skills and Qualifications
  Bachelor’s degree from a recognized university with minimum 2 years of experience in the relevant field scoring 7 and above CGPA.
Have a strong foundation in enterprise data modeling
Be able to read and write SQL queries, with a strong understanding of writing performant queries for large datasets
Have a strong background in data visualization with a specific focus in Tableau and Microsoft BI
Be able to identify the best solutions to use for various business requests and understand the implications of business requests on other users
  Preferred Qualifications / Experience:
  Basic understanding of SQL Language
Tableau
Power BI / Power Query
SAP Business Analysis for Office
Basic Knowledge of SAP Data Structure and SAP Business Warehouse
  Your benefits:
  An ExxonMobil career is one designed to last. Our commitment to you runs deep: our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you: 
Competitive compensation 
Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits 
Retirement benefits 
Global networking & cross-functional opportunities
Annual vacations & holidays
Day care assistance program
Training and development program
Tuition assistance program
Workplace flexibility policy
Relocation program
Transportation facility

Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company’s eligibility guidelines. 
EEO Statement
  ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.
Stay connected with us
  Learn more about ExxonMobil in India, visit ExxonMobil India and Energy Factor India.
Follow us on LinkedIn and Instagram
Like us on Facebook
Subscribe our channel at YouTube
Business solicitation and recruiting scams
  ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.
  Alternate Location:  
  Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship. 
  Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",USD 30K - 56K *
702,Sr. Analyst - Global Data Management,Colgate-Palmolive,"Mumbai, MH, IN",Senior-level / Expert,"No Relocation Assistance Offered
# 156838 - Mumbai, Maharashtra, India

Who We Are
Colgate-Palmolive Company is a caring, innovative growth company that is reimagining a healthier future for all people, their pets and our planet. Focused on Oral Care, Personal Care, Home Care and Pet Nutrition, we sell our products in more than 200 countries and territories under brands such as Colgate, Palmolive, elmex, hello, meridol, Sorriso, Tom’s of Maine, EltaMD, Filorga, Irish Spring, PCA SKIN, Protex, Sanex, Softsoap, Speed Stick, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Pet Nutrition.

We are recognized for our leadership and innovation in promoting sustainability and community wellbeing, including our achievements in decreasing plastic waste and promoting recyclability, saving water, conserving natural resources and improving children’s oral health.

If you want to work for a company that lives by their values, then give your career a reason to smile and join our global team!
    Roles and Responsibilities:
  The Global Data Management (GDM) Analyst- Finance position supports business functions by providing master data expertise and managing the Finance master data governance and maintenance processes. Providing support and liaise with the business and the Global GDM Team with related projects and issue resolution of queries. Identify and implement improvements resulting in increased operational and business efficiency. 
  Key Responsibilities:
  Validate and ensure that all master data is accurate, complete and fully approved during the life cycle, in accordance to external and internal standards. Release/Reject requests and provide feedback on decision
Monitor data processes to ensure compliance with process cycle times and related performance measures and KPIs,
Monitors performance indicators/metrics for data within their span of responsibility and regularly reports status to supervisor 
Analyze data in the systems to support business functions when requested
Providing consultancy and support in issues resolution
Prepares and generates data quality reports and analysis
Plans and executes data cleansing initiatives
Participates and/or manages related projects
Ensures internal control and SOX rules are followed along GDM governance process
Provides training to end-users when needed or requested
Develops and maintains Data Management related documentation (procedures, policies, end-user manuals, training materials, etc),
Identifies improvement to Data Management governance process, tools or systems and works on their implementation when approved,
Participates in audits, cooperates with internal and external auditors providing them required information,
Analyzes data in the systems as a part of gap-fit analysis and/or Data Management standardization projects, identifies use of the certain data elements, attributes, fields, proposes standardized values and works on their implementation.

Key Relationships:
    End-users of GDM solutions from subsidiaries within the functional scope of responsibility
Business functions representatives from all levels of organization being involved directly in GDM governance processes or being impacted by GDM
Global GDM Domain Leaders and other regional GDM team members
Other CBS Centers
Project Teams
Global IT Organization
Other stakeholders required to solve master data issue or master data related conflict
  Required Education, Experience and Professional Qualifications:
  Bachelor degree minimum
Post graduation in Finance
Experience in General Accounting,Finance master data management desirable
Experience implementing new systems/applications, desirable
  Required Technical Skills and Abilities:
  SAP and MDM knowledge
Data Analysis skills
Communication Skills
Project Management Skills
Strategy / Vision

Our Commitment to Sustainability
With the Colgate brand in more homes than any other, we are presented with great opportunities and new challenges as we work to integrate sustainability into all aspects of our business and create positive social impact. We are determined to position ourselves for further growth as we act on our 2025 Sustainability & Social Impact Strategy.

Our Commitment to Diversity, Equity & Inclusion
Achieving our purpose starts with our people — ensuring our workforce represents the people and communities we serve —and creating an environment where our people feel they belong; where we can be our authentic selves, feel treated with respect and have the support of leadership to impact the business in a meaningful way.

Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.

 #LI-Hybrid",USD 45K - 84K *
703,Data Scientist (all genders),HRS,"Chandigarh, Associate, IN, 160001",Senior-level / Expert,"HRS AS A COMPANY
HRS, a pioneer in business travel, aims to elevate every stay through innovative technology. With over 50 years of experience, their digital platform, driven by ProcureTech, TravelTech, and FinTech, transforms how companies and travelers Stay, Work, and Pay.

ProcureTech digitally revolutionizes lodging procurement, connecting corporations and suppliers in a cutting-edge ecosystem. This enables seamless efficiency and automation, surpassing travelers' expectations.

TravelTech redefines the online lodging experience, offering personalized content from selection to check-in, ensuring an unparalleled journey for corporate travelers.

In FinTech, HRS introduces advancements like mobile banking and digital payments, turning corporate back offices into touchless lodging enablers, eliminating legacy cost barriers. The innovative 2-click book-to-pay feature streamlines interactions for travelers and hoteliers.

Combining these technology propositions, HRS unlocks exponential catalyst effects. Their data-driven focus delivers value-added services and high-return network effects, creating substantial customer value.

HRS's exponential growth since 1972 serves over 35% of the global Fortune 500 and leading hotel chains.

Join HRS to shape the future of business travel, empowered by a culture of growth and setting new industry standards worldwide.
BUSINESS UNIT
Data & Analytics Platform
The HRS Data & Analytics Platform is one of the key enablers of HRS GROUP's tech- and data driven business travel solutions. State of the art services and solutions like strategic consulting & hotel procurement, travel payment and expense solutions or efficient tools to manage corporate meetings and group booking facilitate the travel processes and guarantee savings along the value chain.
Around 50 Data Specialists (Analysts, Scientists and Engineers) work together in our Data Community to create analytics solutions that serve our corporate customers, hotel partners, internal stakeholders, and ultimately millions of business travelers worldwide.
HRS Data & Analytics leverage a rich data landscape (spend data, booking data, rate data, web analytics data, etc.) turning raw data into actionable insights to provide (semi-) automated decision support to customers and business stakeholders with advanced analytical solutions. We bring state-of-the-art algorithms in production, to enhance Search & Booking experience (with personalized recommendations), or optimize the corporate hotel portfolio to the objectives of customers and the needs of the travelers.
Your mission is to help reinventing how business work, stay, and pay, powered by Data & Analytics solutions and make it the next innovation of the HRS Group together with a great international team of passionate and result-driven entrepreneurial minds.
POSITION
We are looking for an experienced Data Scientist (all genders) supporting our teams from our Chandigarh/ Mohali office and reporting to HRS HQ. The candidate will be responsible for coordinating with stakeholders, business teams, and data teams, converting business requirements into methodological designs, and implement data science models supporting different areas of the business. The candidate loves solving real-life business problems with analytics, data science and machine learning methodologies, starting from sound business understanding, developing prototypes, and finally deploying ready-to-use products for customers. The candidate embraces working with AWS resources and -capabilities, can model multidimensional datasets, and can implement and maintain necessary data pipelines sponsoring the models. This is a role with high visibility to senior leadership and with high opportunity for impact for those willing to roll up their sleeves and dive deep to achieve results.
CHALLENGE
Collaborate closely with business stakeholders, peers, and other data teams on gaining business insights, translating business requirements, and designing/ implementing data science solutions for data-driven business operations enablement and decision support.
Produce answers, insights, and decision support tooling that are easily communicated to the business for continuous business betterment by applying data science and machine learning methodologies, complemented by data pipelining with SQL/ Python/ DBT, as well as analytics using dashboarding solutions.
Promote a culture of data-driven decision making within the organization and proactively assist further development of our data&analytics platform
Collaborate with data experts across HRS Group to establish best-practices, exchange on latest trends, and stay abreast of your area of responsibility
Work together with the management team to continuously refine and develop HRS Group’s data & analytics capabilities and -strategies
FOR THIS EXCITING MISSION YOU ARE EQUIPPED WITH...
Proven hands-on experience in data science or -engineering and understanding what it takes to design, build and maintain successful data platforms, -services and -products
Superior expertise in Software Engineering in Python or R, and SQL
Knowledge of cloud technologies such as AWS, GCP, Azure, esp. Docker, and Apache Airflow
Sound experience in machine learning techniques and the ability to identify the appropriate technique in different scenarios
Sound project management capabilities, commercial awareness, and ability to develop and execute experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Excellent communication skills to collaborate with business stakeholders, technical engineers and management.
Fluency in English is a must
PERSPECTIVE
Access to a global network of a globally united and mutually responsible “Tribe of Intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.
Our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. You will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.
LOCATION, MOBILITY, INCENTIVE
The attractive remuneration is in line with the market and, in addition to a fixed monthly salary, all necessary work equipment and mobility, will also include an annual or multi-year bonus.",USD 136K - 205K *
704,Software Engineer-SE - AWS Big Data,NECSWS,"Mumbai, India",Senior-level / Expert,"Company Description
NEC Software Solutions (India) 
On 1st July 2021, Rave Technologies became NEC Software Solutions India. This change brought us under the global NEC Corporation brand. We are proud to be part of an organisation with 122 years of experience in evolution with technology and innovation.
We have more than 30 years of experience in providing end to end IT services across the globe and have earned a reputation for delighting our customers by consistently surpassing expectations and helping them deliver robust, market-ready software products that meet the highest standards of engineering and user experience. Supported by more than 1300 exceptionally talented manpower, we are a hub for offshore support and technology services.
We work with diverse industry verticals which include publishing, media, financial services, retail, healthcare and technology companies around the world. Our customers range from two-person startups to $bn listed companies.
For more information, visit at www.necsws.com/india.
About NEC Corporation 
NEC Corporation is a Japanese multinational information technology and electronics company, headquartered in Tokyo, Japan. It is recognised as a ‘Top 50 Innovative Company’ globally and the NEC Group globally provides “Solutions for Society” that promote the safety, security, fairness and equality of society. Their main goal is to help create a safer society with their innovations in technologies.
NEC Corporation has established itself as a leader in the integration of IT and network technologies while promoting the brand statement of “Orchestrating a brighter world.” NEC enables businesses and communities to adapt to rapid changes taking place in both society and the market as it provides for the social values of safety, security, fairness and efficiency to promote a more sustainable world where everyone has the chance to reach their full potential. 
For more information, visit NEC at https://www.nec.com.
Job Description
Role: Data Engineer
Experience: 10+yrs
Location: mumbai
 • Productive experience in the context of Big Data, ETL, Data Ingestion, Data Modeling & Pipelines, Data Architectures
• Work as a Product Owner for Data Engineering related modules / requirements
implementing the integration, preparation, enrichment, storage and sharing of data
Close participation in Product Owner meetings to together design the product roadmap
setup, monitoring and optimization of the data pipeline including the necessary hardware and software infrastructure
implement security and data protection aspects
• Knowledge and experience in:
batch processing frameworks & tools (e.g. Apache Spark, HDInsight, Hadoop, AWS)
real-time streaming (e.g. Apache Spark Structured Streaming, Kafka, AWS Kinesis, AWS Lambdas)
• Knowledge of NoSQL, relational database systems, data warehouses, data lakes, interface protocols (REST, MQTT, ODBC/JDBC, ...), Python, Java, Bash
• Design and development in the area of data management, data governance, data catalog
• Experience with enterprise application integration and encryption
• Design and implementation of data integration scenarios and use cases in cloud environments (AWS)
• Integration of (cloud) solutions / data platforms into enterprise application landscapes.
• DevOps and work on continuous improvement of software and processes
• unit and integration testing
• coder versioning in code repos and build pipelines
Additional Information
Good Communication Skills required.",USD 45K - 84K *
705,Sr. Manager - ML Operations,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Description
As our team continues to expand rapidly, we are seeking to hire ML Ops Engineer at the Senior Manager level. The ideal candidate will possess robust experience in Machine Learning and be adept at navigating the complexities associated with deploying and maintaining ML models in a production environment. Your role will encompass the complete lifecycle of machine learning applications, from their development and testing to their deployment and monitoring.
Furthermore, you will be entrusted with comprehensive project management, working in collaboration with data scientists and data engineers across different regions to design and sustain scalable data models and pipelines. As a leader, you will also be expected to mentor and guide your team members, helping them to implement ML Ops best practices and bringing in your subject matter expertise.
This position is based in Visa's offices in Bangalore, India, and presents an excellent opportunity for those looking to make a significant impact in the field of ML Ops Engineering.
Essential Functions
Lead the MLOps team and develop a strategic vision for the use and operation of machine learning based solutions within the Global solutions portfolio.
Oversee the development and implementation of machine learning models. Ensure models are built with scalability, flexibility and production deployment in mind.
Manage the deployment of machine learning models into production environments. Work closely with the IT team to ensure smooth deployment and integration with existing systems.
Define and develop processes and tools to perform model re-training, model performance evaluation and score optimization for existing ML models, introducing automation where possible.
Be able to interpret performance evaluation results, provide alternative improvements and present the findings to other data scientist groups across regional teams.
Create necessary validation and documentation to support the model approval process with the Model Risk Management group to make it production ready.
Collaborate with Data engineers, Data scientists and various groups within the organization to identify areas of improvement, bottlenecks and re-use existing frameworks/processes.
Strong understanding of development and implementation aspects of ML/AI, especially on billion-scale datasets.
Participate in the hiring process to build the ML Ops team and create seamless onboarding experience for the new team members and continuously support and mentor the team members.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
•8+ years of relevant work experience and a Bachelors degree, OR 11+ years of relevant work experience

Preferred Qualifications
•9 or more years of relevant work experience with a Bachelor Degree or 7 or more relevant years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 3 or more years of experience with a PhD
•Exposure to Financial Services/ Payments Industry
Technical skills:
•Experience with machine learning model design, implementation, deployment and management.
•Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
•Strong programming skills in building data pipelines using PySpark, Hive, Airflow.
•Experience working with scheduling tools (Airflow, Oozie) or building data processing orchestration workflows.
•Hands-on experience working with large scale data ingestion, processing, and storage in the Hadoop ecosystem
•Experience in writing and optimizing SQL queries in Big data environment.
•Experience working in Linux/Unix environment and exposure to command line utilities.
•Experience creating/supporting production software/systems and a proven track record of identifying and resolving performance bottlenecks for production systems.
•Experience working in building and integrating the code in the defined CI/CD framework using git.
•Experience working in machine learning models, deep learning models based on unstructured, structured, and streaming datasets.
•Experience in drafting solution architecture frameworks that rely on API’s and micro-services.

Strategic and Functional Excellence
•Ability to translate data and technical concepts into requirements documents, business cases and user stories.
•Results-oriented with strong problem-solving skills and demonstrated intellectual and analytical rigor
•Good business acumen with a track record in solving business problems through data-driven quantitative methodologies.
•Very detailed oriented, is expected to ensure highest level of quality/rigor in reports and data analysis
•Should have strong problem-solving capabilities and ability to quickly propose feasible solutions and effectively communicate strategy and risk mitigation approaches to leadership
•Demonstrated ability to incorporate new techniques to solve business problems

Leadership and Stakeholder Management

•Very strong project management and organizational, skills and experience in planning, organizing, and managing multiple large projects with diverse cross-functional teams
•Excellent written and verbal communication skills for coordinating across teams.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
706,"Manager, Statistical Programming",Bristol Myers Squibb,Hyderabad - Mindspace,Mid-level / Intermediate,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Position Summary
Managers of Statistical programming provide comprehensive programming expertise to clinical project teams to support the development, regulatory approval and market acceptance of  Bristol Myers Squibb (BMS) products. This position is primarily responsible for the design, development and implementation of technical solutions for integrating, analyzing and reporting clinical data.  Managers of Statistical Programming  develop collaborative relationships and work effectively within  Global Biometrics & Data Sciences (GBDS), with external vendors and members of cross-functional development teams.
Key Responsibilities
·       Create SAS programs to generate derived analysis datasets and content for tables, listings, and figures; Perform programming validation to ensure quality of analysis datasets and programming outputs
·       Provides programming support for project teams, including development of programming strategies, standards, specifications and programmed analysis
·       Support the electronic submission preparation and review
·       Reviews key planning documents (e.g., statistical analysis plan, data presentation plan, data review plan) to ensure alignment with development team objectives and clarity and completeness of programming assumptions and requirements; Assesses impact on programming activities
·       Interacts with vendors regarding project standards, programming conventions, programming specifications and file transfers
·       Provides leadership for ensuring quality of Global Biometric and Data Sciences (GBDS)  deliverables by consistently applying standards and complying with regulatory requirements, guidance and corporate and departmental SOPs and work practices
·       Identifies opportunities for increased efficiency and consistency within GBDS and our interactions with strategic vendors
·       Support improvement initiatives
Minimum Requirements:
·       Bachelor’s degree in statistics, biostatistics, mathematics, computer science or life sciences required.
·       At least 5 years programming experience in industry recommended.
·       For US positions: US military experience will be considered towards industry experience.
·       Demonstrated proficiency in using SAS, R or other programming languages  to produce derived analysis datasets and TFLs.
·       Have in-depth understanding of clinical data structure (e.g. CDISC standards) and relational database.
·       Demonstrated skills in using software tools and applications, e.g., MS office, XML, Pinnacle 21.
·       Demonstrated ability in the handling and processing of upstream data, e.g., multiple data forms, workflow, eDC, SDTM.
·       Demonstrated ability in providing outputs to meet downstream requirements, e.g., ADaM, Data Definition Table, e-submission.
·       Have good understanding of regulatory, industry, and technology standards and requirements.
·       Have good knowledge of statistical terminology, clinical tests, medical terminology and protocol designs.
·       Demonstrated ability to work in a team environment with clinical team members.
Preferred Requirements:
• Minimum of 5 years clinical / statistical programming experience within pharmaceutical clinical development - Supporting regulatory filings (e.g. NDA, BLA, MAA)
• Knowledge of the drug development process, clinical trial methodology, statistics and familiarity with global regulatory requirements
• Experience in other software packages (e.g. R)
·       Experience with the Linux operating system
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 30K - 56K *
707,Data Engineer 1,JLL,IND-CORP Bengaluru-TDIM - PTT,Mid-level / Intermediate,"Responsibilities:
Design, develop, and maintain scalable and efficient cloud-based data infrastructure using SQL and PySpark.
Collaborate with cross-functional teams to understand data requirements, identify potential data sources, and define data ingestion architecture.
Design and implement efficient data pipeline framework, ensuring the smooth flow of data from various sources to data lakes, data warehouses, and analytical platforms.
Troubleshoot and resolve issues related to data processing, data quality, and data pipeline performance.
Stay updated with emerging technologies, tools, and best practices in cloud data engineering, SQL, and PySpark.
Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver data solutions that meet their needs.
Document data infrastructure, data pipelines, and ETL processes, ensuring knowledge transfer and smooth handovers.
Sounds like you? To apply, you need to be:
Requirements:
Bachelor's degree in Computer Science, Data Engineering, or a related field. (A master's degree is a plus.)
Minimum of 2 years of experience in data engineering or full-stack development, with a focus on cloud-based environments.
Strong expertise in SQL and PySpark, with a proven track record of working on large-scale data projects.
Experience with cloud platforms (any 1) such as Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP).
Proficiency in designing and implementing data pipelines, ETL processes, and workflow automation.
Familiarity with data warehousing concepts, dimensional modelling, and data governance best practices.
Strong problem-solving skills and ability to analyze complex data processing issues.
Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams.
Attention to detail and a commitment to delivering high-quality, reliable data solutions.
Ability to adapt to evolving technologies and work effectively in a fast-paced, dynamic environment.
Preferred Qualifications:
Experience with managing big data technologies (e.g., Spark, Python, Serverless Stack, API, etc.).
Familiarity with cloud-based data warehousing platforms (e.g., AWS Redshift, Google BigQuery, Snowflake, etc.).
Knowledge of data visualization tools (e.g., Tableau, Power BI) for creating meaningful data reports and dashboards is a plus.
Location:
On-site –Bengaluru, KA
If this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements.  We’re interested in getting to know you and what you bring to the table!
About JLL –
For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500® company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com.
JLL Privacy Notice
Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.
For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.
For additional details please see our career site pages for each country.
For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here.
Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities.  If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process –  you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",USD 90K - 150K *
708,ServiceNow Platform AI Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
Join the team that's revolutionizing the industry, only at ServiceNow!!
Do you want to work on the latest offerings of Gen AI from ServiceNow and leverage the large language models (LLMs) for different use cases across the DT organization?
Do you want to configure, finetune the Now LLM for internal use cases?
Do you want to work on the latest and cutting egde GenAI solutions that teams within DT (Digital Technology) can use? Then this is the role for you!!
At ServiceNow, we are looking for a skilled & motivated Now Platform AI Engineer to join our team who is focussed on implementing, enhancing, integrating and optimizing GenAI solutions. You will closely work with the ServiceNow Platform Team to understand, validate and deploy the Gen AI solutions internally. You will collaborate cross-organization and partner with key stakeholders including GTM (Go to Market), Digital Employee Experience, Digital Customer Experience in DT Organization
You will Accelerate the value realization of Gen AI-powered solutions for DT organization at scale.
Responsibilities include but are not limited to:
As Customer Zero, Partner and collaborate with the product team for GenAI solutions
Create Alignment with all the Business Units within DT on GenAI use cases
Act as the bridge between Product team and the BU’s of DT to identify, evaluate and test GenAI solutions
Create POCs for the Use cases of DT organization, work with the product team to identify gaps and work towards solving them
Customize and enhance NowAssist to leverage AI capabilities for DT use cases
Be the enablement team in DT for the GenAI use cases.
Collaborate with Platform to refine the models based on feedback from stakeholders
Develop and Implement monitoring and alerting systems to track model performance and address issues proactively
Share knowledge with team members and contribute to a collaborative and innovative work culture
Qualifications
To be successful in this role, you should have:
4+ years of deep development experience in AI, ML or Analytics
Servicenow Platform Experience delivering AI-powered products/solutions like Predictive Intelligene and GenAI Solution
A desire to be an enablement subject matter expert (SME) on the AI & GenAI capabilities within the ServiceNow platform
Demonstrated experience in gathering and transforming product requirements into an actionable product roadmap
Exceptional problem-solving skills
Enjoys working in a highly collaborative environment
Experience delivering AI-powered products/solutions that leverage LLM and Search
FD21
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 129K - 223K *
709,Senior Data Analyst,Experian,"Hyderabad, India",Senior-level / Expert,"Company Description
Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.
We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.
Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group
 Job Description
Experian Consumer Information Service (CIS) is looking for a Delivery Analyst, based in Hyderabad, India to work alongside our UK colleagues to deliver business outcomes for the UK&I region.  
  Background: 
This is an incredibly exciting time for the Experian UKI Region, as we look to build our presence out in Hyderabad and embark on a technology transformation programme to meet our global ambition to significantly scale our business over the next five years. This is an opportunity to join us on this journey and be part of a collaborative team that uses Agile DevSecOps principles to deliver business value.   
  By way of background, the business unit currently comprises of 27 engineering teams who deliver over 70 products achieving $250m revenue per annum.  
  Our unique culture and agile ways of working offer a great opportunity to those seeking to join a talented set of diverse problem solvers to design, build and maintain our products. We pride ourselves in excellence, adopting best practices and holding ourselves to the highest standards. 
  The Role: 
The CIS team is at the forefront of change to digitise customer journeys, helping consumers fulfil their dreams more quickly and easily than ever. You will be working with lenders, fintechs and digital marketplaces to create industry disrupting solutions in one of the biggest financial services markets. 
  The delivery analyst will work from requirements from the client and interpret these and implement the changes in our own solution. They will be responsible for delivery, as well as feeding into design choices for new deliveries and ensuring work is carried out according to business standards. They will work closely with the Client Manager, Data and Analytics teams, and the Go To Market Team to support on executing the pipeline. 
  Key Responsibilities:  
  Line manage a small team of other analysts and guide them in delivering results for clients 
Understand the end to end process for customer delivery, and manage a backlog and pipeline of work for junior analysts 
Maintaining existing solutions and delivering solutions for new clients 
Configuration of products via database tables, using SQL queries 
Configuration of the product to deliver excellent client outcomes 
Using an in-house tool to build scorecards using decision trees and arithmetic logic calculations 
Working according to all regulatory requirements as well as existing change processes and security standards 
Advocate for a culture that achieves business goals, delights customers and acts in a manner conducive to the fair and reasonable treatment of all consumers, irrespective of whether these are Experian UK clients and consumers or not 
Oversee the maintenance and upkeep of documentation for operational processes 
Develop product knowledge 
Accurately Configure product following client requirements 
Develop a constructive working relationship with the client management teams  
Ensure that your delivery Analysis activities are delivered to time, quality and schedule. 
Ensure your delivery meets all the functional requirements provided by product consultants 
Create and maintain any other relevant documentation as required for successful delivery e.g. User Guides, Implementation Guides, Training Guides etc., providing that it is within scope of the role 
Identify any changes needed to product functional documentation in line with any changes made to the product 
Qualifications
Qualifications   
Degree level and / or equivalent level of professional experience, preferably with some element of mathematics, statistics, or computer science. 
Technical knowledge coupled with reasonable understanding of business operating principles 
Communication - Communicate progress of work (progress reports & future plans) to the team and recommend effective corrective actions where necessary, this will be done through retrospectives. 
Customer Service - Pro-actively manage UK internal stakeholder expectations. 
Continuous process improvement - Identify measures to improve delivery and customer satisfaction. 
Networking - use effective working relationships within Experian and third-party suppliers to ensure developments add value and meet business expectations. 
Experience  
Working collaboratively, leads by example and inspires trust of others 
Coordinating with stakeholders, sales teams and leadership teams around feasible achievements and upcoming opportunities 
E - Directing junior analysts  
Required Technical Skills/Knowledge  
Experience using Excel for data manipulation and presentation 
Basic knowledge of SQL to INSERT/UPDATE/DELETE operations 
Statistical & Mathematical Ability
Beneficial Skills/Knowledge  
Experience in the credit industry 
Additional Information
Who are Experian?
We unlock the power of data to create opportunities for consumers, businesses and society. At life’s big moments – from buying a home or car, to sending a child to university, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage their data with confidence so they can maximize every opportunity.
For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done. Our 17,000 people in 37 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.
Could this be the role for you? Apply now to start your journey with Experian.
To learn more about our culture and what it’s really like to work here, check out our LinkedIn and social media channels using the hashtags #ExperianLife and #ExperianWay.
Why choose us?

Our colleagues’ health and wellbeing are a top priority for us, that’s why our reward, benefits and wellbeing programmes are designed so you can come to work feeling your very best self. Our benefits focus on health, money and lifestyle so you can tailor your benefits to your own personal needs. Whether it’s your physical and mental wellness, getting to work or planning for the future, we have a range of flexible options to have you covered!

We are committed to building an inclusive culture and to creating an environment where people can balance successful careers with their commitments and interests outside of work. Our flexible working practices support our belief that this balance brings long-lasting benefits for our business as well as our people. Some roles lend themselves to flexible options more than others, and if this is important to you, we are open to discussing agile working opportunities during the hiring process
Experian Careers - Creating a better tomorrow together
Find out what its like to work for Experian by clicking here",USD 92K - 145K *
710,Senior Software Engineer- Data Science,Epiq,"IND-Hyderabad-Sohini Tech Park, 3rd Floor, Financial District",Senior-level / Expert,"It's fun to work at a company where people truly believe in what they are doing!
Job Description:
Job Summary:
This position entails developing back end applications using C# and SQL Server for high-volume, mission critical use. The role will primarily focus on hands-on coding of the project using the technologies listed below. Proven ability to organize workload and priorities and complete tasks on time & to work effectively in a team environment. Acts as a resource for other software engineers; and a liaison between department manager and other analysts, as well as the business team.
Essential Job Responsibilities
Use Agile Scrum SDLC methodologies in the full life cycle software development process including requirements analysis, software design, prototyping, programming, debugging and testing of system software production applications.
Participate in technical design and implementation.
Proactively raises issues if specification will lead to quality, system performance, or architectural issues in product.
Collaborate with fellow developers in areas of expertise as well as members of business unit.
Demonstrate self-directed and proactive approach to solving problems.
Develop, debug and deliver enterprise applications.
Demonstrate self-directed and proactive approach to solving problems.
Proactively mentor fellow developers in areas of expertise.  
Qualifications & Characteristics
6+ years of experience developing software in Python
6+ Experience entity Framework experience, Flask. 
2+ years of experience developing web applications with experience in AngularJs/SPA/WebApi a plus.
Excellent coding skills and aptitude.
Outstanding troubleshooting and technical support skills 
Experience writing multi-tier components for high volume systems 
Strong oral and written communications skills 
Advanced degree or training in related technical field preferred 
Work is fast-paced and performed in an office environment with extensive contact with clients and employees. The industry we serve demands the highest level of confidentiality and professionalism in safeguarding client and project information.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
It is Epiq’s policy to comply with all applicable equal employment opportunity laws by making all employment decisions without unlawful regard or consideration of any individual’s race, religion, ethnicity, color, sex, sexual orientation, gender identity or expressions, transgender status, sexual and other reproductive health decisions, marital status, age, national origin, genetic information, ancestry, citizenship, physical or mental disability, veteran or family status or any other basis protected by applicable national, federal, state, provincial or local law. Epiq’s policy prohibits unlawful discrimination based on any of these impermissible bases, as well as any bases or grounds protected by applicable law in each jurisdiction. In addition Epiq will take affirmative action for minorities, women, covered veterans and individuals with disabilities. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. Epiq is pleased to provide such assistance and no applicant will be penalized as a result of such a request.  Pursuant to relevant law, where applicable, Epiq will consider for employment qualified applicants with arrest and conviction records.",USD 45K - 84K *
711,Lead-Business Intelligence&Data Warehousing,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Services, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best in class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimising processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone?s Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues ? who in turn help to build the success of our business and reflect the diversity of the communities we serve.
Job Description
- Engage with market leaders to understand problems to be solved; translate the problems to BIDW problems
- Think beyond the ask and develop solutions that will contribute to existing solutions
- Accountable for high quality and timely completion of specified reporting and dashboarding work
- Understanding the end to end process of generating reports; underlying data sources
- Develop users manual for reporting procedures and related process changes
- Lead the transformation of reports into new age tools and technologies
- Maintain the log of issues; risks and mitigation plans
- Identifying operational improvements and finding solutions by applying CI tools and techniques
- Responsible for completing tasks and transactions within agreed metrics
- Knows and applies fundamental work theories/concepts/processes in own areas of work
- Solves problems by analyzing solution alternatives
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Driving CI culture; implementing CI projects and innovation for withing the team
Qualifications
- Adv Excel; Logical Reasoning
Strong Verbal and Written Communication
- Adv SQL; Hadoop; Hive; Phython; Spark
- Advanced Developer knowledge of Tableau; PowerBI;
- Automation knowledge using Alteryx/Python
- Planning & Organising; Problem Solving
- Process Mapping Tools and Techniques
- Process Coaching
Additional Information
Last Date of Application-5th Sept 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
712,Senior BD Data Analytics Consultant,Swiss Re,"Bengaluru, KA, IN",Senior-level / Expert,"Job Description:
Are you a highly motivated and intellectually curious individual with a passion for analytics? Do you have a passion for building data pipelines and visualizations to generate actionable insights.
In Swiss Re, as a part of the Business Development team, you'll always be presented with a variety of new opportunities as you continue to improve your skills.
To elaborate
We are looking for a strong individual contributor who in his / her position as a Senior BD Data Analytics consultant will leverage their strong understanding of corporate finance to design, develop, and maintain robust dashboards that will highlight trends for new and existing KPIs.
You will work closely with stakeholders to identify business problems, risks, and opportunities through building new analytics tools or upgrading our existing tools.
You'll serve as a domain expert for data analysis and visualization methods while using critical reasoning to understand the needs of customers, capture requirements, and develop tools individually or in collaboration with the team.
You'll collaborate with Swiss Re's sharpest minds to use data to drive business decision making.
Key Duties & Responsibilities
Design, develop and maintain tools or dashboards which business specific trends and opportunities.
Build scalable solutions for operational, reporting, and analytical data needs.
Continuously gain a deeper understanding of the industry and data to generations new business relevant insights.
The Expertise and Skills You Bring
Technical skills
Bachelor's/PG degree (or equivalent related experience)
5+ years professional experience as Business Intelligence Analyst / Data Analyst roles
Experience in Banking / (Re) Insurance / Big 4 / Consulting firms is preferable.
2-3+ years hands-on experience with databases to structure data from various sources to build powerful visualizations
Proficiency in visualization tools as Power BI or Tableau
Soft Skills
Good interpersonal skills with critical thinking and attention to detail
Be proactive. Exhibit curiosity and passion to perform.
Proven ability to research, manipulate, and analyze raw data to translate data trends into relevant business insights and draw actionable recommendations.
Strong analytical mind-set with an ability to identify, interpret, and visualize the patterns in datasets to tell the story behind the data.
Ability to develop credibility and build partnerships with key contacts across the organization to facilitate efficiency and opportunities for cross team collaboration.
  About Swiss Re
  Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer, working to make the world more resilient. We anticipate and manage a wide variety of risks, from natural catastrophes and climate change to cybercrime. We cover both Property & Casualty and Life & Health. Combining experience with creative thinking and cutting-edge expertise, we create new opportunities and solutions for our clients. This is possible thanks to the collaboration of more than 14,000 employees across the world.

Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. We embrace a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability.
    Keywords:  
Reference Code: 127693 
   ",USD 45K - 84K *
713,Senior Data Integration Engineer,Experian,"Hyderabad, India",Senior-level / Expert,"Company Description
Experian unlocks the power of data to create opportunities for consumers, businesses and society. During life’s big moments – from buying a home or car, to sending a child to college, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage data with confidence so they can maximize every opportunity. We gather, analyse and process data in ways others can’t. We help individuals take financial control and access financial services, businesses make smarter decision and thrive, lenders lend more responsibly, and organizations prevent identity fraud and crime. For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done. Our 20,600 people in 43 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.
Job Description
A Senior Data Integration Engineer provides infrastructure, data integration & data visualisation cloud and on-prem solutions for all Experian BUs. They are responsible for the location, quality, performance, timeliness and all other functional requirements to ensure the right data is in the right place at the right time at the lowest cost.
 Summary
Projects - As part of Agile project teams, support the entire project lifecycle for new Data integration and data visualisation solutions:
Working with the BU, define & design the technical solution to meet the business and technology need in terms of SLA for functional & non-functional requirements
Confirm the design meets the Architectural, Data & Security standards
Deliver the data integration aspects of the project including data replication, data validation, data latency, data refresh frequency
Deliver the data visualisation infrastructure & application setup & operation
Deliver both on-prem and cloud hosted solutions
Service
Provide services & support for all integration & visualisation data platforms to meet the business functional & non-functional requirements in a 24/7 operation
Manage the SNOW ITSM queues (Incident, problem, change etc) to exceed all SLAs
Deliver ongoing Service Improvement Plans for all data platforms to support increasing platform usage and data volumes
Governance
Ensure all data platforms meet data & security standards & policies
Ensure all Vulnerabilities are managed to SLA and Archer records raised for any non-compliance
Ensure all data platforms have an agreed and published roadmap to meet the TLMP
Partnerships
Manage BU stake holders and form trusted valued partnerships to form a strategic view for all data integration & visualisation solutions.
Manage all escalations & prevent unnecessary Exec level involvement
Manage Third party vendors ensuring value & measurable outcomes from all engagements.
 Key Responsibilities
Produce detailed technical designs approved by the architecture & security boards for all new BU solutions
Provide advice on technical aspects of infrastructure deployment and integration (including requests for changes, deviations from specifications, etc.) and ensure that relevant technical strategies, policies, standards and practices are applied correctly.
Ensure all data integration & visualisation designs are consistent in driving improvements in implementation / performance and maintainability
Maintain an in-depth knowledge of specific specialisms, and provides expert advice regarding their application, in relation to data integration and data visualisation
Supervise specialist external consultancy. The specialism can be any aspect of information or communication technology, technique, method, product or application area.
Responsible for dissemination of technical information relating to their specific specialism, to ensure a high degree of multi aspect technical capability in the team
Adhere to all regulatory requirements within area of responsibility and escalate issues quickly.
Pro-actively identify risks and take steps to mitigate these.
Ensure team members understand the importance of adhering to their regulatory obligations and responsibility for implementation of company policies and procedures.
Ensure team members understand the operating model and the functional and individual responsibilities
Maintain awareness of opportunities provided by new technology to address challenges or to enable new ways of working.
Within own sphere of influence, works to further organisational goals, by the study and use of emerging technologies and products.
Contribute to briefings and presentations about their relevance and potential value to the organisation.
Specify and design large or complex systems. Select appropriate design standards, methods and tools, consistent with agreed enterprise and solution architectures and ensures they are applied effectively.
Review others’ system and infrastructure designs to ensure selection of appropriate technology, efficient use of resources, and integration of multiple systems and technology.
Evaluate and undertake impact analysis on major design options and assesses and manages associated risks.
Ensure that the system design balances functional, service quality, security and systems management requirements.
Understand and participate in continual performance review; ensuring stretching personal objectives, a personal development plan and regular self and team feedback.
Comply with the Training and Competency requirements and complete required training in a timely manner.
Qualifications
Knowledge, Skills and Experience
Minimum 5-8 Years experience with data infrastructure components & platforms e.g. AWS Data services including Data Migration Services, RDS/Postgres, Scripting/Terraform, Programming/Python, Linux, Windows, Cloud Services
Minimum 5 Years experience with database services including SQL, Replication, on-prem & cloud hosted Databases
Minimum 5 years experience of MicroStrategy & Tableau or similar products.
Familiar with web architectures, APIs, cloud infrastructure, SaaS, PaaS, IaaS, etc. and DBMS architectures, as required
Familiar with architecture tools & utilities, e.g. MS office Suite, MS Visio, PowerPoint
Familiar with Experian products/applications - Non-functional capabilities / requirements
Familiar with Compliance & Security - Security related Architecture
Good at building relationships within department and across division
Good technical and non-technical communication skills, written & oral, internal / external, formal & informal
Qualifications / Certifications
Cloud or On-prem data integration & visualisation accreditation
Industry or vendor specific certification is desirable 
Additional Information
Experian Careers - Creating a better tomorrow together
Find out what its like to work for Experian by clicking here",USD 45K - 84K *
714,Project Engineer- Data Management,Hitachi,"(HE)Office Bengaluru, Bhoruka Tech Park",Senior-level / Expert,"Location:
Bangalore, Karnataka, India
Job ID:
R0020344
Date Posted:
2023-06-22
Company Name:
HITACHI ENERGY TECHNOLOGY SERVICES PRIVATE LIMITED
Profession (Job Category):
Engineering & Science
Job Schedule: 
Full time
Remote:
No
Job Description:
Company Information:
Hitachi Energy is a pioneering technology leader that is helping to increase access to affordable, reliable, sustainable, and modern energy for all. We help to power your home, keep the factories running, and our hospitals and schools open. Come as you are and prepare to get better as you learn from others. Bring your passion, bring your energy, and plug into a team that appreciates a simple truth: Diversity + Collaboration = Great Innovation.
Visit us - www.hitachienergy.com
About the business:
The Hitachi Energy Indian Operations Center (INOPC) is a competence center with around 2300 skilled engineers who focus on tendering, engineering, planning, procurement, project Management, functional system testing, installation supervision, documentation and commissioning. However, over the last decade, it has evolved to become the largest Operations hub.. The India Operations Centre team at Chennai, Bangalore and Gurugram supports Hitachi Energy’s units in more than 40 countries across a wide portfolio of all the four business units in Hitachi Energy To date, the team has executed engineering and commissioning for projects in more than 80 countries.
Your Responsibalities:
Analyze and understand customer engineering, business and software requirements, propose effective and efficient data management solutions, estimate required effort, identify risks and formulate implementation approach and assumptions.
Understand database design concepts, the benefits and limits of various types of databases and ability to recognize how to efficiently store and analyze various types of data.
Design, develop, test, integrate and document data management applications and related work for customer projects, while following best engineering and software development practices.
Support software releases and assist onsite/support team with expert knowledge, problem analysis, troubleshoot and resolution of defects as required to bringing issues to closure. 
Actively research and further own knowledge in data management skills and improve software development practices and documentation.
Must be willing to travel for short periods of time to visit or support customers around the world.
Living Hitachi Energy’s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.
Your Requirements:
Master’s degree in electrical engineering orPhD degree in Electrical Engineering with special emphasis on Power System and Data Management skills.
Must have 5-9 years of experience.
Demonstrated programming skills in high performance, high programming level languages such as C/FORTRAN/C++.
Familiarity with operating systems such as Linux or similar.
Formal classroom education in Data Management course.
Formal classroom education in Data Structures and Databases.
Experience developing power system application software for Electric Utilities or Electricity Markets
Experience with multi-threading, high performance, memory intensive analytical applications
Proficient skills in English written and oral communication.",USD 37K - 70K *
715,Trainee - Data Scientist,Equifax,IND-Bengaluru-Equifax Credit Information Services,Entry-level / Junior,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds, and make a meaningful impact, we want to hear from you.
Synopsis of the role
The role of a data analytics consultant will be highly specialized and it will involve reviewing data to discover insights and offering expertise in data management. They will use the results of their analysis to make predictions and help guide business strategy and decision-making.
What you’ll do
Work with the Equifax bureau in India to build bureau based Analytics capabilities and use the new age technology to implement those solutions.
Expected to demonstrate independence in execution, results interpretation and presentation, and the production of documentation strong enough to evidence a sound challenge to both internal and external parties.
Knowledge of credit bureau, housing and/or demographic data is a plus. Manipulate large amounts of data and integrate diverse data sources into solutions.
Contribute to Building the BFSI Analytics practice through on- going identification of new opportunities
Understanding of key business and risk KPI’s for retail banking products, drawing insights from bureau datasets
Self-motivation, discipline, task focus, the ability to structure and present work and a proven record of delivering high quality results to strict deadlines
What experience you need
0 to 1 year experience in handling BFSI analytics/implementing models/Big data/Cloud solution architect
Good knowledge of SAS, SQL, Python, R.
Understanding of Retail banking products.
Analytical skill, logical thinking and problem solving capabilities.
Adaptability to work in project-based engagements across different kinds of banking clients.
Should be a team player.
Analytical skill, logical thinking and problem-solving capabilities.
Self-starter with high energy levels and ability to work in a fast-paced environment.
Self-motivation, discipline, task focus, the ability to structure and present work and a proven record of delivering high quality results to strict deadlines. 
What could set you apart
Adaptability to work in project based engagements across different kinds of banking clients
Knowledge on statistical and probability concepts
Self-starter with high energy levels and ability to work in a fast paced environment
We offer hybrid mode of working, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
Equifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Primary Location:
IND-Bangalore-Equifax Credit Information Services
Function:
Function - Data and Analytics
Schedule:
Full time",USD 58K - 130K *
716,"Director, Data Analytics Engineering",Western Digital,"Bengaluru, India",Executive-level / Director,"Company Description
At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.
At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that. Our technology helped people put a man on the moon.
We are a key partner to some of the largest and highest growth organizations in the world. From energizing the most competitive gaming platforms, to enabling systems to make cities safer and cars smarter and more connected, to powering the data centers behind many of the world’s biggest companies and public cloud, Western Digital is fueling a brighter, smarter future.
Binge-watch any shows, use social media or shop online lately? You’ll find Western Digital supporting the storage infrastructure behind many of these platforms. And, that flash memory card that captures and preserves your most precious moments? That’s us, too.
We offer an expansive portfolio of technologies, storage devices and platforms for business and consumers alike. Our data-centric solutions are comprised of the Western Digital®, G-Technology™, SanDisk® and WD® brands.
Today’s exceptional challenges require your unique skills. It’s You & Western Digital. Together, we’re the next BIG thing in data.
 ABOUT ADVANCED ANALYTICS OFFICE (AAO) and BIG DATA PLATFORM (BDP)
AAO is missioned with accelerating Analytics solutions at scale across the Enterprise to rapidly capture business value. These solutions target key business metrics, such as, reducing manufacturing cost, improve capital efficiency, reduce time-to market to develop new products, improve operational efficiency, and improve customer experience. These solutions are built using cutting edge Industrial 4.0 technologies and are delivered through a platform approach to enable rapid scaling. The solutions span AI/ML for improving manufacturing yield, quality, equipment uptime, and adaptive testing, Operations Research for capacity and scheduling optimization, Digital Twin for inventory and logistics optimization, and Product Telematics for managing customer fleet management solutions.
Big data platform, BDP team provides self-service data and application platforms enabling rapid scaling of services to make ever increasing business impact. You will have the opportunity to partner in making remarkable things happen across WDT’s more than dozen factories across the globe, global product development teams, customer solutions, and supporting operations like Finance, supply chain, Procurement, Sales etc
Job Description
We are looking for a dynamic Senior Analytics Partner (Director role equivalent) who will play a pivotal role in bridging language barriers across Enterprise Functional domain problems and AI/ML application solution approaches. In other words, the candidate will be playing an AI translator role while working across Enterprise domain functions. Though a Senior Technologist role, the primary responsibility will be to engage with the internal stakeholders in discovery work to build and qualify the pipeline of analytics projects. This will often involve understanding ambiguously defined problem from stakeholders,  and then recasting the problem statement for clarity and getting buy-in from stakeholders. The position definitely will require establishing credibility with the stakeholders and will exercise both your technical and influence skills.  
 Serve as an internal business consultant, to identify, evaluate, develop, and manage complex projects that involve advanced analytics.
Role requires a focus on both business understanding and Analytics technologies; need ability to see business opportunities and how to unleash them through new solutions.
Role requires ability to effectively communicate complex technical concepts to non-technical stakeholders, including the ability to break down technical jargon into plain language and to communicate the benefits and risks of AI in a clear and concise manner.
Engage in discovery work with stakeholders to identify, refine and qualify analytics project and influence the project direction and scope for best stakeholder outcome.
Must be comfortable with ambiguity, exploring requirements that are not yet clearly defined, and bringing clarity to business for prioritizing projects and resources.
Should be open to learning new material, staying up to date with fast evolving technologies, and expanding beyond current areas of expertise.
As an Analytics Business Partner (AI translator), you need to have solid understanding of Machine Learning techniques on Inferential techniques, Image Analytics, NLP, Gen AI (LLM), Reinforcement learning etc., to conceptualize high-level business solution.
Architect and design end-to-end analytics solutions on cloud/Hybrid-cloud platforms. Collaborate with infrastructure teams on compute, storage, and network requirements.
Role requires a good business domain experience in engineering, procurement, supply chain, manufacturing, order management. Preference will be given to knowledge in High-Tech industry, and specifically semiconductors.
Preference will be given to candidates who have experience in assessing and capturing business value of AI projects, and have done consulting engagements.
Stay up-to-date on cloud, edge computing and advancements related to analytics and AI. Identify how new capabilities can be applied to business problems.
Qualifications
Master's or Ph.D. in a relevant field (e.g., Data Science, Computer Science, Statistics, Engineering, Applied Sciences).
15+ years of proven experience with at least 10+ years of data science or advanced analytics, with a track record of successful project execution.
Very comfortable leading or participating in cross-functional teams.
Experience in drafting AI project proposals/executing plan.
Strong ability to translate business/function problems into analytics problem for practical solutioning.
Solid exposure ton data visualization tools and programming languages (e.g., Python, R).
Excellent communication and stakeholder management skills to influence stakeholders to act based on insights from analytics.
Additional Information
All your information will be kept confidential according to EEO guidelines.",USD 170K - 221K *
717,Data Architect,BETSOL,"Bengaluru, India",Senior-level / Expert,"Company Description
BETSOL is a cloud-first digital transformation and data management company offering products and IT services to enterprises in over 40 countries. BETSOL team holds several engineering patents, is recognized with industry awards, and BETSOL maintains a net promoter score that is 2x the industry average. BETSOL’s open source backup and recovery product line, Zmanda (Zmanda.com), delivers up to 50% savings in total cost of ownership (TCO) and best-in-class performance. BETSOL Global IT Services (BETSOL.com) builds and supports end-to-end enterprise solutions, reducing time-to-market for its customers. BETSOL offices are set against the vibrant backdrops of Broomfield, Colorado and Bangalore, India. We take pride in being an employee-centric organization, offering comprehensive health insurance, competitive salaries, 401K, volunteer programs, and scholarship opportunities. Office amenities include a fitness center, cafe, and recreational facilities. Learn more at betsol.com
Job Description
We are seeking a Data Architect (DA) who will be a part of Enterprise Data Architecture team with strong experience in the following responsibility areas:
Data Strategy, Architecture and Governance
Define and enforce the enterprise level data strategy for our clients
Develop, maintain, and evangelize data architecture guiding principles, policies, best practices, reference architecture and standards
Represent data architecture concerns in design, implementation, and deployment reviews
Provide general guidance to teams on data architecture topics
Facilitate data architecture working sessions across solution teams
Data Discovery, Quality, Analysis, Transformation, Migration, Modeling, Lifecycle Management and Master Data Management (MDM)
Manage and actively contribute to data quality and cleansing activities.
Establish and manage metadata, semantic master data on data domains such as customers, contacts, contracts, etc.
Experienced in discovery, analysis, transformation and modeling of data coming out of Salesforce and other custom applications.
Create, establish, and enforce an MDM strategy and architecture.
Play a lead role in selecting and implementing technologies supporting MDM, data discovery and analysis tools and champion related process changes.
Lead data innovation initiatives
Maintain currency with leading and emerging data technologies including “big data” platforms, NoSQL databases, data streaming, in-memory data management, real-time analytics, cloud data services
Identify business opportunities for applying leading and emerging data technologies like Microsoft Fabric, Purview, Athena, Snowflake etc
Lead proofs of concept and prototypes of leading and emerging data technologies.
Provide guidance to business, solution development and operations teams in applying leading and emerging data technologies.
Lead next generation of data warehouse (real-time DW, DW as-a-Service), reporting and analytics.
Working in a fast paced and complex environment, the DA will need to develop a clear technical vision for the teams to follow, as well as be an excellent collaborator and evangelist for the data strategy and architecture guiding principles, policies, best practices, reference architecture and standards.
Required Skills:
Databases: SQL Server, Oracle, MySQL
Query Languages: SQL, T-SQL, PL/SQL
ETL Tools: SSIS, ADF
Reporting & Analytics Tools: SSRS, Power BI, Analysis Services
Data Warehouses: Microsoft Fabric, Athena, Snowflake
Strong experience with database modelling, development, query-building, and analysis tools 
Experience with designing and building complex ETL, cleansing, and data synchronization processes across information systems.
Customer focused, action oriented and committed to driving quality results.
Self-motivated and able to work independently with the ability to quickly learn and adapt to new processes and technologies to meet business needs and drive business value.
Strong ability to resolve conflicts with the ability to influence and drive consensus.
Able to effectively deal with and manage ambiguity.
Must be a team player and be able to work collaboratively with and through others.
Excellent verbal and written communication skills including presentation skills (MS Visio, MS PowerPoint), and the ability to interact with global technical and functional teams including the business.
Strong analytical and problem-solving skills.
Willingness and ability to mentor junior staff.
Qualifications
Bachelor's/Master's degree; preferably in a related field
8-10 years of relevant experience on data strategy, data architecture and management consulting
Significant experience leading complex data integration/management engagements.
Strong implementation experience and deep knowledge in Master Data Management, Data Integration, and Data Quality
Data Management experience with Oracle EBS, Salesforce.com, Enterprise MDM, Data Discovery and Data Quality solution technologies preferred.",USD 117K - 193K *
718,Associate Data Scientist (ML & NLP),Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About this role:
The Service’s Data Science team innovates the way towards helping clients receive value, so technology leaders will be able to make smarter decisions in a different way. This team works  on delivering valuable insights from unstructured data, developing statistical and machine learning based methods to build, measure and improve client engagement & retention
What you’ll do: 
Drive retention and growth by empowering service delivery groups and sales in some of our key initiatives
Derive key insights utilizing unsupervised machine learning based on hundreds of pages of unstructured data from several sources
Build statistical models to predict retention probabilities dynamically for a given client and help Service Delivery leverage the data insights
Prioritize what clients our Service Delivery associates should talk to and what Gartner asset they should recommend converting an unengaged client to an engaged one.
Analyze surveys and correlation between survey responses and client engagement in a meaningful way to result in actionable insights
Meaningful extraction of key client priorities using text analytics
What you’ll need:
Bachelor’s or Masters’ degree in Physics, Math, Technology, Computer Science or related branches
2 - 4 years in Data Science using Machine Learning and NLP techniques
Knowledge of R or Python needed to be able to code the models
Well versed with Statistical and advanced modelling techniques
Ability to work on projects that involve ML & statistical techniques with large volume of data
What you will get:
Competitive salary, generous paid time off policy, charity match program, Group Medical Insurance, Parental Leave, Employee Assistance Program (EAP) and more!
Collaborative, team-oriented culture that embraces diversity
Professional development and unlimited growth opportunities
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:71072
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 86K - 156K *
719,"Data Analyst, Tenant & Employment Solutions",TransUnion,Chennai,Entry-level / Junior,"TransUnion's Job Applicant Privacy Notice
What We'll Bring:
What We'll Bring:
At TransUnion, we ensure every individual is reliably represented in global commerce so consumers and organizations can transact with confidence and achieve great things. We call this Information for Good®.
In this Product Analyst role, you'll support teams building the best-of-breed solution for tenant and employment screening. In your first 90 days, you'll onboard into a team laser focused on data integrity and quality. As we move forward, your efforts will surface trends, stoke curiosity, and help set strategy for products that impact property managers, renters, employers, and job seekers. Your success means data feels accessible and trusted by decision-makers.
What You'll Bring:
What You Bring — You have:
Thrived in a matrixed environment where you offered quantitative analysis and insights for a diverse set of team leaders
Taken ownership and provided timely service to your stakeholders
Written complex SQL to analyze data trends and pull reports using pgAdmin, Toad, or similar SQL tools
Used Tableau or similar business intelligence and analytics tools
Built and maintained Excel spreadsheets and presented with PowerPoint
Communicated clearly with cross-functional stakeholders from technical and non-technical backgrounds at various levels of seniority
Asked for help and demonstrated proactive communication to minimize blockers
Displayed empathy and positivity when met with a challenge
Impact You'll Make:
Impact You'll Make — You will:
Present trends and analysis to internal and external stakeholders who need data on TransUnion's Tenant & Employment Solutions
Pair with other analysts to consolidate Tenant & Employment work under your ownership
Earn trust through consistent delivery of weekly, monthly, and quarterly reports
Complete ad hoc requests for operations and compliance teams
Maintain audit and reporting processes for vendors and data partners
Assist with QA of data quality and vendor integrations to minimize negative impacts on reporting and customers
Maintain real-time dashboards and process documentation to empower teammates and other departments
Coach teammates to self-serve and avoid misinterpretation of data
Fuel product discovery and design through data insights
Partner with technical stakeholders to ensure data integrity and quality
TransUnion Job Title
Analyst, Product Management",USD 58K - 92K *
720,ML Ops Engineer,Acceldata,"Bengaluru, India",Mid-level / Intermediate,"About Acceldata 
Acceldata is an enterprise Data Observability organization that was first to the market, having coined the term ‘Data Observability’ in 2018. Founded by industry veterans who have spent decades in the AI, Analytics, and Data Monitoring space, Acceldata is a startup in the hyper-growth phase. Having raised $100+ million in total, Acceldata is now a 250+ strong entity that is looking to help Enterprises and SMEs/SMBs take control of their pipelines across the cloud-native, multi-cloud, hybrid cloud, or on-premises data systems.

As a result of data teams struggling to manage the data that supported mission-critical analytics and AI-based applications, Acceldata built the world’s most comprehensive data observability platform that transforms how organisations build and operate data products.

Position Summary

Join our team as an ML Ops Engineer with a focus on designing and implementing cloud solutions. The role involves building MLOps on-premises (using Kubernetes) or in the cloud as required. We are seeking an individual with a minimum of 2 years of experience as an ML Ops Engineer, particularly with expertise gained at Acceldata. As a valued member of our AI strategy team, you will contribute to the seamless integration and optimization of machine learning operations within our technology stack.

We’re looking for someone who can:

Design and implement cloud solutions, build MLOps on Prem (Kubernetes) or cloud as needed
Build and maintain CI/CD pipelines orchestration
Data science model review, run the code refactoring and optimization, containerization, deployment, versioning, and monitoring of its quality
Data science models productionization and reliability
Communicate with a team of data scientists, data engineers and architect, document the processes

What makes you the right fit for this position?

Ability to design and implement cloud solutions and ability to build MLOps pipelines on cloud solutions (AWS, MS Azure or GCP)
Experience with MLOps Frameworks like Kubeflow, MLFlow, DataRobot, Airflow etc., experience with Docker and Kubernetes, OpenShift
Programming languages like Python, Go, Ruby or Bash, good understanding of Linux, knowledge of frameworks such as scikit-learn, Keras, PyTorch, Tensorflow, etc.
Ability to understand tools used by data scientist and experience with software development and test automation
Acceldata is an equal-opportunity employer

At Acceldata, we are committed to providing equal employment opportunities regardless of job history, disability, gender identity, religion, race, color, caste, marital/parental status, veteran status or any other special status. We stand against the discrimination of employees and individuals and are proud to be an equitable workplace that welcomes individuals from all walks of life if they fit the designated roles and responsibilities.

Life @ Acceldata

#LifeAtAcceldata is all about working with some of the best minds in the industry and experiencing a culture that values an ‘out-of-the-box’ mindset. If you want to push boundaries, learn continuously and grow to be the best version of yourself, Acceldata is the place to be! 
We also believe in providing our employees with the right tools and resources to help them excel at their job. We offer Uber transport facilities, free lunch, healthy performance-based bonuses, ESOPs, and above industry compensation. Annual reimbursement of up to INR 50K for learning & development programs aimed at career enhancement of employees.

What should you know about joining Acceldata?  

At Acceldata, each job and role serves a purpose towards our business goals. You’ll have opportunities to make an immediate impact on mission-critical projects as you work with highly capable and ambitious peer groups.   

Join Acceldata and help us achieve our data goals. Learn more about our solutions and products here: Acceldata Product Overview & Demo ",USD 30K - 56K *
721,Communication Analyst - Business Intelligence,Valeo,CHENNAI - CHE7-2,Entry-level / Junior,"Valeo is a tech global company, designing breakthrough solutions to reinvent the mobility. We are an automotive supplier partner to automakers and new mobility actors worldwide. Our vision? Invent a greener and more secured mobility, thanks to solutions focusing on intuitive driving and reducing CO2 emissions. We are leader on our businesses, and recognized as one of the largest global innovative companies.
Presentation Template
Create set of slides for all DFC products
Maintain up to date DFC Presentation Templates
Customer & Management presentation
Support giving visuals for the Team
Organize training for DFC Team on presentation and create a training support (Presentation PPT & Videos)
DFC  Communication Website
Creation of a Website for DFC Communication with external communication , visual for presentation, Presentation templates, training contents etc…
DFC Monthly Newsletter
Create the Newsletter based on the template
Ensure update from contributors on time
Other communication Topics
Marketing supports to promote our products
Events promotions topics
Design or business school degree, experience of the automotive field.
Dual competencies in design and business fields would be appreciated.
Min. 1 year of experience in a similar activity
Job:
R&D Engineer
Organization:
Software
Schedule:
Full time
Employee Status:
Regular
Job Type:
Permanent contract
Job Posting Date:
2023-12-08
Join Us !
Being part of our team, you will join:
- one of the largest global innovative companies, with more than 20,000 engineers working in Research & Development
- a multi-cultural environment that values diversity and international collaboration
- more than 100,000 colleagues in 31 countries... which make a lot of opportunity for career growth
- a business highly committed to limiting the environmental impact if its activities and ranked by Corporate Knights as the number one company in the automotive sector in terms of sustainable development

More information on Valeo: https://www.valeo.com",USD 22K - 42K *
722,Lead Artificial Intelligence Architect,Boeing,"IND - Bengaluru, India",Senior-level / Expert,"Lead Artificial Intelligence Architect
Company:
Boeing India Private Limited
Job ID:
00000406554
Date Posted:
2023-12-07
Location:
IND - Bangalore, India
Job Description Qualifications:
The Boeing Company is looking for a Lead Artificial Intelligence Architect based out of Bangalore
Boeing is transforming its business and adopting a data centric culture and modernizing its suite of applications. This position will drive the transformation by collaborating and working closely with businesses, functions, Application Architects, Supplier Architects/Developers, Cloud Vendor Architects and Information Technology Architects such as Security. The Lead Architect will be partnering with Company Application Architects/Developers and Supplier Architects/Developers building solutions that include system design, technology selection, solution design, process design, and execution. This position will also have the opportunity to collaborate with other common service functions, interact with the most innovative and diverse people around the globe.
Position Responsibilities:
Leads activities to define requirements, design and verify robust architecture, data and information management systems and components
Leads the identification of design constraints and ensures architecture conforms to requirements
Incorporates architecture functions into software development lifecycle
Leads the development and configuration management of architecture views and models
Assesses of feasibility of architecture solutions and alternatives
Performs trade-off analyses
Evaluates products to assess suitability for integration into delivery system environments
Drafts data and information management products and service standards
Assesses impact of architectural decisions to product lifecycle
Develops architecture and data/information management standards and strategies
Coaches and mentors others
 Basic Qualifications (Required Skills/Experience):
10+ years of experience with web application architecture, Service Oriented Architecture (SOA) or cloud based development
10+ years of experience working with Cloud native development
Experience with application integration, APIs and Microservices
Experience as an IT architect in a large-scale, hybrid cloud and on-prem environment
Experience working in the field of Artificial Intelligence including Machine Learning
 Preferred Qualifications (Desired Skills/Experience):
Bachelor's Degree or higher
 Typical Education/Experience: 
Education/experience typically acquired through advanced technical education (e.g. Bachelor) and typically 14 or more years' related work experience or an equivalent combination of technical education and experience (e.g. PhD+9 years' related work experience, Master+12 years' related work experience, 18 years' related work experience, etc.).
 Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.
Boeing is the world's largest aerospace company and leading manufacturer of commercial airplanes and defense, space and security systems. We are engineers and technicians. Skilled scientists and thinkers. Bold innovators and dreamers. Join us, and you can build something better for yourself, for our customers and for the world.
Relocation:
No relocation available
Export Control Requirement:
Safety Sensitive:
This is not a safety sensitive position
Contingent Upon Award Program
This position is not contingent upon program award
Experience Level:
Individual Contributor - 5
Job Type:
Regular
Job Code:
BAULI5 (B78)",USD 45K - 84K *
723,Data Engineer Lead,GoTo Group,Noida,Senior-level / Expert,"Job Responsibilities
Oversee a team of 4-8 individuals: Guide the team's efforts, conduct code reviews as needed, and ensure overall team success.
Take ownership of the majority of deliverables for the data engineering team from a delivery standpoint.
Supervise the data intelligence team, collaborating with data science, internet marketing, ads & campaign management, and other teams to comprehend their requirements and develop high-quality solutions to meet their needs.
Familiarize yourself with operational services and provide support to teams encountering issues while utilizing our services.
Prioritize the continuous improvement of existing services.
Establish goals for team members, assist in sprint planning, and monitor their performance.
Lead initiatives to construct, implement, and maintain the data infrastructure.
Skills
Possess 5+ years of core data engineering experience.
Demonstrate 3+ years of expertise in streaming pipelines using Apache Spark, Apache Beam, or similar technologies.
Adapt swiftly to changes in requirements and be open to working with diverse technologies if necessary.
Have experience in leading technical teams.
Proficient in programming with Python and Java.
Have experience with Kafka, Pub/Sub, NSQ, or any other message queue service.
Familiarity with Apache Airflow.
Strong skills in SQL.
Bonus Points:
Understanding of any cloud platform.
Familiarity with any graph database.
Experience with monitoring tools such as Prometheus and Grafana is a plus.

About GoTo Group
GoTo Group is the largest digital ecosystem in Indonesia with its mission to “Empower Progress’ by offering technological infrastructure and solutions for everyone to access and thrive in the digital economy. The GoTo ecosystem consists of on-demand transportation services, e-commerce, food and grocery delivery, logistics and fulfillment, as well as financial and payment services through the Gojek, Tokopedia and GoTo Financial platforms.It is the first platform in Southeast Asia that hosts these crucial cases in a single ecosystem, capturing the majority of Indonesia’s vast consumer household.

About Gojek 
Gojek is Southeast Asia’s leading on-demand platform and pioneer of the multi-service ecosystem with over 2.5 million driver partners across the regions offering a wide range of services such as transportation, food delivery, logistics and more. With its mission to create impact at scale, Gojek is committed to resolving consumer problems and raising standards of living by connecting consumers to the best providers of goods and services in the market.

About GoTo Financial
GoTo Financial accelerates financial inclusion through its leading financial services and merchants solutions. Its consumer services include GoPay and GoPayLater and serve businesses of all sizes through Midtrans, Moka, GoBiz Plus, GoBiz, and Selly. With its trusted and inclusive ecosystem of products, GoTo Financial is open to new growth opportunities and aims to empower everyone to Make It Happen, Make It Together, Make It Last.

About Tokopedia  
Tokopedia is an Indonesian technology company with a mission to democratize commerce through technology. It has been a driving force behind Indonesia's digital development since its foundation in 2009, with more than 99% of districts and empowered around 12 million merchants listed nationwide. With Nakama ranging all across Indonesia, Tokopedia aims to simplify the lives of many to #FindYourPurpose together.



GoTo and its business units, including Gojek, Tokopedia, GoToFinancial and GoToLogistics (""GoTo"") only post job opportunities on our official channels on our respective company websites and on LinkedIn. GoTo is not liable for any job postings or job offers that did not originate from us. You should conduct your own due diligence to prevent being victims of any fake job scams, if they did not originate from GoTo's official recruitment channels.",USD 45K - 84K *
724,Software Engineering PMTS- Java & Big data,Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
UIP - Software Engineering PMTS
Salesforce Company
Our Tech and Product team is responsible for innovating and maintaining a massive distributed systems engineering platform that ships hundreds of features to production for tens of millions of users across all industries every day. Our users count on our platform to be highly reliable, lightning fast, supremely secure, and to preserve all of their customizations and integrations every time we ship. Our platform is deeply customizable to meet the differing demands of our vast user base, creating an exciting environment filled with complex challenges for our hundreds of agile engineering teams every day.

Check out our ""We are Salesforce Engineering"" video
We are Salesforce Engineering
Who we are / Team
The mission of the Unified Intelligence Platform is to make using data at scale easy and enabling, by marrying together cutting-edge technology with an exceptional user experience. Massive amounts of data are generated each day at Salesforce. Crafting a platform that enables internal users to understand, optimize, and re-envision how the business is and should operate is critical. Modern query engines (e.g. Spark and Trino), coupled with ML tech (e.g. Tensorflow, Pytorch) and a easy to use user experience (Jupyter, Sagemaker, a comprehensive data catalog and a data portal) are a few of the key ingredients this team is weaving together to make this possible.

We are defining the next generation of trusted enterprise computing in the cloud. We're a fast-paced, agile and innovative team. We're highly collaborative and work across all areas of our technology stack. We enable critical services for the business, qualify complex compute changes, enable big data analytics and trail-blaze new engineering solutions for the cloud.
Responsibilities
Architect, Design, Build, Drive and take ownership of business critical data and platform services.
Working on multiple technical projects leading and bringing them to completion
Collaborating with Principal Architects and Principal Engineers across the org on building the Data Platform
Working with the technical teams guiding on the architecture and implementing the best practices
Working with the internal business teams (customers) to understand their needs and enable them for success
Embrace accountability for various technical deliveries through all phases of the development life cycle—from code to test to production
Partnering with the cross org teams in various areas (E.g. Data Lake Engines, Security, Cloud Infra)
Technical acumen in big data evolving the platform with business impactful technical choices, industry practices
Lead the team with active participation in all parts of the Agile process, including planning, execution, and retrospectives.
Be the leading technical representative for the team when dealing with plans and problems that involve cross teams.
Qualifications
12+ years of experience working with large scale data platforms, designing solutions with modern data systems to support exponential data growth.
Experience writing code with programming languages like Java, Scala & Python.
Deep understanding and experience with big data processing engines such as Apache Spark, Apache Trino
Experience with container and container orchestration technologies such as Docker and Kubernetes
Experience in solving the data compute and storage challenges for large scale data for low latency, high QPS
Experience with big data technologies like Hadoop, Kafka, Spark, Trino, Hive, Iceberg and others.
Experience with common ML tools and platforms, such as Jupyter, AWS SageMaker
Experience working with Public Cloud platforms like AWS, GCP or Azure.
Good understanding and experience in Security concepts such as OAuth, RBAC, OPA
Experience in storing and accessing the data securely with permission controls at scale in Public Cloud
Experience working in a agile based development teams
Experience working in Service Ownership and Devops model teams
Excellent analytical and problem solving skills
Excellent communication skills, working with customers, senior leadership and various levels of Engineering
Strong Technical Influence and experience Collaborating with the architects, engineers, cross org teams
Passionate and Self Driven in leading the complex projects and bringing clarity to the team
Experience working in global team across different timezones (PST and IST)
Hands-on Salesforce.com knowledge of product and functionality a plus
Experience contributing to Open Source Technologies is a plus
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 45K - 84K *
725,Associate Data Engineering,BlackRock,HA3-Gurgaon - DLF Cyber City,Mid-level / Intermediate,"About this role
Overview:
Data is at the heart of Aladdin and increasingly the ability to consume, store, analyze and gain insight from data has become a key component of our competitive advantage. The DOE team is responsible for the data ecosystem within BlackRock. Our goal is to build and maintain a leading-edge data platform that provides highly available, consistent data of the highest quality for all users of the platform, notably investors, operations teams and data scientists. We focus on evolving our platform to deliver exponential scale to the firm, powering the future growth of Aladdin.
Data Pipeline Engineers at BlackRock get to experience working at one of the most recognized financial companies in the world while being part of a software development team responsible for next generation technologies and solutions. Our engineers design and build large scale data storage, computation and distribution systems. They partner with data and analytics experts to deliver high quality analytical and derived data to our consumers.
We are looking for data engineers who like to innovate and seek complex problems. We recognize that strength comes from diversity and will embrace your unique skills, curiosity, drive, and passion while giving you the opportunity to grow technically and as an individual. We are committed to open source and we regularly give our work back to the community. Engineers looking to work in the areas of orchestration, data modeling, data pipelines, APIs, storage, distribution, distributed computation, consumption and infrastructure are ideal candidates.
Responsibilities
Data Pipeline Engineers are expected to be involved from inception of projects, understand requirements, architect, develop, deploy, and maintain data pipelines (ETL / ELT). Typically, they work in a multi-disciplinary squad (we follow Agile!) which involves partnering with program and product managers to expand product offering based on business demands. Design is an iterative process, whether for UX, services or infrastructure. Our goal is to drive up user engagement and adoption of the platform while constantly working towards modernizing and improving platform performance and scalability.
Deployment and maintenance require close interaction with various teams. This requires maintaining a positive and collaborative working relationship with teams within DOE as well as with wider Aladdin developer community. Production support for applications is usually required for issues that cannot be resolved by operations team. Creative and inventive problem-solving skills for reduced turnaround times are highly valued.
Preparing user documentation to maintain both development and operations continuity is integral to the role.
And Ideal candidate would have:
· At least 8+ years’ experience as a data engineer
· Experience in SQL, Sybase, Linux is a must
· 2+ years experience using modern data stack (spark, snowflake, Big Query etc.) on cloud platforms (Azure, GCP, AWS)
· Experience building ETL/ELT pipelines for complex data engineering projects (using Airflow, dbt, Great Expectations would be a plus)
· Experience with Database Modeling, Normalization techniques
· Experience with object-oriented design patterns
· Experience with dev ops tools like Git, Maven, Jenkins, Gitlab CI, Azure DevOps
· Experience with Agile development concepts and related tools
· Ability to trouble shoot and fix performance issues across the codebase and database queries
· Excellent written and verbal communication skills
· Ability to operate in a fast-paced environment
· Strong interpersonal skills with a can-do attitude under challenging circumstances
· BA/BS or equivalent practical experience
Skills that would be a plus
· Perl, C++, ETL tools (Informatica, Talend, dbt etc.)
· Experience with Snowflake or other Cloud Data warehousing products
· Exposure with Workflow management tools such as Airflow
· Exposure to messaging platforms such as Kafka
· Exposure to NoSQL platforms such as Cassandra, MongoDB
· Building and Delivering REST APIs
Our benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.
About BlackRock
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being.  Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.
For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock
BlackRock is proud to be an Equal Opportunity Employer.  We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",USD 90K - 150K *
726,Data Scientist,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Experience in creating advanced statistical methods. Mine and analyze data, applying statistical methods as necessary, pertaining to customers’ discovery, and viewing experiences to identify and create critical insights
Research, develop and apply data science, machine learning, and statistical methods to large data sets. Mine data using modern tools and programming languages
Experience in creating statistical models and/or optimization frameworks for improving processes/products/profits
Translate analytic insights into concrete, actionable recommendations for business or product improvement
Create and deliver proof of concepts using state-of-the-art algorithms to demonstrate the value of our AI and ML solutions.
Partner closely with digital leaders throughout the lifecycle of project. Ensure that necessary data is captured; analytic needs are well-defined up front and coordinate the analytic needs
Should have independently handled a project technically and experienced in turning ideas into actionable designs
Maintain proficiency within the data science domain by keeping up with technology and trend shifts.
Qualifications
B.E/B.Tech
Additional Information
4 - 6 years of experience working as a data scientist
Extensive know-how of Python and R, experience in object-oriented programming languages with high code quality (Clean Code). Python environments, Jupyter notebooks.
Exploratory Data Analysis implementation and statistical concepts.
Solid understanding of Feature Engineering, Feature Selection.
Python libraries such as numpy, pandas, sklearn, pytorch, keras, scipy.
Proven track record in machine learning, neural networks, pattern analysis, time series forecasting, data analysis as well as data-pipeline technologies (e.g., Kubernetes, Docker, NoSQL-Databases, Workflow-Engine, Spark, Hadoop.)
Solid understanding of statistics; knowledge of Cloud Technologies (ideally Microsoft Azure) and SQL are beneficial
Excellent communication, presentation & cross-functional collaboration skills
  “To know more about Bosch Global Business Services, click here”
 ",USD 136K - 205K *
727,Senior Machine Learning Engineer - GenAI,Quantiphi,IN MH Mumbai Eureka,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Must have skills:
4+ years of relevant hands-on technical experience implementing, and developing cloud ML solutions on AWS.
Hands-on experience working with (Retrieval Augmented Generation) RAG architecture.
Hands-on experience fine-tuning large language models( LLM) and Generative AI (GAI), specifically LLama2. 
Strong familiarity with higher-level trends in LLMs and open-source platforms.
Should have experience with Deep Learning Concepts. Transformers, BERT, Attention models
Design, develop, and deploy Gen AI models and systems at scale, with a focus on real-world applications 
Implement and manage MLOps principles and best practices for Gen AI models
Hands-on experience on AWS Machine Learning services. Proven experience using AWS Sagemaker leveraging different types of data sources, Training jobs, real-time and batch Inference, and Processing Jobs. 
Experience with at least one of the workflow orchestration tools, Airflow, StepFunctions, SageMaker Pipelines, Kubeflow etc.
Proven experience in leveraging large sets of structured and unstructured data
Knowledge of a variety of machine learning techniques (Supervised/unsupervised etc.) (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Ability to collaborate with cross-functional teams such as Developers, QA, Project Managers, and other stakeholders to understand their requirements and implement solutions.
Ability to think creatively and work well both as part of a team and as an individual contributor

 Good to have skills:
Experience of working for customers/workloads in the Edtech domain with use cases. 
Experience with Recommender systems
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 150K - 230K *
728,AI/ML Engineer,Valeo,CHENNAI - CHE7-2,Mid-level / Intermediate,"Valeo is a tech global company, designing breakthrough solutions to reinvent the mobility. We are an automotive supplier partner to automakers and new mobility actors worldwide. Our vision? Invent a greener and more secured mobility, thanks to solutions focusing on intuitive driving and reducing CO2 emissions. We are leader on our businesses, and recognized as one of the largest global innovative companies.
● Develop and maintain NLP and machine learning solutions tailored to the organization's
specific needs.
○ Implement and fine-tune state-of-the-art models, particularly focusing on Local LLMs such as
Llama-2 and GPT4all.
○ Collaborate with the data team to understand and interpret data structures and needs.
○ Conduct rigorous model training, validation, and testing to ensure optimal performance.
○ Stay updated with the latest advancements in NLP and Generative AI research and methodologies.
○ Work closely with other technical teams to integrate NLP and AI solutions into broader systems or
platforms.
○ Skills: NLP and NLG, Spacy, BERT, Topic modeling, Named Entity recognition, POS tagging, Gen
AI, LLM, Text vectorization, multi-class classification, Machine learning Algorithms
● Creating data pipelines:
○ Read source data from different formats (excel, csv, txt, pdf etc) and transform the data using
suitable scripts in a way to bring out business value from the data
○ Load the data into servers ensuring good data quality, right quantity, technical accuracy and
sufficiency to meet project objectives
○ Prepare both structured and unstructured data to the right format to train machine learning
algorithms.
●
Proof of concepts:
○ Create quick Proof of concepts using Streamlite, Flask and other similar Front ends.
○ Take care of the functionality and version management of PoCs
○ Own the PoCs and help the deployment team to productionize the application.
Job:
R&D Engineer
Organization:
Product Technical
Schedule:
Full time
Employee Status:
Regular
Job Type:
Permanent contract
Job Posting Date:
2023-11-20
Join Us !
Being part of our team, you will join:
- one of the largest global innovative companies, with more than 20,000 engineers working in Research & Development
- a multi-cultural environment that values diversity and international collaboration
- more than 100,000 colleagues in 31 countries... which make a lot of opportunity for career growth
- a business highly committed to limiting the environmental impact if its activities and ranked by Corporate Knights as the number one company in the automotive sector in terms of sustainable development

More information on Valeo: https://www.valeo.com",USD 120K - 160K *
729,Software Engineer - Data Ops,Freshworks,"Bengaluru, India",Entry-level / Junior,"Company Description
Freshworks makes it fast and easy for businesses to delight their customers and employees. We do this by taking a fresh approach to building and delivering software that is affordable, quick to implement, and designed for the end-user. More than 50,000 companies -- from startups to public companies -- around the world use Freshworks software-as-a-service to enable a better customer experience (CRM) and employee experience (ITSM, HRSM).Headquartered in San Mateo, California, Freshworks has a dedicated team operating from 13 global locations to serve customers, including American Express, Sony, Vice Media, TaylorMade, Sotheby’s, Stitchfix, OfficeMax, Multichoice, Delivery Hero, ITV, and Klarna.Freshworks transforms the way world-class organizations collaborate with customers and co-workers. The suite includes Freshdesk (omnichannel customer support), Freshsales (sales automation), Freshmarketer (marketing automation), Freshservice (IT service desk), Freshteam (HR management system).
Job Description
We are looking for a candidate with 2+ years of experience in the below,
Oversee the day-to-day operations including monitoring, data observability, data ingestion, regular checks for issues, anomalies, and bottlenecks & issue resolution
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, etc
Implement monitoring systems and processes to track the performance and observability of data
Identify bottlenecks, and proactively address performance issues to ensure high availability and responsiveness
Lead data incident management processes, including data outages, breaches, or data-related disruptions
Work collaboratively with Data teams and ML teams on on any new/enhancement requests 
Should be willing to support month/week ends and work in flexible working hours when required 
Qualifications
Good knowledge in Data Structures and Algorithms
Good in SQL, and RDBMS concepts 
 Any one of the following programing languages, Scala, Python or Java 
Knowledge of Big data ecosystem
Good understanding of AWS or any cloud platform 
Additional Information
All your information will be kept confidential according to EEO guidelines.
At Freshworks, we are creating a global workplace that enables everyone to find their true potential, purpose, and passion irrespective of their background, gender, race, sexual orientation, religion and ethnicity. We are committed to providing equal opportunity for all and believe that diversity in the workplace creates a more vibrant, richer work environment that advances the goals of our employees, communities and the business.",USD 22K - 42K *
730,Tableau Developer / ETL,Salesforce,India - Hyderabad,Mid-level / Intermediate,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
ETL Data Warehouse Developer for CorpDev and M&A business

Business Technology connects people and technology to transform the future of work at Salesforce. Guided by our core values of Trust, Customer Success, Equality, Innovation, and Sustainability, we deliver business outcomes that fuel growth, drive competitive advantage, and empower our employees and customers globally. BT’s scope stretches beyond traditional IT: We are also strategic partners, advocating for the best outcomes for our customers, always innovating, and helping to shape the future of work.

We oversee technology strategy, Salesforce on Salesforce, customer and partner enablement, applications engineering, infrastructure, collaboration, enterprise operations, architecture, and program enablement. We are Customer Zero, the best example of Salesforce products delivered globally, at scale, sustainably.

Salesforce’s Corporate Development team supports critical business data and insights leveraging key Salesforce data to track and provide visibility into highly consumed data. As a Data Engineer, you’ll be a critical part of the development and enhancement of an innovative data environment by leveraging industry best practices and cutting edge approaches. You’ll collaborate with engineering to nail-down the data infrastructure, and with our business partners within the organization to anticipate data needs, and proactively develop data solutions to address the toughest business problems. In short, you'll be building the foundation that allows the rest of the organization to understand our users and turn it into actionable steps to make our product even better and our business run smoother.

Our ideal candidate isn’t satisfied until a project is seen through to meaningful impact. If you love working with data and want to see your work impact the entire organization, we want to talk to you!

What you’ll do:
Work alongside and support a talented team of data engineers.
Build and maintain scalable automated data pipelines ground up. Be an expert of stitching and calibrating data across various data sources.
Work with Salesforce’s data ingestion, data platform and product teams to understand and validate instrumentation and data flow.
Develop data set processes for data modeling, mining and production.
Integrate new data management technologies and software engineering tools into existing structures
Support regular ad-hoc data querying and analysis to better understand customer behaviors.
Understand, monitor, QA, translate, collaborate with business teams to ensure ongoing data quality.

What a successful candidate will have:
5+ years experience designing, implementing and maintaining relational / data warehousing environments (custom or structured ETL, preferably working with large data environments)
3+ years experience in robust ETL tools such as Informatica
2+ years experience with hands on experience using Snowflake
1-3 years experience with developing robust and tested Python applications to support the data warehouse
Experience working with Linux and debugging performance issues.
Strong background in Data Warehousing concepts and schema design
Experience implementing and managing Python open source data tooling such as Airflow, DBT, SQLAlchemy, pandas, Jupyter
History of designing, building and launching extremely efficient & reliable data pipelines to move data (both large and small amounts) throughout a Data Warehouse.
Hands-on expertise in modern cloud data platforms (Snowflake, Databricks, Big Query, RedShift), data analytics tools (Tableau, Looker, Power BI), data programming models (DataFrames, pandas), and AI (Python, R, Jupyter Notebooks).
Must exhibit strong communication skills, empathy, and initiative
Work close with business stakeholders and engaged maturing the working relationship between engineering and the business
Additional desired skills:
Corporate Development and M&A subject matter expertise
Snowflake Certifications is a plus
CorpDev and M&A subject matter expertise
Emphasis on Python and Snowflake
Engineer to work closer with business stakeholders and more engaged in that working relationship at a higher level than initial role
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 30K - 56K *
731,"Process Specialist, Product & Supply Master Data Management",Diageo,Bengaluru Karle Town SEZ,Senior-level / Expert,"Job Description :
Context / Scope
Global Diageo Business Services (GDBS) is a global multifunctional shared service entity that processes DIAGEO-wide transactions across various world regions. Processes in scope are: Order to Cash (OTC), Source to Pay (STP) and Record to Report (RTR) and Data Services (MDM).
Diageo also has Captive Centers that support service provision in Global markets. GDBS is a multicultural, multi-language and matrixed environment.
A program is underway to establish a Captive Service Centre in Bangalore to service global markets.
The Data Service Stream in GDBS provides master data services which inclusive of data compliance and maintenance activities for GDBS served countries. This is being realized in cross-market and end-to-end functional responsibilities with the aim to continue the great steps forward that have been achieved in FY16 by the Data community.
The Data Service stream underpins and enables the proper operation of the business processes by ensuring timely, accurate, compliant, and relevant master data maintenance – processes being STP, OTC, RTR, ETEC, HRO, Supply chain. Master data maintenance in scope for the team are: Vendor, Customer, Finance, Commercial, Employee and Product & Supply master data.
The Master Data Services supporting & serves multiple markets / countries across the globe Diageo operating business.
Dimensions
The role is responsible for a specific area of Master Data maintenance across GDBS served markets.
Market Complexity
The role would entail responsibility for the step change, standardization, and process harmonization of Master Data maintenance across GDBS served countries.
Purpose of Role
The purpose of this role is to complete the creation and amendment of Customer/Vendor/Employee/Product/Supply/Finance Master Data in SAP for relevant markets within the agreed lead-times, and while maintaining business compliance. The role will also involve some business reporting.
Diageo Capabilities
Be authentic – Maintain great relationships with internal partners and communicate in the right way. Stand for process quality and compliance.
Find solutions – The role involves processing critical data requests under significant time pressure to agreed timelines. The candidate should be pro-active and highlight opportunities to improve processes where possible.
Consistently deliver great performance – The role holder must be a self-starter and have strong prioritisation skills, staying focused on what business outcomes need to be delivered. They must demonstrate brilliant execution in all aspects of the role. Attention to detail, rigour and structure is critical.
Lead People for Success– The role involves dealing with a large number of requests from various teams. The candidate should be able to work with challenging demands from different partners.
Top 3-5 Accountabilities
Data Maintenance
Create, maintain Master Data based on authorised business requests, according to the relevant policies and procedures
Review Master Data Quality to ensure data is accurate and complete.
Work with the Data & Information Governance team to ensure Diageo standard methodology for data quality is implemented.
Achieve individual goals including daily task, turnaround time, accuracy, and knowledge in the business process.
Procuring approval for exception requests such as DUTY, TAX, etc.,
e2e Knowledge in Product & supply along with planning scope
Perform testing in SAP test environment on any new technical change in system
e2e ownership on the controls specified to the tasks
Backup for Team Leader
Operational Reporting
Complete and issue data-oriented reporting as requested on a timely basis
Process Improvement
Identify and pursue opportunities to streamline processes and increase process compliance with our partners
Training and Capability Enhancement
Train new team members and provide basic insight for partners on Data related processes in SAP
Evaluate level of Right First Time requests versus rejections to identify any capability gaps to be addressed
Qualifications and Experience Required
Essential
Fluency in English
4-6 years’ meaningful work experience Product & supply master domain
Working knowledge on PLM/SAP application
Working knowledge on Product & supply master tools such as PLM/SAP, APO & any other Master data maintenance systems
Understanding of Product master SLA’s, Generating required reports, and review with partners.
Excellent in working on MS office application
Should have adequate knowledge about process improvements tools and technologies (like MDS, etc.,)
Attention to Detail/Accuracy - Demonstrates sound commitment to importance of “Right First Time” principle through ensuring own work is 99% error free
Ability to work in a complex multi-functional or multinational environment
Basic Knowledge to navigate the ticketing portal and more specific to Material Master domain
SAP knowledge for Material master including planning scope
Review of supporting documents related to maintenance activity
Perform Material master Creation/Amendment/Deletion in SAP
Update and maintain critical information (such as DUTY, TAX, etc.,)
Publishing report on monthly basis to Governance/market & management
Query handling by coordinating with market data-coordinator, Data governance or relevant stakeholder across various region(s)
Periodical review of DTP to foresee any process deviation/updates for specific market/Global
Perform testing in SAP test environment on any new technical change in system
e2e ownership on the controls specified to the tasks
Trainer for all new joiners & work as a coach within team
Ability to work quickly and accurately under pressure
Pro-active approach
Solid grasp of data management disciplines and their business benefits
Strong presentation and partner management skills
Highly energetic / self-motivated person
Efficient of addressing the root cause of the issue for all customer concern from market
Ownership of all controls for all the tasks which we carried
Strong knowledge to simplify and standardize the existing process
Work towards the process automation, system enhancement, etc.,
Backup for Team Leader
Desirable:
Demonstrated energy and aim to make a difference in the data role.
Prior business experience preferable
Good communication skills, able to explain processes or reasons clearly and concisely for data request rejection
Knowledge of SAP would be an advantage
Strong excel (macro preparation) experience
Very Good presentation skills to Data governance/key partners
Barriers to Success in Role (Optional)
Lack of rigour and attention to detail, or an ability to work at pace.
Lack of communication skills or ability to build good professional relationships.
Inability to work with a broad set of partners functionally and culturally.
Lack of English fluency
Inability to work assertively and proactively
Not a teammate
Inability to aim for resolution
Insufficiently open minded
Flexible Working Options
Based on market requirements
Additional Requirements (Based on process)
Basic Knowledge about e2e supply chain function
Understand the strategy about Logistics/Move process
Understanding of Transport Management working methodology across Material, Customer & Vendor domains
Knowledge on Create/Maintain of Hubs, Customer Locations, Docks, Carriers & Tariff
Ability to solve the uploading issues within Transport management system
Knowledge in create/maintain of any Product Hierarchy in PLM/SAP application
Validation of existing and any new Brand in system on the products
PLM workflow handling knowledge (Addition, Deletion & Cancel)
Supports to business on handling additional Product & supply scope of activities (tax code update, stock valuation, obsoletion, etc.,)
Knowledge in MS access database is key
Worker Type :
Regular
Primary Location:
Bangalore Karle Town SEZ
Additional Locations :
Job Posting Start Date :
2023-12-07",USD 45K - 84K *
732,"Senior Data Engineer - MySQL, SSIS, SSRS",Quantiphi,IN KA Bengaluru,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Job Profile: Senior Data Engineer
Experience: 3+ Years
Location: Mumbai/Bangalore/Trivandrum
Must Have Skills: 
Qualification : Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent experience). 
Experience : Minimum of 2 years of experience as a Data Engineer with a strong command of SQL Script and SSIS. 
Good knowledge of advanced SQL concepts, SSIS scripting and Optimization techniques
Working knowledge with SQL databases like SQL Server, Oracle, Postgresql, etc. is mandatory 
Good knowledge of Data Migration like migration from on premise database to cloud or one cloud to another 
Understand Architecture Requirements and ensure effective design, development, validation, and support activities. 
Data Integration: Develop and maintain ETL processes using SQL Server Integration Services (SSIS) to extract, transform, and load data from diverse sources into MS Azure Database
Data Quality: Implement data quality checks and monitoring mechanisms to identify and address data anomalies and inconsistencies. 
Performance Tuning: Optimize SQL queries, ETL workflows, and data pipelines to enhance system performance and minimize processing times. 
Data Documentation: Maintain comprehensive documentation of data sources, ETL processes, and data models to facilitate knowledge sharing and collaboration
Security: Implement and uphold data security protocols to safeguard sensitive information and ensure compliance with data privacy regulations. 
Azure Expertise: Should be able to design and develop Azure Database and Data Warehouse, Azure SQL Script, migrating data from on premises to Azure Cloud database. (Mandate requirement) 
Collaboration: Collaborate closely with data analysts, data scientists, and business stakeholders to understand data requirements and deliver data solutions that align with business needs. 
Familiarity with data warehousing concepts and best practices 
Good to have skills: 
Knowledge of BI tools 
Knowledge of working with streaming pipelines 
Knowledge of data warehousing, data modeling and concepts like OLAP and OLTP
AWS certification(s) is a plus 
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 121K - 190K *
733,Lead-Data Analysis,Tesco Bengaluru,"Bengaluru, India",Senior-level / Expert,"Company Description
Tesco Bengaluru
We are a multi-disciplinary team creating a sustainable competitive advantage for Tesco by standardizing processes, delivering cost savings, enabling agility, providing cutting-edge technological solutions and empowering our colleagues to do ever more for our customers. With cross-functional expertise in Global Business Services and Retail Technology & Engineering, a wide network of teams and strong governance we reduce complexity thereby offering high quality services for our customers. Tesco Bengaluru, established in 2004 to enable standardization and build centralized capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 4,40,000 colleagues.
At Tesco Business Solutions, we have a mission to simplify, scale & partner to serve our customers, colleagues and suppliers through a best-in-class intelligent Business Services model . We do this by building a world class business services model by executing service model framework right at the heart of everything we do for our worldwide customers. The key objective is to implement and execute service model across all our functions and markets consistently. The ethos of business services is to free-up our colleagues from a regular manual operational work. We use cognitive technology to augment our key decision making. We also built a Continuous Improvement (CI) culture across functions to drive bottom-up business efficiencies by optimizing processes. Business services colleagues need to act as a business partner with our group stakeholders to build a collaborative partnership driving continuous improvement across markets and functions to lead the best customer experience by serving our shoppers a little better every day.
At Tesco, inclusion means that Everyone's Welcome. Everyone is treated fairly and with respect; by valuing individuality and uniqueness we create a sense of belonging.
Diversity and inclusion have always been at the heart of Tesco. It is embedded in our values: we treat people how they want to be treated. We always want our colleagues to feel they can be themselves at work and we are committed to helping them be at their best.
Across the Tesco group we are building an inclusive workplace, a place to actively celebrate the cultures, personalities and preferences of our colleagues, who in turn help to build the success of our business and reflect the diversity of the communities we serve.
 Job Description
Analyse complex data sets using Business Intelligence tools; data modelling techniques and Commercial Retail analytics expertise. Work across all functions irrespective of geography to support to define and solve business problems using Big data analytics. Make it consumable using visual storytelling and visualization tools such as reports and dashboards built using approved tools (Tableau; PyDash)
-Represent Talent Acquisition in all forums/ seminars pertaining to process; compliance and audit
-Perform other miscellaneous duties as required by management
-Driving CI culture; implementing CI projects and innovation for withing the team
-Driving Data analysis for testing key business hypothesis and asks; developing complex visualizations; self-service tools and cockpits for answering recurring business asks and measurements
- Experience in handling quick turnaround business requests; leading partner communication and solving business asks holistically going beyond the basic partner asks
- Ability to select the right tools and techniques for solving the problem in hand
- Ensuring analysis; tools/ dashboards are developed with the right technical rigor meeting Tesco technical standards
- Applied experience in handling large data-systems and datasets
- Extensive experience in handling high volume; time pressured business asks and ad-hocs requests
- Ability to develop production ready visualization solutions and automated reports
- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki
- Understands business needs and in depth understanding of Tesco processes
- Help mentor team members and guide daily work and projects to meet encouraged performance metrics
- Come up with new insights and analysis to support business priorities and solve business problems
- Draw Entity Relationship diagrams by exploring & mining data required for Solution building & analysis
- Assist in Designing the Data modelling; Data engineering & work flow automations
- Continuously analyse the data from different sources and use analytics to detect leakages & flaws in the Engines; Investigate tables; data and processes for inaccuracies and missing data to ensure accuracy and Perform accurate promotion funding calculations and analysis
Qualifications
Strong understanding of Business Decisions; Expert Skills to analyze large datasets using Adv Excel; Adv SQL; Hive; Phython; Expert Skills to develop visualizations; self-service dashboards and reports using Tableau & Statistical Concepts (Correlation Analysis and Hyp. Testing); Strong DW concepts (Hadoop; Teradata); Strong Automation skills in using alteryx/python
Additional Information
Last Date of Application- 9th Dec 2023
Important Notice: 
On behalf of Tesco Bengaluru, we must caution all job seekers and educational institutions that Tesco Bengaluru does not authorise any third parties to release employment offers or conduct recruitment drives via a third party. Hence, beware of inauthentic and fraudulent job offers or recruitment drives from any individuals or websites purporting to represent Tesco. Further, Tesco Bengaluru does not charge any fee or other emoluments for any reason (including without limitation, visa fees) or seek compensation from educational institutions to participate in recruitment events. 
Accordingly, please check the authenticity of any such offers before acting on them and where acted upon, you do so at your own risk. Tesco Bengaluru shall neither be responsible for honouring or making good the promises made by fraudulent third parties, nor for any monetary or any other loss incurred by the aggrieved individual or educational institution. 
In the event that you come across any fraudulent activities in the name of Tesco Bengaluru, please feel free report the incident at recruitment_compliance_india@tesco.com ",USD 45K - 84K *
734,Senior Consultant Data Engineer – Cloud,Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Ready to make a global impact by industrializing AI?
 Visa AI as a Service (AIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, AIaS powers and automates industrialization of data, models, and applications for predictive and generative AI. Combined with strong governance, AIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!
 This role is for a Senior Consultant Data Engineer – Cloud, with a strong development background, whose primary objective will be to extend our AI as a Service platform to the Public Cloud while enhancing, optimizing our existing codebase and development procedures, as well as developing new solutions. We are seeking for an experienced professional with a solid background in public cloud and AI/ML production systems.
 The ideal candidate will have a strong mix of hands-on technical knowledge and leadership skills, with the ability to inspire and drive the team towards achieving our technical objectives They should be hands-on, knowledgeable about cloud technologies, business drivers, and emerging AI/ML trends, and experienced with public cloud services such as AWS, GCP and Azure. The role demands a proactive leader who can guide the team through uncertainty, educate stakeholders, and influence decisions as needed. The candidate should possess strong interpersonal skills, excellent written and verbal communication, and the ability to handle complex projects and deadlines. A problem-solving mindset and a hands-on approach are key to succeeding in this role.
 This role offers ample opportunities for learning and growth, and the chance to be part of delivering the next big thing for our AI as Services team. If you are experienced and passionate about cloud technology, AI, and machine learning, and are excited about making a significant impact, we would love to hear from you.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications
10 years of relevant work experience with a bachelor’s degree or 8 years of relevant work experience with an advanced degree (e.g., Masters, MBA, JD, MD) or 3 years relevant work experience with a PhD.

Preferred Qualifications
5 or more years of related hands-on experience in delivering robust and scalable solutions on public cloud platforms such as AWS, Google Cloud Platform, and Microsoft Azure, preferably in an AI/ML production environment.
Expertise in one or more of Golang, Java, Rust and C/C++.
Proven hands-on experience in delivering robust and scalable solutions on public cloud platforms such as AWS, Google Cloud Platform, or Microsoft Azure.
Strong understanding of cloud architecture and service offerings including compute, storage, databases, networking, AI, and ML.
Experience in Cloud AI/ML Solutions such as - AWS Sagemaker, Comprehend, GCP AutoML etc.Expertise in AWS EKS, ElasticCache, CloudWatch
Strong cloud security and best practices for cloud infrastructure management.
Experience in Cloud Big Data Services.
Demonstrated expertise in designing, developing, and deploying cloud-based applications.
Proven knowledge of successful design, and development of data driven real time and batch systems.
Hands-on with Ray (on-prem, K8s, AWS, GCP or Azure)
Strong System Design / Software Design Skills
Well versed with common software development tools, CICD, Agile methodologies and scrum practices
Professional Cloud Provider Certifications in infrastructure , solutioning and AI/ML platforms shall be a plus.
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
735,Project Assistant - Power BI Developer - Gurugram,Turner & Townsend,"Gurugram, India",Senior-level / Expert,"Company Description
Who is Turner & Townsend?
All over the world people are using buildings, infrastructure, and assets we helped to deliver. It could be the hospital they work in, the railway they travel on every day, the fuel that powers their car or the data centre they depend on at work. For more than 75 years we’ve been helping to deliver transformational programmes across the real estate, infrastructure and natural resources sectors, making a difference to people’s lives and ensuring a return on investment for our clients and their investors.
Our purpose:
Transforming performance for a green, inclusive, and productive world.
The world is changing and we have a responsibility to support that change, helping drive it and be part of it. Through the commitment, capability and care our team brings, we build trust between clients, suppliers, governments and society. Delivering better outcomes that have a positive impact on the world around us. We work smarter to face the challenges of the future; bringing the clarity that helps teams realise their full potential across the real estate, infrastructure and natural resources sectors. It’s how we’ve made the difference for more than 75 years.
Our values:
Love a challenge: We love a challenge and we work hard to make change happen and see things through. We don’t stand still, challenging ourselves and others to do better every day. And we are trusted to do the right thing, raising standards all the time.
Stronger together: We’re stronger together by connecting people in diverse teams, so that we can all collaborate to deliver our best work. We focus on what matters and use our influence to build a better world for everyone.
Bring out the best in everyone: We bring out the best in everyone. We help each other to make the most of our potential, always learning from our experience. We treat each other with care and respect and make time to give everyone a voice
Job Description
Main purpose of position:
Power BI and Digital reporting for all our projects and new clients.
Key responsibilities:
Prepare and Monitor Power BI reports.
Customize Power BI reports as per client requirements.
Implement data capturing process via Power Platforms
Prepare and Monitor Digital reports.
Qualifications
Graduate,
Good command on Power BI, DAX, Data analysis
Good communication skills.
Additional Information
Our inspired people share our vision and mission. We provide a great place to work, where each person has the opportunity and voice to affect change.
We want our people to succeed both in work and life. To support this we promote a healthy, productive and flexible working environment that respects work-life balance. 
Turner & Townsend is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees and actively encourage applications from all sectors of the community.
Please find out more about us at www.turnerandtownsend.com/
 Join our social media conversations for more information about Turner & Townsend and our exciting future projects: 
Twitter
Instagram
LinkedIn
It is strictly against Turner & Townsend policy for candidates to pay any fee in relation to our recruitment process. No recruitment agency working with Turner & Townsend will ask candidates to pay a fee at any time. 
Any unsolicited resumes/CVs submitted through our website or to Turner & Townsend personal e-mail accounts, are considered property of Turner & Townsend and are not subject to payment of agency fees. In order to be an authorised Recruitment Agency/Search Firm for Turner & Townsend, there must be a formal written agreement in place and the agency must be invited, by the Recruitment Team, to submit candidates for review. ",USD 85K - 135K *
736,Senior Data Engineer,insightsoftware,"Hyderabad, India",Senior-level / Expert,"Company Description
 insightsoftware is a leading provider of reporting, analytics, and performance management solutions. Over 30,000 organizations worldwide rely on us to support business needs in the areas of accounting, finance, operations, supply chain, tax, budgeting, planning, HR, and disclosure management. We enable the Office of the CFO to connect to and make sense of their data in real time so they can proactively drive greater financial intelligence across their organization. Our best-in-class solutions provide customers with increased productivity, visibility, accuracy, and compliance. Learn more at insightsoftware.com.
Job Description
Develops and maintains scalable data pipelines for bulk data movement between systems of record and systems of reference
Develops and maintains scalable application to application integrations
Aligns initiatives between business teams and technical teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization
Implements processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes
Writes appropriate unit or integration tests to implement test-driven development
Continually contributes to and enhances data team documentation
Performs data analysis required to troubleshoot and resolve data related issues
Works closely with a team of frontend and backend engineers, product managers, and analysts
Defines company data assets, artifacts and data models
Qualifications
Required qualifications:
5 years of Data Engineering and Data Integration
5 Years of Data Warehousing
3 Years of Data Architecture and Modeling
2 years of Cloud Data Engineering
Agile Methodologies
Preferred skills:
AWS or Azure Data Certifications
Experience with databricks, spark, python
Experience with Microsoft stack (SQL Server, SSIS, PowerBI, etc)
Experience with Salesforce
Additional Information
All your information will be kept confidential according to EEO guidelines.
** At this time insightsoftware is not able to offer sponsorship to candidates who are not eligible to work in the country where the position is located. **
insightsoftware About Us: Hear From Our Team - InsightSoftware (wistia.com)
Background checks are required for employment with insightsoftware, where permitted by country, state/province.",USD 121K - 190K *
737,Power BI Developer/Analyst,Sopra Steria,"Kanchipuram, Tamil Nadu, India",Entry-level / Junior,"Company Description
About Sopra Steria
Sopra Steria, major Tech player in Europe recognised for its consulting, digital services and software development, helps its clients drive their digital transformation and obtain tangible and sustainable benefits. It provides end-to-end solutions to make large companies and organisations more competitive by combining in-depth knowledge of a wide range of business sectors and innovative technologies with a fully collaborative approach. Sopra Steria places people at the heart of everything it does and is committed to putting digital to work for its clients in order to build a positive future for all. With 50,000 employees in nearly 30 countries, the Group generated revenue of €5.1 billion in 2022.
The world is how we shape it.
Job Description
A good Knowledge of Power BI in the below aspect and other BI tools and technologies.
Knowledge of Power BI Desktop / Power Query /Power BI Service
How to connect with different data sources & connectivity with Databases (Online portal, O365 platforms, APIs, SQL, Azure Data Factory, Data warehouse & Data lakes)
How to build the interactive visualization and how to import and use the market-based visuals on the power Bi report
Expertise in Data Modelling concepts and creating models based on different data sources.
Knowledge of managing or creating Dataflows
Understand and create a workspace on Power Bi service/ manage space in Workspace
Knowledge of On-Premises Data Gateway.
Publish the app and report in Power – Bi with the scheduled refresh
Assign user access and apply Row & Page Level Security in Power BI
How to connect with Third Party applications with Power BI
Knowledge of different databases used with Power BI
Hands-on experience in Python or R should be able to connect data sources with the help of Python or R wherever applicable.
Proficiency in MS Office Tools should be well-versed with MS Excel functions, VBA Macros, and automation tools.
Experience in Microsoft Automate and Microsoft Power Apps will be a plus
Total Experience Expected: 04-06 years
Qualifications
B.E/B.Tech/MCA
Additional Information
At our organization, we are committed to fighting against all forms of discrimination. We foster a work environment that is inclusive and respectful of all differences.
All of our positions are open to people with disabilities.",USD 22K - 42K *
738,Lead NLP Engineer,Increasingly,"Bengaluru, India",Senior-level / Expert,"Company Description
About Increasingly
Increasingly is an award-winning, fast-growing retail technology company focused specifically on the automation of cross-selling for online retailers.
Our clients include large global corporations like Samsung & Canon to several small to medium size retailers across the globe. Our AI-based algorithms help a customer buying a TV on Samsung to find the matching sound bar & purchase both together.
Increasingly is headquartered in London with offices in Lisbon & Bangalore. We work with clients in over 30 countries & 20 languages.
We are looking to rapidly expand our technology & product development operations in India. And we need smart, ambitious people like you who enjoy a fun yet challenging work environment.
We believe strongly that diversity & inclusion are the foundations for a lasting, incredible culture. We also believe that it’s important to get the balance right between work & life.
Job Description
NLP Engineer responsibilities include transforming natural language data into useful features using NLP techniques to feed classification algorithms. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques.

Responsibilities
Your ultimate goal is to develop efficient self-learning NLP Search.
You will design NLP search algorithms & proof of concepts.
You will select appropriate annotated datasets for Supervised Learning methods
You will use effective text representations to transform natural language into useful features
Find and implement the right algorithms and tools for NLP tasks
Develop NLP systems according to requirements
Train the developed model and run evaluation experiments
Perform statistical analysis of results and refine models
Extend ML libraries and frameworks to apply in NLP tasks
Study and transform data science prototypes
Qualifications
We would love it if you have
BS/MS in Computer Science, Mathematics, Computational Linguistics or similar field
Must have 7+ years in elastic search
2+ years of proven experience as an NLP Engineer 
NLP techniques for text representation, semantic extraction techniques, data structures and modeling
Ability to effectively design software architecture
Deep understanding of text representation techniques (such as n-grams, a bag of words, sentiment analysis etc), statistics and classification algorithms
Good to have: Knowledge of Python, Java and R
Ability to write robust and testable code
Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
An analytical mind with problem-solving abilities
Additional Information
What are the benefits
You'll get to work in one of the hottest & fastest-growing retail technologies in Europe right now.  
You'll get paid a competitive salary & be working directly with a super-experienced team of people.  
You'll get a great place to come to work every day. Varied, complex, challenging & with a great culture that you can shape & change. 
Group Health Insurance",USD 71K - 210K *
739,Senior Data Analyst,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
When you’re one of us, you get to run with the best. For decades, we’ve been helping marketers from the world’s top brands personalize experiences for millions of people with our cutting-edge technology, solutions and services. Epsilon’s best-in-class identity gives brands a clear, privacy-safe view of their customers, which they can use across our suite of digital media, messaging and loyalty solutions. We process 400+ billion consumer actions each day and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon India is now Great Place to Work-Certified™. Epsilon has also been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Positioned at the core of Publicis Groupe, Epsilon is a global company with more than 8,000 employees around the world. For more information, visit epsilon.com/apac or our LinkedIn page.
Job Description
The Auto practice within Epsilon accelerates and drives growth for major players of the automotive industry, from Original Equipment Manufacturers (OEM) to Dealers big and small in the US and Canada. Part of a 1,600-member global team, the practice offers the automotive world’s largest service reminder platform along with agency services and digital media solutions. A leader in the automotive space, the team supports over 50% dealers in the US and manages 280M+ customer vehicle relations. Our Auto team is home to innovative thoughts, latest in technology and is always at the front of learning new. The Automotive Analytics team within Epsilon partners with internal and external clients and data providers, leveraging advanced statistical and data management techniques to drive strategic thought and effective decision making. The Senior Data Analyst manages analytic initiatives from conception to completion, providing clients and key stakeholders actionable results and insights that help them achieve their business objectives. This role requires a strong analytical mindset, being able to take large datasets and use statistical methodologies to solve business problems. 
Role Responsibilities:
Drive analytical projects employing various statistical methodologies and software packages.
Serve as the day-to-day contact for project phases from kick-off to presentation of results.
Explore data requirements, integrates data from multiple sources using programming scripts to produce required data elements.
Prepare reports, uncovering insights and developing business recommendations based on data findings and effectively present that to key internal and external stakeholders.
Bring in value addition and innovation to the existing or new process/projects by researching new ways of doing things.
Follows the best practices of programming, reporting, dashboarding, project documentation, and system management.
Ensures data integrity and accuracy through rigorous testing and quality control processes, inspiring confidence in the analysis results.
Collaborates within and cross teams to gather details and deliver results to stakeholders.
 Qualifications
Master’s or Bachelor’s degree in engineering or quantitative discipline (Statistics, Economics, Mathematics, Analytics, Data Science).
5-7 years of hands-on coding skills in Python, SAS, SQL, PySpark
4+ years of experience working on Apache Spark, DBMS (Oracle, SQL Server)
4+ years of experience in Reporting, Dashboarding and Presenting Insights.
Good knowledge of Statistical concepts. Machine Learning knowledge is a plus.
Deep knowledge of Primary and Secondary Market Research
Telecom B2B marketing experience/knowledge preferred.
Good experience in visual representation of data, presentation, and storytelling skills.
Excellent communication skills and able to build good working relationship with clients.
Flexibility to work in a virtual environment with stakeholders in US time zones.
Exhibit technical acumen and possess good learning mindset.
Highly motivated and collaborative team player with good interpersonal skills.
 ",USD 92K - 145K *
740,Senior Machine Learning Engineer,Quantiphi,IN MH Mumbai Eureka,Senior-level / Expert,"While technology is the heart of our business, a global and diverse culture is the heart of our success. We love our people and we take pride in catering them to a culture built on transparency, diversity, integrity, learning and growth.


If working in an environment that encourages you to innovate and excel, not just in professional but personal life, interests you- you would enjoy your career with Quantiphi!
Be(come) a Machine Learning expert and lend your skill set to solving tough business problems Interface with client companies to understand their business pain points and identify where data science and analytics can be the solution Develop high-level solution architectures and work with our offshore team to build, test, and assess models to predict and optimize business outcomes Work closely with the offshore delivery manager to ensure a seamless delivery and communication cadence Communicate complex concepts and insights in a clear and interpretable manner Maintain an entrepreneurial spirit as you learn new ways to solve problems
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",USD 150K - 230K *
741,Data Engineer,Autodesk,APAC - India - Bengaluru - Sunriver,Mid-level / Intermediate,"Job Requisition ID #
23WD74051
Position Overview
We are looking for an exceptional data engineer to transform, optimize, test, and maintain architectures for enterprise analytics databases, data pipelines, and processing systems, as well as optimizing data flow and collection for teams. The mission of the team is to empower decision makers and the broader data communities through trusted data assets and scalable self-serve analytics. The focus of your work will be engineering new pipelines and maintaining, creating frameworks, enhancing existing data pipeline with new features to ensure accurate data delivery to stakeholders in a timely manner, also support ad-hoc reporting requirements that facilitate data-driven actionable insights at Autodesk.
Responsibilities
Maintain/develop data pipelines required for the extraction, transformation, cleaning, pre-processing, aggregation and loading of data from a wide variety of data sources using Python, SQL, DBT, other data technologies
Design, implement, test and maintain data pipelines/ new features based on stakeholders' requirements
Develop/maintain scalable, available, quality assured analytical building blocks/datasets by close coordination with data analysts
Optimize/ maintain workflows/ scripts on present data warehouses and present ETL
Design / develop / maintain components of data processing frameworks
Build and maintain data quality and durability tracking mechanisms to provide visibility into and address inevitable changes in data ingestion, processing, and storage
Translate technical designs into business appropriate representations and analyze business needs and requirements ensuring implementation of data services directly correlates to the strategy and growth of the business
Focus on automation use cases, CI/CD approaches and self-service modules relevant for data domains
Address questions from downstream data consumers through appropriate channels
Create data tools for analytics and BI teams that assist them in building and optimizing our product into an innovative industry leader
Stay up to date with data engineering best practices, patterns, evaluate and analyze new technologies, capabilities, open-source software in context of our data strategy to ensure we are adapting, extending, or replacing our own core technologies to stay ahead of the industry
Contribute to Analytics engineering process
Minimum Qualifications
Bachelor's degree in computer science, information systems, or a related discipline
3+ years in the Data Engineer role
Built processes supporting data transformation, data structures, metadata, dependency, data quality, and workload management
Experience with Snowflake, Hands-on experience with Snowflake utilities, Snow SQL, Snow Pipe. Must have worked on Snowflake Cost optimization scenarios.
Overall solid programming skills, able to write modular, maintainable code, preferably Python & SQL
Have experience with workflow management solutions like Airflow
Have experience on Data transformations tools like DBT
Experience working with Git
Experience working with big data environment, like, Hive, Spark and Presto
Strong analytical, problem solving and interpersonal skills
Familiar with Scrum
Ready to work flexible European hours
Preferred Qualifications
Snowflake
DBT
Fivetran
Airflow
CI/CD (Jenkins)
Basic understanding of Power BI
AWS environment, for example S3, Lambda, Glue, Cloud watch
Basic understanding of Salesforce
Experience working with remote teams spread across multiple time-zones
Attention to detail
Have a hunger to learn and the ability to operate in a self-guided manner
#LI-DA1
Learn More
About Autodesk
Welcome to Autodesk! Amazing things are created every day with our software – from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.
We take great pride in our culture here at Autodesk – our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.
When you’re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!
Salary transparency
Salary is one part of Autodesk’s competitive compensation package. Offers are based on the candidate’s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package.
Diversity & Belonging
We take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https://www.autodesk.com/company/diversity-and-belonging
Are you an existing contractor or consultant with Autodesk?
Please search for open jobs and apply internally (not on this external site).",USD 90K - 150K *
742,Geospatial Data Scientist,Blue Sky Analytics,"Gurugram, Haryana, India",Senior-level / Expert,"Blue Sky Analytics is a Indo-Dutch firm specialised in converting satellite data into environmental & climate intelligence for use cases in Climate Risk Analytics, Asset Monitoring and Carbon Markets for banks, financial institutions, insurance firms, corporates and players in the carbon market value chain.
In simpler terms, we:
Compile physical risk parameters into extensive climate risk analytics.
Digitally monitor construction of roads, highways, real estate assets, solar plants, transmission lines etc,
Digitally monitor deforestation, afforestation, changes related to health of forests, nature based carbon projects, or
also monitor global water bodies like rivers and lakes, predict floods & droughts,
monitor wildfires, area burnt, etc
We are a remote-first team (data scientists, Engineers, Sales & Marketing) based in Gurugram, Mumbai and The Hague, with teams also spread across India. Awarded for our innovation in Space/ Climate/AI & Data by Bloomberg, Forbes, Fast Company, MIT, Times, The Tech for Global Good, Space Oscars, and recently by World Economic Forum, Blue Sky Analytics is rapidly growing its client portfolio in Asset Monitoring, Climate risk and Carbon Markets, serving various global clients with high quality high resolution historical and ongoing monitoring, reporting, and verification (MRV) along with detailed climate risk analytics.
What will I be doing?
Handle large amounts of image and location datasets.
Develop data frames and automated pipelines for data from multiple sources.
Visualise datasets and employ machine learning algorithms for predictive analysis.
Collaborate across teams to ensure seamless execution of tasks.
Curate and analyse geospatial datasets, including satellite imagery, elevation data, meteorological datasets, openstreetmaps, demographic data, socio-econometric data, and topography.
Extract valuable insights about events and phenomena occurring on our planet.
Create processes and tools to monitor and analyse data accuracy.
Innovate algorithms for tracking global environmental issues such as depleting water levels, illegal tree logging, and oil spills.
Utilise geospatial libraries (GDAL/Rasterio) for data reading and writing.
Apply GIS software (QGIS) for visualisation and query purposes.
Implement advanced statistical techniques, regression, and other statistical tests.
Produce maps showcasing spatial distribution of various data, including emission statistics and pollution hotspots.
Generate reports containing maps, visualisations, and resources developed during dataset management.
Requirements
What skills and experience do I need?
Excellent coding skills in Python, including proficiency with NumPy, SciPy, and pandas.
Significant experience with git, GitHub, SQL, and AWS (S3 and EC2).
Hands-on experience with geospatial libraries like GDAL and rasterio.
Proficient in GIS software such as QGIS for visualisation and query.
Practical experience with basic machine learning algorithms for predictive analysis.
Demonstrable experience in implementing efficient neural network models and deploying them in a production environment.
Knowledge of advanced statistical techniques, concepts (regression, properties of distributions), and their practical applications.
Capable of writing clear and insightful reports, making complex data accessible to diverse audiences.
Minimum of 2 years of demonstrable industry experience working with large and noisy datasets.
Curiosity and genuine care about environmental issues and the planet.
Benefits
Remote Work: You have the flexibility to work from home.
Embracing Open-Source Principles: We create a supportive community where you can utilise, engage, and collaborate on projects without restriction.
Comprehensive Healthcare Coverage: We provide comprehensive health benefits for you and your family, ensuring that you have peace of mind.
Biannual Retreats: We understand the importance of taking breaks and having fun. Our biannual retreats offer a great chance to relax, unwind and still be productive at work.",USD 136K - 205K *
743,Staff AI Scientist,Uniphore,Bengaluru or Chennai,Senior-level / Expert,"Uniphore is one of the largest B2B AI-native companies—decades-proven, built-for-scale and designed for the enterprise. The company drives business outcomes, across multiple industry verticals, and enables the largest global deployments.  
  Uniphore infuses AI into every part of the enterprise that impacts the customer. We deliver the only multimodal architecture centered on customers that combines Generative AI, Knowledge AI, Emotion AI, workflow automation and a co-pilot to guide you. We understand better than anyone how to capture voice, video and text and how to analyze all types of data.  
  As AI becomes more powerful, every part of the enterprise that impacts the customer will be disrupted. We believe the future will run on the connective tissue between people, machines and data: all in the service of creating the most human processes and experiences for customers and employees. 

We are currently searching for a bright Deep Learning NLP Engineer for our AI Scientist role to report to our Director of AI Science. This is a tremendous opportunity to work with the best and the brightest in the industry on our world class technologies. 
The ideal candidate will work on
Building and modifying (fine-tuning) pre-trained enterprise-grade large language models and multi-modal models   
Able to do a scientific evaluation of NLP/LLM models, come up with new techniques for model validation, evaluation, trust and safety. 
Able to train/fine tune multi-modal models using RLHF and other reinforcement learning techniques to ensure trust and safety 
Equipping large language models with the ability to integrate with other tools 
Specifying guidelines and designing annotation processes for data, work closely with Data team on data preprocessing, consumption and automated/maunal annotations 
Skills
Minimum of a Master’s degree including Computer Science, Engineering or related fields. 
8+ years of industry experience in AI, NLP, Vision and ASR
In-depth knowledge of deep learning and expertise in PyTorch/TensorFlow.
Familiar with Transformers and have used Huggingface library and LLMs to solve NLP problems. 
Worked with large amounts of data and developed approaches to address quality issues, and ability to interpret data with a focus on business goals. 
Solid expertise in Python programming. 
Hands-on experience in developing production-ready, scalable code. 
Ability to lead projects independently, mentor and guide junior team members. 
Be able to work in a fast paced, startup environment cross functionally with engineering, product, marketing and customer solutions team.
Relevant Technologies
ML: Hugging Face, PyTorch, MLOps tools. 
Deployment: Docker, AWS, Terraform, Garden 
Datastores: Postgres, S3. 
Benefits
Uniphore offers a competitive offer and premium benefits, including insurance, pre-IPO options, leave and other perks. 
Uniphore is an equal opportunity employer committed to diversity in the workplace. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, disability, veteran status, and other protected characteristics.
 For more information on how Uniphore uses AI to unify—and humanize—every enterprise experience, please visit www.uniphore.com.

All applicants - to review our privacy notice, please click here

Information regarding recruiting and phishing scams: 
Employment offers will always be made by a Uniphore hiring manager or Talent Acquisition team member with a @uniphore.com email address only. We will never text you about an employment opportunity, interviews or employment offers, and we do not make job offers after only one interview. Additionally, we will never ask you to provide funds for onboarding, supplies or anything else, nor we will ask you to submit your personal information (date of birth, passport details, banking information, social security number, etc.) as part of the interview process. If you are receiving an employment inquiry or employment offer from a non Uniphore.com email address, please assume it is spam. If you believe you have been a victim of a phishing or false employment scam, you may want to report this incidents to the FBI iC3, or visit the Department of Homeland Security’s Cyber Smart website to learn how to report such scam.",USD 38K - 100K *
744,Civil 3D Technician (Chennai/Gurgaon/Noida/Mumbai),Ramboll,"Gurgaon, India",Senior-level / Expert,"Company Description
Ramboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative and empowering culture.
Ramboll was founded in 1945 in Denmark. Today, we employ 16,000 engineering, design and consultancy specialists. We hold a leading position in the Nordic market (Denmark, Sweden, Norway, and Finland) and have more than 300 offices in 35 countries.
Job Description
Main Job Responsibilities:
Should have drafting knowledge of various roads drawings/ layouts related to roads design in Civil 3D including road layout, cross section, generation of plan and profile drawings, grading, generating of detailed cross sections from the model.   He should be well versed with the various BIM requirements and capable of handling and producing models to an LOD 400. Preparation of concept, Detailed, Tender, shops and GFC drawings.
Should be well versed with AutoCAD Civil 3D and Navisworks. Knowledge in Revit is an added advantage.
Required Knowledge & Skill :
Will be committed to achieving program delivery
Will undertake production of project drawings using AutoCAD, Civil 3D
Will be expected to work to the company Quality, Safety and Environmental standards and adhere to the CAD standards set in the project Drawing Manual
Qualifications
Qualification and Experience required:
10 + years with experience in design and drafting in AutoCAD Civil 3D
Will need to have the ability and desire to work on a diverse range of drawing work and be able to communicate with the engineers on the project.
Must have a sound understanding of the use of XREFS and manipulating large files .
Will possess the good interpersonal skills and the ability to listen to the views of other parties .
Will need to be a team player.  Dedicated to the delivery of project.
Ability to work to tight deadlines, with minimal supervision.
Additional Information
How to apply
Apply online. Attach your CV, cover letter and relevant documents showcasing why you are the right fit for the role, and when you are available to start. We look forward to receiving your application.",USD 37K - 70K *
745,Data Engineer-Associate-P&T,PwC,Bengaluru (SDC) - Pine Valley Embassy Golf Links,Senior-level / Expert,"Line of Service
Internal Firm Services
Industry/Sector
Not Applicable
Specialism
IFS - Internal Firm Services - Other
Management Level
Associate
Job Description & Summary
A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change.

Our team collaborates with product strategy and product managers to govern readiness standards in achieving principles (compliance, privacy, security) by design for what PwC’s technology assets require to be successful in the market. They provide guidance for product development across the lifecycle (ideation / strategy through commercialization / monetization). Additionally, they facilitate market readiness for technology assets overall, as changes occur to assets or market conditions throughout the asset’s life cycle.
Preferred Knowledge/Skills:
Demonstrates intimate knowledge and/or a proven record of success in the following areas:
Understanding architectural design and data platform delivery in technologies that include, but are not limited to cloud, ETL, data streaming, data storage, data modeling, APIs/microservices, automation, continuous integration/continuous deployment;
Showcasing work experience as a Data Engineer, Data Architect or similar role;
Showcasing data engineering knowledge around  complex efforts within established Software Development Lifecycles and methodologies including agile, scrum, iterative and waterfall;
Showcasing technical knowledge that spans multiple platforms and portfolio of applications with demonstrated knowledge of the business strategic priorities in order to resolve complex problems;
Utilizing IT processes and frameworks including, but not limited to, Identity Access Management (IdAM), Enterprise Application Integration, Data Warehousing, Business Intelligence, Reporting, Mobility, Master Data Management, and Search;
Understanding of database structure principles;
Showcasing advanced experience building and maintaining optimal data pipeline architecture and data streaming and integrations using tools such as ADF, SSIS, Informatica, API Management, Enterprise Service Bus (preferably Kafka);
Showcasing advanced SQL knowledge and experience working with relational databases and performance optimization;
Demonstrating data mining and segmentation techniques;
Exhibiting knowledge in relational SQL, NoSQL and Big Data technologies;
Understanding Data Federation/Virtualization technologies, such as PowerBI, Tableau, D3.js, and implementing Cloud based solutions;
Assessing  and analyzing system requirements;
Showcasing analytical skills and a problem-solving attitude;
Demonstrating virtual leadership and motivational skills;
Recommending and participating in activities related to the design, development and maintenance of the Enterprise Data Architecture;
developing internal relationships and PwC brand;
Demonstrating time management skills with the ability to handle multiple projects simultaneously;
Leveraging business knowledge and interpersonal skills to build, maintain, and influence relationships with leaders throughout the business and IT.
Basic Qualifications:
Minimum Degree Required:
Bachelor Degree
Minimum Years of Experience:
3.0-5.0 year
Preferred Qualifications:
Degree Preferred:
Master Degree
Preferred Fields of Study:
Software Engineering, Computer and Information Science, Data Processing/Analytics
Additional Educational Preferences:
Other related fields of study with relevant experience may be considered.
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Azure Data Factory, Databricks Platform
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
Not Specified
Available for Work Visa Sponsorship?
No
Government Clearance Required?
Yes
Job Posting End Date",USD 121K - 190K *
746,Senior Data Engineer,JLL,IND-CORP Bengaluru-TDIM - PTT,Senior-level / Expert,"Senior Data Engineer
JLL Technologies COE

What this job involves: 

 #JLLTechAmbitions 

About the role
JLL Technologies Enterprise Data team is a newly established central organization that oversees JLL’s data strategy. We are seeking data professionals to work with our colleagues at JLL around the globe in providing solutions, developing new products, building enterprise reporting & analytics capability to reshape the business of Commercial Real Estate using the power of data and we are just getting started on that journey! 

We are looking for a Senior Data Engineer who is self-starter to work in a diverse and fast-paced environment that can join our Enterprise Data team. This is an individual contributor role that is responsible for designing and developing of data solutions that are strategic for the business and built on the latest technologies and patterns. This a global role that requires partnering with the broader JLLT team at the country, regional and global level by utilizing in-depth knowledge of data, infrastructure, technologies and data engineering experience. 

Key Responsibilities:
As a Data Engineer, you will be responsible for:
Develop systems that ingest, cleanse and normalize diverse datasets, develop data pipelines from various internal and external sources and build structure for previously unstructured data 
Interact with internal colleagues and external professionals to determine requirements, anticipate future needs, and identify areas of opportunity to drive data development 
Develop good understanding of how data will flow & stored through an organization across multiple applications such as CRM, Broker & Sales tools, Finance, HR etc 
Unify, enrich, and analyze variety of data to derive insights and opportunities 
Design & develop data management and data persistence solutions for application use cases leveraging relational, non-relational databases and enhancing our data processing capabilities 
Develop POCs to influence platform architects, product managers and software engineers to validate solution proposals and migrate 
Develop data lake solution to store structured and unstructured data from internal and external sources and provide technical guidance to help migrate colleagues to modern technology platform 
Contribute and adhere to CI/CD processes, development best practices and strengthen the discipline in Data Engineering Org 
Sounds like you? To apply you need to be: 
Experience and Education:
In order to achieve the key objectives of role, you will need the following skills and experience
7+ years’ overall work experience and bachelor’s degree in Information Science, Computer Science, Mathematics, Statistics or a quantitative discipline in science, business, or social science.
Hands-on engineer who is curious about technology, should be able to quickly adopt to change and one who understands the technologies supporting areas such as Cloud Computing (AWS, Azure(preferred), etc.), Micro Services, Streaming Technologies, Network, Security, etc. 
3 or more years of active development experience as a data developer using Python-spark, Spark Streaming, Azure SQL Server, Cosmos DB/Mongo DB, Azure Event Hubs, Azure Data Lake Storage, Azure Search etc. 
Design & develop data management and data persistence solutions for application use cases leveraging relational, non-relational databases and enhancing our data processing capabilities 
Build, test and enhance data curation pipelines integration data from wide variety of sources like DBMS, File systems, APIs and streaming systems for various KPIs and metrics development with high data quality and integrity 
Maintain the health and monitoring of assigned data engineering capabilities that span analytic functions by triaging maintenance issues; ensure high availability of the platform; monitor workload demands; work with Infrastructure Engineering teams to maintain the data platform; serve as an SME of one or more application 
Team player, Reliable, self-motivated, and self-disciplined individual capable of executing on multiple projects simultaneously within a fast-paced environment working with cross functional teams 
5+ years of experience working with source code control systems and Continuous Integration/Continuous Deployment tools 
Independent and able to manage, prioritize & lead workload 
Technical Skills & Competencies
Data Structures and Algorithms
Experience in writing high performance production ready code.
Azure infrastructure - Databricks and Azure Functions
Python libraries such as NumPy, SciPy, Pandas, etc
What we can do for you:
At JLL, we make sure that you become the best version of yourself by helping you realize your full potential in a fully entrepreneurial and inclusive work environment. If you harbour a passion for learning and adapting new technologies, JLL will continuously provide you with platforms to enrich your technical domains.  We will empower your ambitions through our dedicated Total Rewards Program, competitive pay, and benefits package. It’s no surprise that JLL has been recognized by the Ethisphere Institute as one of the 2019 World’s Most Ethical Companies for the 12th consecutive year.

Apply today!
Location:
On-site –Bengaluru, KA
If this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements.  We’re interested in getting to know you and what you bring to the table!
About JLL –
For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500® company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com.
JLL Privacy Notice
Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.
For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.
For additional details please see our career site pages for each country.
For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here.
Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities.  If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process –  you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",USD 121K - 190K *
747,Staff Machine Learning Engineer (MLOps),Tide,"Hyderabad, Remote",Senior-level / Expert,"Department: Data Science
Who are Tide:
At Tide, we’re on a mission to save businesses time and money. We’re the leading provider of UK SME business accounts and one of the fastest-growing FinTechs in the UK. Using the latest tech, we design solutions with SMEs in mind and our member-driven financial platform is  transforming the business banking market. Not only do we offer our members business accounts and related banking services, but also a comprehensive set of highly connected admin tools for businesses. 
Tide is about doing what you love. We’re looking for someone to join us on our exciting scale up journey and be a part of something special. We are wanting passionate Tideans to drive innovation and help build a best-in-class platform to support our members. You will be comfortable in ambiguous situations and will be able to navigate the evolving FinTech environment. Imagine shaping how millions of Tide members discover and engage with business banking platforms and building this on a global scale. 
As a Staff ML Engineer you’ll be:
Creating and maintaining ML pipelines to operationalize ML models.
Developing & deploying low latency and highly scalable dockerized micro services.
Collaborating in cross-functional software/architecture design sessions to find the best solutions for the problems that we are facing.
Working with Peer ML engineers who will be responsible for scaling and deploying machine learning models for Tide.
Participating in an agile development team that delivers value iteratively.
Building ML platform to speed up develop & deploy cycle and monitoring of models in production.
What makes you a great fit:
You have 10+ years of experience in Machine Learning Engineering
You can prioritise ML Data Science and Machine Learning product roadmaps for the respective businesses based on OKRs and priorities
You have experience leading a team of backend developers and/or ML engineers, coaching best practices and architecting solutions.
You have extensive development experience in Python/Java, including development of microservices using e. g. Flask, Django, etc. 
You have experience in building data solutions, both batch processes and streaming applications.
You are familiar with event-driven designs, specifically you have worked with Kafka, Pulsar, , etc. before.
You have a high-level understanding with big-data technologies such as Spark, SparkML, Hadoop etc. Strong knowledge of Cloud (AWS or other)
You have worked with feature store, ML Observability and automated MLOps systems. 
You’re organised, pragmatic and capable of engaging, guiding and leading cross functional teams or managing large scale enterprise products.
You have technical knowledge and experience and have strong empathy for developer audience.
You’re a self-starter who can work comfortably in a fast-moving company where priorities can change, and processes may need to be created from scratch with minimal guidance.
You have significant experience working with varied stakeholders.
You have good technical knowledge in SQL, strong in Python programming. 
You have high development standards, especially for code quality, code reviews, unit testing, continuous integration and deployment.
You have a good understanding on how the performance optimization works in the end-to-end data pipeline including ML/DS inferencing.
You have excellent leadership skills - you have managed a team of data scientists before and coached them to become better versions of themselves.
Our Tech Stack (You don’t have to excel in all, but willing to learn them):
Databricks on AWS 
Python Flask
Snowflake
Tecton - feature store 
Fiddler - model observability platform
What you’ll get in return:
Make work, work for you! We are embracing new ways of working and support flexible working arrangements. With our Working Out of Office (WOO) policy our colleagues can work remotely from home or anywhere in their assigned Indian state. Additionally, you can work from a different country or Indian state for 90 days of the year. Plus, you’ll get:
Competitive salary
Self & Family Health Insurance
Term & Life Insurance
OPD Benefits
Mental wellbeing through Plumm
Learning & Development Budget
WFH Setup allowance
15 days of Privilege leaves
12 days of Casual leaves
12 days of Sick leaves
3 paid days off for volunteering or L&D activities
Stock Options
Tidean Ways of Working 
At Tide, we’re Member First and Data Driven, but above all, we’re One Team. Our Working Out of Office (WOO) policy allows you to work from anywhere in the world for up to 90 days a year. We are remote first, but when you do want to meet new people, collaborate with your team or simply hang out with your colleagues, our offices are always available and equipped to the highest standard. We offer flexible working hours and trust our employees to do their work well, at times that suit them and their team.
Tide is a place for everyone
At Tide, we believe that we can only succeed if we let our differences enrich our culture. Our Tideans come from a variety of backgrounds and experience levels. We consider everyone irrespective of their ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status. We believe it’s what makes us awesome at solving problems! We are One Team and foster a transparent and inclusive environment, where everyone’s voice is heard.
#LI-SJ1 #LI-Remote",USD 150K - 230K *
748,Data Engineer - I,Junglee Games,"Bengaluru, Karnataka, India",Entry-level / Junior,"We are Asia’s fastest-growing skill-based gaming company and partner brand of Flutter which is a multi-billion dollar global gaming organization. We are focused on providing our customers with the most innovative and exciting gaming experience possible. Our success has been driven by our commitment to excellence, our passion for gaming, and our ability to continuously innovate. We are driven by our strong value system, which encompasses an obsession with data, a hustler’s attitude, an owner's mindset, leading with love, and embracing change.
As our Data Engineer-I, you will be responsible for designing and developing highly scalable data pipeline solutions and collectively owning its data integrity and consistency. You must be able to see the big picture of the company's data situation and be an expert in building distributed data solutions. You need to take the challenges and ownership that come with developing a complex system.
You will be working in a fast-paced and agile work environment delivering quality and innovative solutions in highly collaborative environments that have immediate business impact. As a DE-II, you will also get to work with Senior Engineers at Junglee Games to evolve the design and architecture of the system.
Responsibilities:
Hands-on - Responsible for writing code primarily in Spark, Python, and/or Scala.
Hands-on - Responsible for developing streaming applications like spark structured streaming, and Kafka streams.
Scale our current data infrastructure to handle millions of events/transactions per day
Own data integrity and consistency of our Data lake and Data warehouse.
Working with AWS-managed services and managing NoSQL stores like Cassandra, ElasticSearch, Redis, MongoDB, ScyllaDB, etc.
Monitor and improvise the best practices and processes to manage data pipeline and ETL operations.
Work closely with Senior engineers to design, implement and deploy Data pipelines that impact the Junglee Games business with an emphasis on the gaming industry.
Solve complex problems in an innovative way and deliver quality solutions while taking ownership and accountability of assigned things.
Demonstrate good learnability and adopt technologies that help build large-scale, performant, reliable, and sustainable systems.
The ideal candidate will be a leader, a quick learner, and be able to work independently.
Collaborating with peers on all elements of the development process as per industry coding standards and creating appropriate technical documentation.
Requirements
A solid engineer having 1-3 years expierence with strong abstraction, coding, and distributed system development
Excellent programming skills in Python/Scala and expertise in multi-threading and object-oriented programming.
In-depth knowledge of Spark, Kafka, Streaming Systems, AWS, and Cloud Data Warehouse like Trino/Snowflake and Docker/Kubernetes.
A proven track record of leading a team and development in a startup/e-commerce ecosystem within a high-growth & matrix environment
Empathetic, motivated, and good team-player
Excellent listener and interpreter.
Special consideration was given for
Knowledge in Big Data, Amazon Web Services(AWS), and Apache Spark.
Knowledge in Cloud Data warehouses such as Redshift, Snowflake, Trino
Knowledge of streaming applications such as Spark Streaming, and Kafka.
Knowledge in writing complex SQL procedures.
What Junglee offers for this role:
Meaningful global exposure and opportunity to represent Junglee as part of Flutter Entertainment, the largest real-money gaming company in the world
Ample learning opportunities and to work with some of the best industry leaders and minds
Being a part of a vibrant, intelligent, and rapidly growing team.
In-depth understanding of the gaming ecosystem.
Competitive Compensation and Incentives.
Excellent work environment, great culture, and global exposure.
About Junglee Games
Junglee Games is a leader in the skill-gaming space, with over 100 million registered players. Founded in San Francisco in 2012 and part of the $30 Bn Flutter Entertainment Group, Junglee Games is the fastest-growing skill games company in Southeast Asia. Some of our notable games are Junglee Rummy, Howzat, Junglee Poker, and Carrom Stars.
Our mission is to build entertainment for millions of people around the world and help them connect with each other through high-quality games. We focus on creating exhilarating and immersive gaming experiences and also incorporate social features to promote interaction and competition among players. Our games are available on multiple platforms, including web browsers, and Android and iOS devices.
Since our inception, we have drawn 700+ of the world’s most talented people into our ranks. Our team has worked on international AAA titles like Transformers, Star Wars: The Old Republic, Real Steel, Rio, Mech Conquest, and Dueling Blades. Our designers have worked on some of Hollywood’s biggest hits, including the movie Avatar.
Junglee Games is not just a gaming business. It is a blend of data science, innovation, cutting-edge technology, and, most importantly, a value-driven culture that is creating the next set of conscious leaders. An equal-opportunity employer, Junglee Games has been certified as a Great Place to Work for four years in a row. We celebrate diversity and are committed to creating an inclusive environment for all our employees.
Junglee Games has received various accolades for its contribution to the online gaming space. The company continues to innovate and develop new games, expanding its presence in the global gaming market.
Website: https://www.jungleegames.com/
LinkedIn: https://www.linkedin.com/company/junglee-games",USD 60K - 125K *
749,"Sr. Associate BI and Data Analyst (Tableau, SQL)",Workday,IND.Pune,Mid-level / Intermediate,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
The Workday Revenue Operations organization is a high-performance team working to help steer us to $10B in revenue and beyond. The Revenue Operations (RevOps) Business Intelligence (BI) group is a key player in driving this growth, by providing self-service insights when and where users need them to support decision making and drive business outcomes. Whether via dashboards, reports or alerts and regardless of applications, this group ensures all RevOps insights are accurate, consistent, easy to understand and actionable.

Global coverage with staggered support hours.
About the Role
As an Associate BI & Data Analyst, you will play a crucial role to ensure accurate and consistent insights. You have an opportunity to establish a strong partnership to implement/follow new monitoring and quality assurance (QA) practices to improve availability and accuracy of Marketing & Sales data and insights.  You will partner closely with onsite BI workmates (US based) and collaborate closely with our Business Technology Data Engineers & Platform Support workmates (India based).
Responsibilities:
Documentation:
Maintain Data and Dashboard refresh monitoring, common issues & resolution tracker
Maintain operational efficiency tracker with metrics, such as, data-quality, data/dashboard refresh delays, etc.
Quality Assurance (QA):
Maintain & Execute data-validation playbooks (ex: SQL queries) to validate data readiness and data accuracy
Maintain & Execute Tableau playbooks (step-by-step instructions) to validate dashboard readiness & accuracy
User Testing (UT):
Validate and Sign-off data-enhancements and/or new data-products by collaborating with onsite BI team (US based), Data Engineers and Data Platform support (Pune based) to ensure business requirements are met.
QA Tableau dashboard enhancements or new dashboard releases by collaborating with onsite BI team (US based)
Production Support:
Monitor business-owner Data & Tableau refreshes, resolve refresh issues/failures, work with Business Technology (BT) to prevent refresh issues.
Troubleshoot and resolve data & dashboard bugs/issues within the scope of RevOps BI (Alteryx Tableau bugs).
Troubleshoot and resolve data & dashboard access issues.
Agile/Scrum:
Follow Agile methodology, including sprint planning and review meetings, daily stand-ups, and following epics and stories written by onsite BI team (US based).
About You
4 years of experience in data analysis using SQL 
3 years of experience in Tableau building/ managing dashboards
Preferably with programming experience in any language, primarily to automate data, dashboard validation (QA).
Ability to learn fast, execute and take ownership of tasks
Great teamwork and interpersonal skills.
Excellent verbal and written communications
Excellent problem solving and analytical skills.
Programming experience, primarily to maintain/automate data validations & QA scripts preferred
Experience with Alteryx or other data integration tools preferred.
Experience with Marketing, Sales and CX business knowledge preferred.
Experience with Agile methodology preferred.


Our Approach to Flexible Work
 With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!",USD 67K - 110K *
750,Software Engineering SMTS- Data Science & ETL,Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
In Cloud Economics and Capacity Management (CECM) team, we are looking for an experienced and committed data engineer to build data pipelines and metrics for Salesforce internal customers in order to establish a robust platform that enables strategic decision-making pertaining to Salesforce infrastructure expenditure and capacity management. The right candidate must have strong data architecture, ETL, SQL and a proven track record working with enterprise metrics to build automated data pipelines. The candidate should also have strong operational skills to drive efficiency and speed, expertise building repeatable data engineering processes, and a vision for how to deliver data products. Experience with Tableau analytics tool is a huge plus.

Responsibilities:
Develop, automate, enhance, maintain ETL pipelines
Maintaining , deploying and code versioning the ETL process.
Using GIT CI/CD for DevOps.
Design & develop easy, repeatable and reusable automation data frameworks.
Responsible for end-to-end data management activities, including but not limited to platform analysis including tuning performance issues, monitoring applications, analyzing logs and performing system operations.
Review and validate logical and physical design to ensure alignment with the defined solution architecture. Review solution design and ensure that the defined standards and framework are followed.
Evaluate and determine root cause and resolve production issues.
Work with internal team members and external partners to support data collection and analysis and understand reporting needs
Work and collaborate with global teams across EMEA , AMER, and APAC.

Required Skills/Experience:
Minimum B.Tech Degree
4 to 5+ years related information systems experience in data engineering, data modelling, automation and analytics
Deep understanding of data engineering concepts, database designs, associated tools, system components, internal processes and architecture.
Experience working as a technical lead/solution architect in a customer-focused team
Experience working closely with Data Science teams
Team-first mentality. Excellent social skills in order to build tight-knit relationships that will be essential for the success in this role.
Must be able to strategically communicate status and identify risks
Self-starter, highly motivated, able to shift directions quickly when priorities change, think through problems to come up with innovative solutions and deliver against tight deadlines.
Must be results oriented and able to move forward without complete information and with minimal direction
Hands-on expertise in building scalable data pipelines using best practices in data modelling and ETL/ELT processes
Deep proficiency in SQL and demonstrated experience in Python
Proficiency in technologies like Spark, Trino, Hive, Airflow
Airflow, CI/CD pipelines via Jenkins or similar tools, Github
Experience in AWS technologies
Experience with data visualization tools like Tableau,Salesforce analytics solution is a plus.
Experience working with globally distributed engineering teams preferred.
Experience working in Agile and Scrum methodology
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 45K - 84K *
751,Data Scientist,Equifax,IND-Bengaluru-Equifax-Analytics,Senior-level / Expert,"Equifax is where you can power your possible. If you want to achieve your true potential, chart new paths, develop new skills, collaborate with bright minds,  and make a meaningful impact, we want to hear from you.
Synopsis of the role
Responsible to understand client’s business requirements in terms of analytical needs and be a part of a High-class delivery team to deliver unparalleled analytical solutions using best in class analytical techniques.
What you’ll do
Ability to understand BFSI business problems and consult client on the appropriate solutions
Provide thought leadership to projects and help develop unique solutions and deliver analytical outputs.
Contribute to Building the BFSI Analytics practice through on- going identification of new opportunities.
Provide hands-on support to the project team in developing ML models.
Work with the Equifax bureau in India to build bureau-based Analytics capabilities and use the new age technology to implement those solutions
Develop best practices and streamline the process in order to improve the efficiency of the team.
Manage a team of junior data scientists and develop the capabilities within the team in AI and ML areas.
What experience you need
Understanding of key business and risk KPI’s for retail banking products
4+ years’ experience in handling BFSI analytics/implementing models/Big data/Cloud solution architect
Credit risk modeling development experience is a must.
R/Python coding experience is a must have technical skill
Regulatory modeling development experience is good to have ( ECL, Stress testing & IFRS9)
Highly analytical with experience of working in teams.
Self-starter with high energy levels and ability to work in a fast paced environment.
In-depth business & risk understanding.
Adaptability to work in project based engagements across different kinds of banking clients.
Team management experience would be preferred
What could set you apart
Energetic & international work environment
Young, enthusiastic and highly collaborative teammates. Learn from and work with some of brightest minds in the banking lending, credit risk and marketing analytics space - both in India & International
Fabulous opportunity to work with some of our largest blue-chip customers
Chance to use cutting-edge statistical/modelling tools across literally hundreds of data assets
Offices located in the center of Bangalore & Mumbai
Opportunity to make an impact in the fastest growing Data & Tech bureau
Equifax D&A University: skill lab, group & individual learning
We offer a hybrid work setting, comprehensive compensation and healthcare packages, attractive paid time off, and organizational growth potential through our online learning platform with guided career tracks.
Are you ready to power your possible?  Apply today, and get started on a path toward an exciting new career at Equifax, where you can make a difference!
 Equifax is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Primary Location:
IND-Bangalore-Equifax-Analytics
Function:
Function - Data and Analytics
Schedule:
Full time",USD 136K - 205K *
752,Sr. Engineering Manager - AI/ML,ThoughtSpot,"Bengaluru, Bengaluru North, Karnataka, India",Senior-level / Expert,"About the role:
  We are looking for a Engineering Leader (AI/ML) to lead rock star engineers for our application team and share our passion for building revolutionary user interfaces. Our goal is to redefine how business users visualise and analyse large data sets, making the UI a critical differentiator for our product. The challenge is to build a highly interactive app that delivers complex functionalities of a BI application in an intuitive and easy to understand fashion for business users. At the same time the application should have lightning fast response times even when a large amount of data is pushed into it.
This is truly an opportunity to build and lead something from scratch that will be the first of its kind in the business intelligence market.
  What you'll do: 
Recruit and build world-class engineering teams with diversity of thought. Develop and grow leaders to continue pushing the boundaries of engineering excellence and execution
Collaborate closely with other functions and teams, to continue innovating in user experience and building best-in-class software systems powering them
Help evolve a culture of selfless excellence in which each person does the best work of their life and amplifies everyone around them
Lead technical direction, quality and execution for the application layer at ThoughtSpot.
What you bring (One or more of the experiences below and an insatiable desire to build and scale globally):
Are an engineer at heart and crave putting imagination into action. You likely have 10+ years of experience crafting world-class 1.0 products of complexity and building robust, high-performance and intelligent systems for them with a B.Tech/M.tech in CS.
Have expertise in one or more areas like building and scaling web apps, Machine Learning, UI Engineering, Information Visualization,  etc.
Lead AI/ML initiatives across similar portfolio teams 
Have provided senior technical leadership at the highest levels in a strong engineering culture and responsible for analysis, forecast and predictions. Your team members are thankful to you for their impact and growth as engineers and leaders.
Love building and leading exceptional cross-geo teams in a fast-paced, entrepreneurial environment. You have a strong bias for action and being resourceful
Are obsessed with the customer experience and uncompromising engineering standards
#Li
What makes ThoughtSpot a great place to work?
ThoughtSpot is the experience layer of the modern data stack, leading the industry with our AI-Powered Analytics and natural language search. We hire people with unique identities, backgrounds, and perspectives—this balance-for-the-better philosophy is key to our success. When paired with our culture of Selfless Excellence and our drive for continuous improvement (2% done), ThoughtSpot cultivates a respectful culture that pushes norms to create world-class products. If you’re excited by the opportunity to work with some of the brightest minds in the business and make your mark on a truly innovative company, we invite you to read more about our mission, and apply to the role that’s right for you.
ThoughtSpot for All
Building a diverse and inclusive team isn't just the right thing to do for our people, it's the right thing to do for our business. We know we can’t solve complex data problems with a single perspective. It takes many voices, experiences, and areas of expertise to deliver the innovative solutions our customers need. At ThoughtSpot, we continually celebrate the diverse communities that individuals cultivate to empower every Spotter to bring their whole authentic self to work.
We’re committed to being real and continuously learning when it comes to equality, equity, and creating space for underrepresented groups to thrive. 
Research shows that in order to apply for a job, women feel they need to meet 100% of the criteria while men usually apply after meeting 60%. Regardless of how you identify, if you believe you can do the job and are a good match, we encourage you to apply. 
About ThoughtSpot
The world’s most innovative companies use AI-Powered Analytics from ThoughtSpot to empower every person in their organization, from C-suite executive to frontline employee, with the ability to ask and answer data questions, create and interact with data-driven insights, and use these insights to make informed decisions and take action. ThoughtSpot is simple enough for any business person to use, yet built to handle even the largest, most complex data, wherever it may reside. That’s why customers like T-Mobile, BT, Snowflake, HubSpot, Exxon, Daimler, Medtronic, Hulu, Nasdaq, OpenTable, Huel, and Nationwide Building Society have turned to ThoughtSpot to transform their data driven decision-making cultures.
Please see our Candidate Privacy Notice. By submitting your application to us, you acknowledge and agree that:
You have read and understood the Candidate Privacy Notice (“Notice”) and acknowledge the collection, processing, use and disclosure of your personal information as set out in the Notice.
You are not required to provide any requested information to us, but failure to do so may result in not being able to continue your candidacy for a job with us.
The information you give us is true and correct to the best of your knowledge and belief, and you have not knowingly omitted any related unfavorable information. Providing any inaccurate or misleading information may make you ineligible for employment.

To all recruitment agencies: ThoughtSpot does not accept agency resumes. Please do not forward resumes to our jobs alias, ThoughtSpot employees, or any other organization location. ThoughtSpot nor its employees are not responsible for any fees related to unsolicited resumes.",USD 45K - 84K *
753,"Data Science Manager - LLM, Deep Learning, Machine Learning - REF7997L",Zscaler,"Bengaluru, India",Senior-level / Expert,"About Zscaler
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location. 
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances. 
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.
Responsibilities:
As a Data Scientist, you will work in an award-winning team that does full-lifecycle full-stack Machine Learning product development, from feature engineering to model building and evaluation.
Our team’s use cases include but are not limited to threat detection, malware detection, content classification, anomaly detection, and AIOps (advanced networking diagnosis). These various use cases give you the opportunity and challenges to experience multiple machine learning algorithms and tools. You will design and create machine learning models to provide faster and more effective ways to address cloud security, cloud operations, and cloud intelligence use cases.
You might not be an expert in every stage of a Machine Learning project, but you should have interests and curiosity in various parts ranging from the data to the model’s business impact.
Required Skills :
-  A degree in Machine Learning, Computer Science, or Electrical Engineering from a reputable school (Ph.D. degree preferred but not required)
- Passion for leveraging ML/AI to solve real-world business problems (better security and better business results)
- 9+ years of industry experience in one or more machine/deep learning frameworks
- 9+ years of industry experience with Python and SQL
- Excellent interpersonal, technical, and communication skills
- Good business sense
- Ability to learn, evaluate, and adopt new technologies fast
- Ability to lead and execute projects from start to finish
- Solid computer science foundation
  Desirable Skill Sets:
- 9+ years professional experience
- Experience with various public cloud services (such as AWS, Google, Azure) and ML automation platforms (such as Kubeflow)
- Experience with various program languages such as Go
- Good understanding of operating systems and distributed systems
- Familiarity with networking and networking security
  #LI - YK1
By applying for this role, you adhere to applicable laws, regulations, and Zscaler policies, including those related to security and privacy standards and guidelines.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
See more information by clicking on the Know Your Rights: Workplace Discrimination is Illegal link.
Pay Transparency
Zscaler complies with all applicable federal, state, and local pay transparency rules. For additional information about the federal requirements, click here.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support.",USD 152K - 255K *
754,Data Engineer-Senior Associate-P&T,PwC,Bengaluru (SDC) - Pine Valley Embassy Golf Links,Senior-level / Expert,"Line of Service
Internal Firm Services
Industry/Sector
Not Applicable
Specialism
IFS - Internal Firm Services - Other
Management Level
Senior Associate
Job Description & Summary
A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change.

Our team collaborates with product strategy and product managers to govern readiness standards in achieving principles (compliance, privacy, security) by design for what PwC’s technology assets require to be successful in the market. They provide guidance for product development across the lifecycle (ideation / strategy through commercialization / monetization). Additionally, they facilitate market readiness for technology assets overall, as changes occur to assets or market conditions throughout the asset’s life cycle.
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
Preferred Qualifications:
Preferred Fields of Study: Software Engineering, Computer and Information Science, Data Processing/Analytics
Additional Educational Preferences: Other related fields of study with relevant experience may be considered.
Preferred Knowledge/Skills: Demonstrates intimate knowledge and/or a proven record of success in the following areas:
● Understanding architectural design and data platform delivery in technologies that include, but are not limited to cloud, ETL, data streaming, data storage, data modeling, APIs/microservices, automation, continuous integration/continuous deployment;
● Showcasing work experience as a Data Engineer, Data Architect or similar role;
● Showcasing data engineering knowledge around complex efforts within established Software Development Lifecycles and methodologies including agile, scrum, iterative and waterfall
● Showcasing technical knowledge that spans multiple platforms and portfolio of applications with demonstrated knowledge of the business strategic priorities in order to resolve complex problems;
● Utilizing IT processes and frameworks including, but not limited to, Identity Access Management (IdAM), Enterprise Application Integration, Data Warehousing, Business Intelligence, Reporting, Mobility, Master Data Management, and Search;
● Understanding of database structure principles;
● Showcasing advanced experience building and maintaining optimal data pipeline architecture and data streaming and integrations using tools such as ADF, SSIS, Informatica, API Management, Enterprise Service Bus (preferably Kafka); ● Showcasing advanced SQL knowledge and experience working with relational databases and performance optimization;
● Demonstrating data mining and segmentation techniques;
● Exhibiting knowledge in relational SQL, NoSQL and Big Data technologies;
● Understanding Data Federation/Virtualization technologies, such as PowerBI, Tableau, D3.js, and implementing Cloud based solutions;
● Assessing and analyzing system requirements;
● Showcasing analytical skills and a problem-solving attitude;
● Demonstrating virtual leadership and motivational skills;
● Recommending and participating in activities related to the design, development and maintenance of the Enterprise Data Architecture;
● developing internal relationships and PwC brand;
● Demonstrating time management skills with the ability to handle multiple projects simultaneously;
● Leveraging business knowledge and interpersonal skills to build, maintain, and influence relationships with leaders throughout the business and IT
Basic Qualifications:
Minimum Degree Required:
Bachelor Degree
Minimum Years of Experience:
5.5-9.0 year(s)
Preferred Qualifications:
Degree Preferred:
Master Degree
Preferred Fields of Study:
Software Engineering, Computer and Information Science, Data Processing/Analytics
Additional Educational Preferences:
Other related fields of study with relevant experience may be considered.
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Azure Data Factory, Databricks Platform
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
Not Specified
Available for Work Visa Sponsorship?
No
Government Clearance Required?
Yes
Job Posting End Date",USD 121K - 190K *
755,Business Analyst with SQL and Data Management - Assistant Manger,State Street,"Bengaluru, India",Entry-level / Junior,"Job Title: Treasury Business Analyst with SQL and Data Management Knowledge
Purpose of Role:
The Finance Risk Infrastructure Business Solutions Team (FRIBS) is responsible for providing business and technology solutions for our Finance and Risk business partners.
The Business Analyst is a position responsible for contributing to assessment efforts division-wide and beyond and using thorough understanding of business systems, financial industry, and system development lifecycle methodology (ies) to provide the highest level of expertise to support very complex longer-term projects throughout their life cycle, with the emphasis on the analysis stage
Major Responsibilities:
Leads and reviews draft detailed requirements and related documentation
Directs complex and challenging business/system requirements by facilitating strategic user meetings and interviewing users, and resolving issues
Identify, compile, analyze and document business data requirements that accurately and thoroughly reflect business needs with clear, concise language consistent with methodology framework
Leads the analysis of current processes and data lineage; recommends solutions and improved data architecture; consults as subject matter expert on impact of systems changes to business processes
Serves as advocate for business area regarding system needs and requests with various groups.
Monitors project planning and management by documenting and maintaining plans, managing issue logs and preparing project documentation
Demonstrates understanding of the impact of data problems on the organization as a whole, and facilitate collaboration to achieve resolutions with strategic data sourcing and transformation.
Support the resolution of data, information and processing challenges that are having an adverse impact on the operational environment and/or business performance
Create reporting around data governance progress for key stakeholders and management.
Participate/Initiate data quality efforts working closely with key stakeholders to design, develop and deploy process redesign, and tool implementation, where needed
In addition to users, communicates with and act as liaison between with developers, testers, and implementation specialists
Model data and analyze business processes to assist the business in identifying ways to maximize operational efficiencies, quality and compliance
Key Characteristics:
Strong understanding of Investment banking and Treasury product classes
Strong understanding of enterprise data management concepts, principles and practices.
Experience in supporting Asset Liability Management. Liquidity Management and other  treasury functions by managing and providing data through repositories
Ability to understand data models, data taxonomy, and a deep appreciation of data standards and data quality.
Exceptional analytical, conceptual and problem-solving abilities.
Excellent project management skills to manage multiple issues simultaneously.
Strong presentation and interpersonal skills.
Anticipates client needs, investigates the underlying causes and identifies short- and long-term solutions
Anticipates client business issues and developments in own discipline; uses knowledge to focus work and drive improvements
Identifies patterns and links; looks beyond the immediate problem to the wider implications; generates new solutions to complex problems
Self-confidence, high energy and tenacity in bringing issues to closure and moving forward are highly desired
Qualifications:
Strong research, analytical, and problem-solving skills;
Demonstrated understanding of system development life cycle methodology(ies)
Demonstrated competency to support complex projects
Excellent attention to detail
Strong written and oral communication skills to motivate, build consensus, and influence staff and customers are required
Sound judgement and excellent ability to prioritize and multi-task
Excellent understanding of business systems and industry requirements
Excellent MS Office – Word, Excel, Powerpoint, Visio, Project
Excellent SQL knowledge.
Through understanding of Databases and Database concepts.
10+ years of Financial Services Industry preferred BA/BS Computer Science / Business / MIS (or equivalent work experience to substitute for education",USD 22K - 42K *
756,AI/ML Scientist,Verisk,"Hyderabad, India",Mid-level / Intermediate,"Company Description
We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.
Job Description
About the Role
The research team at Verisk EES (Extreme Event Solutions) works on innovative research in AI for climate risk. We are looking for highly talented and motivated candidates passionate about doing industrial R&D, building, and deploying AI and ML solutions for real-world problems. You will play a critical part in expanding our model capabilities to improve our understanding and predictions of climate extremes and enhance the view of risk we provide to our clients. In this role you will be responsible for building, deploying, and validating machine learning algorithms to solve real-world climate problems, focusing initially on atmospheric-perils modeling. This role is a perfect blend between machine learning and climate science, and you will find in it many opportunities to express your technical skills and creative mindset.
About the Day-to-Day Responsibilities of the Role
Design, build, deploy, and maintain machine learning models to achieve research and business objectives of the Research department.
Collaborate with and provide support to other research groups to develop new machine learning tools and enhance existing models.
Evaluate model performance on real-world data and present findings to key decision makers.
Identify appropriate data sources and process, clean, and verify integrity of data used for analysis
Qualifications
Ph.D. degree (completed or close to completion) in engineering, fluid mechanics, atmospheric science, computer science, statistics, or a related field.
2+ years of experience building machine learning models in industry or academia.
Good theoretical understanding of the physical processes governing climate phenomena and fluid dynamics (turbulence, convection, closure models, etc.)
Publications in relevant top-tier journals / conferences is preferred.
Strong command of machine learning algorithms for spatiotemporal data and physical processes (LSTM, TCN, CNN, Transformers, PINNs, Neural Operators etc.)
Experience with Generative models (GANS, Diffusion models) is a plus.
Experience with common data science toolkits such as scikit-learn, PyTorch or TensorFlow.
High degree of comfort deploying machine learning models in a HPC environment.
Excellent verbal and written communication skills, including the ability to convey technical ideas to a non-technical audience.
Team-focused and evidence of supporting project team members.
Additional Information
In 2022, Verisk received Great Place to Work® Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We’re also one of the 38 companies on the UK’s Best Workplaces™ list and one of 18 companies on Spain’s Best Workplaces™ list.
For over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we’ve grown to provide analytic insights that help transform industries focused on some of the world’s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.
Verisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale. We’re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.

Everyone at Verisk—from our chief executive officer to our newest employee—is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.
• Be Remarkable by doing something better each day in service to our customers and each other
• Add Value by delivering immediate and sustained results that drive positive outcomes
• Innovate by redefining what’s possible, embracing challenges, and pushing boundaries
Verisk Businesses
Underwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision
Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences
Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient
Extreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.
Specialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance
Marketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement
Life Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.
Verisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger
Verisk Analytics is an equal opportunity employer.
All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.
http://www.verisk.com/careers.html
Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.",USD 30K - 56K *
757,Senior Software Engineer- MLOps Platform DevOps Lead,Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
Key Responsibilities:
Lead a team of engineers to build, enhance and support technical platforms that meet the needs of the Data Scientist for operationalizing Machine Learning models including feature engineering, model cataloging, deployment to a compute environment, and model monitoring.
Integrate the various technologies part of a platform to insure friction-less user experience
Implementation automations to provision and upgrade platforms in AWS Cloud to increase efficiency and speed-to-delivery
Understand the MLOps management platform landscape and participate in advancing,  optimizing and/or simplifying it
Work closely with Platform Architects to define and implement platform roadmaps
Participate in proof-of-concepts to evaluate new and emerging technologies relevant to Data Solutions
Oversee Incident and problem management
Oversee the planning and deployment of platform upgrade
Perform platform-related services
Troubleshoot advanced deployment and cloud (Relevant to MLOps Platform) infrastructure issues
Develop SOP, workbooks and knowledge articles to ensure consistent and reliable platform operations
Ensure Data Platforms are scalable, available, reliable, secure and generally meet agreed SLAs
Engage with technology partners to further advance the MLOps platforms and to maintain robust in-house knowledge required to successfully fulfill our responsibilities
Take part to vendor management
Work Experience
Combined 8+ years of experience working as a platform/infrastructure engineering, including 3+ years in operations and support experience
Certifications
BS or MS in Computer Science or related
Certification in AWS (Developer/Solution Architect/DevOps/Data Specialty) is a preferable
Skills/abilities
Hands-on Experience with MLOps technologies ( MLFlow, ModelOps) and Data Science Platforms (Domino Data Lab, AWS Sage maker)
Experience with configuration and maintenance of Data Management platforms (Cloudera Data Platform, AWS Data Ecosystem) are a plus
Demonstrated ability to support enterprise scale multi-tenant ML Platforms on Cloud
Ability to interface with and assist various teams across organization to make best use of the MLOps platform
Thorough understanding of and working experience in Cloud eco-system, in particular AWS
Experience with CFT/Terraform, Infrastructure as Code (IaC) and configuration languages.
Experience with containerization (EKS) based platform deployment with autoscaling.
Agile software development.
Large-scale distributed software services and solutions.
Distributed cloud-computing platforms and technologies like Kubernetes and Spark ecosystem.
Programming languages and framework such as SQL, Unix Shell Scripts, Python, Angular, etc.
Experience with implementing improvements in areas such as maintainability, scalability, availability, extensibility and security
Experience implementing, maintaining, and troubleshooting continuous integration/continuous delivery (CI/CD)
Working knowledge of ITSM best practices and tools (e.g. ServiceNow)
Working knowledge of information security best practices
Operate independently within the guidelines of overall position and objectives
Appropriately raise and escalate issues and/or risks and challenge assumptions
Demonstrates a strong attention to detail and a commitment to process quality, continuous improvement, and operational excellence.
Proven experience of working on application development projects; exceptional working knowledge of common SDLC models
Proven experience with Incident resolution management (Includes communication with technical and non-technical stakeholders)
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
758,IET – CP - Azure Databricks - Associate 2 - Bangalore,Nike,Bengaluru (SDC) - Bagmane Tech Park,Mid-level / Intermediate,"Line of Service
Advisory
Industry/Sector
Not Applicable
Specialism
Functional & Industry Technologies
Management Level
Associate
Job Description & Summary
A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
As an Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Invite and give in the moment feedback in a constructive manner.
Share and collaborate effectively with others.
Identify and make suggestions for improvements when problems and/or opportunities arise.
Handle, manipulate and analyse data and information responsibly.
Follow risk management and compliance procedures.
Keep up-to-date with developments in area of specialism.
Communicate confidently in a clear, concise and articulate manner - verbally and in the materials I produce.
Build and maintain an internal and external network.
Seek opportunities to learn about how PwC works as a global network of firms.
Uphold the firm's code of ethics and business conduct.
Position: Azure Databricks
Education - Btech/Mtech/BCA/MCA/MSc/MS
Experience - 3- 5 years
Azure Databricks - JD
• Proficiency in Azure Databricks, Azure Data Factory, and other relevant Azure services such as Azure Storage, Azure SQL Database, and Azure Synapse Analytics.
• Strong hands-on experience with programming languages like Python, Pyspark, SQL for data processing and transformation
• Deep understanding of data engineering, proficient knowledge of Azure technologies, and possess the ability to analyze and transform complex data sets.
• Design and develop end-to-end data conversion workflows on Azure Databricks, ensuring efficient and accurate processing of data.
• Implement robust ETL processes to extract data from various sources, perform data transformations, and load it into target data repositories.
• Optimize data conversion workflows for performance, scalability, and reliability, leveraging best practices and industry standards.
• Integrate Azure Databricks workflows with Azure Data Factory pipelines, ensuring seamless data movement and orchestration.
• In-depth understanding of ETL concepts, data warehousing principles, and data modeling techniques.
Certifications (such as Azure Data Engineer Associate or Databricks Certified Data Engineer Associate
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
Not Specified
Available for Work Visa Sponsorship?
No
Government Clearance Required?
No
Job Posting End Date",USD 30K - 56K *
759,Manager - Data Engineer - US Tech - P&T,PwC,Bengaluru (SDC) - Bagmane Tech Park,Mid-level / Intermediate,"Line of Service
Internal Firm Services
Industry/Sector
Not Applicable
Specialism
IFS - Internal Firm Services - Other
Management Level
Manager
Job Description & Summary
A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.
AC - Data Engineering - Manager
US Tech Architect
Job Requirements and Preferences:
Basic Qualifications:
Minimum Degree Required:
Bachelor Degree
Minimum Years of Experience:
9-12 years
Preferred Qualifications:
Preferred Fields of Study:
Software Engineering, Computer and Information Science, Data Processing/Analytics
Additional Educational Preferences:
Other related fields of study with relevant experience may be considered.
Preferred Knowledge/Skills:
Demonstrates intimate knowledge and/or a proven record of success in the following areas:
Understanding architectural design and data platform delivery in technologies that include, but are not limited to cloud, ETL, data streaming, data storage, APIs/microservices, automation, continuous integration/continuous deployment;
Showcasing work experience as a Data Engineer,  or similar role;
Showcasing data engineering knowledge around  complex efforts within established Software Development Lifecycles and methodologies including agile, scrum, iterative and waterfall;
Showcasing technical knowledge that spans multiple platforms and portfolio of applications with demonstrated knowledge of the business strategic priorities in order to resolve complex problems;
Utilizing IT processes and frameworks including, but not limited to, Identity Access Management (IdAM), Enterprise Application Integration, Data Warehousing, etc.
Understanding of database structure principles;
Showcasing advanced experience building and maintaining optimal data pipeline architecture and data streaming and integrations using tools using ADF and basic understanding of Azure Databricks, Deltalake
Prior experience of working in other ETL tools like SSIS, Informatica, API Management, Enterprise Service Bus (preferably Kafka) would be preferable.
Showcasing advanced SQL knowledge and experience working with relational databases and performance optimization;
Exhibiting knowledge in relational SQL, NoSQL and Big Data technologies;
Understanding Data Federation/Virtualization technologies, such as PowerBI, Tableau, D3.js, etc.
Assessing  and analyzing system requirements;
Showcasing analytical skills and a problem-solving attitude;
Demonstrating virtual leadership and motivational skills;
developing internal relationships and PwC brand.
Demonstrating time management skills with the ability to handle multiple projects simultaneously.
Leveraging business knowledge and interpersonal skills to build, maintain, and influence relationships with leaders throughout the business and IT.
Preferred skills
Minimum years experience required
Additional application instructions
Education (if blank, degree and/or field of study not specified)
Degrees/Field of Study required:
Degrees/Field of Study preferred:
Certifications (if blank, certifications not specified)
Required Skills
Optional Skills
Desired Languages (If blank, desired languages not specified)
Travel Requirements
0%
Available for Work Visa Sponsorship?
No
Government Clearance Required?
No
Job Posting End Date",USD 90K - 150K *
760,Data Engineer,Current Job Openings at Noodle.ai,"Bengaluru, Karnataka, India",Mid-level / Intermediate,"ABOUT THE OPPORTUNITY
Noodle’s Data Engineers have a strong understanding of database structures, modeling and data warehousing techniques; know how to create SQL queries, stored procedures, views and define best practices for engineering scalable secure data pipelines. Members of our Data Engineering team are passionate about embracing the challenge of dealing with petabyte or even exabytes of data on a daily basis.
WHAT YOU'LL DO
Contribute to the data engineering development work
Collaboration with multiple stake holders including and not limited to the Infrastructure, DevOps, Data science among other team
Interface with customer facing teams 
Support and monitor multiple data pipelines across different customers
Work closely with the development teams to understand changes to every release
ABOUT YOU
MUST HAVE
2+ years of experience with data pipelining and development
BE/B.Tech or Advanced degree in a relevant field (Computer Science and Engineering, Technology and related fields)
Good knowledge on Python programming language
Good knowledge in SQL queries (Not limited to PostgreSQL)
Experience in data pipeline orchestration tools like Airflow
Basic understanding of containers and familiarity with docker commands
Hands on experience of working with distributed data systems such as Spark,Hive, HDFS
Very good debugging skills
Flexible to learn new technologies and adapt to dynamic environment
HELPFUL TO HAVE
Exposure to cloud preferably AWS, S3 , EMR
Experience on processing large scale time series data would be preferred
Exposure to kubernetes
Understanding of ML model lifecycle and pipelines
Experience with (and excitement for) interdisciplinary collaboration
ABOUT NOODLE.AI
At Noodle.ai our mission is to create a world without waste. Our products focus where the waste is – in factories and supply chains around the world.  We think traditional rules-based software is failing business leaders, so we’re developing next-generation enterprise software that leverages Enterprise Artificial Intelligence to tackle volatility in supply chains. We are a diverse and interdisciplinary team, looking for collaborative and intellectually curious Noodlers hungry to learn from other perspectives, create together, and have fun along the way. 
WANT TO HELP SHAPE THE FUTURE OF ENTERPRISE ARTIFICIAL INTELLIGENCE®?  LET’S NOODLE. ",USD 90K - 150K *
761,Senior Software Engineer II - Data Engineering,Poshmark,"Chennai, India",Mid-level / Intermediate,"Confidence can sometimes hold us back from applying for a job. Here’s a secret: there's no such thing as a ""perfect"" candidate. Poshmark is looking for exceptional people who want to make a positive impact through their work and help create an organization where everyone can thrive. So whatever background you bring with you, please apply if this role would make you excited to come to work every day.
The Big Data team is a central player in the Poshmark organization. Our mission is to build a world-class big data platform to bring value out of data for us and for our customers. Our goal is to democratize data, support exploding business, provide reporting and analytics self-service tools, and fuel existing and new business critical initiatives.
  This position will be responsible for designing, developing & maintaining growth data pipeline and integrating with advertising platforms like Facebook, Google etc to drive insights for business growth. The role requires to partner with Data Scientists, Analysts, Marketing and Growth campaign managers. In addition, this role involves making an impact by driving continuous improvements in moving, aggregating, profiling, sampling, testing and analyzing terabytes of data.
  Responsibilities
Build highly scalable, available, fault-tolerant data processing systems using AWS technologies - Hive, Kafka, Spark, and other big data technologies. These systems should handle batch and real-time data processing over 10s of terabytes of data ingested every day and petabytes of data warehouse.
Build domain expertise and ownership -- become technically knowledgeable in the area of Attribution, Marketing, Integrating with Ad platforms.
Participate in architecture discussions, influence product roadmap, and take ownership and responsibility over new projects
Maintain and support existing platforms and evolve to newer technology stacks and architectures
6-Month Accomplishments
Get familiar with the poshmark ecosystem i.e data Infrastructure and data tools - Redshift, Spark, Druid etc.
Help optimize current tools and ETL used for various business needs
Identify gaps in current infrastructure and propose solutions
Regularly provide meaningful design feedback and code review to peers
12+ Month Accomplishments
Design technical solutions for large complexity problems with minimal supervision
You’ve rolled out a high impact project to production
Collaborate with the engineering team to improve data collection and data quality.
Collaborate with machine learning engineers, data scientists and analytics on different projects.
Desired Skills
4+ years of experience in building highly scalable solutions in data storage, real-time analysis and reporting for multi-terabyte data sets
Expertise architecting and building large-scale data processing systems using Big Data technologies like Hadoop, Hbase, Spark, Storm, Kafka, Druid, Flink etc.
Experience with SQL and NoSQL databases Amazon Redshift/Spectrum, AWS S3
Solid software development skills in Java/Scala/Ruby/Python
Solid understanding of Jenkins / Github
Integration experience with advertising and attribution partners like FB, Google, AppsFlyer, Snapchat etc.
Be self-driven, take complete ownership of initiatives and make pragmatic technical decisions
Collaborate with cross-functional teams of developers, QA and operations to execute deliverables
About Us
Poshmark is a leading social marketplace for new and secondhand style for women, men, kids, pets, home, and more. By combining the human connection of physical shopping with the scale, ease, and selection benefits of e-commerce, Poshmark makes buying and selling simple, social, and sustainable. Its community of more than 80 million registered users across the U.S. and Canada, is driving the future of commerce while promoting more sustainable consumption. For more information, please visit www.poshmark.com, and for company news and announcements, please visit investors.poshmark.com. You can also find Poshmark on Instagram, Facebook, Twitter, Pinterest, and YouTube.
Why Poshmark?
At Poshmark, we’re constantly challenging the status quo and are looking for innovative and passionate people to help shape the future of Poshmark. We’re disrupting the industry by combining social connections with e-commerce through data-driven solutions and the latest technology to optimize our platform. We’re nothing without our amazing team who deliver an unparalleled social shopping experience to the millions of people we connect each day.
We built Poshmark around four core values: 1) focus on people to create empowered communities that drive success; 2) together we grow to support each other to strive for our dreams; 3) lead with love to foster genuine connections built upon a foundation of respect; and 4) embrace your weirdness to accept and empower one another on their own unique journey. We’re invested in our team and community, working together to build an entirely new way to shop. That way, when we win, we all win together. Come help us build the most connected shopping experience ever.  We will set you up with comprehensive global and in-country benefits to support you and your family needs.
Poshmark is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
View Poshmark's Job Applicant Privacy Policy here.",USD 90K - 150K *
762,AI Software Development Engineer,Intel,IND - Bengaluru,Senior-level / Expert,"Job Details:
Job Description: 
Generative AI technology provides many advantages for engineers, support teams, developers, and DevOps professionals looking to boost productivity. This type of AI offers a secure, scalable architecture that can connect to diverse data sources and models which can address wide range of use cases. For those interested in working with cutting-edge AI, there are exciting opportunities to apply generative models to streamline workflows and enhance productivity. The role will involve collaborating with cross-functional teams to identify business needs and implement customized solutions. You will have the chance to push boundaries in AI research and development while delivering tangible value. If you are passionate about leveraging technology to solve problems, this is a dynamic chance to drive innovation.

We are looking for a skilled AI Full Stack Developer with 4-7 years of experience to join our innovative team. You will work on building state-of-the-art AI applications utilizing advanced techniques like large language models, neural networks, and natural language processing.

As a AI Full Stack Developer, you will:

Collaborate with cross-functional teams to conceptualize, build, and launch AI-powered products and features
Design, develop, and integrate scalable AI models and systems, leveraging frameworks like PyTorch and TensorFlow
Continuously train, evaluate, and optimize AI models to improve performance
Architect and implement robust data pipelines to support model development and deployment
Develop intuitive interfaces and UX to deliver seamless AI-powered experiences
Monitor and maintain AI systems in production to ensure optimal performance
Stay up-to-date on the latest AI/ML advancements and identify opportunities to innovate
Mentor and share knowledge with teammates to promote AI best practices
We are looking for someone passionate about AI/ML with hands-on experience in:
Building, deploying, and maintaining real-world AI applications
Fine-tuning and optimizing large language models like GPT-3
Conversational AI and natural language processing
Data engineering and pipeline development
This is a unique opportunity to join a team at the forefront of AI innovation. If you have the skills and passion for this role, we want to hear from you
Qualifications:
B.Tech/M Tech. Computer Science with 3-7 years of software development experience in Artificial Intelligence
Experience designing and building AI applications
Strong programming knowledge in Python and parallel programming skills
Model development experience preferred
Experience with embeddings and vector search platforms
Experience with prompt engineering and using augmented data with LLMs
Proficiency in working with UNIX/Linux environments and command-line tools
Experience in LLMs, API development
Good working project experience in cloud computing ie, AWS/ Azure/GCP cloud Services
Experience working on ML services like AWS Bedrock or AzureOpen AI
          Job Type:
Experienced Hire
Shift:
Shift 1 (India)
Primary Location: 
India, Bangalore
Additional Locations:
Business group:
The Network & Edge Group brings together our network connectivity and edge into a business unit chartered to drive technology end to end product leadership. It's leadership Ethernet, Switch, IPU, Photonics, Network and Edge portfolio is comprised of leadership products critically important to our customers.
Posting Statement:
All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
Position of Trust
N/A
Work Model for this Role
This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs.",USD 45K - 84K *
763,Data Scientist,Dew Software,"Pune, Maharashtra, India",Senior-level / Expert,"Dew Software is seeking a skilled Data Scientist to join our dynamic team. As a leading player in the technology industry, we work with clients from various sectors, helping them leverage data to drive strategic decision-making and business growth. As a Data Scientist at Dew Software, you will have the opportunity to work with cutting-edge technologies and innovative approaches to solve complex problems and deliver actionable insights to our clients.

In this role, you will collaborate with cross-functional teams to understand business requirements, collect and analyze data, build predictive models, and communicate findings and recommendations to stakeholders. By leveraging your expertise in data analysis, statistics, and machine learning, you will contribute to the development of data-driven solutions that have a direct impact on our clients' success. Join our team of data enthusiasts and make a difference through the power of data!

Responsibilities
Ability to create AI models utilizing deep learning, neural networks, and ML algorithms to derive business insights and fuel informed decision-making.
Thorough understanding of linear algebra, probability, and statistics to comprehend and use AI models such as Naive Bayes, Gaussian mixture models, and linear discriminant analysis. 
Knowledge to build a variety of AI applications, including language translation, visual recognition or perception, and targeted advertising based on sentiment analysis.
Develop scalable algorithms capable of learning, analyzing and predicting future events.
Structure business problems and drive viable, data-driven hypotheses in collaboration with business partners.
Ability to skillfully enumerate a business problem, quantify its impact, size relevant data, and document applicable sources.
Devise, develop and disseminate actionable intelligence from disparate data sources using advanced data analytics tools and techniques.
Able to work proactively and take initiative without being specifically directed.
·Ability to perform in depth data analysis including but not limited to:
               Machine Learning
              Classification
Optimization
 Time Series analysis
Pattern Recognition
Establish and develop end-to-end automated processes (i.e.: data analyses, model development & implementation, manual processes, etc.)
Ability to communicate complex topics in an easy-to-understand manner when presenting to management.
Ability to visualize data and intelligence in easy-to-understand story telling.
Requirements
Bachelor's or Master's degree in Data Science, Computer Science, Mathematics, or related field
2+ years of experience as a Data Scientist or in a similar role
Strong programming skills in Python or R
Solid understanding of statistical analysis, machine learning, and data mining techniques
Experience with data visualization tools such as Tableau or Power BI
Proficient in SQL and working with large datasets
Ability to work independently and collaborate effectively in a team environment
Excellent problem-solving and analytical skills
Effective communication and presentation skills
3+ years with relational databases (ex. Oracle, Teradata, SQL Server, etc.)
3+ years working with languages Python and SQL
3+ years applying statistics in data analyses (ex. regression modeling, econometrics, classification labeling, recommendation, parametric/non-parametric modeling, etc.)
2 or more years’ experience presenting and delivering results to business partners and leadership.
NodeJS: Node.js works great in real-time web apps that employ push technology over WebSocket. Node’s real-time, two-way connections—where the client and server can each initiate communication—enable the freer exchange of data.
NestJS: The backend framework developed in NestJS gives a structure development approach to build an efficient and scalable architecture.
WebRTC: WebRTC enables Web applications and sites to capture and optionally stream audio and/or video media, as well as to exchange arbitrary data between browsers without requiring an intermediary.",USD 136K - 205K *
764,Data Analytics Manager,GSK,Bengaluru Luxor North Tower,Mid-level / Intermediate,"Key Responsibilities :
 Partner with study teams to define, document, and configure/develop data analytics aids required to execute clinical trial as per protocol and regulatory requirements.  Acts as a subject matter expert and lead within own discipline to investigate new technology as directed.  Provides required contribution to complex technical tasks, including programming of data visualizations tools (e.g. Spotfire).  Contributes to, the planning, coordination and execution of multiple programming activities to deliver all required outputs.  Ensures the collection of programs/outputs and issues are adequately managed for programming activities to achieve business outcomes.  Shares learnings with peers and contributes to internal technical discussions/forums.  Anticipates problems within discipline, proactively uses own expertise and/or seeks input from others, to recommend solutions and influence appropriate change.  In matrix discussions uses technical expertise to provide innovative solutions to project related problems of colleagues and of other projects.  Makes decisions on the implementation of programming possible solutions for low risk pieces of work and proactively proposes options for higher risk activities. Later contributes to the maintenance, bug fixing, and enhancements to implemented solutions.  Contributes to the development or improvement of departmental policies and working practices. Develops responses to audit/inspection questions and complete CAPAs within agreed timelines
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
  
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
  ",USD 110K - 155K *
765,Business Intelligent Specialist,Rackspace,India - Remote,Mid-level / Intermediate,"The Business Intelligent Specialist will be responsible for overall metrics and business improvement reporting. The ideal candidate will possess a good understanding of private cloud technologies, the ability to interpret disparate data sets, and develop action plans to optimize business operations. This person will be expected to take ownership and drive positive change within the organization. 

Role Responsibilities Monthly metrics reporting: Establish, maintain, and communicate key performance indicators against annual, quarterly, and monthly goals. Refresh management dashboards, regional reports, and executive review documents as needed.  Collaborate proactively and independently with stakeholders to construct use cases and generate standardized outputs.  Clarify and transform complex or ambiguous business problem statements into actionable analysis requirements.  Create robust documentation and effectively communicate project progress and outcomes.  Provide analytical support for the PS Delivery team.  Develop and deploy metrics to address key business questions.  Work closely with leadership to understand business challenges and provide data-driven insights for better decision-making.  Communicate complex analysis and insights to leaders through verbal and written presentations.  

Skills & Experience Bachelor’s degree in business administration, finance, computer information systems, engineering, operations research, mathematics, or other relevant analytical disciplines, or equivalent experience.  Minimum of 7 years of professional experience as a Business Analyst, Data Analyst, or in a related role.  Strong proficiency in Microsoft Excel, PowerBI and statistical analysis tools.  Excellent written and oral communication skills, with the ability to effectively communicate across different business areas.  Solid operational business understanding, including awareness of the potential impact of business decisions on various internal and external stakeholders and systems.

 Advanced understanding of best practice analysis, programming, and visualization techniques.  Experience with SQL or other database querying languages for data extraction and analysis is beneficial. Understanding how private cloud technologies work is a plus. Strong attention to detail, ability to work independently, adjust priorities, and thrive in a continuously changing environment.  Experience collaborating with cross-functional teams. Mindset focus on staying updated with the latest industry trends, tools, and best practices.  

About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
  More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",USD 26K - 49K *
766,"Senior Site Reliability Engineer, Data Science Platform",NVIDIA,"India, Pune",Senior-level / Expert,"We are now looking for a Sr. Site Reliability Engineer (SRE), Data Science Platform. At NVIDIA, we pride ourselves on data-driven decision-making, and the data science team is at the heart of this initiative. We are looking for an excellent Sr. Site Reliability Engineer with extensive data infrastructure experience for our data science platform supporting NVIDIA's cloud platform services. Our data science platform serves as the basis for advanced real time data analytics, streaming, data lake and sophisticated ML/AI training with offline/online inferencing for NVIDIA's cloud services.
Site Reliability Engineering is an engineering discipline to design, build and maintain large scale production systems with high efficiency and availability using the combination of software and systems engineering practices. SRE at NVIDIA ensures reliability and uptime as promised to the users and at the same time enabling developers to make changes to the existing system through careful preparation and planning while keeping an eye on capacity, latency and performance. SRE is also a mindset and a set of engineering approaches to running better production systems and optimizations. The person in this position will be responsible for Service Response and Workflows and will drive tools/service development to maintain and improve service SLOs.
What you’ll be doing:
Working on building tools to improve the SRE Observability.
Rapidly debug and triage incidents and user-reported issues.
Make valuable contribution to the overall health, performance, and reliability of Nvidia's Cloud Data Science platform and Infrastructure Services.
Taking ownership of automating, scripting, and tooling of new/existing scripts to help the team achieve 100% automation of daily tasks.
Support services before they go live through activities such as system design consulting, developing software platforms and frameworks, capacity management and launch reviews.
Clear SRE Observability understanding and experience in building new tools and automation using Python/GO.
Maintain services once they are live by measuring and monitoring availability, latency and overall system health.
Scale systems sustainably through mechanisms like automation, and evolve systems by pushing for changes that improve reliability and velocity.
Practice balanced incident response and blameless postmortems.
Be part of an on call rotation to support production systems.
What we need to see:
MS or BS in Computer Science/Engineering or a related field or equivalent experience.
5+ years Site reliability engineering experience working on large scale distributed micro services in a production environment with a real passion for automation and tooling.
SRE approach and who can understand Error budgeting, SLO’s, SLA’s.
Clear understanding on Incident management, change management and problem management process. Ability to detect all service-impacting issues, accurate triage, partner communication, impact containment, service restoration, and post-incident follow-up.
Proven strengths in problem-solving and root causing issues, while continuously seeking ways to drive optimization, efficiency and the bottom line.
Strong experience on streaming data infra services involving web services, Kafka, Spark etc.
Expert knowledge with building and operating large scale observability platforms for monitoring and logging (ELK, Prometheus etc)
Excellent interpersonal skills including the ability to identify and communicate data driven insights
Ways to stand out from the crowd:
Experience with operating large scale distributed systems with strong SLAs.
Excellent scripting: Python, GO.
Strong experience on operating data platforms.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services. Our work opens up new universes to explore, enables amazing creativity and discovery, and powers what were once science fiction inventions from artificial intelligence to autonomous cars. NVIDIA is looking for great people like you to help us accelerate the next wave of artificial intelligence.",USD 45K - 84K *
767,Senior Manager Data Engineering,Publicis Groupe,"Bengaluru, India",Senior-level / Expert,"Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value.
Job Description
As Senior Manager in Data Engineering, you would be responsible for defining and executing data strategy for clients. Your role would be focused on high-quality strategy, definition, and delivery of solutions involving:
Data Integration, Governance & Wrangling
Data Storage and Computation Frameworks, Performance Optimizations
Analytics & Visualizations
Infrastructure & Cloud Computing
Data Management Platforms
The role requires a hands-on technologist with expertise in databases, Hadoop, MDM and reporting to provide strategic and tactical direction to customers in the areas of marketing and technology. The person should have a strong programming background like Java.
As a data engineering practitioner, you should have a point of view and understanding of build vs. buy, performance considerations, hosting, business intelligence, reporting & analytics. Ideally, you have experience in integrating data with marketing scenarios like segmentation, targeting, consumer 360 view, etc.
Responsibilities:
Provide inputs to define and execute strategic roadmap for enterprise data architecture by identifying the current landscape and future business goals
Provide technical leadership and hands-on implementation role in the areas of data techniques including data access, integration, modeling, visualization, mining, design and implementation
Lead a globally distributed team to deliver high quality solutions. Manage functional & non-functional scope and quality
Help establish standard data practices like governance and address other non-functional issues like data security, privacy and quality
Help establish best practice like standards and guidelines for design & development, deployment, support and analytics and mining
Help establish best practice in acquiring, storing and analyzing structured, semi-structured and un-structured data from the enterprise and outside like social
Come up with analytics solutions based on the business goals and appropriate data visualization to support the goals
Manage and provide technical leadership to large data programs or multiple programs implementation based on the requirement using agile technologies
Define and drive key transformational programs like customer 360 degree view for the clients
Functional understanding related to digital marketing & customer experience solution blocks, Master data Management (MDM), Customer Relationship Management (CRM), Campaign Management, Tag Management, Media Buying, Optimizations, Recommendations & Targeting, DMP, and DSP.
Understanding Digital data sources such as Open source data (ex: Facebook, Twitter, LinkedIn etc.), Web log Data (SiteCatalyst, Google Analytics), 3rd party paid data (ex: Acxiom, ACNielsen etc.) and business application data (CRM, Ecommerce etc.)
Run workshops with clients and align client stakeholders to optimal solutions
 Qualifications
12+ years of experience within the field of data engineering
Excellent understanding of data technologies landscape
Well versed with pros and cons of various database technologies like Relational, NO SQL, MPP, Columnar databases
Well versed with Software as a service, Platform as a service and Infrastructure as a service concepts and can drive clients to a decision
Expert in programming languages like Java, Scala and / or JavaScript
Expert in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models
Expert in one or more ETL, BI, Analytics and advanced visualization technologies
Expert in in Hadoop eco-system with one or more distribution like Cloudera and HortonWorks
Expert in agile development with CI / CD pipeline with data projects
Knowledge in computation frameworks like Storm and Spark
Knowledge in cloud and social media technologies and integrations
Expert in master data management and building customer 360 degree views
Strong analytical and problem solving skills
Strong communication skills verbal, written and visual presentations
Strong coordination and negotiation skills
Multi geo experience and distributed delivery experience in large programs
Business Knowledge:  Data driven marketing experience would be a plus
Additional Information
Benefits of Working Here:
Gender-Neutral Policy.
18 paid holidays throughout the year for NCR/BLR (22 For Mumbai).
Generous parental leave and new parent transition program.
Flexible work arrangements.
Employee Assistance Programs to help you in wellness and well being.",USD 121K - 190K *
768,Senior Data Modeler,Sanofi,Hyderabad,Senior-level / Expert,"About Sanofi 
We are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people’s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions. 
 Sanofi has recently embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions that will accelerate Manufacturing and supply performance and help bring drugs and vaccines to patients faster, to improve health and save lives. 
 Role Purpose
As part of the Digital M&S Foundations organization, the data modeler designs implements, and documents data architecture and data modeling solutions, which include the use of relational and dimensional databases. These solutions support Manufacturing and Supply Data Analytical products and other business interests. 
 The successful candidate will: 
 Be responsible for the development of the conceptual, logical, and physical data models in line with the architecture and platform strategy 
Oversee and govern the expansion of existing data architecture and the optimization of data query performance via best practices. The candidate must be able to work independently and collaboratively with the M&S teams 
 Demonstrate strong expertise in one of the following functional business areas of M&S: Manufacturing, Quality, or Supply Chain 
Roles & Responsibilities
Design and implement business data models in line with data foundation strategy and standards 
Work with business and application/solution teams to understand requirements, build data flows, and develop conceptual/logical/physical data models 
Define and govern data modeling and design standards, tools, best practices, and related development for enterprise data models. 
Identify the architecture, infrastructure, and interfaces to data sources, tools supporting automated data loads, security concerns, and analytic models.  
Hands-on data modeling, design, configuration, and performance tuning 
Work proactively and independently to address project requirements and articulate issues/challenges to reduce project delivery risks. 
About you
Bachelor’s or master’s degree in computer/data engineering technical or related experience. 
8+ years of hands-on relational, dimensional, and/or analytic experience, including 5+ years of hands-on experience with data from core manufacturing and supply chain systems such as SAP, Quality Management, LIMS, MES, Planning 
Experience hands-on programming in SQL  
Experience with data warehouse (Snowflake), data lake (AWS-based), and enterprise big data platforms in a pharmaceutical company. 
Good knowledge of metadata management, data modeling, and related tools: Snowflake, Informatica, DBT 
Experience with Agile  
Good communication, and presentation skills 
Pursue progress, discover extraordinary
Better is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.
At Sanofi, we provide equal opportunities to all regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, or gender identity.
Watch our ALL IN video and check out our Diversity Equity and Inclusion actions at sanofi.com!
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",USD 100K - 160K *
769,ML Engineering Intern (6 months),Tower Research Capital,Gurgaon,Entry-level / Junior,"Tower Research Capital, a high-frequency proprietary trading firm founded in 1998, seeks an Intern to join our Core AI & Machine Learning team.
Responsibilities
Set up in-house CI/CD tools to deploy machine learning models into production environments.
Developing data pipelines for cleaning, collecting, processing, and analyzing diverse datasets.
Support the development and implementation of statistical and machine learning algorithms and models.
Conduct experiments and tests to evaluate model performance.
Contribute to optimizing and fine-tuning existing machine learning models.
Qualifications
A bachelor’s, master's, or PhD (ongoing or complete) degree or equivalent from a top university, available to join from January 2023 for 6 months for an in-office internship.
Prior experience with training, building, and deploying models via Tensorflow/Pytorch (or similar) is mandatory.
Experience with CI/CD pipelines and MLOps for automating model deployments.
Skilled in using Linux, SQL, Git, and BASH scripting.
Strong knowledge of Python and hands-on.
Experience in the Finance domain is a plus.
Benefits
Tower continues to enhance the in-house trading system and strategies that have positioned the firm as a leader in the thriving field of quantitative trading. While Tower offers challenges and rewards rivaling those of any Wall Street firm, Tower’s cubicle-free workplace, jeans-clad workforce, and well-stocked kitchens reflect the premium the firm places on the quality of life. Benefits include:
Competitive stipend
Breakfast, lunch, dinner, and snacks on a daily basis
Cab facility within Gurgaon
Tower Research Capital is an equal opportunity employer.",None
770,Product Management - Vice President - Data Product(Risk Product team),Paytm,"Noida, Uttar Pradesh",Executive-level / Director,"Title - Product Management - Vice President
About Paytm: Paytm is India's leading financial services company that offers full-stack payments & financial solutions to consumers, offline merchants and online platforms. The company is on a mission to bring half a billion Indians into the mainstream economy through payments, commerce, banking, investments, and financial services. Its investors include Softbank, Ant Financial, AGH Holdings, Elevation Capital, Berkshire Hathaway, T Rowe Price, and Discovery Capital.   

About the Role: As a Product Manager for Risk Platform involves you to have a pivotal role in enabling internal as well as external risk cases on the platform. You will collaborate with leadership and cross-functional partners in driving the conceptual and technical development of Risk products. As a key member of the Risk Platform Product Management team, you'll collaborate closely with a talented troop of Risk Engineers along with various Business, Product, and Analytics stakeholders within Paytm. Your efforts will directly enhance the overall security of Paytm Product and shape the strategic direction of Paytm Products.

Expectations/Requirements:

Build a real-time data platform that enables complex data workflows and pipelines that move and process data at the Paytm scale
- Build a platform for production-grade models on large-scale datasets to optimize fraud rules performance by utilizing advanced statistical modeling, machine learning, or data mining techniques
- Develop a foundation for laying out non-functional qualities in the platform including resiliency, scalability, security, and lineage
- Analyze, define, design, and document requirements for data, workflow, and logical processes
- Advise on the available standards, methods, tools, and applications relevant to Business Intelligence, Data Analytics, and Data Science and can make correct choices from alternatives
- Own multiple projects working toward a scalable data infrastructure that supports internal customers' needs.

Superpowers/ Skills that will help you succeed in this role:
Should have a Bachelor’s / Masters or an equivalent degree, preferably in engineering or management and have build data platform or ML serving platform.
Ability to think strategically about complex issues, driving thoughtful recommendations and action plans
Ability to work autonomously or in a team and within ambiguous, constantly-evolving environments
Superior communication, presentation and interpersonal skills
Strong ability to interact with, build consensus and influence across a variety of internal and external business partners at all levels of leadership.
Analytical and data-driven, you love digging into the data to analyze what’s happening and define and measure success on every project.
Strong analytical and problem-solving ability.
Highly motivated, self-starter with a proven track record of delivering success while operating within a team environment.
Services/Payments industry experience a plus

Why join us? ·  A collaborative output driven program that brings cohesiveness across businesses through technology·  Improve the average revenue per use by increasing the cross-sell opportunities·  A solid 360 feedback from your peer teams on your support of their goals·  Respect, that is earned, not demanded from your peers and manager 

Compensation: If you are the right fit, we believe in creating wealth for you. With enviable 500 mn+ registered users, 21 mn+ merchants and depth of data in our ecosystem, we are in a unique position to democratize credit for deserving consumers & merchants – and we are committed to it. India’s largest digital lending story is brewing here. It’s your opportunity to be a part of the story!",USD 49K - 91K *
771,Presales Data Architect – Azure,Rackspace,India - Remote,Senior-level / Expert,"Presales Data Architect – Azure
 In this role you will be helping to grow the Rackspace Cloud data practice.  You will be the expert in the region and support the sales of our data projects on Azure.  Our Presales Data Architects are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with our sales team to propose solutions to customers to achieve business outcomes using Google Cloud.
 This is a solutions pre-sales role that places significant emphasis on consultative engagements with a wide range of customer stakeholders, Business Owners, Business Analytics, Data Engineering teams, Application Development, End Users and Management teams.
 Successful candidates will be adept at evangelizing the Rackspace Data Services value proposition – across Professional Services and Managed Services; aligning it to each unique set of customer challenges and articulating the business benefits that can be delivered.
 A key aspect of the role is to engage with customers early in their transformation journey to establish Rackspace credentials as a partner that can help assess, plan and execute the required data transformation or modernization.
  You Will:
·       Data Architect is client facing, pre-sales technologist that works with designated accounts and acts as a technical advocate for Rackspace clients.
·       You are responsible for understanding clients’ business requirements as they pertain to Data solutions, qualifying opportunities and creating designs that match the requirements with appropriate products, managed and professional services.
·       Is considered a thought leader and develops IP & collateral for data and analytics.
·       Sells and positions implementation and advisory services primarily in their assigned LOB, but also understands and advises clients on where other strategic and advisory services fit their needs.
·       Client Facing Sales Support – Works with sales account team, interfacing directly with the Rackspace prospects and customers.
·       Builds trusted advisor relationships, understanding client’s business challenges and proposing solutions.
·       Develops High Level Designs and Architectures – Creates and documents architectures that address client business problems which can be used to ensure a smooth transition from presales to delivery.
·       Create Proposals – Develop proposals, SOWs (Statements Of Work), business cases and RFP responses,
·       Sales Planning – Work with management and sales teams to develop account prioritization and support strategies that will ensure a long-term trusted relationship status.
·       Partner Relationship Management – Develop healthy and trusted relationships with key partners in the geography.
·       Intellectual Property Development – Contribute to the development of Rackspace intellectual property and industry recognition (white papers, speaking engagements etc.
·       Administrative Overhead – Respond to email, phone calls, complete timesheets in a timely manner, expense reports and status reports as required Administrative Overhead.
·       Training – Develop and execute a professional plan that will enhance skills.
·       Contribute to sales process improvement, including developing knowledge bases, creating sales tools, and mentoring other Solutions Architects
 Technical Requirements:
 ·       2+ years of Azure Data platform experience and 5+ years of experience as a Data Architect with a proven track record and experience leading engagements from design to implementation of data analytics solutions.
·       Advanced SQL skills, including the ability to write, tune, and interpret SQL queries; tool specific experience in the RDBMS listed above is ideal.
·       Strong Spark, SQL, Data Modeling, Data lakehouse concepts.
·       Design and optimize data models on AWS Cloud using Azure data stores such as Synapse, Azure SQL, ADLS Gen2, Purview, Python, Fabric, etc
·       Proven experience in migrating data warehouses from SQL Server, Oracle, Teradata and Informatica to Azure.
·       Azure Data Certifications
 Other Requirements:
·       Highly motivated self-starter and team player and demonstrated success in prior roles.
·       Track record of success working through technical challenges within enterprise organizations
·       Ability to prioritize deals, training, and initiatives through highly effective time management
·       Excellent problem solving, analytical, presentation, and whiteboarding skills
·       Track record of success dealing with ambiguity (internal and external) and working collaboratively with other departments and organizations to solve challenging problems
·       Strong knowledge of technology and industry trends that affect data analytics decisions for enterprise organizations
  
About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
  More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",USD 117K - 193K *
772,Data Analyst - Contractual,Razorpay,Bengaluru,Mid-level / Intermediate,"Razorpay was founded by Shashank Kumar and Harshil Mathur in 2014. Razorpay is building a new-age digital banking hub (Neobank) for businesses in India with the mission is to enable frictionless banking and payments experiences for businesses of all shapes and sizes. What started as a B2B payments company is processing billions of dollars of payments for lakhs of businesses across India. 
We are a full-stack financial services organisation, committed to helping Indian businesses with comprehensive and innovative payment and business banking solutions built over robust technology to address the entire length and breadth of the payment and banking journey for any business. Over the past year, we've disbursed loans worth millions of dollars in loans to thousands of businesses. In parallel, Razorpay is reimagining how businesses manage money by simplifying business banking (via Razorpay X) and enabling capital availability for businesses (via Razorpay Capital). 
The Role:
Data Analyst will work with the central analytics team at Razorpay. This will give you an opportunity to work in a fast-paced environment aimed at creating a very high impact and to work with a diverse team of smart and hardworking professionals from various backgrounds. Some of the responsibilities include developing reports, dashboards and data models.
Roles and Responsibilities:
Describe and manipulate data sets, sources, and structures. Develop reports to make data more meaningful to business initiatives, analyze data quantitatively and qualitatively and communicate findings.
Develop data models to transform raw data into meaningful insights
Design, develop, and deploy dashboards using Looker, PowerBI/Tableau, Excel, etc.
Owning the full BI lifecycle from requirements gathering through design & development, and through release and support/maintenance phases
Identify repeat processes and assist in process documentation and automation
Articulate key process flows, manage multiple inputs and priorities.
Mandatory Qualifications:
Bachelor's/Master’s degree in Engineering, Economics, Finance, Mathematics, Statistics, Business Administration or a related quantitative field
1-3 years of relevant analytics and BI experience
Basic Knowledge about data warehouse design and data mining
Expert knowledge of SQL, Excel, and any BI tool like Looker/Power BI/Tableau, etc.
Strong experience in creating data-rich dashboards, writing DAX expressions, and data access management.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Good communication skills and ability to coordinate with multiple stakeholders across multiple functions
Work experience in Consumer tech/startups would be a plus
Razorpay believes in and follows an equal employment opportunity policy that doesn't discriminate on gender, religion, sexual orientation, colour, nationality, age, etc. We welcome interests and applications from all groups and communities across the globe.
  Follow us on LinkedIn & Twitter",USD 67K - 110K *
773,Machine Learning Engineer,ServiceNow,"Hyderabad, India",Senior-level / Expert,"Company Description
At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. 
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.
Job Description
What you get to do in this role:
The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and latest advanced technologies to enable end-to-end, industry-leading work experiences for customers. We are a group of researchers, applied scientists, engineers, and product managers with a dual mission. We build and evolve the AI platform, and partner with teams to build products and end-to-end AI-powered work experiences. In equal measure, we lay the foundations, research, experiment, and de-risk AI technologies that unlock new work experiences in the future.
You will play a major part in building AI and Machine Learning (ML) solutions that transform the user experience and workflow efficiency of enterprise services. Traditional analytical tools tend to require a technically knowledgeable user to produce even simple results. We are taking a completely fresh approach with the expectation that any user, regardless of technical knowledge, can use the AI/ML solutions we develop to operate the services in the enterprise setting in a thoughtful and scalable manner. We are just getting started with our early-adopter customers and we need your help in building and making available an amazing range of solutions to our 5k+ enterprise customers around the world.
Build the best cloud-based AI/ML solutions to power intelligent enterprise services
Collaborate daily with a team of like-minded developers, product managers and quality engineers to produce quality software
Work with product owners to understand detailed requirements and own your code from design, implementation, testing and delivery of high-quality solutions to our users
Qualifications
To be successful in this role you have:
2+ years of experience with Python, Java or a similar OO language
Experience of core AI/ML techniques and algorithms
Passion for JavaScript and the Web as a platform, reusability, and componentization
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Experience with any of the modern UI frameworks like Angular, React or Vue
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
Additional Information
ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.",USD 150K - 230K *
774,Sr Machine Learning Engineer,Wabtec,Bengaluru - KA - IND (ITC Greens),Senior-level / Expert,"Wabtec Corporation is a leading global provider of equipment, systems, digital solutions and value-added services for freight and transit rail. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation and Faiveley Transport, the company has unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems. Wabtec is focused on performance that drives progress, creating transportation solutions that move and improve the world. Wabtec has approximately 27,000 employees in facilities throughout the world. Visit the company’s new website at: http://www.WabtecCorp.com.

It’s not just about your career… or your job title…it’s about who you are and the impact you are going to make on the world. Do you want to go into uncharted waters…do things that haven’t been done to make yours and someone else's life better? Wabtec has been doing that for decades and we will continue to do so! Through our people, leadership development, services, technology and scale, Wabtec delivers better outcomes for global customers by speaking the language of industry.
It’s not just about your career or job title… It’s about who you are and the impact you will make on the world. Because whether it’s for each other or our customers, we put People First. When our people come together, we Expand the Possible and continuously look for ways to improve what we create and how we do it. If you are constantly striving to grow, you’re in good company. We are revolutionizing the way the world moves for future generations, and we want someone who is ready to move with us.
Who are we?
Wabtec Corporation is a leading global provider of equipment, systems, digital solutions, and value-added services for freight and transit rail as well as the mining, marine, and industrial markets. Drawing on nearly four centuries of collective experience across Wabtec, GE Transportation, and Faiveley Transport, the company has grown to become One Wabtec, with unmatched digital expertise, technological innovation, and world-class manufacturing and services, enabling the digital-rail-and-transit ecosystems.

Wabtec is focused on performance that drives progress and unlocks our customers’ potential by delivering innovative and lasting transportation solutions that move and improve the world. We are lifelong learners obsessed with making things better to drive exceptional results. Wabtec has approximately 27K employees in facilities throughout the world. Visit our website to learn more!
Who will you be working with?
Sr. Machine Learning Engineering will work closely with DAI’s data scientists and Wabtec’s cloud architects to deploy scalable machine learning and deep learning solutions in predictive maintenance, cloud and edge video analytics, robotics and automation.  
How will you make a difference?
The Sr. Machine Learning Engineer, working as part of Wabtec’s Digital Applied Innovation (DAI) team will be responsible for architecting and deploying new advanced AI solutions throughout the freight and passenger transportation industry. DAI is a cross-disciplined entrepreneurial group that carries out applied research in AI/ML, designs and deploys cutting edge algorithms and new digital solutions throughout the Wabtec portfolio of businesses.
What do we want to know about you?
Qualifications/Requirements
Bachelor’s in engineering, Physics, Chemistry, Mathematics, or Computer Science from an accredited university or college, or relevant and significant industry experience.
Experience in the fields of AI/ML, NLP, edge computing, and Docker solutions.
Proficient in C/C++, python, GO or similar languages.
Proficient with Deep Learning Frameworks (TensorFlow, PyTorch)
Experience with Natural language processing frameworks
A minimum of 8 years of technical experience in a technology business
A minimum of 3 years of experience as a machine learning engineer
Has had experience in deploying scalable AI solutions that solve industry problems
What will your typical day look like?
you will:
Help set and execute the vision for scalable AI solutions at Wabtec and drive a culture of applied innovation
Work closely with the DAI data scientists to build and deploy highly scalable AI solutions that drive business value for our business units and customers
Set the architecture and framework for scalable video edge analytic solutions that can be leveraged throughout different parts of the business
Partner with the head of DAI and business development teams to engage directly with business unit and external customers to understand pain-points 
Be a machine learning cross-functional leader with organizations such as, Freight Engineering, Services, Transit Engineering, Digital Electronics, Freight Components, Mining and Marine operations to drive new digital solution opportunities 
Lead education and awareness of deploying AI solutions throughout Wabtec to build the pipeline for advanced machine learning engineers within the organization
Be heavily involved in external collaboration efforts with startups, incubators and universities to grow Wabtec’s AI skill base and resource arm  
Act as coach for to others in driving digital industrial solutions across all functional engineering areas
What about the physical demands of the job?
You may also be asked to perform other duties outside of your function or trade, for which adequate training will be provided if necessary.
Our Commitment to Embrace Diversity:
Wabtec is a global company that invests not just in our products, but also our people by embracing diversity and inclusion. We care about our relationships with our employees and take pride in celebrating the variety of experiences, expertise, and backgrounds that bring us together. At Wabtec, we aspire to create a place where we all belong and where diversity is welcomed and appreciated.   
To fulfill that commitment, we rely on a culture of leadership, diversity, and inclusion. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We have created a space where everyone is given the opportunity to contribute based on their individual experiences and perspectives and recognize that these differences and diverse perspectives make us better.
We believe in hiring talented people of varied backgrounds, experiences, and styles… People like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.
Wabtec Corporation is committed to taking on the world’s toughest challenges. In order to fulfill that commitment we rely on a culture of leadership, diversity and inclusiveness. We aim to employ the world’s brightest minds to help us create a limitless source of ideas and opportunities. We believe in hiring talented people of varied backgrounds, experiences and styles…people like you! Wabtec Corporation is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, or protected Veteran status. If you have a disability or special need that requires accommodation, please let us know.",USD 150K - 230K *
775,Data Scientist,Ninja Van,"Hyderabad, India",Senior-level / Expert,"Ninja Van is a late-stage logtech startup that is disrupting a massive industry with innovation and cutting edge technology. Launched 2014 in Singapore, we have grown rapidly to become one of Southeast Asia's largest and fastest-growing express logistics companies. Since our inception, we’ve delivered to 100 million different customers across the region with added predictability, flexibility and convenience. Join us in our mission to connect shippers and shoppers across Southeast Asia to a world of new possibilities. 

More about us: 
- We process 250 million API requests and 3TB of data every day.
- We deliver more than 2 million parcels every day.
- 100% network coverage with 2600+ hubs and stations in 6 SEA markets (Singapore, Malaysia, Indonesia, Thailand, Vietnam and Philippines), reaching 500 million consumers.
- 2 Million active shippers in all e-commerce segments, from the largest marketplaces to the individual social commerce sellers.
- Raised more than US$500 million over five rounds.

We are looking for world-class talent to join our crack team of engineers, product managers and designers. We want people who are passionate about creating software that makes a difference to the world. We like people who are brimming with ideas and who take initiative rather than wait to be told what to do. We prize team-first mentality, personal responsibility and tenacity to solve hard problems and meet deadlines. As part of a small and lean team, you will have a very direct impact on the success of the company.
Roles and Responsibilities
Communicate and collaborate with business stakeholders to identify opportunities to leverage on data assets for the organisation.
Develop data products centered on machine learning / artificial intelligence to support business and operational needs, impacting growth.
Work with engineering and product teams to drive productionisation of data products creating value to our stakeholders.
Accelerate growth of our research arm, to build a world-class data organisation focused on rapid experimentation and discovery.
Design and develop scalable and performant ETL pipelines to prototype and operationalize data science and data analytics use cases.
Requirements
Proficiency in at least one data analysis language (Python / R) and strong in fundamentals of machine learning libraries.
Deep knowledge in statistics, probability and foundational machine learning.
Strong communication skills in writing and presentation.
While we use SQL, Python (and their libraries) in our daily work, we welcome new ideas from you to further develop our toolset.
Tech Stack
Backend: Play (Java 8+), Golang, Node.js, Python, FastAPI
Frontend: AngularJS, ReactJS
Mobile: Android, Flutter, React Native
Cache: Hazelcast, Redis
Data storage: MySQL, TiDB, Elasticsearch, Delta Lake
Infrastructure monitoring: Prometheus, Grafana
Orchestrator: Kubernetes
Containerization: Docker, Containerd
Cloud Provider: GCP, AWS
Data pipelines: Apache Kafka, Spark Streaming, Maxwell/Debezium, PySpark, TiCDC
Workflow manager: Apache Airflow
Query engines: Apache Spark, Trino

Submit a job application
By applying to the job, you acknowledge that you have read, understood and agreed to our Privacy Policy Notice (the “Notice”) and consent to the collection, use and/or disclosure of your personal data by Ninja Logistics Pte Ltd (the “Company”) for the purposes set out in the Notice. In the event that your job application or personal data was received from any third party pursuant to the purposes set out in the Notice, you warrant that such third party has been duly authorised by you to disclose your personal data to us for the purposes set out in the the Notice. ",USD 128K - 198K *
776,Senior Gen-AI Developer,dentsu international,"Pune, India",Senior-level / Expert,"Company Description
Dentsu Media is the largest area of specialism within the dentsu network. It is brought to markets globally, through three award-winning agency brands: Carat, iProspect and dentsu X. All three are underpinned by a scaled network offering of talent, capabilities, and services to support, grow and transform the world’s leading advertisers. Operating across more than 145 countries, dentsu Media is trusted by leading brands across a broad range of sectors, from pioneering technology to cutting-edge fashion. Dentsu leverages technology, creativity, and in-depth data analytics to drive superior results that amplify its clients' brands. Dentsu Media is transforming advertising as a force for growth, a force for good and has become the destination for employees to cultivate meaningful careers and for brands to accelerate previously unseen, sustainable growth.
Job Description
Responsibilities:
Develop and implement state-of-the-art generative AI models and algorithms.
Collaborate with cross-functional teams to identify business challenges and define AI solutions.
Design and optimize neural networks for generative tasks, including image synthesis, text generation, and audio generation.
Conduct research and stay up-to-date with the latest advancements in generative AI.
Evaluate and improve the performance of existing generative models.
Collaborate with data scientists and engineers to gather and preprocess data for training generative models.
Implement and maintain scalable and efficient training pipelines.
Collaborate with software engineers to deploy and integrate generative models into production systems.
Ensure the ethical and responsible use of generative AI technologies.
Primary Technical Skills:
Strong programming skills in Python and experience with backend development.
Understanding of deep learning frameworks such as TensorFlow or PyTorch.
Solid understanding of computer vision and natural language processing.
Familiarity with cloud platforms such as AWS or Azure(Preferred).
Proficiency in data preprocessing and manipulation.
Secondary Technical Skills:
Knowledge of computer vision, natural language processing, or audio processing is a plus.
Knowledge of distributed computing and parallel processing.
Familiarity with reinforcement learning algorithms.
Strong mathematical and statistical foundation.
Qualifications
Degree in Computer Science, Engineering, or a related field.
Experience in developing and deploying generative AI models in real-world scenarios.
Strong problem-solving and analytical skills.
Excellent communication and teamwork abilities.
Ability to work in a fast-paced and dynamic environment
Additional Information
  ",USD 60K - 192K *
777,Senior Data Engineer,Version 1,"Bengaluru, India",Senior-level / Expert,"Company Description
Version 1 is a Technology Services company, delivering impactful change to help our customers navigate the rapidly changing digital-first world. We have recently hired our 3000th employee, doubling in size since 2020. We plan to triple in size in the next 5 years. We are 12 years a Best Workplace in Ireland (GPTW 1st place), 5 in the UK (GPTW 5th place) and 1 in India (GPTW 1st place).
We work hard to ensure we understand what our customers need from their technology solutions and then we deliver. We are an award-winning company who provide world class customer service; we think big, and we hire great people.
We believe in continuously improving to make a real difference to the careers and work environment of our people. Being a Great Place to Work involves listening to our people and ensuring they are Trusted and Empowered. We are an open and transparent workplace. We have open-door management and balanced policies. Constructive feedback is encouraged and welcomed at all levels.
No 1 Best place to work in Ireland #GPTW2023 !!
5th Best Large Workplace in the UK #GPTW2023!!
No 1 Best place to work in India #GPTW2023 !!
10th place in Glassdoor Top 50 UK companies
UK & Ireland’s premier Oracle, Microsoft & AWS partner
Market leader in Oracle ERP and Cloud Applications
Consulting, implementation and support services
3000 strong,€255m/ £220m revenue business
We are an award-winning company who provide world class customer service; we think big and we hire great people. Version 1 are more than just another IT services company - we are leaders in implementing and supporting Oracle, Microsoft and AWS technologies.
Invest in us and we’ll invest in you; if you are driven, committed and up for a challenge, we want to meet you.
Job Description
The Senior Data Engineer, 5+ years, the role requires someone with excellent SQL, Azure Synapse Analytics, Delta Lake, PySpark, Medallion Architecture, Dimensional Modelling, and Data Warehouses/Analytics more generally. You should be proactive and interested in our business and new technologies about Data as Microsoft Fabric. This is an excellent opportunity for someone to learn and grow with the company and learn new technologies.
The ideal candidate will have a deep understanding of Azure cloud technologies and be able to design, build, and maintain scalable and secure data pipelines. They will also be able to work with stakeholders to understand business requirements and translate them into technical specifications.
The Senior Data Engineer will also be responsible for:
Design, build, and maintain data pipelines on Azure cloud.
Integrate data from various sources.
Troubleshoot data problems and optimize performance.
Stay up to date on the latest Azure cloud technologies.
Gathering and analyzing data requirements.
Work with stakeholders to understand business requirements and translate them into technical specifications.
Creating new ETL pipelines and amending existing ones.
Delivering and presenting proofs of concept to of key technology components to stakeholders.
Working with other members of the project team to support delivery of additional project components.
Qualifications
Skills:
Strong Azure Synapse Analytics experience.
Strong SQL skills.
Experience between 3-5 Years.
Hands-on experience in Delta Lake and PySpark.
Experience Medallion Architecture.
Dimensional Modelling.
Use version control (GIT) as per team deployment strategy.
Experience planning changes.
Experience developing ETL solutions.
Demonstrated competencies with multi-dimensional design, star schemas, facts, and dimensions.
Nice to have
BI and Analytics professional experience across a range of technologies including Microsoft Power BI, and Python.
 Azure DevOps and CICD pipelines.
 Security – IAM (Identity and Access Management) experience: row-level security, Azure groups, and resources.
Experience with data modeling.
Microsoft certifications in Data like DP-203.
Interest in Microsoft Fabric.
Additional Information
At Version 1, we believe in providing our employees with a comprehensive benefits package that prioritizes their well-being, professional growth, and financial stability.

One of our standout advantages is the ability to work remote or with a hybrid schedule along with business travel, allowing our employees to strike a balance between work and life. 

We prioritize the health and safety of our employees, providing private medical and life insurance coverage, as well as free eye tests and contributions towards glasses. Our team members can also stay ahead of the curve with incentivized certifications and accreditations, including AWS, Microsoft, Oracle, and Red Hat.

Our employee-designed Profit Share scheme divides a portion of our company's profits each quarter among all full-time employees. We are dedicated to helping our employees reach their full potential, offering Pathways Career Development Quarterly, a program designed to support professional growth.",USD 121K - 190K *
778,R&D Staff Software Development Engineer 1 (Java & Spark),Sopra Steria,"Noida, Uttar Pradesh, India",Senior-level / Expert,"Company Description
About Sopra Banking Software
Our teams consist of exceptional people with Entrepreneurship, Diversity, Respect, and Collaboration as values at the core. We bring together people from different lifestyles, backgrounds and cultures to partner with more than 1,500 leading Financial institutions worldwide. The rich variety of our solutions, the strength of our conviction and our passion for innovation enable us to support our clients on a daily basis and in their future projects, as well as in their goals regarding Financial inclusion. Our customers, based in over 80 countries, benefit every day from our technologies and software, as well as the expertise of our 5,000 employees. Sopra Banking Software is a subsidiary of the Sopra Steria Group, a European leader in consulting, digital services and software development. With more than 50,000 employees, the Sopra Steria Group generated a turnover of €5.1 billion in 2022. And with the power of our parent group, Sopra Steria, behind us, anything is possible for our teams and our partners.
Job Description
How would you shape finance?
Sopra Banking software has an opportunity for a Staff Software Development Engineer 1 in our R&D team at Noida location.
Be part of one of the world’s fastest growing fintechs. Design the future of finance together with 5,000+ industry experts. Create your own tailor-made fintech career and find your own path. Be part of Sopra Banking Software, and let’s carve out the future together.
Discover SBS on YouTube
Minimum Qualifications
Bachelor's or higher engineering degree in Computer Science, or related technical field, or equivalent additional professional experience.
Should have 9-12 years of overall experience in delivering solutions based on Java and open-source technologies as an engineer in global organizations.
Hands on experience with java 8 or higher, spring, Spring batch, MongoDB or PostgreSQL, microservices architecture, Reactive programming, Redis (caching), Angular (GUI) and Cloud computing.
 Preferred Qualifications
Hands on experience of analysis and development with Data Processing platform using Spark
Strong exposure on working in the large enterprise grade components with ability to manage the E2E delivery
In-depth Experience in Microservices based Cloud Native architecture with Java background and having exposure to digital transformation and digital technologies
Good exposure on working with large enterprise grade components
Good experience and understanding of working in an agile environment
Good understanding of DevOps processes (CI/CD pipeline)
Fintech or lending domain experience is a plus but not necessary.
Strong communicator with ability to collaborate cross-functionally, build relationships, and achieve broader organizational goals.
Self-starter, who can take initiatives and get things done.
 What you will do
Use your deep technical understanding for contribution to the architectural design for the product.
Build software products for banking and financing institutions with R&D teams that are openly collaborative, are non-hierarchical, respect contributions and work with agility
Enable, empower, and encourage teams for continuous improvement of technology and processes
Challenging and supporting people and engineering practices to improve the quality of product.
Enable, empower and encourage teams for continuous improvement of processes
Provide governance to product team to ensure quality and efficiency of solutions
Act as a mentor to team and reinforce organizational values and culture
 Total Experience Expected: 08-11 years
Qualifications
Bachelor's or higher engineering degree in Computer Science, or related technical field, or equivalent additional professional experience
Additional Information
 Secondary Location: Noida Campus
At our organization, we are committed to fighting against all forms of discrimination. We foster a work environment that is inclusive and respectful of all differences.
All of our positions are open to people with disabilities.",USD 45K - 84K *
779,"Senior Data Engineer, e-commerce solutions-2",Mastercard,"Gurgaon, India",Senior-level / Expert,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer, e-commerce solutions-2
Senior Data Engineer, e-commerce solutions
Overview

Data and Analytics team build internal analytic partnerships, strengthening focus on the health of the business, portfolio and revenue optimization opportunities, initiative tracking, new product development and Go-To Market strategies.
• Are you excited about Data Assets and the value they bring to an organization?
• Are you an evangelist for data driven decision making?
• Are you motivated to be part of a Global Analytics team that builds large scale Analytical Capabilities supporting end users across 6 continents?
• Are you interested in proactively looking to improve data driven decisions for a global corporation?

The ideal candidate has a knack for seeing solutions in sprawling data sets and the business mindset to convert insights into strategic opportunities for our company.

Role
• Work closely with global analytics teams to architect, develop, and maintain advanced reporting solutions on large volumes of data to support analytics and reporting needs across products, markets, and services.
• Translate business requirements into tangible solution specifications and high quality, on time deliverables.
• Create repeatable processes to support development of reporting needs.
• Effectively use tools to manipulate large-scale databases, synthesizing data insights. Provide 1st level insights/conclusions/assessments and present findings via Tableau/PowerBI dashboards, Excel, and PowerPoint.
• Apply quality control, data validation, and cleansing processes to new and existing data sources.
• Provide guidance and mentorship to junior team members.

All About You

• 7+ years’ experience in data engineering and management, data mining, data analytics, data reporting, data product development and quantitative analysis.
• Financial Institution or a Payments experience a plus
• Proactive self-starter seeking initiatives to advance.
• Data architecture experience and experience in building data models.
• Experience with data validation, quality control and cleansing processes to new and existing data sources.
• Advanced SQL skills, ability to write optimized queries for large data sets.
• Expert in writing stored procedures, functions and views is preferable.
• Experience on Platforms/Environments: Cloudera Hadoop, Big data technology stack, SQL Server, Microsoft BI Stack, Cloud, Snowflake, and other relevant technologies
• Exposure to Python, Scala, Hive, Impala, Spark, Cloud, and other related technologies.
• Experience in data pipeline creation via tools such as Alteryx, SSIS etc.
• Advanced knowledge of any of the job scheduling tools such as Apache Airflow, NIFI, and other related tools.
• Experience with data visualization tools such as Tableau, Domo, and/or PowerBI is a plus.
• Experience presenting data findings in a readable and insight driven format. Experience building support decks.
• Must be able to interact with management, internal stakeholders and collect requirements.
• Must be able to perform in a team, use judgment and operate under ambiguity.
• Experience for leading the entire project and manage timely execution of the plan, provide regular update to key stakeholders.

Education

• Bachelor’s or master’s degree in a Computer Science, Information Technology, Engineering, Mathematics, Statistics, M.S./M.B.A. preferred.

Additional Competencies
• Excellent English, quantitative, technical, and communication (oral/written) skills.
• Analytical/Problem Solving
• Team player, excellent communication skills
• In depth technical knowledge, drive, and ability to learn new technologies.
• Strong attention to detail and quality
• Creativity/Innovation
• Self-motivated, operates with a sense of urgency.
• Project Management/Risk Mitigation
• Able to prioritize and perform multiple tasks simultaneously.

Corporate Security Responsibility

Responsibilities

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must.
• Abide by Mastercard’s security policies and practices.
• Ensure the confidentiality and integrity of the information being accessed.
• Report any suspected information security violation or breach, and
• Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.",USD 121K - 190K *
780,Associate Lead Product Data Management,MillerKnoll,Bengaluru - IBU Cunningham Road,Mid-level / Intermediate,"Why join us? 

Our purpose is to design for the good of humankind. It’s the ideal we strive toward each day in everything we do. Being a part of MillerKnoll means being a part of something larger than your work team, or even your brand. We are redefining modern for the 21st century. And our success allows MillerKnoll to support causes that align with our values, so we can build a more sustainable, equitable, and beautiful future for everyone.

Job Description
As we grow and mature in the Product Data domain and look forward to new and upcoming improvements to process and tools, we are working on creating a niche space focused on the CSP and other North America product data tools and processes. For this we are seeking to hire an Associate Lead – Product Data Management who will oversee all activities within this specialized team and has the knowledge and expertise in CSP, PDM and other allied technology and its associated Product Data tools along with other product database management systems. The role will lead the group of NA contract and retail teams.
The role includes all technical challenges associated with analyzing, defining, and documenting specification requirements, designing & developing product data technology solutions as per business needs. The ideal aspirant should understand the product data lifecycle to implement solutions that deliver on end-user needs. Responsible for the accuracy and data integrity of product information that is used for both internal and external customer tools and technology including SIF, price books, order acknowledgements, and manufacturing systems. 

Responsibilities
Lead and manage a team of Product data associates of varied experience levels, guiding them towards success.
Work assignment, distribution, task estimation, goal planning and conducting performance reviews as per company policy.
Empowering team members with skills to improve their confidence, product knowledge, and communication skills.
Keep up to date with emerging applications, technologies, and standards in the field.
Project planning and tracking. Cross team coordination for project delivery.
Individually develop/contribute and maintain data vocabulary content for our custom extensions and tools.
Execute on the vision of the project team to structure new product offerings and vocabulary into the system with precision.
Maintain existing products and options in system; provides changes to current product offerings.
Ensuring data accuracy of products, options, prices and ensure consistency of data representation across product lines.
Manage data maintenance schedules and coordinate them with product effective dates.
Manage process flow of all MillerKnoll product information via Corporate Source Product (CSP) Database.
Work with cross functional teams to handle insourcing/outsourcing data relationships and data changes.
Participate in a cross-functional team to research, identify and develop product information solutions necessary to bring a product offering to both internal and external clients.
Follow self-test and evaluation process to ensure data is not faulty before deployment into production environment.
Perform additional responsibilities as requested to achieve business objectives.
Work with accuracy and efficiency while meeting due dates and juggling various projects and timelines.
Perform as first level support for the team's technology support email/phone line responding to user problems and questions.
Capable of understanding client’s/dealer’s requirements and communicate with them fluently during stages of the projects.
Skills & Requirements
A minimum of 12+ years overall experience with the last 3+ years in product data management activities doing data analysis, creation, maintenance and governance of data and its schema/models.
Must be working at a Sr. Product Data Analyst/Specialist position to be eligible to apply.
Should have hands on experience in configured product data systems and knowledge of introducing the new product data in configured data structure.
The aspirant will have to demonstrate very good interpersonal and relationship management skills having worked in a large team environment.
Strong verbal, written and presentation skills with ability to communicate complex technical concepts to technical and non-technical professionals at all levels of the organization.
Experience working with Product owners, Product Managers and Product Engineers to clarify requirements.
Demonstrated ability to lead, influence, solve problems, and work with all levels in the organization, including executive leadership.
Strong knowledge in product data technology, PDM, CSP, CET and pCon and any other PIM concepts is significant advantage.
Clear understanding of the data requirements for both downstream and upstream teams.
Should be detail oriented and possess analytical and problem-solving skills.
Ability to troubleshoot technical and functional problems with intuitive problem-solving techniques.
Highly self-motivated and organized to achieve the monthly data freeze dates and product release cycles.
Good communication skills verbal and written (English).
Should be willing to be flexible in terms of working shifts and be ready to extend hours to support release cycles.
MillerKnoll is an equal opportunity employer.
Who We Hire?

Simply put, we hire everyone. MillerKnoll is comprised of people of all abilities, gender identities and expressions, ages, ethnicities, sexual orientations, veterans from every branch of military service, and more. Here, you can bring your whole self to work. We’re committed to equal opportunity employment, including veterans and people with disabilities.",USD 30K - 56K *
781,"Big Data Engineer (Pyspark, Python and SQL))",Telstra,Telstra ICC Hyderabad,Mid-level / Intermediate,"Employment Type
Permanent
Closing Date
28 Dec 2023 11:59pm
Job Title
Big Data Engineer (Pyspark, Python and SQL))
Job Summary
As a Data Engineering Analyst, you create and provide access to high quality and reliable data solutions. In collaboration with your colleagues you deliver and develop best practice data solutions and pipelines. You are known for the integrity and accuracy of data that enables quality data-driven business decisions and equip Telstra to deliver better customer and business outcomes. In a DevOps model, you will develop the data pipelines using Continuous Integration; Continuous Deployment (CICD) techniques.
Job Description
About Telstra
We're Australia's leading telecommunications and technology company. And with a global presence in more than 22 countries, we have a strong global footprint. Our purpose is to build a connected future so everyone can thrive. We're all about providing the best experience and delivering the best tech on the best network. This includes making Telstra the place you want to work.
We offer a full range of services and compete in all telecommunications markets throughout Australia and are the most well-known brand in technology and communications industry.
We have operations in more than 20 countries, including in India. In India we are a licensed Telecom Service provider (TSP) and have extended our global networks into India with offices in Bangalore, Mumbai and Delhi. We’ve opened an Innovation and Capability Centre (ICC) in Bangalore and have a presence in Pune and Hyderabad. In India, we’ve set out to build a platform for innovative delivery and engagement that will strengthen our position as an industry leader. We’re combining innovation, automation and technology to solve the world’s biggest technological challenges in areas such as Internet of Things (IoT), 5G, Artificial Intelligence (AI), Machine Learning, and more.
Here’s what you can expect from us
Hybrid way of work, which will allow us to enjoy the benefits of both remote and in-office collaboration. This means that we will have more flexibility, autonomy, and diversity in our work environment, while also maintaining the connection, culture, and creativity that we value as a team. We believe that this is the best way to support our employees' well-being, productivity, and innovation in the post-pandemic world.
Flexible working. Choose when and how you work so you can be at your best.
Maternity Leave. Up to 26 weeks provided to the birth mother with benefits for all child births.
(Women in Tech) Initiative to promote women in tech. We believe that diversity and inclusion are essential for innovation and growth, and we want to support and empower more women to pursue careers in STEM fields.
Pay for performance. We recognize outstanding contributions through our competitive incentive programs.
Insurance benefits. Receive generous insurance benefits such as medical, accidental and life insurance.
Unlimited learning. Level up your skills with access to 17,000 learning programs. Learn ‘on the job’ and achieve university credits towards degrees and master’s programs.
Global presence. With a global presence across 22 countries, there are many opportunities to work where we do business.
Function overview
Make a difference as part of Product and Technology, your mission will be simple: capture market value at scale by building products our customers love that are simple to experience, seamless to deliver, and are profitable to the core.
What you'll do
Being part of Data Engineering means you'll be part of a team that focuses on extending our network superiority to enable the continued execution of our digital strategy. With us, you'll be working with world-leading technology and change the way we do IT to ensure business needs drive priorities, accelerating our digitization programe.
We are seeking a highly skilled Data Engineer with expertise in Spark, Python, Scala. The successful candidate will be responsible for will be responsible for designing, developing, and maintaining data pipelines using Spark, Python, Scala, and related technologies. The Data Engineer will also be responsible for ensuring data quality, data security, and optimal performance of the data pipelines. Any new engineer would be mostly into developing reusable data processing and storage frameworks that can be used across data platform.
Hadoop Data Engineering – Hive, Oozie, Yarn / MapReduce, Spark (must) with SCALA (Pref) or Python, Strong SQL.
Key Responsibilities
Design, develop, and maintain data pipelines using Spark, Python, Scala, and related technologies on Hadoop/Cloudera Platform
Work with high volume data and ensure data quality and accuracy.
Implement data security and privacy best practices to protect sensitive data.
Develop and maintain documentation on data pipeline architecture, data models, and data workflows.
Monitor and troubleshoot data pipelines to ensure they are performing optimally.
Stay up to date with the latest developments in Azure, AWS, Spark, Python, Scala, and related technologies and apply them to solve business problems.
Optimize data pipelines for cost and performance.
Automate data processing tasks and workflows to reduce manual intervention.
Ability to work in Agile Feature teams.
Provide training and educate other team members around core capabilities and helps them deliver high quality solutions and deliverables/documentation.
Self-Motivator to perform Design / Develop user requirements, test and deploy the changes into production.
Who we're looking for.
4-6 Years of experience on Spark Core, Spark SQL, SQL/Hive/Impala 
Exposure on Hadoop Ecosystem(HDP/Cloudera/MapR/EMR etc)  
Experience of working on File formats (Parquet/ORC/AVRO/Delta/Hudi etc.)  
Experience with high volume data processing and data streaming technologies 
Experience of using Orchestration tools like Control-m 
Strong experience in data modelling, schema design, and ETL development using SQL and related technologies. 
Familiarity with data security and privacy best practices 
Good exposure on TDD 
Exposure on using CI tools like Git, Bitbucket, Github, Gitlab, Azure DevOps 
Exposure on using CD tools like Jenkins, Bamboo, Azure DevOps 
Cloud exposure (Hadoop)  
Experience and knowledgeable on the following: Azure data offerings - ADF, ADLS2, Azure Databricks, Azure Synapse, Eventhubs, CosmosDB etc, Presto/Athena  
Exposure of working on Power BI  
Prior experience in building or working in team building reusable frameworks 
Good understanding of Data Architecture and design principles. (Delta/Kappa/Lambda architecture)  
Exposure to Code Quality - Static and Dynamic code scans  
Good knowledge of NoSQL Databases/ HBase/ MongoDB / Cassandra / Cosmos DB 
Good knowledge of GraphDB(Neo4J) 
Experience with enterprise data management, Datawarehouse, data modelling, Business Intelligence, data integration. 
Expertise in SQL and stored procedure. 
Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms. 
Experience in working on Azure SQL Data warehouse (Synapse) and Azure analysis service or Redshift or Synapse 
Propose best practices/standards 
Translate, load and present disparate datasets in multiple formats/sources including JSON, XML etc. 
Should be able to provided scalable and robust solution architecture depending on the business needs.  
Should be able to compare tools and technologies and recommend a tool or technology  
Should be well versed with overall IT landscape, technologies and should be able to analyse how different technologies integrates with each other 
Call to action
If you're excited about the opportunity to be part of a team, committed to delivering amazing experiences to our customers – this could be the role for you!
___________________________
We’re committed to building a diverse and inclusive workforce in all its forms. We encourage applicants from diverse gender, cultural and linguistic backgrounds and applicants who may be living with a disability. We also offer flexibility in all our roles, to ensure everyone can participate.
To learn more about how we support our people, including accessibility adjustments we can provide you through the recruitment process, visit www.telstra.com.au/careers/diversity-and-inclusion.",USD 37K - 70K *
782,Python Developer and Data Modeler,Unison Consulting Pte Ltd,"Bengaluru, Karnataka, India",Mid-level / Intermediate,"Data Modeling: Design and implement efficient data models to support various business requirements using Python.
Python Development: Utilize your expertise in Python programming to create scalable and maintainable code for data processing and manipulation.
Pandas Mastery: Demonstrate proficiency in Pandas library to analyze, clean, and transform large datasets with precision.
PyData Ecosystem: Leverage the PyData ecosystem tools and libraries to enhance data analysis and visualization capabilities.
Collaboration: Work closely with cross-functional teams, including data scientists, analysts, and engineers, to understand requirements and deliver effective data solutions.
Requirements
Python Proficiency: Strong hands-on experience with Python programming language and its ecosystem.
Data Modeling Skills: Proven expertise in designing and implementing effective data models for diverse business needs.
Pandas Expertise: In-depth knowledge of Pandas library for data manipulation and analysis.
PyData Familiarity: Experience working with various PyData tools and libraries for efficient data processing.
Problem-Solving Skills: Ability to analyze complex problems and develop creative and effective solutions.
Communication Skills: Excellent communication skills to collaborate with team members and present findings to non-technical stakeholders.",USD 100K - 160K *
783,Software Engineering MTS-AI/ML,Salesforce,India - Bengaluru,Mid-level / Intermediate,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
Salesforce Personalization is the best-in-class tool to enable organizations to harness data combined with sophisticated AI modeling and flexible business rules to automatically deliver omnichannel relevant, personalized experiences in real-time so organizations can increase revenue, shorten sales cycles, and improve customer satisfaction.

This is an exciting opportunity to build something new in AI/Personalisation domain! We want to build the Next Best Experience AI-generated decisions at the individual level in any channel: chat, web, messaging, etc by Optimising toward business goals across Salesforce’s C360 clouds. We will offer experimentation and rules-based decisions as required, but inspiring our customers to rely on AI first.

Build and deliver personalisation services exposed in-context to the Salesforce customer so they can deliver AI-generated, personalised experiences to their customers.

Responsibilities:
Deliver on full life cycle software components for our mission critical, enterprise SaaS web applications
Support our commitment to continuous integration, unit tests, and functional automation
Build and code components
Provide attention to detail and a commitment to delivery of high-quality, stable deliverables
Work seamlessly as part of a multi-site, multi-cultural, development and testing team
Continually evangelize Scrum and an Agile development processes
Be self-motivated; driven to achieve and exceed committed milestones
Display strong collaboration skills, including the ability to mentor and be mentored
Desire to work in a growing, fast-paced environment of innovation

Required Skills:
Experience developing SaaS applications
Deep knowledge of object-oriented programming and experience with at least one object-oriented programming language (Java, Javascript, C++, C#, Ruby, Python)
High proficiency in at least one high-level programming language and web framework (React.js, NodeJS, Angular Express etc.)
Solid experience on web technologies, such as JavaScript, CSS, HTML5, JavaScript, JSON
Proven understanding of database technologies such as SQL, PL/SQL, and relational database schema design
Experience building high throughput, low latency REST APIs
Experience in automated testing including unit and functional testing
Excellent interpersonal skills
Experience in AI and ML is a BIG PLUS

Preferred Qualifications:
Experience building highly scalable web applications.
Experience with Agile software development and test-driven development.
Track record of being a top performer in current and past roles
Experience troubleshooting full service stack, end-to-end ownership
Present the designs to internal/external groups and review designs of others
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 37K - 70K *
784,State Street Global Advisor- ESG Portfolio Characteristics-Data Engineer- Manager,State Street,"Bengaluru, India",Senior-level / Expert,"Company profile
State Street Corporation (NYSE: STT) is one of the world's leading providers of financial services to institutional investors, including investment servicing, investment management and investment research and trading. With $33.99 trillion in assets under custody and administration and $2.81 trillion* in assets under management as of September 30, 2018, State Street operates in more than 100 geographic markets worldwide, including the US, Canada, Europe, the Middle East and Asia. For more information, visit State Street’s website at www.statestreet.com.
*This figure is presented as of September 30, 2018 and includes approximately $28 billion of assets with respect to SPDR products for which State Street Global Advisors Funds Distributors, LLC (SSGA FD) acts solely as the marketing agent. SSGA FD and State Street Global Advisors are affiliated.
About Business Line
Application Technology Solutions (ATS) function group is essential for State Street Global Advisors. It enables us to deliver data and insights to our clients using advanced technologies such as cloud, artificial intelligence and robotics process automation. We are leading the company’s digital transformation and modernization initiatives and enhancing business capabilities with industry best practices. We value technology skills and innovation in our collaborative global organization. We are looking for top technical talent to join our team and create innovative technology solutions that will help us become a next-generation financial services company. If you want to grow your technical skills, solve real problems and make an impact on our industry, join us.
Responsibilities
Implement provided requirements to enhance and/or build data pipelines.
End-to-end impact analysis for new designs and production issues alike.
Participate in agile ceremonies to provide plans, estimates and updates.
Provide scalable solutions that work with large datasets without impacting performance.
Identify and escalate risks and dependencies early on.
Attention to detail and adherence to best practices.
Qualification & Certifications
8+ years of IT experience with advanced Python and SQL.
3+ years of hands on data engineering experience building and deploying data pipelines in any cloud solution.
Bachelor’s degree or equivalent related work experience.
Hands on development (and maintenance) experience with a large scale project.
Experience in Agile SDLC.
Primary Skills (Must Have)
Strong demonstrated skills in data engineering projects.
Familiarity with one of orchestration tools such as Airflow, DBT and Delta live tables.
Familiarity in cloud native tools (AWS preferred).
Basic familiarity with Unix.
A good understanding of enterprise architecture design principles.
Strong analytic, debugging, problem solving and collaborative skills.",USD 121K - 190K *
785,"Specialist, SIMPHONI Data Management Tester, Research IT",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.

#HYDIT #LI-Hybrid
Qualifications & Experience
Bachelor’s degree in computer science, Engineering or related Data Science and Engineering disciplines is preferred
3+ years of relevant industry experience required.
Manual Testing, Automation Testing (Selenium (QTP), LoadRunner(SIMILAR), etc) for data & analytics solutions
Expertise in software testing methodologies, tools, and techniques. 
Experience with SDLC, continuous integration, and deployment. 
Experience with authoring test plans, scripts and trace matrix.
Experience with defect management including reporting.
Understanding of scripting (Python,php,java, R etc.), Statistical Analysis, Spotfire and SQL is a plus
Experience with AWS (Data Lake, AWS Glue, IAM, S3, RDS, Fargate, Lambda, API Gateway etc.) is preferred.
Experience in using agile tools (e.g., Jira) and IT Service Management tools (e.g., ServiceNow).
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
786,Data Science NLP developer,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
2-8 years of experience in commercial software development & data science for medium to large scale deployments. Must have worked on multi domain and wide range of technologies and hands-on on leading technologies. Quick learner and passionate to drive the programs through technical strengths.Tasks
Research & Development of Algorithms in the area of ML, NLP, NLU and Text Analytics
Work closely with the research & product teams to investigate the approach & develop professional grade software for Business Units
Study & extend the Open-Source frameworks in ML & NLP, Analytics for suitable requirements.
Grasp and learn from the on-job assignments in the area of research, suggest innovative approaches & work independently.
Own the complete pipeline with Data Engineering activities.
Benchmarking with SOTA models and extend/improve the results by closely working with domain experts and senior researchers.
Requirements
In Depth knowledge of Machine Learning Algorithms and that are used in NLP and NLU
Conceptual and hands on experience in using and implementing Deep Learning architectures like CNN, RNN and its various flavors.
Strong knowledge in Data Structures
Expert in Production Deployment and Development using python
In depth knowledge of python libraries like NumPy, SciKit, Pandas etc.
Production experience on know-how of SDLC/Agile development
Strong Mathematics w.r.t Machine Learning and Deep Learning
Experience in extending functionalities from Open-Source projects.
Experience in working as or along with Research Team shall be an added advantage.
Technical Skills and Competency:
Excellent in Python programming skill is a MUST.
Hands on experience in Python in Production is mandatory.
R knowledge would be an added advantage.
Experience in NLTK, Spacy, Spark ML shall be an added advantage.
Knowledge of Web-Services/SoA/RESTful Services and Semantics shall be an added advantage.
Excellent Communication and Interpersonal skills
Fundamentals of Generative AI and Experience with LLMs & RAG would be a big plus.
 Qualifications
BE/MS/M. Tech (Electronics, Computer Science or related)
Additional Information
2-8 Years of experience",USD 45K - 84K *
787,Product Data Analyst,MillerKnoll,Bengaluru - IBU Cunningham Road,Entry-level / Junior,"Why join us? 

Our purpose is to design for the good of humankind. It’s the ideal we strive toward each day in everything we do. Being a part of MillerKnoll means being a part of something larger than your work team, or even your brand. We are redefining modern for the 21st century. And our success allows MillerKnoll to support causes that align with our values, so we can build a more sustainable, equitable, and beautiful future for everyone.
Role: Product Data Analyst  
Location: Bangalore
Job Description
The Product Data Specialist position is responsible for organizing, creating and updating product information in our internal systems.  This position will help build and maintain a wide breadth of data associated with our product assortment including but not limited to pricing, dimensions, care instructions, design history, key features, and compliance details. 
Essential Functions
Ensure the timely and accurate creation of new SKUs to support product launches via CSV upload and/or direct data entry into relevant systems maintaining strict adherence to data integrity standards.
Audit SKU and product level data to ensure adherence to data integrity standards, updating where appropriate.
Update product information including cost, price, or other facets are made in a timely and accurate fashion.
Gather product data from a variety of sources including vendor websites, PDFs, and spreadsheets and organize into CSV files for upload into backend systems. 
Perform additional responsibilities as requested to achieve business objectives of the team.
Ideal candidate
Bachelor’s degree or equivalent experience working with large data sets.
4-6 years’ experience working with ERP systems and/or content management systems.
Superior attention to detail.
Strong excel / CSV skills; comfortable working with and manipulating large data sets.
Ability to work effectively with a variety of internal and external business partners.
Ability to work independently and manage multiple projects, with excellent time management skills.
Excellent written, verbal and interpersonal communication skills.
Ability to take direction, constructive criticism and to work within specified deadlines.
Adhere to process and procedures defined for the role, the team and the organization.
Demonstrates ability to work effectively with a variety of internal and external business partners.
Knowledge of NetSuite or similar ERP or PIM systems a plus.
Herman Miller is an equal opportunity employer
Who We Hire?

Simply put, we hire everyone. MillerKnoll is comprised of people of all abilities, gender identities and expressions, ages, ethnicities, sexual orientations, veterans from every branch of military service, and more. Here, you can bring your whole self to work. We’re committed to equal opportunity employment, including veterans and people with disabilities.",USD 22K - 42K *
788,Sr. Associate Revenue Optimization Data Analyst,SAS,"Pune, India",Mid-level / Intermediate,"  Passionate people. Loyal clients. Leading solutions.
With a rich culture of creative collaboration and professional growth, IDeaS’ team members build successful careers with us.
IDeaS is proud to be a global powerhouse of innovation and excellence; challenge and reward. No matter where we’re working, our teams come together to create leading revenue management solutions that accelerate our clients’ growth through revenue optimization.
Now we just need you!
In this position you will be responsible for resolving basic client business and decision issues directly with the client via portal. You will contribute to the quality of the system forecasts and decisions, thereby to client retention.Each team member in this position must consistently demonstrate their ability to flourish in a highly pressurized team environment whilst maintaining a flexible attitude and meticulous attention to detail to the work assigned.
What you’ll be doing...
Gain a basic understanding of IDeaS products and processes in relation to the hospitality business Resolve basic Business or Decision issues for the client including questions on business practices, system configuration, system usage and monitoring Ensure portal issues, entered as cases, case activities or tasks in Salesforce are resolved accurately within pre-defined resolution timeframes and details entered in Salesforce Communicate with clients via the appropriate method Interact with and support the internal clients like Client Relationship Manager, Project Managers, Quality Assurance, Research and other teams Ensure timely identification of issues and appropriate escalations to the senior ROA member
What you’ll bring to us…
 Assist in special departmental projects Acquire Technical Skills to qualify for Sr. Associate Revenue Optimization Data Analyst certifications Execute special procedures to create structured data analysis or ad-hoc reports for IDeaS clients
We Support Who You Are….
As a global company, we strive to create an inclusive environment where diverse perspectives spark innovation and meet the challenges of an evolving world.  Whether you’re launching a new career or expanding your current one, IDeaS is a company where you can balance great work with all other aspects of your life. 
At IDeaS, we also aspire to live our values each day by being Accountable, Curious, Passionate and Authentic. And we continue our quest to build a more inclusive environment that attracts, represents and provides a place for diverse ideas, unique perspectives, and authentic voices. 
Additional Information:To qualify, applicants must be legally authorized to work in [India], and should not require, now or in the future, sponsorship for employment visa status.
SAS is an equal opportunity/Affirmative Action employer. All qualified applicants are considered for employment without regard to race, color, religion, gender, sexual orientation, gender identity, age, national origin, disability status, protected veteran status or any other characteristic protected by law. Read more: Know Your Rights. Also view the Pay Transparency notice.
Equivalent combination of education, training, and relevant experience may be considered in place of the education requirement stated above.
Resumes may be considered in the order they are received.
IDeaS/SAS employees performing certain job functions may require access to technology or software subject to export or import regulations. To comply with these regulations, IDeaS/SAS may obtain nationality or citizenship information from applicants for employment. IDeaS/SAS collects this information solely for trade law compliance purposes and does not use it to discriminate unfairly in the hiring process.",USD 67K - 110K *
789,Senior Principal - Business Intelligence Architect,GSK,Bengaluru Luxor North Tower,Senior-level / Expert,"Uniting science, technology, and talent to get ahead of disease together
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organisation where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to impact the health of 2.5 billion people around the world in the next 10 years.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a place where people feel inspired, encouraged and challenged to be the best they can be. A place where they can be themselves – feeling welcome, valued and included. Where they can keep growing and look after their wellbeing. So, if you share our ambition, join us at this exciting moment in our journey to get Ahead Together.
The position requires a highly seasoned senior business intelligence architect, with strong knowledge in the areas of Information exchange, management, delivery and consumption. The person should have led multiple projects through software development processes and performed in a variety of client facing and delivery roles in that life cycle with primary focus on Business Intelligence.
Key Responsibilities
Develop solution blueprint and architecture specification for evolving business processes which are primarily focused on business planning and goal setting.
Work with the other architects to explore specific solutions and define the scope of the project 
Serve as liaison to the business community, to ensure that its needs are fully understood by the project team. 
Review prototypes, solution blueprints, and project scope to ensure that the needs of the business are being met. 
Raise awareness of the solution and assist change management team to develop strategies around improving user adoption. 
Collaborating with end users to identify needs and opportunities for improved data management and delivery.
Work very closely with development/testing teams to ensure proper implementation.
Improving and streamlining processes regarding data flow and data quality to improve data accuracy, viability and value. 
Staying current with industry trends and advising and educating management on their relative importance and impact 
Lead and align multiple BI Engineers across use cases towards standards and policies.
The Principle BI Architect must be very experienced in defining common semantic layer, using search capabilities, be the design authority and very familiar with information consumption patterns.
Define the common semantic layer approach by trying to maximise reuse and interoperability across functions and data consumption tools like PowerBI, Spotfire, ThoughtSpot
Enable various ways of data consumption in Self-Service based on MS Azure architecture.
You must have
Balanced mix of technical and business skills with total 16+ years of experience.
Strong abilities in data analysis, visualizations, problem identification and solving.
Strategic direction – both  conforming to and helping to define 
Proficient with BI technologies (Modern BI tools like PowerBI, Thoughtspot etc.) 
Fully capable of defining and verifying OLAP strategies, frameworks etc 
Database Design with high volumes and critical performance needs 
Proficient with SQL, Report forms, consumption devices, usage analysis etc 
Ability of evaluating design options and provide recommendations.
Strong Communication and Interpersonal Skills 
Ability to instill and reinforce a strong customer service and business-oriented ethic in the entire team 
Ability to balance between data needs and requirements for action 
Strong management and leadership skills with a proactive participative management style 
Ability to work well and productively, always projecting a positive outlook in a fast-paced, sometimes stressful environment.
Nice to have –  
Enterprise Data Management 
Requirements planning, formulation and documentation.
Subject Matter Expertise in BioPharma Manufacturing and Supply chain
Tech Stack - PowerBI, Thoughtspot, Azure Cloud, Databricks, SQL, PL/SQL, Azure Analysis Services, Azure Synapse, Data Lakes, Lakehouses, Any Semantic Layer tools, Data virtualization tools, Power Automate, PowerApps
At GSK we value diversity (Gender, LGBTQ +, PwD etc.) and treat all candidates equally. We aim to create an inclusive workplace where all employees feel engaged, supportive of one another, and know their work makes an important contribution.
Why Us?
GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.
Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.
  
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.
GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKline (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.
If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in “gsk.com”, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.         
  ",USD 45K - 84K *
790,"Engineer, Data Analytics",Consilio LLC,"Bengaluru, India",Mid-level / Intermediate,"Overview
The Data Analytics Analyst must be detail oriented, possess written and verbal communication skills and exhibit problem solving skills. Analysts have an aptitude for using a variety of tools, including Relativity, Brainspace, Excel, and Consilio proprietary tools.  Analysts support internal and external clients, both by completing requested tasks and by advising on the most appropriate method to meet the client’s specific needs.
Responsibilities
Attention to detail
Thrive in a collaborative team of independent contributors
Question irregularities and investigate to validate data and outcomes
Balance independent investigation with limitations in asking for assistance
Drive to push skillset forward by learning and testing new tasks
Thrive on providing accurate and impeachable results consistently
Thrive in fast paced environment requiring status updates and communication
 Essential Responsibilities:   
Relativity Expertise:
Run Structured Analytics Sets in accordance with SOP.
Create TAR Builds and prepare for TAR models in accordance with SOP.
Create complex searches with multiple conditions accurately and without error.
Troubleshoot term errors and learn nuances of searching limitations.
Deep knowledge of dtSearch Syntax, including formatting and search limitation nuances.
Service Desk or other Ticketing System:
Utilize ticketing system to pick up, track, and complete requested tasks.
Prioritize requested tasks based on urgency, completion time, and other factors.
Communicate status updates regularly to inform internal client on request status.
Provide Analytics Support:
Understand the client’s objective and employ the appropriate analytics function.
Deploy analytics functions in relativity to support the review team from batching to QC.
Communicate results clearly and concisely to clients.
Follow cyber workflows to identify review population for cyber matters.
Complete specific tasks as requested by consulting teammates to support external clients.
Develop Analytics Expertise.
Track metrics including billing time entry and culling metrics in line with team expectations.
Qualifications
D., Paralegal Certificate, or BS in relevant field Computer Science, Information Systems, Information Retrieval Sciences, among others), or equivalent
Minimum Experience Requirements: [once finalized, this section should not be changed for job posting]
2 to 4 years.
Other Requirements:   
Extensive experience in Relativity UI
Proven work experience in the eDiscovery industry
Extensive knowledge of the Microsoft Suite
Industry certifications
Consilio’s True North Values
ExcellenceWe strive to make every client our advocate
PassionWe DO because we CARE
CollaborationWe win together through teamwork and communication
AgilityWe flex, adapt and embrace change
PeopleWe value, respect and invest in our teammates
VisionWe create clarity of purpose and a clear path forward
Consilio, LLC is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status.",USD 30K - 56K *
791,Machine Learning Specialist for Intelligent Automation,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
Collaborate with cross-functional teams, including automation developers and business analysts, to understand the requirements of Intelligent Automation projects and identify areas where Machine Learning can be leveraged.
Design and develop machine learning models and algorithms tailored to the specific needs, ensuring scalability, accuracy, and reliability.
Implement and maintain ML pipelines for data preprocessing, feature engineering, model training, evaluation, and deployment.
Perform data analysis and identify relevant data sources to extract valuable insights for enhancing automation workflows.
Conduct thorough testing and validation of ML models to ensure their robustness and accuracy in real-world scenarios.
Monitor and optimize ML models' performance, making necessary adjustments and improvements as needed.
Document all ML-related processes, code, and project details comprehensively for future reference and knowledge sharing.
Be the go-to expert for all Python-related automation development, including automation infrastructure, ensuring its smooth functioning, performance optimization, and security.
Qualifications
B.E/B.Tech
Additional Information
•    Bachelor's or Master's degree in Engineering (Preferred: Computer Science, Data Science, Machine Learning, or a related field.)
•    Proven work experience as a Machine Learning Specialist or a similar role, with 6-8 years of relevant industry experience.
•    Strong proficiency in Python programming and its associated libraries for Machine Learning, such as NumPy, Pandas, SciPy, Scikit-learn, TensorFlow, or PyTorch.
•    Hands-on experience in designing and implementing machine learning models for various applications, with a focus on natural language processing (NLP), computer vision, or predictive analytics.
•    Solid understanding of ML algorithms, statistical concepts, and data evaluation techniques.
•    Familiarity with RPA technologies and the ability to integrate ML solutions seamlessly into existing RPA workflows.
•    Strong problem-solving skills, attention to detail, and the ability to work independently or as part of a team.
•    Excellent communication skills, both verbal and written, to effectively convey technical concepts to non-technical stakeholders.
  “To know more about Bosch Global Business Services, click here”
 ",USD 45K - 84K *
792,"Senior Data Scientist (AI, ML, CV, MLOps)",HERE Technologies,"Navi Mumbai, India",Senior-level / Expert,"What's the role?
HERE is searching for a Senior/Lead Data Scientist (AI/ML) for our Foundation Engineering team. Within Foundation Engineering you would be part of the Technology Innovation Lab, a Lead Data Scientist (AI/ML):
You will develop a Tech driven innovation strategy for TIL based on the principles of design thinking.
Identify and Define relevant channels of engagement across HERE for TIL to expand the impact footprint of the business vertical
Define IP monetization strategy that will enable HERE to earn revenue /enter new market
Define startup/university engagement framework for successful collaboration with these bodies, in line with HERE’s business strategy.
Identify the domains in technology where TIL and HERE should engage and defining a strategy for realization of same through development of disruptive prototypes in line with HERE business strategy
Enabling invention of new frameworks /solutions in the domain of AIML, Blockchain, Location intelligence, distributed computing,quantum computing, tinyML, etc
Improving the innovation index of HERE, by getting research papers published in NeurIPS, IEEE, and awarded recognition in international forums like CES, Stevie ,etc
Enabling y-O-y increase in number of patents being filed by the team
Work with the Manager to Identify and Define lead KPIs related to effective assessment of performance at individual level and impact assessment of innovation implementation at business unit level
Support team to design experiments and stay up to date with industry inventions in AIML(esp Computer Vision), blockchain, quantum computing, Location Intelligence , distributed computing LiDAR and Drone processing, 3D modelling , AR/VR
Identify relevant research papers in above mentioned tech domains and enable team to design solutions for the same
Who are you?
Bachelor’s Degree in Engineering Or Master’s degree Or Phd program n Data Science, Machine Learning, Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Physics, or related fields. 
Understanding of statistical analysis of data and mathematical modeling
Knowledge of Clustering, Regression, Decision Trees, Forecasting, RandomForest, XGBoost, SVM, Deep Neural Networks (CNN, GRU, LSTM, Activation and Pooling layers), GAN, Encoders, Transformers, BERT, Graph Neural Network , diffusion models
Experience in Object Detection, Localization, Segmentation using Computer Vision and Deep Learning
Ability to handle large datasets and images of high resolution (4K) using Scala, Hadoop, Pyspark
AND/OR
Candidates with MSc/MS in Mathematics/Computer Science, Machine learning and AI or related quantitative needs 4+ yrs of experience. Candidates with PhD in related fields may have 2+ yrs of experience
The candidate should possess a certified degree in the field of quantum physics and other related fields.
Should have adequate knowledge about machine learning and artificial intelligence.
Prior experience through internships and volunteering with professionals will also be needed to apply for the quantum engineer profile.
Should possess in-depth knowledge about the emerging and simulating fields and approach challenges with unique perspectives.
The candidates should also possess a basic knowledge of the different programming language. 
What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues. 
HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.
                                                                   Make HERE your destination, we are just getting started! Apply now!
Who are we?
HERE Technologies is a location data and technology platform company. We empower our customers to achieve better outcomes – from helping a city manage its infrastructure or a business optimize its assets to guiding drivers to their destination safely.
  At HERE we take it upon ourselves to be the change we wish to see. We create solutions that fuel innovation, provide opportunity and foster inclusion to improve people’s lives. If you are inspired by an open world and driven to create positive change, join us. Learn more about us on our YouTube Channel.",USD 136K - 205K *
793,Data Analytics Manager (Data Governance),Gartner,Gurgaon - Cyber Park,Mid-level / Intermediate,"About this role:
This role will be responsible for the management of our global data stewardship team. The Data Stewardship team is tasked to establish and follow best practice data strategies and governance frameworks to ensure our enterprise customer data is accurate, complete, secure and reliable. In this leadership role you will need a passion for data quality, an eye for process improvement and the desire for continued develop of a high-performing team of data stewards.
What you’ll do:
● Lead stewardship team within the Data Strategy and Enablement function with responsibility to monitor, process, and correct data by adhering to corporate data quality standards, policies, and controls to ensure the enterprise data is accurate, complete, secure and reliable
● Monitor, publish and adjust stewardship team based on demand/need to support critical business initiatives
● Drive towards enhancing/developing automated solutions to support common stewardship tasks with the goal being more consistency, more efficiency with improved quality
● Participate in collaboration discussions for process and tool enhancements pertaining to the continued improvement of our master customer data
● Lead through example and adopt continuous improvement mindset, promoting operational excellence, and process standardization.
What you’ll need:
● Bachelor Degree preferred
● Excellent verbal and written English
● 5+ years of experience as a data steward, or similar data management function
● 3+ years with team management experience
● Experience using variety of data extraction, querying, profiling tools; Knowledge of Master Data Management desired
● Experience correlating performance results into shareable reports and dashboard for leadership level review
● Strong desire to always improve upon their/their team’s skills in stewardship effectiveness and efficiencies
● Attention to detail
● Demonstrated ability to work independently and with little direction
● Ability to work effectively on multiple projects at the same time
#LI-SA2
Who are we?
At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization’s mission-critical priorities. We’ve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.
What makes Gartner a great place to work?
Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger—as individuals, as communities and as an organization. That’s why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World’s Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner
What we offer:
Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you’ll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.
Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company’s career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.
Job Requisition ID:81355
By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.
Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",USD 110K - 155K *
794,Computer Vision Architect,Bosch Group,"Bengaluru, India",Senior-level / Expert,"Company Description
Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.
Job Description
10 to 18 years of experience in commercial software development business or with startups with market facing products or services. Must have worked on multi domain and wide range of technologies and hands-on on leading technologies. Quick learner and passionate to drive the programs through technical strengths.Engineering
Hands on coding experience
Rapidly produce well-organized, optimized, high quality and documented source code plus frameworks for the team to ramp-up
Perform Code, Design & Architecture reviews.
Translate requirements into the architecture using state of art (technologies/open-source frameworks/in-house frameworks) with very high level of completeness & accuracy.
Design & incorporate the quality aspects of the architecture/project (Re/Usability, Maintainability, Scalability, Reliability, Extensibility, Security, Portability, etc.)
Design & incorporate the non-functional quality aspects like (Throughput, Robustness, Scalability, Fault-Tolerance, etc.)
Develop & Implement V&V Strategy for functional & non-functional requirements.
Prioritize tasks & delegate to the team members, so that team members can execute the tasks independently.
Evaluate, define & evolve/improve, software coding standards, tools, and platforms.
Execute independently at team level all aspects to the Software Engineering Process (requirements, specification, architecture, design, implementation, etc.)
Debug code independently in large & complex source base
Ownership
Takes complete Ownership at Project/Program Level for both Architecture & the Deliveries for multiple projects.
Technology & Architecture
Continuously improve on architecture & design methodologies in the project
Learn new/trending/emerging languages/technologies/open-source frameworks & architectures quickly & apply to the project.
Ensure high level of software quality at project level by adapting lean yet effective state of art practices.
Contribute to the architecture for more than one domain.
Inspire team by becoming a role model via exhibiting the vigorous crave for excellence.
Leadership
Enable the team to make high-level design/architecture choices & implement them.
Lead the Team technically.
Contribute to the Technical & Business Proposals
Coordinate with the Engineering Managers/Customers/Stakeholders
Collaborate with-in Team & Represent team at various levels.
Support recruitment by evaluating architect, designing & coding skills.
Mentor the team members, give them directions, empower them with right tools/methodologies & make a cohesive work environment through Lead by Example
Define self & team level goals.
Come-up with competencies development plan for self & the team.
Present & influence the stakeholders on the Architectural decisions.
Drive the vision & mission of the Department(Choice of scaling competencies though various Learning Programs, Prototyping, Hackathons, etc.)
Mentor new/small project teams to ramp-up in-addition to the current responsibilities.
Mentor & Coach sizeable associates in the group to scale to trending technologies, state of art technologies and methodologies.
Create platform/process for distributed cross location teams to work together smoothly with highest coordination.
Organization
Come with proposals for the demonstrable technical assets in-line with the vision of Organization and current & future Bosch business.
Exhibit key USPs of the group to the prospective customers through proposals & Demos.
Represent the architectural view to the business teams & other stakeholders.
Create visibility for ERD by participating into right platforms & forums.
Secure the future of the team turning into opportunities for Follow-Up Projects, Continued Engagements, Transfer Opportunities & Supporting to the BUs
Skills –
Excellent programming & rapid prototyping skills in Python, C/C+(Optionally)
Exposure to Object Oriented Programming and Design, Data structures / Algorithms is a must.
Expertise on OpenCV, DLib, Numpy.
Excellent knowledge on any/all of the given concepts in Computer Vision - namely Image Classification, Object Detection and Semantic Segmentation developed using state of the art deep learning algorithms.
Hands on experience in developing efficient and real-time convolution neural network models.
Awareness of Machine learning concepts, hyperparameters tunning, metrics and training methods, and able to make benchmarks with other SOTA models.
Hands on working experience with anyone of the deep learning frameworks - TensorFlow, Caffe, Pytorch, Keras, MXNet, Theano.
Experience on Foundation Models especially with EVA & DINO a big plus. Well conversed with MLOps concepts (Hands on experience with mlflow a big plus)
Exposure to model compression and pruning in deep learning.
Familiarity with GPU computing (CUDA, OpenCL), HPC and and, should have hands on experience in local GPU Linux servers or cloud machine learning service providers like AWS, Azure, etc.
Strong Problem Solving & Communication skills.
Highly Motivated, Creative and a Team player.
Responsible on taking the ownership of modules/projects as well as contributing/collaborating the team with individual contributions.
Experience/exposure to usage of Open-Source technologies, State of Art models and understanding of famous model backbones.
Knowledge on containerizing the CV applications as docker or pod and REST API services for DL inference modules.
Experience of CV solution deployment on Edge (NVIDIA, etc.) would be big plus.
 Qualifications
BE/MS/ M. Tech (Electronics, Computer Science or related)
Additional Information
10-18 Years of experience",USD 45K - 84K *
795,"Senior Manager, Statistical Programming, SDTM Implementation",Bristol Myers Squibb,Hyderabad - Mindspace,Senior-level / Expert,"Working with Us
Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.
Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.
This position provides expertise to drive excellence and consistency in statistical programming SDTM implementation team.  Primarily, this position is responsible for providing strategic oversight to project deliverables and related technologies that support analysis and reporting activities.  This person will provide technical expertise, as required, to development teams and serve as a point of escalation for issues unable to be resolved at the team level. 
Position Responsibilities:
Primarily responsible for quality and timely delivery of SDTM artifacts (SDTM Specifications, datasets, define.xml, SDRG, Annotated CRF) for BMS studies
Serve as Study SDTM Programming lead for all regulatory submissions
Expertise in BMS SDTM automation tools, macros and using them for SDTM programming. Identify any inefficiencies and work with experts in up-versioning/enhancing existing tools and macros.
Thorough knowledge of CDISC standards including CDASH/SDTM/ADaM and keep abreast of latest updates in the industry.
Design/implement the SDTM specification as per the CDISC SDTM IG and ensure they meet downstream ADaM and Reporting requirements. Work with standards team to design mapping algorithms for new items.
Provide input to the design of the clinical trial database from an SDTM perspective
Annotate CRFs and Review annotated CRFs in accordance with BMS guidelines and appropriate metadata to reflect tabulation datasets
Maintain high quality of deliverables with validation and resolution of issues surfaced in Pinnacle21 and BMS Quality tools to ensure regulatory compliance.
Provide common language for repeated unresolvable validation issues across projects within a compound for inclusion in SDRG.
Collaborate with stakeholders and Study team members to manage study timelines, and resolve issues
Represent SDTM Programming function in Study team meetings as well as cross-functional working groups.
Support and identify areas for automation & innovation as process enhancements to improve quality of work and efficiencies
Provide oversight of CRO/vendor programming activities to ensure adherence of standards as well as receiving quality and timely deliverables
Participate in study/project team meetings as a core member and provide technical expertise/support.
Degree and Experience requirements:
  BA/BS in a relevant scientific discipline with more than 7 plus years Pharmaceutical/CRO experience as a SAS Programmer supporting clinical trials for regulatory submissions with expertise in CDSIC/SDTM.
If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.
Uniquely Interesting Work, Life-changing Careers
With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.
On-site Protocol
Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.
BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.
BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.
BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.
Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",USD 45K - 84K *
796,"Staff Data Scientist (7Yrs to 9Yrs, TensorFlow , Python , Bigdata)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Payments are a very exciting and fast-developing area with a lot of new and innovative ideas coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation. VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area. 
If you want to be in the exciting payment space, learn fast and make big impacts, Ecosystem & Operation Risk technology which is part of Visa’s Value-Added Services business unit is an ideal place for you! 
In Ecosystem & Operation Risk group, Payment Fraud Disruption team is responsible for building critical risk and fraud detection and prevention applications and services at Visa. This includes idea generation, architecture, design, development, and testing of products, applications, and services that provide Visa clients with solutions to detect, prevent, and mitigate fraud for Visa and Visa client payment systems. 
This position is ideal for an experienced data scientist who is passionate about collaborating with business and technology partners in solving challenging fraud prevention problems. You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa’s payment systems.  
The right candidate will possess strong ML and Data Science background, with demonstrated experience in building, training, implementing and optimized advanced AI models for payments, risk or fraud prevention products that created business value and delivered impact within the payments or payments risk domain or have experience building AI/ML solutions for similar industries.  
A successful candidate is a technical leader with the ability to engage in high bandwidth conversations with business and technology partners and be able to think broadly about Visa’s business and drive solutions that will enhance the safety and integrity of Visa’s payment ecosystem. The candidate will help deliver innovative insights to Visa's strategic products and business. This role represents an exciting opportunity to make key contributions to strategic offering for Visa. This candidate needs to have strong academic track record and be able to demonstrate excellent software engineering skills. The candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and excellent collaboration skills. 
The ideal candidate will bring the excitement and passion to leverage Generative AI to advance existing fraud detection mechanisms and to innovate and solve new fraud use cases. This engineer will use code generation capabilities like GitHub copilot to drive efficiencies in software development. 
 Essential Functions 
As a Data Scientist you will help design, enhance, and build next generation fraud detection solutions in an agile development environment. 
Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product stakeholders.  
Work with software engineers to ensure feasibility of solutions. Deliver prototypes and production code based on need. 
Experiment with in-house and third-party data sets to test hypotheses on relevance and value of data to business problems. 
Build needed data transformations on structured and un-structured data. 
Build and experiment with modeling and scoring algorithms. This includes development of custom algorithms as well as use of packaged tools based on machine learning, data mining and statistical techniques. 
Devise and implement methods for adaptive learning with controls on effectiveness, methods for explaining model decisions where necessary, model validation, A/B testing of models. 
Devise and implement methods for efficiently monitoring model effectiveness and performance in production. 
Devise and implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production. 
Contribute to development and adoption of shared predictive analytics infrastructure.  
Mentor and train other data scientists on the team on key solutions 
Able to work on multiple projects and initiatives with different/competing timelines and demands. 
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner 
Collaborate across engineering teams and leaders in Ecosystem& Operational Risk, Visa Research, AI Platform, Operations, and Infrastructure (O&I), security and platform teams. 
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
Qualifications
Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Relevant coursework in modeling techniques such as logistic regression, Naïve Bayes, SVM, decision trees, or neural networks
Expert in leading-edge areas such as Machine Learning, Deep Learning, Stream Computing and MLOps
Ability to program in one or more scripting languages such as Perl or Python and programming languages such as Java or Scala
Excellent understanding of algorithms and data structures.
Excellent analytic and problem-solving capability combined with ambition to solve real-world problems
Excellent interpersonal, facilitation, and effective communication skills (both written and verbal) and the ability to present complex ideas in a clear, concise way
Have great work ethics, and be a team player striving to bring the best results as a team
High level of competence in Python, Scala, and Unix/Linux scripts
Extensive experience with SAS/SQL/Hive for extracting and aggregating data
Experience working with large datasets using tools like Pig or Hive is a plus
Experience with Big Data and analytics leveraging technologies like Hadoop, Spark, Scala, and MapReduce
Deep learning experience working with TensorFlow is necessary
Experience with Natural Language Processing is necessary
Passionate about delivering zero defect code that meet or exceed the proposed defect SLA and have high sense of accountability for quality and timeliness of one’s own deliverables and team deliverables
Be systematic and be able to do deep research wanting to uncover the details
Have good work ethics, and be a team player to bring the best results as a team
You have the passion to understand people and always strive to improve our products
Highly driven, resourceful and results oriented
Demonstrated ability to lead and navigate through ambiguity
While you'll have the skill to see and understand the big picture, you're able to stay focused on the task at hand to achieve immediate goals

Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science, Operations Research, Statistics, or highly quantitative field (or equivalent experience) with strength in Deep Learning, Machine Learning, Data Mining, Statistical or other mathematical analysis
Real world experience using Hadoop and the related query engines (Hive / Impala)
Experience with one or more common statistical tools such SAS, R, KNIME, Matlab
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences is a plus
Experience with data visualization and business intelligence tools like Tableau
Modeling experience in card industry or financial service company using for fraud, credit risk, payments is plus
Proficiency in designing & solving classification/prediction problems using open-source libraries such as Scikit learn
Experience in developing large scale, enterprise class distributed systems of high availability, low latency, & strong data consistency
Experience developing instrumentation for software components, to help facilitate real-time and remote troubleshooting/performance monitoring
Experience in architecting solutions with Continuous Integration and Continuous Delivery in mind
Familiarity with in distributed in-memory computing technologies
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 136K - 205K *
797,Lead ML & AI Engineer,HERE Technologies,"Navi Mumbai, India",Senior-level / Expert,"What's the role?
What's the role? 
HERE is searching for a Lead Data Scientist (AI/ML) for our Foundation Engineering team. Within Foundation Engineering you would be part of the Technology Innovation Lab, a Lead Data Scientist (AI/ML):
You will develop a Tech driven innovation strategy for TIL based on the principles of design thinking.
Identify and Define relevant channels of engagement across HERE for TIL to expand the impact footprint of the business vertical
Define IP monetization strategy that will enable HERE to earn revenue /enter new market
Define startup/university engagement framework for successful collaboration with these bodies, in line with HERE’s business strategy.
Identify the domains in technology where TIL and HERE should engage and defining a strategy for realization of same through development of disruptive prototypes in line with HERE business strategy
Enabling invention of new frameworks /solutions in the domain of AIML, Blockchain, Location intelligence, distributed computing,quantum computing, tinyML, etc
Improving the innovation index of HERE, by getting research papers published in NeurIPS, IEEE, and awarded recognition in international forums like CES, Stevie ,etc
Enabling y-O-y increase in number of patents being filed by the team
Work with the Manager to Identify and Define lead KPIs related to effective assessment of performance at individual level and impact assessment of innovation implementation at business unit level
Support team to design experiments and stay up to date with industry inventions in AIML(esp Computer Vision), blockchain, quantum computing, Location Intelligence , distributed computing LiDAR and Drone processing, 3D modelling , AR/VR
Identify relevant research papers in above mentioned tech domains and enable team to design solutions for the same
Who are you?
Bachelor’s Degree in Engineering Or Master’s degree Or Phd program n Data Science, Machine Learning, Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Physics, or related fields. 
Understanding of statistical analysis of data and mathematical modeling
Knowledge of Clustering, Regression, Decision Trees, Forecasting, RandomForest, XGBoost, SVM, Deep Neural Networks (CNN, GRU, LSTM, Activation and Pooling layers), GAN, Encoders, Transformers, BERT, Graph Neural Network , diffusion models
Experience in Object Detection, Localization, Segmentation using Computer Vision and Deep Learning
Ability to handle large datasets and images of high resolution (4K) using Scala, Hadoop, Pyspark
AND/OR
Candidates with MSc/MS in Mathematics/Computer Science, Machine learning and AI or related quantitative needs 10yrs of experience. Candidates with PhD in related fields may have 5 yrs of experience
The candidate should possess a certified degree in the field of quantum physics and other related fields.
Should have adequate knowledge about machine learning and artificial intelligence.
Prior experience through internships and volunteering with professionals will also be needed to apply for the quantum engineer profile.
Should possess in-depth knowledge about the emerging and simulating fields and approach challenges with unique perspectives.
The candidates should also possess a basic knowledge of the different programming language. 
What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues. 
Who are you?
HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.
Who are we?
HERE Technologies is a location data and technology platform company. We empower our customers to achieve better outcomes – from helping a city manage its infrastructure or a business optimize its assets to guiding drivers to their destination safely.
  At HERE we take it upon ourselves to be the change we wish to see. We create solutions that fuel innovation, provide opportunity and foster inclusion to improve people’s lives. If you are inspired by an open world and driven to create positive change, join us. Learn more about us on our YouTube Channel.",USD 129K - 223K *
798,"Data Scientist - Sr. Consultant level ( 9Yrs to 11yrs, TensorFlow , Python,R , Bigdata)",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Payments are a very exciting and fast-developing area with a lot of new and innovative ideas coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation. VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area. 
If you want to be in the exciting payment space, learn fast and make big impacts, Ecosystem & Operation Risk technology which is part of Visa’s Value-Added Services business unit is an ideal place for you! 
In Ecosystem & Operation Risk group, Payment Fraud Disruption team is responsible for building critical risk and fraud detection and prevention applications and services at Visa. This includes idea generation, architecture, design, development, and testing of products, applications, and services that provide Visa clients with solutions to detect, prevent, and mitigate fraud for Visa and Visa client payment systems. 
This position is ideal for an experienced data scientist who is passionate about collaborating with business and technology partners in solving challenging fraud prevention problems. You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa’s payment systems.  
 This position is ideal for an experienced data scientist who is passionate about collaborating with business and technology partners in solving challenging fraud prevention problems. You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa’s payment systems.  
The right candidate will possess strong ML and Data Science background, with demonstrated experience in building, training, implementing and optimized advanced AI models for payments, risk or fraud prevention products that created business value and delivered impact within the payments or payments risk domain or have experience building AI/ML solutions for similar industries.  
A successful candidate is a technical leader with the ability to engage in high bandwidth conversations with business and technology partners and be able to think broadly about Visa’s business and drive solutions that will enhance the safety and integrity of Visa’s payment ecosystem. The candidate will help deliver innovative insights to Visa's strategic products and business. This role represents an exciting opportunity to make key contributions to strategic offering for Visa. This candidate needs to have strong academic track record and be able to demonstrate excellent software engineering skills. The candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and excellent collaboration skills. 
The ideal candidate will bring the excitement and passion to leverage Generative AI to advance existing fraud detection mechanisms and to innovate and solve new fraud use cases. This engineer will use code generation capabilities like GitHub copilot to drive efficiencies in software development. 
 Essential Functions 
As a Data Scientist - Sr. Consultant  you will help design, enhance, and build next generation fraud detection solutions in an agile development environment. 
Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product stakeholders.  
Work with software engineers to ensure feasibility of solutions. Deliver prototypes and production code based on need. 
Experiment with in-house and third-party data sets to test hypotheses on relevance and value of data to business problems. 
Build needed data transformations on structured and un-structured data. 
Build and experiment with modeling and scoring algorithms. This includes development of custom algorithms as well as use of packaged tools based on machine learning, data mining and statistical techniques. 
Devise and implement methods for adaptive learning with controls on effectiveness, methods for explaining model decisions where necessary, model validation, A/B testing of models. 
Devise and implement methods for efficiently monitoring model effectiveness and performance in production. 
Devise and implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production. 
Contribute to development and adoption of shared predictive analytics infrastructure.  
Mentor and train other data scientists on the team on key solutions 
Able to work on multiple projects and initiatives with different/competing timelines and demands. 
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner 
Collaborate across engineering teams and leaders in Ecosystem& Operational Risk, Visa Research, AI Platform, Operations, and Infrastructure (O&I), security and platform teams. 
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office three days a week, Tuesdays, Wednesdays, and Thursdays with a general guidepost of being in the office 50% of the time based on business needs. 
Qualifications
Basic Qualifications:
8+ years of relevant work experience with a Bachelor’s Degree or at least 5 years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 2 years of work experience with a PhD, OR 11+ years of relevant work experience.
Major in Computer Science, Operations Research, Statistics, or highly quantitative field (or equivalent experience) with strength in Deep Learning, Machine Learning, Data Mining, Statistical or other mathematical analysis
Relevant coursework in modeling techniques such as logistic regression, Naïve Bayes, SVM, decision trees, or neural networks
Expert in leading-edge areas such as Machine Learning, Deep Learning, Stream Computing and MLOps
Ability to program in one or more scripting languages such as Perl or Python and programming languages such as Java or Scala
Excellent understanding of algorithms and data structures.
Excellent analytic and problem-solving capability combined with ambition to solve real-world problems
Excellent interpersonal, facilitation, and effective communication skills (both written and verbal) and the ability to present complex ideas in a clear, concise way
Have great work ethics, and be a team player striving to bring the best results as a team
High level of competence in Python, Scala, and Unix/Linux scripts
Extensive experience with SAS/SQL/Hive for extracting and aggregating data
Experience working with large datasets using tools like Pig or Hive is a plus
Experience with Big Data and analytics leveraging technologies like Hadoop, Spark, Scala, and MapReduce
Deep learning experience working with TensorFlow is necessary
Experience with Natural Language Processing is necessary



Preferred Qualifications:
9 or more years of relevant work experience with a Bachelor Degree or 7 or more relevant years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 3 or more years of experience with a PhD
PhD degree in Computer Science or related field and 10+ years of Machine Learning System Development Experience after PhD
Real world experience using Hadoop and the related query engines (Hive / Impala)
Experience with one or more common statistical tools such SAS, R, KNIME, Matlab
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences is a plus
Experience with data visualization and business intelligence tools like Tableau
Modeling experience in card industry or financial service company using for fraud, credit risk, payments is plus
Proficiency in designing & solving classification/prediction problems using open-source libraries such as Scikit learn
Experience in developing large scale, enterprise class distributed systems of high availability, low latency, & strong data consistency
Experience developing instrumentation for software components, to help facilitate real-time and remote troubleshooting/performance monitoring
Experience in architecting solutions with Continuous Integration and Continuous Delivery in mind
Familiarity with in distributed in-memory computing technologies
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 136K - 205K *
799,Lead Data Modeler,Salesforce,India - Hyderabad,Senior-level / Expert,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
Overview of the Role:
The Senior Data Modeler role is a part of Salesforce’s Tech and Product (T&P) Data Modeling Team. The Data Modeling team, a part of the Salesforce Technology organization, works with product owners, software engineers, architects and others to ensure that Salesforce delivers the data model and software that is expected of the #1 AI+Data+CRM.
The Senior Data Modeler will be joining a world-class data modeling team with a real passion for well-architected enterprise software that delivers unparalleled customer success. You will work on Salesforce standard data models for our “horizontal” applications (e.g. sales, service, marketing) as well as our fast-growing industry-specific apps, helping to shape the structure of data across a much broader range of subject areas than most data modelers see in their careers. You will also contribute to our canonical data model that is the standard data model for Data Cloud. Salesforce is leading the way to bring AI, data, automation and deep industry-specific functionality to our customers. Join our high performance culture of trust, collaboration, transparency, continuous improvement and making work fun!
Responsibilities:
Success will be measured by the individual’s ability to deliver, and help others deliver, well-architected data models at a steady pace of innovation.
* Co-design data models with Salesforce product teams for OLTP, OLAP and AI.
* Design, develop, test and publish canonical data models for Data Cloud.
* Work to improve the data modeling design skills of the product team members who we work with.
* Identify overlapping data model requirements across multiple product teams and influence the combined data model design to consensus and consistency.
* Perform essential steps in the data model oversight process such as ensuring that data model requests have the right information captured and are routed to the right people.
* Assist in continuous improvement of Salesforce’s processes, methods and tooling to improve our efficiency and effectiveness.
* Assist in creating data model documentation and collateral so that the Salesforce ecosystem is enabled to understand and properly adopt the Salesforce data model.
Required Qualifications: 
* 10+ years of demonstrated, hands-on data modeling and enterprise software design experience in multiple industries for OLTP (relational) and analytical systems
* Good knowledge of data modeling principles and best practices including a good understanding of canonical data modeling concepts
* Ability to quickly grasp technological and business concepts
* Strong verbal and written communication skills; experience communicating with engineers, architects. software professionals and product management to succinctly explain technical and functional concepts
* Experience with the full software lifecycle delivering enterprise software products or large-company enterprise information technology projects
* Experience and desire to work within a fast-paced environment with short release cycles and an iterative development methodology
* Able to work on multiple projects/products simultaneously and comfortable working with minimal specifications
* Technical degree or equivalent relevant experience required. Experience will be evaluated based on the core competencies for the role (e.g. extracurricular leadership roles, military experience, volunteer roles, work experience, etc.)
Preferred Qualifications: 
* Experience across a variety of business processes and industries; especially communications, media, energy, utilities, financial services, health, manufacturing, consumer packaged goods, retail, non-profit, education, public sector and sustainability
* Strong, hands-on knowledge of SQL (or Salesforce SOQL) including performance tuning
* Strong knowledge of Salesforce product and platform features, capabilities, and the best use of them
* Good understanding of enterprise architecture principles
* Experience with Agile development methodologies
* Knowledge of modern, non-relational databases (e.g. No-SQL databases, Graph databases, etc.), data lakes, data warehouses, AI pipelines or similar.
* Experience with data modeling tools, processes, BI tools, reporting software and data analysis and data analytics
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.
Salesforce welcomes all.",USD 100K - 160K *
800,Senior Data Analyst,Innovaccer,"Noida, Uttar Pradesh, India",Senior-level / Expert,"Your Role
We are looking for a Senior-Data Analyst to help our customers to migrate to the latest architecture at Innovaccer so that customers can get all the latest upgrades and features from the platform which will improve overall customer satisfaction and platform efficiency. You are expected to lead, manage and run migration projects.

A Day in the Life
Guide and mentor the team in best practices for handling Migration projects for the next 6-9 months
Review and provide feedback before the deliverables are shared with the customer
Work on customer migration projects keeping track of progress
Create a report/tracking process to track the overall progress of the migration and manage Data engineers in daily work
Work on automation or identify the potential automaton use cases which will help the team to work efficiently
Define and document best practices along with thorough message specifications
Monitor and tune the process of migration for high efficiency during the migration process
Drive the daily meetings highlighting dependencies and work across teams which includes platform developers, projects data engineers and program managers

What You Need
4+ years in an analytics role in data services/product firm
Data modeling ability - knowledge of different data modeling concepts
Previous experience in working on migration projects especially the workflow/pipelines migrations
Strong knowledge of SQL (Postgres and Snowflake is a must), scripting languages (Groovy/JavaScript/Python)
Exposure to Python Libraries - Numpy, Scipy, Scikit-Learn
Self-starter, curious, accountable, enjoys a healthy level of autonomy, strong work ethic, able to succeed in a fast-paced, high-intensity start up environment
Extensive experience relaying technical and non-technical information in a clear and concise manner
Demonstrated expert problem solving and analytical skills
Excellence in multitasking and managing multiple high-priority customer engagements at once
Ability to assess complex client environments and workflows and arrive at integration solutions that will satisfy seamless experience between our platform and theirs
Competence to mentor junior team members and introduce industry expertise and best practices across integration development
Bachelor’s degree in Engineering, Computer Science. Advanced degree in any of the areas above would be a plus
  What We Offer
Industry-Focused Certifications: Meet leading healthcare experts, discuss innovative strategies, and become a subject matter expert with our comprehensive set of certifications
Rewards and Recognition: Feeling like you’re outperforming on your projects? Get recognition for your dedicated efforts and demonstrated work ethic
Health Insurance and Mental Well-being: We offer health benefits and insurance to you and your family for hospital-related expenses pertaining to any illness, disease, or injury. We also have Employee Assistance Programs (EAPs) to give you 24X7 access to certified therapists and psychologists
Sabbatical Leave Policy: Do you want to focus on skill development, pursue an academic career, or just reset? We’ve got you covered
Open Floor Plan: Cubicles are a thing of the past and to modernize our office space, we have open floor sittings at every office location. Share ideas with your peers and bond better in an open floor office where there are no barriers and you are inspired to be creative
Paternity and Maternity Leave: Enjoy the industry’s best parental leave policy to welcome your bundle of joy and enjoy quality time with them
Paid Time Off: Maintain a healthy work–life balance and take time off from work to focus on your well-being and big life moments",USD 92K - 145K *
801,Gen AI Architect,CloudMoyo,"Pune, India",Senior-level / Expert,"Company Description
CloudMoyo is the partner of choice for solutions at the intersection of cloud, analytics, and AI. As a leading cloud and analytics partner for Microsoft, we bring together powerful business intelligence (BI) capabilities using the Azure data platform to help modern enterprises define their path to the cloud, transform complex data into actionable insights, and modernize their data landscape. Headquartered in Bellevue, WA, with an innovation center in Pune, India, and a presence in Kansas City, CloudMoyo is poised to help intelligent enterprises build innovative solutions and stay ahead in the disruption cycle. Our proven track record includes developing enterprise solutions for Fortune 1000 companies such as Microsoft and Kansas City Southern. 
Here at CloudMoyo, we are driven by our values of FORTE, which stands for Fairness, Openness, Respect, Teamwork, and Execution. We strongly believe that our expertise is founded on the efforts of our employees, who reflect our FORTE values in their work. Our workplace culture is driven by unshakable commitment to building a world-class workplace for all employees, one characterized by meaningful interactions, flat hierarchy, challenging assignments, opportunities to grow with the best in the field, and exciting rewards and benefits. We work hard and play hard, and this is an integral part of our culture—which means we love any excuse to celebrate anniversaries, go-lives, new customers, and holidays and festivals. If you’re a talented, hard-working, and fun-loving person looking to grow in this role, then CloudMoyo may be a great fit for your next professional adventure. You can learn more about our culture and life at CloudMoyo here.
Job Description
JD :
Strong understanding of AI/ML concepts and techniques
Proficiency in programming languages such as Python, JavaScipt, with hands on experience in AI/ML libraries and frameworks
Experience with AI/ML model lifecycle activities, like data preprocessing, feature engineering, deployment, data visualization, etc
Good understanding on model deployment, design, architecture, AIOps, MLOps, etc
Good to have experience with Generative AI and Large Language Models
Design and develop generative Al models and algorithms using state-of-the-art techniques such as GPT, VAE, and GANs
Manage project infrastructure and the development of AI models and projects
Lead the development of generative Al solutions from concept to production.
Interface with customer for understanding requirements.
Should be able to quickly develop POC project(s) or develop prototype
Collaborate with cross-functional teams to define Al project requirements and objectives, ensuring alignment with overall business goals.
Evaluate the performance of generative Al models and make necessary adjustments.
Hands on experience in developing Rest Ful services is required.
Good understanding of RAG
Good familiarity with one or more cloud platforms / hyper-scalers (eg, GCP, Azure, AWS, NVIDIA) and experience in deploying AI/ML models in cloud environments.
Experience of architecting AI/ML systems as well as integrating AI/ML features into business applications and solutions
Document and maintain generative Al code and models.
Strong analytical and problem-solving skills, with the ability to analyze complex datasets and extract actionable insights.
Knowledge of software development practices, version control systems (eg, Git), and agile methodologies
Excellent communication and collaboration skills to work effectively in cross-functional teams.
Should be able to communicate architecture decisions effectively to multiple stakeholders including presenting to client Architecture Review Boards (ARBs)
Strong organizational, leadership and time management skills, with the ability to prioritize and manage multiple projects simultaneously.
Additional Information
Benefits and perks
Comprehensive healthcare (including dental and vision)
Disability insurance
Paid maternity leave
Offsite travel opportunities
Flexible work hours
Benefits and job perks mentioned above may vary depending on your employment type with CloudMoyo and the country in which you are working.",USD 204K - 330K *
802,"Sr. Systems Engineer - SQL, Shell, ETL Admin, Python",Visa,"Bengaluru, India",Senior-level / Expert,"Company Description
Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.
Job Description
Job Duties and Responsibilities: 
Monitor and manage Windows/Linux Servers and operations across environments
Resolve ETL & Data Warehouse job related issues 
Work with development team on production defects fixes 
Building CI/CD pipelines and managing them
Maintain/improve production operations SLA 
 This position will be based in Bangalore, India and will be reporting to Senior Engineering Manager. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.
 This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.
 Qualifications
Basic Qualification

2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experience

Preferred Qualifications

Skills, Experience and Requirements: 

2+ years of experience in production operations on large Enterprise Data Warehouse
Hands on working knowledge in Data Warehouse Environment and proficient in SQL Queries & Python
Good hands on experience in Unix operating system and shell scripting 
Troubleshooting of ETL jobs and addressing production issue 
Experience in Talend Admin, Jenkins(CI/CD) and Hadoop ecosystem 
Good Communication skills – written and verbal with the ability to understand and interact with the diverse range of stakeholders 
Candidate should be able to work without much supervision
The ability to tackle challenges and address problems head-on
Stay on top of the open source technology and be ready to learn/adopt new technology continuously
Highly driven, resourceful and results oriented
Good team player and excellent interpersonal skills
Good analytical and problem-solving skills
Demonstrated ability to lead and navigate through ambiguity
Additional Information
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.",USD 45K - 84K *
803,Marketing Data Analyst,Whatfix,"Bengaluru, Karnataka, India",Mid-level / Intermediate,"Location: Bengaluru,Karnataka,India
Who are we?
Whatfix is a data-driven digital adoption platform (DAP) that enables organizations and users to maximize the benefits of software. Whatfix acts as an interactive overlay on top of any application to guide users with real-time guidance, self-help support, and user feedback. With product analytics and AI, Whatfix enables scalable success with technology, maximizing productivity, and leveraging data-driven insights for better decision-making. The company has seven offices globally in the US, India, UK, Germany, Singapore, and Australia, and works with Fortune 500 companies around the world. Whatfix has raised $140 million to date and is backed by marquee investors including Softbank, Sequoia, Dragoneer, and Cisco Investments. 
“Hustle Mode ON” is the motto we live by. 
Whatfix has been named among the top 20 B2B tech companies like Adobe, PayPal, and Cisco.
With YoY revenue growth of over 65%, we have also been recognized among the top 20 fastest-growing SaaS companies worldwide in the SaaS 1000 list.
Recognized by Forrester and Everest Group as a 'Leader' in the digital adoption space, and listed by LinkedIn among one of the Top 5 startups in India in 2020
Listed in Deloitte Technology Fast 500™ among fastest-growing companies in North America for 2022 and 2021 and recognized as Great Place to Work 2022-2023
Our Customer centricity is evident from a Customer rating of 4.67 on G2 Crowd & 4.7 on Gartner Peer Insights
 What you'll get to do?
Evaluate the impact of various marketing programs across channels in achieving key objectives including impact on net new leads, lead conversions and opportunities
Develop, own and maintain dashboards and reporting tools to track the effectiveness of marketing campaigns and efficiency improvement over time
Understand the different digital marketing channels and apply this knowledge to define success programs strategy
Perform ongoing analysis of digital marketing performance to inform strategy and in-market optimization decisions
Understand business challenges, KPIs that need to be improved and metrics driving the business
Work closely with the Marketing and Engineering teams to analyze traffic patterns, report behaviour, anomalies and trends and provide actionable insights to the stakeholders
Understand and master user journey funnels to maximize the value of overall traffic generated across channels and properties
Work with marketing leadership to build yearly and quarterly plans and set targets for individual teams across the marketing team
Continuously scout and identify new products and tools that can help in improving marketing data analysis, reporting and testing capabilities
Understand and suggest key improvements across the marketing funnel to ensure a highly optimized state at all times
Show up as a strategic partner and subject matter expert to help shape goals and success metrics
Work closely with Sales Operations team to ensure data reporting is even and consistent at all times
Work closely with the Finance team to build/maintain SaaS metrics for the marketing and pre-sales team
What you should have?
2+ years of experience focused on data analysis, quantitative analysis and business reasoning
Bachelor’s degree in a technical or business field
Expert in data mining concepts, business intelligence, trends, and forecasting
Ability to work independently, proactively, and with ambiguity prioritizing marketing efforts while ensuring processes are followed and projects are completed on time
High level for attention to detail and being able to identify process improvements both subjectively and objectively
Strong presentation skills, especially related to building compelling presentations
Experience with Pardot/Marketo, Salesforce/HubSpot, Google Analytics, Google Data Studio, Outreach/SalesLoft
Perks & Benefits (India) 
Best-in-class medical insurance coverage
Free lunch & dinner buffet 
Doorstep cab drop facility 
Education Sponsorship 
Internal job transfer & global mobility programs 
Scope to represent Whatfix at global events
We also provide uncapped incentives, bonus plans and opportunities to employees (especially those in GTM teams) to travel to meet our global customers
Please Note: 
We are an equal opportunity employer and value diverse people because of and not in spite of the differences. We do not discriminate on the basis of race, religion, colour, national origin, ethnicity, gender, sexual orientation, age, marital status, veteran status, or disability status
We are an equal opportunity employer and value diverse people because of and not in spite of the differences. We do not discriminate on the basis of race, religion, color, national origin, ethnicity, gender, sexual orientation, age, marital status, veteran status, or disability status.
Apply to this job",USD 30K - 56K *
